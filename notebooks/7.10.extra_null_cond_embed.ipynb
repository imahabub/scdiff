{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnyang\u001b[0m (\u001b[33mprotein-optimization\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Mounts/rbg-storage1/users/johnyang/cellot/notebooks/wandb/run-20230710_210258-ien9czxs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/protein-optimization/cellot-notebooks/runs/ien9czxs' target=\"_blank\">dulcet-cosmos-13</a></strong> to <a href='https://wandb.ai/protein-optimization/cellot-notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/protein-optimization/cellot-notebooks' target=\"_blank\">https://wandb.ai/protein-optimization/cellot-notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/protein-optimization/cellot-notebooks/runs/ien9czxs' target=\"_blank\">https://wandb.ai/protein-optimization/cellot-notebooks/runs/ien9czxs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-ylwt16su:v59, 96.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.2\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('protein-optimization/sc_diff/model-ylwt16su:v59', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./artifacts/model-ylwt16su:v59'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellot.models.cond_score_module import CondScoreModuleV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f'{artifact_dir}/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_STR = '''\n",
    "DEBUG: False\n",
    "TARGET: trametinib\n",
    "LATENT_DIM: 50\n",
    "COND_CLASSES: 190\n",
    "SEED: 42\n",
    "AE_PATH: /Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/full_ae\n",
    "VAL_SIZE: 0.1\n",
    "DEVICES: 1\n",
    "WARM_START: False\n",
    "WARM_START_PATH: null\n",
    "MODEL_CLASS: CondScoreModule\n",
    "\n",
    "\n",
    "diffuser:\n",
    "  min_b: 0.01\n",
    "  max_b: 1.0\n",
    "  schedule: exponential\n",
    "  score_scaling: var\n",
    "  coordinate_scaling: 1.0\n",
    "  latent_dim: ${LATENT_DIM}\n",
    "  dt: 0.01\n",
    "  min_t: 0\n",
    "\n",
    "ae:\n",
    "  name: scgen\n",
    "  beta: 0.0\n",
    "  dropout: 0.0\n",
    "  hidden_units: [512, 512]\n",
    "  latent_dim: 50\n",
    "\n",
    "score_network:\n",
    "  latent_dim: ${LATENT_DIM}\n",
    "  cond_classes: ${COND_CLASSES}\n",
    "  model_dim: 256   # Adjusted to 64\n",
    "  n_layers: 6    # Adjusted to 12\n",
    "  nhead: 8\n",
    "  dim_feedforward: 2048\n",
    "  dropout: 0.1\n",
    "  ffn_hidden_dim: 1024\n",
    "  extra_null_cond_embedding: False\n",
    "\n",
    "\n",
    "data:\n",
    "  type: cell\n",
    "  source: control\n",
    "  condition: drug\n",
    "  path: /Mounts/rbg-storage1/users/johnyang/cellot/datasets/scrna-sciplex3/hvg.h5ad\n",
    "  target: ${TARGET}\n",
    "\n",
    "datasplit:\n",
    "  groupby: drug   \n",
    "  name: train_test\n",
    "  test_size: 0.2\n",
    "  random_state: 0\n",
    "  \n",
    "dataloader:\n",
    "  batch_size: 256   # Adjusted to 256\n",
    "  shuffle: true\n",
    "  num_workers: 80\n",
    "  \n",
    "experiment:\n",
    "  name: base\n",
    "  mode: train\n",
    "  num_loader_workers: 0\n",
    "  port: 12319\n",
    "  dist_mode: single\n",
    "  use_wandb: True\n",
    "  ckpt_path: null\n",
    "  wandb_logger:\n",
    "    project: sc_diff\n",
    "    name: ${experiment.name}\n",
    "    dir: /Mounts/rbg-storage1/users/johnyang/cellot/\n",
    "    log_model: all\n",
    "    tags: ['experimental']\n",
    "  lr: 0.0001\n",
    "\n",
    "\n",
    "trainer:\n",
    "  accelerator: 'gpu'\n",
    "  check_val_every_n_epoch: 50\n",
    "  log_every_n_steps: 100\n",
    "  num_sanity_val_steps: 1\n",
    "  enable_progress_bar: True\n",
    "  enable_checkpointing: True\n",
    "  fast_dev_run: False\n",
    "  profiler: simple\n",
    "  max_epochs: 10000\n",
    "  strategy: auto\n",
    "  enable_model_summary: True\n",
    "  overfit_batches: 0.0\n",
    "  limit_train_batches: 1.0\n",
    "  limit_val_batches: 1.0\n",
    "  limit_predict_batches: 1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "config = OmegaConf.create(YAML_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f'{artifact_dir}/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "from cellot.train.utils import get_free_gpu\n",
    "replica_id = int(get_free_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = f'cuda:{replica_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEBUG': False, 'TARGET': 'trametinib', 'LATENT_DIM': 50, 'COND_CLASSES': 190, 'SEED': 42, 'AE_PATH': '/Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/full_ae', 'VAL_SIZE': 0.1, 'DEVICES': 1, 'WARM_START': False, 'WARM_START_PATH': None, 'MODEL_CLASS': 'CondScoreModule', 'diffuser': {'min_b': 0.01, 'max_b': 1.0, 'schedule': 'exponential', 'score_scaling': 'var', 'coordinate_scaling': 1.0, 'latent_dim': '${LATENT_DIM}', 'dt': 0.01, 'min_t': 0}, 'ae': {'name': 'scgen', 'beta': 0.0, 'dropout': 0.0, 'hidden_units': [512, 512], 'latent_dim': 50}, 'score_network': {'latent_dim': '${LATENT_DIM}', 'cond_classes': '${COND_CLASSES}', 'model_dim': 256, 'n_layers': 6, 'nhead': 8, 'dim_feedforward': 2048, 'dropout': 0.1, 'ffn_hidden_dim': 1024, 'extra_null_cond_embedding': False}, 'data': {'type': 'cell', 'source': 'control', 'condition': 'drug', 'path': '/Mounts/rbg-storage1/users/johnyang/cellot/datasets/scrna-sciplex3/hvg.h5ad', 'target': '${TARGET}'}, 'datasplit': {'groupby': 'drug', 'name': 'train_test', 'test_size': 0.2, 'random_state': 0}, 'dataloader': {'batch_size': 256, 'shuffle': True, 'num_workers': 80}, 'experiment': {'name': 'base', 'mode': 'train', 'num_loader_workers': 0, 'port': 12319, 'dist_mode': 'single', 'use_wandb': True, 'ckpt_path': None, 'wandb_logger': {'project': 'sc_diff', 'name': '${experiment.name}', 'dir': '/Mounts/rbg-storage1/users/johnyang/cellot/', 'log_model': 'all', 'tags': ['experimental']}, 'lr': 0.0001}, 'trainer': {'accelerator': 'gpu', 'check_val_every_n_epoch': 50, 'log_every_n_steps': 100, 'num_sanity_val_steps': 1, 'enable_progress_bar': True, 'enable_checkpointing': True, 'fast_dev_run': False, 'profiler': 'simple', 'max_epochs': 10000, 'strategy': 'auto', 'enable_model_summary': True, 'overfit_batches': 0.0, 'limit_train_batches': 1.0, 'limit_val_batches': 1.0, 'limit_predict_batches': 1.0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout is 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm = CondScoreModuleV2.load_from_checkpoint(hparams=config, checkpoint_path=ckpt_path).to(device)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import cellot.models\n",
    "from cellot.data.cell import load_cell_data\n",
    "import torch\n",
    "from cellot.models.ae import AutoEncoder\n",
    "from pathlib import Path\n",
    "\n",
    "def load_data(config, **kwargs):\n",
    "    data_type = config.get(\"data.type\", \"cell\")\n",
    "    if data_type in [\"cell\", \"cell-merged\", \"tupro-cohort\"]:\n",
    "        loadfxn = load_cell_data\n",
    "\n",
    "    elif data_type == \"toy\":\n",
    "        loadfxn = load_toy_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return loadfxn(config, **kwargs)\n",
    "\n",
    "\n",
    "def load_model(config, device, restore=None, **kwargs):\n",
    "    # def load_autoencoder_model(config, restore=None, **kwargs):\n",
    "    \n",
    "    def load_optimizer(config, params):\n",
    "        kwargs = dict(config.get(\"optim\", {}))\n",
    "        assert kwargs.pop(\"optimizer\", \"Adam\") == \"Adam\"\n",
    "        optim = torch.optim.Adam(params, **kwargs)\n",
    "        return optim\n",
    "\n",
    "\n",
    "    def load_networks(config, **kwargs):\n",
    "        kwargs = kwargs.copy()\n",
    "        kwargs.update(dict(config.get(\"ae\", {})))\n",
    "        name = kwargs.pop(\"name\")\n",
    "\n",
    "        # if name == \"scgen\":\n",
    "        model = AutoEncoder\n",
    "\n",
    "        # elif name == \"cae\":\n",
    "        #     model = ConditionalAutoEncoder\n",
    "        # else:\n",
    "        #     raise ValueError\n",
    "\n",
    "        return model(**kwargs)\n",
    "    \n",
    "    model = load_networks(config, **kwargs)\n",
    "    optim = load_optimizer(config, model.parameters())\n",
    "\n",
    "    if restore is not None and Path(restore).exists():\n",
    "        print('Loading model from checkpoint')\n",
    "        ckpt = torch.load(restore, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optim.load_state_dict(ckpt[\"optim_state\"])\n",
    "        # if config.model.name == \"scgen\" and \"code_means\" in ckpt:\n",
    "        #     model.code_means = ckpt[\"code_means\"]\n",
    "            \n",
    "    # logger.info(f'Model on device {next(model.parameters()).device}')\n",
    "\n",
    "    return model, optim\n",
    "\n",
    "def load(config, device, restore=None, include_model_kwargs=False, **kwargs):\n",
    "\n",
    "    loader, model_kwargs = load_data(config, include_model_kwargs=True, **kwargs)\n",
    "\n",
    "    model, opt = load_model(config, device, restore=restore, **model_kwargs)\n",
    "\n",
    "    return model, opt, loader\n",
    "# %% [markdown]\n",
    "# ### Training\n",
    "\n",
    "# %%\n",
    "restore_path = '/Mounts/rbg-storage1/users/johnyang/cellot/saved_weights/ae/ae.pt'\n",
    "ae = load_model(config, 'cuda', restore=restore_path, input_dim=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method AutoEncoder.decode of AutoEncoder(\n",
       "  (encoder_net): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=50, bias=True)\n",
       "  )\n",
       "  (decoder_net): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (mse): MSELoss()\n",
       ")>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae[0].decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = ae[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(lm, batch, lamb=4, dt=0.01, t_start=1.0, cond=True):\n",
    "    with torch.inference_mode():\n",
    "        lm.eval()\n",
    "        all_genes_x, y = batch\n",
    "        latent_x = autoencoder.eval().encode(all_genes_x)\n",
    "        \n",
    "        x_t, _ = lm.diffuser.forward_marginal(latent_x.detach().cpu().numpy(), t=t_start)\n",
    "        \n",
    "        for i, t in enumerate(np.arange(t_start, 0, -dt)):\n",
    "            x_t = torch.tensor(x_t).float().to(lm.device)\n",
    "            uncond_score = lm.score_network((x_t, (torch.ones_like(y) * lm.score_network.null_cond_idx).to(device)), t)\n",
    "            if cond:\n",
    "                cond_score = lm.score_network((x_t, y), t)\n",
    "                pred_score = (1 + lamb) * cond_score - lamb * uncond_score\n",
    "            else:\n",
    "                pred_score = uncond_score\n",
    "            \n",
    "            x_t = lm.diffuser.reverse(x_t=x_t.detach().cpu().numpy(), score_t=pred_score.detach().cpu().numpy(), t=t, dt=lm.dt, center=False)\n",
    "        \n",
    "        x_0 = torch.tensor(x_t, dtype=torch.float).to(lm.device)\n",
    "        \n",
    "        recon = autoencoder.eval().decode(x_0)\n",
    "        return recon, latent_x, x_0\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 21:03:13,059 Loaded cell data with TARGET trametinib and OBS SHAPE (20842, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ENSG00000198074.9', 'ENSG00000019186.9', 'ENSG00000108846.15',\n",
       "       'ENSG00000115414.18', 'ENSG00000231185.6', 'ENSG00000112541.13',\n",
       "       'ENSG00000117983.17', 'ENSG00000145819.15', 'ENSG00000184588.17',\n",
       "       'ENSG00000165376.10', 'ENSG00000154529.14', 'ENSG00000182752.9',\n",
       "       'ENSG00000251003.7', 'ENSG00000101144.12', 'ENSG00000117724.12',\n",
       "       'ENSG00000157168.18', 'ENSG00000275395.5', 'ENSG00000185483.11',\n",
       "       'ENSG00000108405.3', 'ENSG00000089199.9', 'ENSG00000254166.2',\n",
       "       'ENSG00000215182.8', 'ENSG00000004948.13', 'ENSG00000227706.3',\n",
       "       'ENSG00000065809.13', 'ENSG00000004799.7', 'ENSG00000144847.12',\n",
       "       'ENSG00000107957.16', 'ENSG00000108602.17', 'ENSG00000059804.15',\n",
       "       'ENSG00000047648.21', 'ENSG00000076706.16', 'ENSG00000003436.15',\n",
       "       'ENSG00000229140.8', 'ENSG00000066279.17', 'ENSG00000153956.15',\n",
       "       'ENSG00000086548.8', 'ENSG00000171408.13', 'ENSG00000005108.15',\n",
       "       'ENSG00000138696.10', 'ENSG00000236213.1', 'ENSG00000038427.15',\n",
       "       'ENSG00000064042.17', 'ENSG00000130656.4', 'ENSG00000180287.16',\n",
       "       'ENSG00000204740.10', 'ENSG00000023171.16', 'ENSG00000153976.2',\n",
       "       'ENSG00000167281.18', 'ENSG00000113448.18'],\n",
       "      dtype='object', name='id')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellot.utils.dev_utils import load_markers\n",
    "\n",
    "sel_mg, gene_idxs = load_markers(config)\n",
    "sel_mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellot.data.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEV_load_ae_cell_data(\n",
    "        config,\n",
    "        data=None,\n",
    "        split_on=None,\n",
    "        return_as=\"loader\",\n",
    "        include_model_kwargs=False,\n",
    "        pair_batch_on=None,\n",
    "        ae=None,\n",
    "        encode_latents=False,\n",
    "        sel_mg=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        assert ae is not None or not encode_latents, \"ae must be provided\"\n",
    "        \n",
    "        if isinstance(return_as, str):\n",
    "            return_as = [return_as]\n",
    "\n",
    "        assert set(return_as).issubset({\"anndata\", \"dataset\", \"loader\"})\n",
    "        config.data.condition = config.data.get(\"condition\", \"drug\")\n",
    "        condition = config.data.condition\n",
    "        \n",
    "        data = read_single_anndata(config, **kwargs)\n",
    "        \n",
    "        inputs = torch.Tensor(\n",
    "            data.X if not sparse.issparse(data.X) else data.X.todense()\n",
    "        )\n",
    "\n",
    "        if encode_latents:\n",
    "            genes = data.var_names.to_list()\n",
    "            data = anndata.AnnData(\n",
    "                ae.eval().encode(inputs).detach().numpy(),\n",
    "                obs=data.obs.copy(),\n",
    "                uns=data.uns.copy(),\n",
    "            )\n",
    "            data.uns[\"genes\"] = genes\n",
    "\n",
    "\n",
    "        # cast to dense and check for nans\n",
    "        if sparse.issparse(data.X):\n",
    "            data.X = data.X.todense()\n",
    "        assert not np.isnan(data.X).any()\n",
    "\n",
    "        if sel_mg is not None:\n",
    "            data = data[:, sel_mg]\n",
    "\n",
    "        dataset_args = dict()\n",
    "        model_kwargs = {}\n",
    "\n",
    "        model_kwargs[\"input_dim\"] = data.n_vars\n",
    "\n",
    "        # if config.get(\"model.name\") == \"cae\":\n",
    "        condition_labels = sorted(data.obs[condition].cat.categories)\n",
    "        model_kwargs[\"conditions\"] = condition_labels\n",
    "        dataset_args[\"obs\"] = condition\n",
    "        dataset_args[\"categories\"] = condition_labels\n",
    "\n",
    "        if \"training\" in config:\n",
    "            pair_batch_on = config.training.get(\"pair_batch_on\", pair_batch_on)\n",
    "\n",
    "        # if split_on is None:\n",
    "            # if config.model.name == \"cellot\":\n",
    "            #     # datasets & dataloaders accessed as loader.train.source\n",
    "        split_on = [\"split\", \"transport\"]\n",
    "        if pair_batch_on is not None:\n",
    "            split_on.append(pair_batch_on)\n",
    "\n",
    "            # if (config.ae.name == \"scgen\" #or config.ae.name == \"cae\"\n",
    "            #     #or config.ae.name == \"popalign\"):\n",
    "            # split_on = [\"split\"]\n",
    "\n",
    "            # else:\n",
    "            #     raise ValueError\n",
    "\n",
    "        if isinstance(split_on, str):\n",
    "            split_on = [split_on]\n",
    "\n",
    "        for key in split_on:\n",
    "            assert key in data.obs.columns\n",
    "\n",
    "        if len(split_on) > 0:\n",
    "            splits = {\n",
    "                (key if isinstance(key, str) else \".\".join(key)): data[index]\n",
    "                for key, index in data.obs[split_on].groupby(split_on).groups.items()\n",
    "            }\n",
    "\n",
    "            dataset = nest_dict(\n",
    "                {\n",
    "                    key: AnnDataDataset(val.copy(), **dataset_args)\n",
    "                    for key, val in splits.items()\n",
    "                },\n",
    "                as_dot_dict=True,\n",
    "            )\n",
    "        else:\n",
    "            dataset = AnnDataDataset(data.copy(), **dataset_args)\n",
    "\n",
    "        if \"loader\" in return_as:\n",
    "            kwargs = dict(config.dataloader)\n",
    "            kwargs.setdefault(\"drop_last\", True)\n",
    "            loader = cast_dataset_to_loader(dataset, **kwargs)\n",
    "\n",
    "        returns = list()\n",
    "        for key in return_as:\n",
    "            if key == \"anndata\":\n",
    "                returns.append(data)\n",
    "\n",
    "            elif key == \"dataset\":\n",
    "                returns.append(dataset)\n",
    "\n",
    "            elif key == \"loader\":\n",
    "                returns.append(loader)\n",
    "\n",
    "        if include_model_kwargs:\n",
    "            returns.append(model_kwargs)\n",
    "\n",
    "        if len(returns) == 1:\n",
    "            return returns[0]\n",
    "\n",
    "        # returns.append(data)\n",
    "\n",
    "        return tuple(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = DEV_load_ae_cell_data(config, return_as='dataset')#, ae=autoencoder.cpu(), encode_latents=True)#, sel_mg=sel_mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'source': <torch.utils.data.dataloader.DataLoader at 0x7f74d08ac700>,\n",
       "  'target': <torch.utils.data.dataloader.DataLoader at 0x7f74d08ac820>},\n",
       " 'train': {'source': <torch.utils.data.dataloader.DataLoader at 0x7f74d08ac280>,\n",
       "  'target': <torch.utils.data.dataloader.DataLoader at 0x7f74d08aca30>}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = cast_dataset_to_loader(datasets, batch_size=256, shuffle=False, drop_last=False)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = datasets.test.source.adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = datasets.test.target.adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3513, 50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[:, gene_idxs[:50]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(656, 50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:, gene_idxs[:50]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellot.losses.mmd import mmd_distance\n",
    "import numpy as np\n",
    "\n",
    "def compute_mmd_loss(lhs, rhs, gammas):\n",
    "    return np.mean([mmd_distance(lhs, rhs, g) for g in gammas])\n",
    "\n",
    "gammas = np.logspace(1, -3, num=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_target = target[:, gene_idxs[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.80774903, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 2.6273441 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:19<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "gts = []\n",
    "recons = []\n",
    "lxs = []\n",
    "xs = []\n",
    "for batch in tqdm(loader.test.source):\n",
    "    batch = [x.to(device) for x in batch]\n",
    "    gts.append(batch)\n",
    "    recon, latent_x, recon_x_0 = inference(lm, batch, lamb=4, dt=0.01, t_start=1.0, cond=True)\n",
    "    recons.append(recon)\n",
    "    lxs.append(latent_x)\n",
    "    xs.append(recon_x_0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0], device='cuda:1')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(gts[0][0][0, gene_idxs[:50]] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "        1, 1], device='cuda:1')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(recons[0][0, gene_idxs[:50]] > 0.1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3513, 1000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_recon = torch.cat(recons, dim=0)\n",
    "all_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lxs = torch.cat(lxs, dim=0)\n",
    "all_xs = torch.cat(xs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 92.57it/s]\n"
     ]
    }
   ],
   "source": [
    "lx_targets = []\n",
    "with torch.inference_mode():\n",
    "    for batch in tqdm(loader.test.target):\n",
    "        batch = [x.to(device) for x in batch]\n",
    "        autoencoder.eval()\n",
    "        x, y = batch\n",
    "        latent_x_target = autoencoder.encode(x)\n",
    "        lx_targets.append(latent_x_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lx_targets = torch.cat(lx_targets, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003377005992064311"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mmd_loss(all_lxs.cpu().numpy(), all_xs.cpu().numpy(), gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005241116983967545"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mmd_loss(all_xs.cpu().numpy(), all_lx_targets.cpu().numpy(), gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017621534580830486"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mmd_loss(all_recon[:, gene_idxs[:50]].detach().cpu().numpy(), sel_target, gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03237136445939541"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mmd_loss(all_recon[:, gene_idxs[:50]].detach().cpu().numpy(), sel_target, gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_mmd_loss(all_recon[:, gene_idxs[:50]].detach().cpu().numpy(), sel_target, gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0322643518447876"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellot import losses\n",
    "losses.compute_scalar_mmd(all_recon[:, gene_idxs[:50]].detach().cpu().numpy(), sel_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
