{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnyang\u001b[0m (\u001b[33mprotein-optimization\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Mounts/rbg-storage1/users/johnyang/cellot/notebooks/wandb/run-20230710_130051-3yb8i49p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/protein-optimization/cellot-notebooks/runs/3yb8i49p' target=\"_blank\">true-mountain-11</a></strong> to <a href='https://wandb.ai/protein-optimization/cellot-notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/protein-optimization/cellot-notebooks' target=\"_blank\">https://wandb.ai/protein-optimization/cellot-notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/protein-optimization/cellot-notebooks/runs/3yb8i49p' target=\"_blank\">https://wandb.ai/protein-optimization/cellot-notebooks/runs/3yb8i49p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-ylwt16su:v59, 96.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('protein-optimization/sc_diff/model-ylwt16su:v59', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./artifacts/model-ylwt16su:v59'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellot.models.cond_score_module import CondScoreModuleV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f'{artifact_dir}/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_STR = '''\n",
    "DEBUG: False\n",
    "TARGET: abexinostat\n",
    "LATENT_DIM: 50\n",
    "COND_CLASSES: 190\n",
    "SEED: 42\n",
    "AE_PATH: /Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/full_ae\n",
    "VAL_SIZE: 0.1\n",
    "DEVICES: 1\n",
    "WARM_START: False\n",
    "WARM_START_PATH: null\n",
    "MODEL_CLASS: CondScoreModule\n",
    "\n",
    "\n",
    "diffuser:\n",
    "  min_b: 0.01\n",
    "  max_b: 1.0\n",
    "  schedule: exponential\n",
    "  score_scaling: var\n",
    "  coordinate_scaling: 1.0\n",
    "  latent_dim: ${LATENT_DIM}\n",
    "  dt: 0.01\n",
    "  min_t: 0\n",
    "\n",
    "ae:\n",
    "  name: scgen\n",
    "  beta: 0.0\n",
    "  dropout: 0.0\n",
    "  hidden_units: [512, 512]\n",
    "  latent_dim: 50\n",
    "\n",
    "score_network:\n",
    "  latent_dim: ${LATENT_DIM}\n",
    "  cond_classes: ${COND_CLASSES}\n",
    "  model_dim: 256   # Adjusted to 64\n",
    "  n_layers: 6    # Adjusted to 12\n",
    "  nhead: 8\n",
    "  dim_feedforward: 2048\n",
    "  dropout: 0.1\n",
    "  ffn_hidden_dim: 1024\n",
    "  extra_null_cond_embedding: False\n",
    "\n",
    "\n",
    "data:\n",
    "  type: cell\n",
    "  source: control\n",
    "  condition: drug\n",
    "  path: /Mounts/rbg-storage1/users/johnyang/cellot/datasets/scrna-sciplex3/hvg.h5ad\n",
    "  target: ${TARGET}\n",
    "\n",
    "datasplit:\n",
    "  groupby: drug   \n",
    "  name: train_test\n",
    "  test_size: 0.2\n",
    "  random_state: 0\n",
    "  \n",
    "dataloader:\n",
    "  batch_size: 256   # Adjusted to 256\n",
    "  shuffle: true\n",
    "  num_workers: 80\n",
    "  \n",
    "experiment:\n",
    "  name: base\n",
    "  mode: train\n",
    "  num_loader_workers: 0\n",
    "  port: 12319\n",
    "  dist_mode: single\n",
    "  use_wandb: True\n",
    "  ckpt_path: null\n",
    "  wandb_logger:\n",
    "    project: sc_diff\n",
    "    name: ${experiment.name}\n",
    "    dir: /Mounts/rbg-storage1/users/johnyang/cellot/\n",
    "    log_model: all\n",
    "    tags: ['experimental']\n",
    "  lr: 0.0001\n",
    "\n",
    "\n",
    "trainer:\n",
    "  accelerator: 'gpu'\n",
    "  check_val_every_n_epoch: 50\n",
    "  log_every_n_steps: 100\n",
    "  num_sanity_val_steps: 1\n",
    "  enable_progress_bar: True\n",
    "  enable_checkpointing: True\n",
    "  fast_dev_run: False\n",
    "  profiler: simple\n",
    "  max_epochs: 10000\n",
    "  strategy: auto\n",
    "  enable_model_summary: True\n",
    "  overfit_batches: 0.0\n",
    "  limit_train_batches: 1.0\n",
    "  limit_val_batches: 1.0\n",
    "  limit_predict_batches: 1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "config = OmegaConf.create(YAML_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f'{artifact_dir}/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using GPUs: 7\n"
     ]
    }
   ],
   "source": [
    "from cellot.train.utils import get_free_gpu\n",
    "replica_id = int(get_free_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = f'cuda:{replica_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEBUG': False, 'TARGET': 'abexinostat', 'LATENT_DIM': 50, 'COND_CLASSES': 190, 'SEED': 42, 'AE_PATH': '/Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/full_ae', 'VAL_SIZE': 0.1, 'DEVICES': 1, 'WARM_START': False, 'WARM_START_PATH': None, 'MODEL_CLASS': 'CondScoreModule', 'diffuser': {'min_b': 0.01, 'max_b': 1.0, 'schedule': 'exponential', 'score_scaling': 'var', 'coordinate_scaling': 1.0, 'latent_dim': '${LATENT_DIM}', 'dt': 0.01, 'min_t': 0}, 'ae': {'name': 'scgen', 'beta': 0.0, 'dropout': 0.0, 'hidden_units': [512, 512], 'latent_dim': 50}, 'score_network': {'latent_dim': '${LATENT_DIM}', 'cond_classes': '${COND_CLASSES}', 'model_dim': 256, 'n_layers': 6, 'nhead': 8, 'dim_feedforward': 2048, 'dropout': 0.1, 'ffn_hidden_dim': 1024, 'extra_null_cond_embedding': False}, 'data': {'type': 'cell', 'source': 'control', 'condition': 'drug', 'path': '/Mounts/rbg-storage1/users/johnyang/cellot/datasets/scrna-sciplex3/hvg.h5ad', 'target': '${TARGET}'}, 'datasplit': {'groupby': 'drug', 'name': 'train_test', 'test_size': 0.2, 'random_state': 0}, 'dataloader': {'batch_size': 256, 'shuffle': True, 'num_workers': 80}, 'experiment': {'name': 'base', 'mode': 'train', 'num_loader_workers': 0, 'port': 12319, 'dist_mode': 'single', 'use_wandb': True, 'ckpt_path': None, 'wandb_logger': {'project': 'sc_diff', 'name': '${experiment.name}', 'dir': '/Mounts/rbg-storage1/users/johnyang/cellot/', 'log_model': 'all', 'tags': ['experimental']}, 'lr': 0.0001}, 'trainer': {'accelerator': 'gpu', 'check_val_every_n_epoch': 50, 'log_every_n_steps': 100, 'num_sanity_val_steps': 1, 'enable_progress_bar': True, 'enable_checkpointing': True, 'fast_dev_run': False, 'profiler': 'simple', 'max_epochs': 10000, 'strategy': 'auto', 'enable_model_summary': True, 'overfit_batches': 0.0, 'limit_train_batches': 1.0, 'limit_val_batches': 1.0, 'limit_predict_batches': 1.0}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout is 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm = CondScoreModuleV2.load_from_checkpoint(hparams=config, checkpoint_path=ckpt_path).to(device)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import cellot.models\n",
    "from cellot.data.cell import load_cell_data\n",
    "import torch\n",
    "from cellot.models.ae import AutoEncoder\n",
    "from pathlib import Path\n",
    "\n",
    "def load_data(config, **kwargs):\n",
    "    data_type = config.get(\"data.type\", \"cell\")\n",
    "    if data_type in [\"cell\", \"cell-merged\", \"tupro-cohort\"]:\n",
    "        loadfxn = load_cell_data\n",
    "\n",
    "    elif data_type == \"toy\":\n",
    "        loadfxn = load_toy_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return loadfxn(config, **kwargs)\n",
    "\n",
    "\n",
    "def load_model(config, device, restore=None, **kwargs):\n",
    "    # def load_autoencoder_model(config, restore=None, **kwargs):\n",
    "    \n",
    "    def load_optimizer(config, params):\n",
    "        kwargs = dict(config.get(\"optim\", {}))\n",
    "        assert kwargs.pop(\"optimizer\", \"Adam\") == \"Adam\"\n",
    "        optim = torch.optim.Adam(params, **kwargs)\n",
    "        return optim\n",
    "\n",
    "\n",
    "    def load_networks(config, **kwargs):\n",
    "        kwargs = kwargs.copy()\n",
    "        kwargs.update(dict(config.get(\"ae\", {})))\n",
    "        name = kwargs.pop(\"name\")\n",
    "\n",
    "        # if name == \"scgen\":\n",
    "        model = AutoEncoder\n",
    "\n",
    "        # elif name == \"cae\":\n",
    "        #     model = ConditionalAutoEncoder\n",
    "        # else:\n",
    "        #     raise ValueError\n",
    "\n",
    "        return model(**kwargs)\n",
    "    \n",
    "    model = load_networks(config, **kwargs)\n",
    "    optim = load_optimizer(config, model.parameters())\n",
    "\n",
    "    if restore is not None and Path(restore).exists():\n",
    "        print('Loading model from checkpoint')\n",
    "        ckpt = torch.load(restore, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optim.load_state_dict(ckpt[\"optim_state\"])\n",
    "        # if config.model.name == \"scgen\" and \"code_means\" in ckpt:\n",
    "        #     model.code_means = ckpt[\"code_means\"]\n",
    "            \n",
    "    # logger.info(f'Model on device {next(model.parameters()).device}')\n",
    "\n",
    "    return model, optim\n",
    "\n",
    "def load(config, device, restore=None, include_model_kwargs=False, **kwargs):\n",
    "\n",
    "    loader, model_kwargs = load_data(config, include_model_kwargs=True, **kwargs)\n",
    "\n",
    "    model, opt = load_model(config, device, restore=restore, **model_kwargs)\n",
    "\n",
    "    return model, opt, loader\n",
    "# %% [markdown]\n",
    "# ### Training\n",
    "\n",
    "# %%\n",
    "restore_path = '/Mounts/rbg-storage1/users/johnyang/cellot/saved_weights/ae/ae.pt'\n",
    "ae = load_model(config, 'cuda', restore=restore_path, input_dim=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method AutoEncoder.decode of AutoEncoder(\n",
       "  (encoder_net): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=50, bias=True)\n",
       "  )\n",
       "  (decoder_net): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (mse): MSELoss()\n",
       ")>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae[0].decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = ae[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(lm, batch, lamb=4, dt=0.01, t_start=1.0, cond=True):\n",
    "    with torch.inference_mode():\n",
    "        lm.eval()\n",
    "        all_genes_x, y = batch\n",
    "        latent_x = autoencoder.eval().encode(all_genes_x)\n",
    "        \n",
    "        x_t, _ = lm.diffuser.forward_marginal(latent_x.detach().cpu().numpy(), t=t_start)\n",
    "        \n",
    "        for i, t in enumerate(np.arange(t_start, 0, -dt)):\n",
    "            x_t = torch.tensor(x_t).float().to(lm.device)\n",
    "            uncond_score = lm.score_network((x_t, torch.zeros_like(y).to(device)), t)\n",
    "            if cond:\n",
    "                cond_score = lm.score_network((x_t, y), t)\n",
    "                pred_score = (1 + lamb) * cond_score - lamb * uncond_score\n",
    "            else:\n",
    "                pred_score = uncond_score\n",
    "            \n",
    "            x_t = lm.diffuser.reverse(x_t=x_t.detach().cpu().numpy(), score_t=pred_score.detach().cpu().numpy(), t=t, dt=lm.dt, center=False)\n",
    "        \n",
    "        x_0 = torch.tensor(x_t, dtype=torch.float).to(lm.device)\n",
    "        \n",
    "        recon = autoencoder.eval().decode(x_0)\n",
    "        return recon\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 13:16:11,922 Loaded cell data with TARGET abexinostat and OBS SHAPE (22070, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ENSG00000160963.13', 'ENSG00000121101.15', 'ENSG00000230666.5',\n",
       "       'ENSG00000175175.5', 'ENSG00000140986.7', 'ENSG00000100867.14',\n",
       "       'ENSG00000173727.12', 'ENSG00000183032.11', 'ENSG00000117724.12',\n",
       "       'ENSG00000259124.1',\n",
       "       ...\n",
       "       'ENSG00000116183.10', 'ENSG00000102683.7', 'ENSG00000117983.17',\n",
       "       'ENSG00000205359.9', 'ENSG00000142347.16', 'ENSG00000232072.1',\n",
       "       'ENSG00000135426.15', 'ENSG00000271856.1', 'ENSG00000185008.17',\n",
       "       'ENSG00000196628.15'],\n",
       "      dtype='object', name='id', length=1000)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellot.data.cell import read_single_anndata\n",
    "def load_markers():\n",
    "    data = read_single_anndata(config, path=None)\n",
    "    key = f'marker_genes-{config.data.condition}-rank'\n",
    "\n",
    "    # rebuttal preprocessing stored marker genes using\n",
    "    # a generic marker_genes-condition-rank key\n",
    "    # instead of e.g. marker_genes-drug-rank\n",
    "    # let's just patch that here:\n",
    "    if key not in data.varm:\n",
    "        key = 'marker_genes-condition-rank'\n",
    "        print('WARNING: using generic condition marker genes')\n",
    "\n",
    "    sel_mg = (\n",
    "        data.varm[key][config.data.target]\n",
    "        .sort_values()\n",
    "        .index\n",
    "    )\n",
    "    marker_gene_indices = [i for i, gene in enumerate(data.var_names) if gene in sel_mg]\n",
    "\n",
    "    return sel_mg, marker_gene_indices\n",
    "\n",
    "sel_mg, gene_idxs = load_markers()\n",
    "sel_mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellot.data.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEV_load_ae_cell_data(\n",
    "        config,\n",
    "        data=None,\n",
    "        split_on=None,\n",
    "        return_as=\"loader\",\n",
    "        include_model_kwargs=False,\n",
    "        pair_batch_on=None,\n",
    "        ae=None,\n",
    "        encode_latents=False,\n",
    "        sel_mg=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        assert ae is not None or not encode_latents, \"ae must be provided\"\n",
    "        \n",
    "        if isinstance(return_as, str):\n",
    "            return_as = [return_as]\n",
    "\n",
    "        assert set(return_as).issubset({\"anndata\", \"dataset\", \"loader\"})\n",
    "        config.data.condition = config.data.get(\"condition\", \"drug\")\n",
    "        condition = config.data.condition\n",
    "        \n",
    "        data = read_single_anndata(config, **kwargs)\n",
    "        \n",
    "        inputs = torch.Tensor(\n",
    "            data.X if not sparse.issparse(data.X) else data.X.todense()\n",
    "        )\n",
    "\n",
    "        if encode_latents:\n",
    "            genes = data.var_names.to_list()\n",
    "            data = anndata.AnnData(\n",
    "                ae.eval().encode(inputs).detach().numpy(),\n",
    "                obs=data.obs.copy(),\n",
    "                uns=data.uns.copy(),\n",
    "            )\n",
    "            data.uns[\"genes\"] = genes\n",
    "\n",
    "\n",
    "        # cast to dense and check for nans\n",
    "        if sparse.issparse(data.X):\n",
    "            data.X = data.X.todense()\n",
    "        assert not np.isnan(data.X).any()\n",
    "\n",
    "        if sel_mg is not None:\n",
    "            data = data[:, sel_mg]\n",
    "\n",
    "        dataset_args = dict()\n",
    "        model_kwargs = {}\n",
    "\n",
    "        model_kwargs[\"input_dim\"] = data.n_vars\n",
    "\n",
    "        # if config.get(\"model.name\") == \"cae\":\n",
    "        condition_labels = sorted(data.obs[condition].cat.categories)\n",
    "        model_kwargs[\"conditions\"] = condition_labels\n",
    "        dataset_args[\"obs\"] = condition\n",
    "        dataset_args[\"categories\"] = condition_labels\n",
    "\n",
    "        if \"training\" in config:\n",
    "            pair_batch_on = config.training.get(\"pair_batch_on\", pair_batch_on)\n",
    "\n",
    "        # if split_on is None:\n",
    "            # if config.model.name == \"cellot\":\n",
    "            #     # datasets & dataloaders accessed as loader.train.source\n",
    "        split_on = [\"split\", \"transport\"]\n",
    "        if pair_batch_on is not None:\n",
    "            split_on.append(pair_batch_on)\n",
    "\n",
    "            # if (config.ae.name == \"scgen\" #or config.ae.name == \"cae\"\n",
    "            #     #or config.ae.name == \"popalign\"):\n",
    "            # split_on = [\"split\"]\n",
    "\n",
    "            # else:\n",
    "            #     raise ValueError\n",
    "\n",
    "        if isinstance(split_on, str):\n",
    "            split_on = [split_on]\n",
    "\n",
    "        for key in split_on:\n",
    "            assert key in data.obs.columns\n",
    "\n",
    "        if len(split_on) > 0:\n",
    "            splits = {\n",
    "                (key if isinstance(key, str) else \".\".join(key)): data[index]\n",
    "                for key, index in data.obs[split_on].groupby(split_on).groups.items()\n",
    "            }\n",
    "\n",
    "            dataset = nest_dict(\n",
    "                {\n",
    "                    key: AnnDataDataset(val.copy(), **dataset_args)\n",
    "                    for key, val in splits.items()\n",
    "                },\n",
    "                as_dot_dict=True,\n",
    "            )\n",
    "        else:\n",
    "            dataset = AnnDataDataset(data.copy(), **dataset_args)\n",
    "\n",
    "        if \"loader\" in return_as:\n",
    "            kwargs = dict(config.dataloader)\n",
    "            kwargs.setdefault(\"drop_last\", True)\n",
    "            loader = cast_dataset_to_loader(dataset, **kwargs)\n",
    "\n",
    "        returns = list()\n",
    "        for key in return_as:\n",
    "            if key == \"anndata\":\n",
    "                returns.append(data)\n",
    "\n",
    "            elif key == \"dataset\":\n",
    "                returns.append(dataset)\n",
    "\n",
    "            elif key == \"loader\":\n",
    "                returns.append(loader)\n",
    "\n",
    "        if include_model_kwargs:\n",
    "            returns.append(model_kwargs)\n",
    "\n",
    "        if len(returns) == 1:\n",
    "            return returns[0]\n",
    "\n",
    "        # returns.append(data)\n",
    "\n",
    "        return tuple(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = DEV_load_ae_cell_data(config, return_as='dataset')#, ae=autoencoder.cpu(), encode_latents=True)#, sel_mg=sel_mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'source': <torch.utils.data.dataloader.DataLoader at 0x7f9c6dc274f0>,\n",
       "  'target': <torch.utils.data.dataloader.DataLoader at 0x7f9c6dc273a0>},\n",
       " 'train': {'source': <torch.utils.data.dataloader.DataLoader at 0x7f9c6dc27820>,\n",
       "  'target': <torch.utils.data.dataloader.DataLoader at 0x7f9c6dc272b0>}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = cast_dataset_to_loader(datasets, batch_size=256, shuffle=False, drop_last=False)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = datasets.test.source.adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = datasets.test.target.adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3513, 50)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[:, gene_idxs[:50]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 50)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:, gene_idxs[:50]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellot.losses.mmd import mmd_distance\n",
    "import numpy as np\n",
    "\n",
    "def compute_mmd_loss(lhs, rhs, gammas):\n",
    "    return np.mean([mmd_distance(lhs, rhs, g) for g in gammas])\n",
    "\n",
    "gammas = np.logspace(1, -3, num=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_target = target[:, gene_idxs[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:20<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "gts = []\n",
    "recons = []\n",
    "for batch in tqdm(loader.test.source):\n",
    "    batch = [x.to(device) for x in batch]\n",
    "    gts.append(batch)\n",
    "    recon = inference(lm, batch, lamb=4, dt=0.01, cond=True)\n",
    "    recons.append(recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0], device='cuda:7')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(gts[0][0][0, gene_idxs[:50]] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0], device='cuda:7')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(recons[0][0, gene_idxs[:50]] > 0.1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3513, 1000])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_recon = torch.cat(recons, dim=0)\n",
    "all_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03229137025773525"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mmd_loss(all_recon[:, gene_idxs[:50]].detach().cpu().numpy(), sel_target, gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
