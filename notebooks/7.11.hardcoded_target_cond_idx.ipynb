{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from absl import logging\n",
    "from absl.flags import FLAGS\n",
    "from cellot import losses\n",
    "from cellot.utils.loaders import load\n",
    "from cellot.models.cellot import compute_loss_f, compute_loss_g, compute_w2_distance\n",
    "from cellot.train.summary import Logger\n",
    "from cellot.data.utils import cast_loader_to_iterator\n",
    "from cellot.models.ae import compute_scgen_shift\n",
    "from tqdm import trange\n",
    "\n",
    "from cellot.models.ae import AutoEncoder\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "logger = logging.getLogger(\"data_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "TARGET = 'all' if not DEBUG else 'abexinostat'\n",
    "LATENT_DIM = 50\n",
    "COND_CLASSES = 189 if not DEBUG else 2\n",
    "\n",
    "from pathlib import Path\n",
    "outdir_path = '/Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/full_ae'\n",
    "outdir = Path(outdir_path)\n",
    "\n",
    "# %%\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "cachedir = outdir / \"cache\"\n",
    "cachedir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import GPUtil\n",
    "import os\n",
    "\n",
    "def get_free_gpu():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "    # Set environment variables for which GPUs to use.\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    chosen_gpu = ''.join(\n",
    "        [str(x) for x in GPUtil.getAvailable(order='memory')])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = chosen_gpu\n",
    "    print(f\"Using GPUs: {chosen_gpu}\")\n",
    "    return chosen_gpu\n",
    "\n",
    "status = cachedir / \"status\"\n",
    "status.write_text(\"running\")\n",
    "\n",
    "device = f'cuda:{get_free_gpu()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "import omegaconf\n",
    "\n",
    "if DEBUG:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "else:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "\n",
    "yaml_str = f\"\"\"\n",
    "model:\n",
    "   name: scgen\n",
    "   beta: 0.0\n",
    "   dropout: 0.0\n",
    "   hidden_units: [512, 512]\n",
    "   latent_dim: 50\n",
    "\n",
    "optim:\n",
    "   lr: 0.001\n",
    "   optimizer: Adam\n",
    "   weight_decay: 1.0e-05\n",
    "\n",
    "scheduler:\n",
    "   gamma: 0.5\n",
    "   step_size: 100000\n",
    "\n",
    "training:\n",
    "  cache_freq: 10000\n",
    "  eval_freq: 2500\n",
    "  logs_freq: 250\n",
    "  n_iters: {n_iters}\n",
    "\n",
    "data:\n",
    "  type: cell\n",
    "  source: control\n",
    "  condition: drug\n",
    "  path: /Mounts/rbg-storage1/users/johnyang/cellot/datasets/scrna-sciplex3/hvg.h5ad\n",
    "  target: {TARGET}\n",
    "\n",
    "datasplit:\n",
    "    groupby: drug   \n",
    "    name: train_test\n",
    "    test_size: 0.2\n",
    "    random_state: 0\n",
    "\n",
    "dataloader:\n",
    "    batch_size: {batch_size}\n",
    "    shuffle: true\n",
    "\"\"\"\n",
    "\n",
    "config = omegaconf.OmegaConf.create(yaml_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ### Utils\n",
    "\n",
    "# %%\n",
    "def load_lr_scheduler(optim, config):\n",
    "    if \"scheduler\" not in config:\n",
    "        return None\n",
    "\n",
    "    return torch.optim.lr_scheduler.StepLR(optim, **config.scheduler)\n",
    "\n",
    "def check_loss(*args):\n",
    "    for arg in args:\n",
    "        if torch.isnan(arg):\n",
    "            raise ValueError\n",
    "\n",
    "\n",
    "def load_item_from_save(path, key, default):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return default\n",
    "\n",
    "    ckpt = torch.load(path)\n",
    "    if key not in ckpt:\n",
    "        logging.warn(f\"'{key}' not found in ckpt: {str(path)}\")\n",
    "        return default\n",
    "\n",
    "    return ckpt[key]\n",
    "\n",
    "# %%\n",
    "import cellot.models\n",
    "# from cellot.data.cell import load_cell_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(config, **kwargs):\n",
    "    data_type = config.get(\"data.type\", \"cell\")\n",
    "    if data_type in [\"cell\", \"cell-merged\", \"tupro-cohort\"]:\n",
    "        loadfxn = load_cell_data\n",
    "\n",
    "    elif data_type == \"toy\":\n",
    "        loadfxn = load_toy_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return loadfxn(config, **kwargs)\n",
    "\n",
    "\n",
    "def load_model(config, device, restore=None, **kwargs):\n",
    "    # def load_autoencoder_model(config, restore=None, **kwargs):\n",
    "    \n",
    "    def load_optimizer(config, params):\n",
    "        kwargs = dict(config.get(\"optim\", {}))\n",
    "        assert kwargs.pop(\"optimizer\", \"Adam\") == \"Adam\"\n",
    "        optim = torch.optim.Adam(params, **kwargs)\n",
    "        return optim\n",
    "\n",
    "\n",
    "    def load_networks(config, **kwargs):\n",
    "        kwargs = kwargs.copy()\n",
    "        kwargs.update(dict(config.get(\"model\", {})))\n",
    "        name = kwargs.pop(\"name\")\n",
    "\n",
    "        if name == \"scgen\":\n",
    "            model = AutoEncoder\n",
    "\n",
    "        # elif name == \"cae\":\n",
    "        #     model = ConditionalAutoEncoder\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        return model(**kwargs)\n",
    "    \n",
    "    model = load_networks(config, **kwargs)\n",
    "    optim = load_optimizer(config, model.parameters())\n",
    "\n",
    "    if restore is not None and Path(restore).exists():\n",
    "        print('Loading model from checkpoint')\n",
    "        ckpt = torch.load(restore, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optim.load_state_dict(ckpt[\"optim_state\"])\n",
    "        if config.model.name == \"scgen\" and \"code_means\" in ckpt:\n",
    "            model.code_means = ckpt[\"code_means\"]\n",
    "            \n",
    "    # logger.info(f'Model on device {next(model.parameters()).device}')\n",
    "\n",
    "    return model, optim\n",
    "\n",
    "def load(config, device, restore=None, include_model_kwargs=False, **kwargs):\n",
    "\n",
    "    loader, model_kwargs = load_data(config, include_model_kwargs=True, **kwargs)\n",
    "\n",
    "    model, opt = load_model(config, device, restore=restore, **model_kwargs)\n",
    "\n",
    "    # if include_model_kwargs:\n",
    "    #     return model, opt, loader, model_kwargs\n",
    "\n",
    "    return model, opt, loader\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ae \u001b[39m=\u001b[39m load_model(config, \u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m, restore\u001b[39m=\u001b[39;49mcachedir \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mlast.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m, input_dim\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(config, device, restore, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoading model from checkpoint\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m ckpt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(restore, map_location\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m---> 46\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(ckpt[\u001b[39m\"\u001b[39;49m\u001b[39mmodel_state\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     47\u001b[0m optim\u001b[39m.\u001b[39mload_state_dict(ckpt[\u001b[39m\"\u001b[39m\u001b[39moptim_state\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscgen\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcode_means\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m ckpt:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_state'"
     ]
    }
   ],
   "source": [
    "ae = load_model(config, 'cuda', restore=cachedir / \"last.pt\", input_dim=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellot.data.cell import *\n",
    "\n",
    "def load_cell_data(\n",
    "    config,\n",
    "    data=None,\n",
    "    split_on=None,\n",
    "    return_as=\"loader\",\n",
    "    include_model_kwargs=False,\n",
    "    pair_batch_on=None,\n",
    "    **kwargs\n",
    "):\n",
    "\n",
    "    if isinstance(return_as, str):\n",
    "        return_as = [return_as]\n",
    "\n",
    "    assert set(return_as).issubset({\"anndata\", \"dataset\", \"loader\"})\n",
    "    config.data.condition = config.data.get(\"condition\", \"drug\")\n",
    "    condition = config.data.condition\n",
    "    \n",
    "    data = read_single_anndata(config, **kwargs)\n",
    "\n",
    "    # if \"ae_emb\" in config.data:\n",
    "        # load path to autoencoder\n",
    "        # assert config.get(\"model.name\", \"cellot\") == \"cellot\"\n",
    "    # path_ae = Path(outdir_path)\n",
    "    # model_kwargs = {\"input_dim\": data.n_vars}\n",
    "    # config_ae = load_config('/Mounts/rbg-storage1/users/johnyang/cellot/configs/models/scgen.yaml')\n",
    "    # ae_model, _ = load_autoencoder_model(\n",
    "    #     config_ae, restore=path_ae / \"cache/model.pt\", **model_kwargs\n",
    "    # )\n",
    "\n",
    "    inputs = torch.Tensor(\n",
    "        data.X if not sparse.issparse(data.X) else data.X.todense()\n",
    "    )\n",
    "\n",
    "    # genes = data.var_names.to_list()\n",
    "    # data = anndata.AnnData(\n",
    "    #     ae[0].eval().encode(inputs).detach().numpy(),\n",
    "    #     obs=data.obs.copy(),\n",
    "    #     uns=data.uns.copy(),\n",
    "    # )\n",
    "    # data.uns[\"genes\"] = genes\n",
    "\n",
    "    # cast to dense and check for nans\n",
    "    if sparse.issparse(data.X):\n",
    "        data.X = data.X.todense()\n",
    "    assert not np.isnan(data.X).any()\n",
    "\n",
    "    dataset_args = dict()\n",
    "    model_kwargs = {}\n",
    "\n",
    "    model_kwargs[\"input_dim\"] = data.n_vars\n",
    "\n",
    "    # if config.get(\"model.name\") == \"cae\":\n",
    "    condition_labels = sorted(data.obs[condition].cat.categories)\n",
    "    model_kwargs[\"conditions\"] = condition_labels\n",
    "    dataset_args[\"obs\"] = condition\n",
    "    dataset_args[\"categories\"] = condition_labels\n",
    "\n",
    "    if \"training\" in config:\n",
    "        pair_batch_on = config.training.get(\"pair_batch_on\", pair_batch_on)\n",
    "\n",
    "    if split_on is None:\n",
    "        if config.model.name == \"cellot\":\n",
    "            # datasets & dataloaders accessed as loader.train.source\n",
    "            split_on = [\"split\", \"transport\"]\n",
    "            if pair_batch_on is not None:\n",
    "                split_on.append(pair_batch_on)\n",
    "\n",
    "        elif (config.model.name == \"scgen\" or config.model.name == \"cae\"\n",
    "              or config.model.name == \"popalign\"):\n",
    "            split_on = [\"split\"]\n",
    "\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    if isinstance(split_on, str):\n",
    "        split_on = [split_on]\n",
    "\n",
    "    for key in split_on:\n",
    "        assert key in data.obs.columns\n",
    "\n",
    "    if len(split_on) > 0:\n",
    "        splits = {\n",
    "            (key if isinstance(key, str) else \".\".join(key)): data[index]\n",
    "            for key, index in data.obs[split_on].groupby(split_on).groups.items()\n",
    "        }\n",
    "\n",
    "        dataset = nest_dict(\n",
    "            {\n",
    "                key: AnnDataDataset(val.copy(), **dataset_args)\n",
    "                for key, val in splits.items()\n",
    "            },\n",
    "            as_dot_dict=True,\n",
    "        )\n",
    "    else:\n",
    "        dataset = AnnDataDataset(data.copy(), **dataset_args)\n",
    "\n",
    "    if \"loader\" in return_as:\n",
    "        kwargs = dict(config.dataloader)\n",
    "        kwargs.setdefault(\"drop_last\", True)\n",
    "        loader = cast_dataset_to_loader(dataset, **kwargs)\n",
    "\n",
    "    returns = list()\n",
    "    for key in return_as:\n",
    "        if key == \"anndata\":\n",
    "            returns.append(data)\n",
    "\n",
    "        elif key == \"dataset\":\n",
    "            returns.append(dataset)\n",
    "\n",
    "        elif key == \"loader\":\n",
    "            returns.append(loader)\n",
    "\n",
    "    if include_model_kwargs:\n",
    "        returns.append(model_kwargs)\n",
    "\n",
    "    if len(returns) == 1:\n",
    "        return returns[0]\n",
    "\n",
    "    # returns.append(data)\n",
    "\n",
    "    return tuple(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 04:14:44,839 Loaded cell data with TARGET all and OBS SHAPE (762039, 16)\n"
     ]
    }
   ],
   "source": [
    "cond_datasets = load_cell_data(config, return_as=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AnnDataDataset' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cond_datasets\u001b[39m.\u001b[39;49mtest\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39madata\u001b[39m.\u001b[39mobs[\u001b[39m'\u001b[39m\u001b[39mdrug\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AnnDataDataset' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "cond_datasets.test.dataset.adata.obs['drug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = cond_datasets.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 152485 × 1000\n",
       "    obs: 'size_factor', 'cell_type', 'replicate', 'dose', 'drug_code', 'pathway_level_1', 'pathway_level_2', 'product_name', 'target', 'pathway', 'drug', 'drug-dose', 'drug_code-dose', 'n_genes', 'transport', 'split'\n",
       "    var: 'gene_short_name', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'hvg', 'pca', 'rank_genes_groups'\n",
       "    obsm: 'X_pca'\n",
       "    varm: 'PCs', 'marker_genes-drug-rank', 'marker_genes-drug-score'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2_methoxyestradiol',\n",
       " '_jq1',\n",
       " 'a_366',\n",
       " 'abexinostat',\n",
       " 'abt_737',\n",
       " 'ac480',\n",
       " 'ag_14361',\n",
       " 'ag_490',\n",
       " 'aicar',\n",
       " 'alendronate_sodium_trihydrate',\n",
       " 'alisertib',\n",
       " 'altretamine',\n",
       " 'alvespimycin_hcl',\n",
       " 'amg_900',\n",
       " 'aminoglutethimide',\n",
       " 'amisulpride',\n",
       " 'anacardic_acid',\n",
       " 'andarine',\n",
       " 'ar_42',\n",
       " 'at9283',\n",
       " 'aurora_a_inhibitor_i',\n",
       " 'avagacestat',\n",
       " 'az_960',\n",
       " 'azacitidine',\n",
       " 'azd1480',\n",
       " 'barasertib',\n",
       " 'baricitinib',\n",
       " 'belinostat',\n",
       " 'bisindolylmaleimide_ix',\n",
       " 'bms_265246',\n",
       " 'bms_536924',\n",
       " 'bms_754807',\n",
       " 'bms_911543',\n",
       " 'bosutinib',\n",
       " 'brd4770',\n",
       " 'busulfan',\n",
       " 'capecitabine',\n",
       " 'carmofur',\n",
       " 'cediranib',\n",
       " 'celecoxib',\n",
       " 'cep_33779',\n",
       " 'cerdulatinib',\n",
       " 'cimetidine',\n",
       " 'clevudine',\n",
       " 'control',\n",
       " 'costunolide',\n",
       " 'crizotinib',\n",
       " 'cudc_101',\n",
       " 'cudc_907',\n",
       " 'curcumin',\n",
       " 'cyc116',\n",
       " 'cyclocytidine_hcl',\n",
       " 'dacinostat',\n",
       " 'danusertib',\n",
       " 'daphnetin',\n",
       " 'dasatinib',\n",
       " 'decitabine',\n",
       " 'disulfiram',\n",
       " 'divalproex_sodium',\n",
       " 'droxinostat',\n",
       " 'eed226',\n",
       " 'ellagic_acid',\n",
       " 'enmd_2076',\n",
       " 'enmd_2076_l__tartaric_acid',\n",
       " 'entacapone',\n",
       " 'entinostat',\n",
       " 'enzastaurin',\n",
       " 'epothilone_a',\n",
       " 'fasudil_hcl',\n",
       " 'fedratinib',\n",
       " 'filgotinib',\n",
       " 'flavopiridol_hcl',\n",
       " 'flll32',\n",
       " 'fluorouracil',\n",
       " 'fulvestrant',\n",
       " 'g007_lk',\n",
       " 'gandotinib',\n",
       " 'givinostat',\n",
       " 'glesatinib?',\n",
       " 'gsk1070916',\n",
       " 'gsk_j1',\n",
       " 'gsk_lsd1_2hcl',\n",
       " 'hesperadin',\n",
       " 'iniparib',\n",
       " 'ino_1001',\n",
       " 'iox2',\n",
       " 'itsa_1',\n",
       " 'ivosidenib',\n",
       " 'jnj_26854165',\n",
       " 'jnj_7706621',\n",
       " 'ki16425',\n",
       " 'ki8751',\n",
       " 'kw_2449',\n",
       " 'lapatinib_ditosylate',\n",
       " 'lenalidomide',\n",
       " 'linifanib',\n",
       " 'lomustine',\n",
       " 'luminespib',\n",
       " 'm344',\n",
       " 'maraviroc',\n",
       " 'mc1568',\n",
       " 'meprednisone',\n",
       " 'mercaptopurine',\n",
       " 'mesna',\n",
       " 'mk_0752',\n",
       " 'mk_5108',\n",
       " 'mln8054',\n",
       " 'mocetinostat',\n",
       " 'momelotinib',\n",
       " 'motesanib_diphosphate',\n",
       " 'navitoclax',\n",
       " 'nilotinib',\n",
       " 'nintedanib',\n",
       " 'nvp_bsk805_2hcl',\n",
       " 'obatoclax_mesylate',\n",
       " 'ofloxacin',\n",
       " 'panobinostat',\n",
       " 'patupilone',\n",
       " 'pci_34051',\n",
       " 'pd173074',\n",
       " 'pd98059',\n",
       " 'pelitinib',\n",
       " 'pf_3845',\n",
       " 'pf_573228',\n",
       " 'pfi_1',\n",
       " 'pha_680632',\n",
       " 'pirarubicin',\n",
       " 'pj34',\n",
       " 'pracinostat',\n",
       " 'prednisone',\n",
       " 'quercetin',\n",
       " 'quisinostat_2hcl',\n",
       " 'raltitrexed',\n",
       " 'ramelteon',\n",
       " 'regorafenib',\n",
       " 'resminostat',\n",
       " 'resveratrol',\n",
       " 'rg108',\n",
       " 'rigosertib',\n",
       " 'roscovitine',\n",
       " 'roxadustat',\n",
       " 'rucaparib_phosphate',\n",
       " 'ruxolitinib',\n",
       " 's3i_201',\n",
       " 's_ruxolitinib',\n",
       " 'sb431542',\n",
       " 'selisistat',\n",
       " 'sgi_1776_free_base',\n",
       " 'sirtinol',\n",
       " 'sl_327',\n",
       " 'sns_314',\n",
       " 'sodium_phenylbutyrate',\n",
       " 'sorafenib_tosylate',\n",
       " 'srt1720_hcl',\n",
       " 'srt2104',\n",
       " 'srt3025_hcl',\n",
       " 'streptozotocin',\n",
       " 'tacedinaline',\n",
       " 'tak_901',\n",
       " 'tanespimycin',\n",
       " 'tazemetostat',\n",
       " 'temsirolimus',\n",
       " 'tg101209',\n",
       " 'tgx_221',\n",
       " 'thalidomide',\n",
       " 'thiotepa',\n",
       " 'tie2_kinase_inhibitor',\n",
       " 'tmp195',\n",
       " 'tofacitinib_citrate',\n",
       " 'toremifene_citrate',\n",
       " 'tozasertib',\n",
       " 'trametinib',\n",
       " 'tranylcypromine_hcl',\n",
       " 'triamcinolone_acetonide',\n",
       " 'trichostatin_a',\n",
       " 'tubastatin_a_hcl',\n",
       " 'tucidinostat',\n",
       " 'unc0379',\n",
       " 'unc0631',\n",
       " 'unc1999',\n",
       " 'valproic_acid_sodium_salt',\n",
       " 'vandetanib',\n",
       " 'veliparib',\n",
       " 'whi_p154',\n",
       " 'wp1066',\n",
       " 'xav_939',\n",
       " 'ym155',\n",
       " 'zileuton',\n",
       " 'zm_447439']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_datasets.test.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2_methoxyestradiol',\n",
       " '_jq1',\n",
       " 'a_366',\n",
       " 'abexinostat',\n",
       " 'abt_737',\n",
       " 'ac480',\n",
       " 'ag_14361',\n",
       " 'ag_490',\n",
       " 'aicar',\n",
       " 'alendronate_sodium_trihydrate',\n",
       " 'alisertib',\n",
       " 'altretamine',\n",
       " 'alvespimycin_hcl',\n",
       " 'amg_900',\n",
       " 'aminoglutethimide',\n",
       " 'amisulpride',\n",
       " 'anacardic_acid',\n",
       " 'andarine',\n",
       " 'ar_42',\n",
       " 'at9283',\n",
       " 'aurora_a_inhibitor_i',\n",
       " 'avagacestat',\n",
       " 'az_960',\n",
       " 'azacitidine',\n",
       " 'azd1480',\n",
       " 'barasertib',\n",
       " 'baricitinib',\n",
       " 'belinostat',\n",
       " 'bisindolylmaleimide_ix',\n",
       " 'bms_265246',\n",
       " 'bms_536924',\n",
       " 'bms_754807',\n",
       " 'bms_911543',\n",
       " 'bosutinib',\n",
       " 'brd4770',\n",
       " 'busulfan',\n",
       " 'capecitabine',\n",
       " 'carmofur',\n",
       " 'cediranib',\n",
       " 'celecoxib',\n",
       " 'cep_33779',\n",
       " 'cerdulatinib',\n",
       " 'cimetidine',\n",
       " 'clevudine',\n",
       " 'control',\n",
       " 'costunolide',\n",
       " 'crizotinib',\n",
       " 'cudc_101',\n",
       " 'cudc_907',\n",
       " 'curcumin',\n",
       " 'cyc116',\n",
       " 'cyclocytidine_hcl',\n",
       " 'dacinostat',\n",
       " 'danusertib',\n",
       " 'daphnetin',\n",
       " 'dasatinib',\n",
       " 'decitabine',\n",
       " 'disulfiram',\n",
       " 'divalproex_sodium',\n",
       " 'droxinostat',\n",
       " 'eed226',\n",
       " 'ellagic_acid',\n",
       " 'enmd_2076',\n",
       " 'enmd_2076_l__tartaric_acid',\n",
       " 'entacapone',\n",
       " 'entinostat',\n",
       " 'enzastaurin',\n",
       " 'epothilone_a',\n",
       " 'fasudil_hcl',\n",
       " 'fedratinib',\n",
       " 'filgotinib',\n",
       " 'flavopiridol_hcl',\n",
       " 'flll32',\n",
       " 'fluorouracil',\n",
       " 'fulvestrant',\n",
       " 'g007_lk',\n",
       " 'gandotinib',\n",
       " 'givinostat',\n",
       " 'glesatinib?',\n",
       " 'gsk1070916',\n",
       " 'gsk_j1',\n",
       " 'gsk_lsd1_2hcl',\n",
       " 'hesperadin',\n",
       " 'iniparib',\n",
       " 'ino_1001',\n",
       " 'iox2',\n",
       " 'itsa_1',\n",
       " 'ivosidenib',\n",
       " 'jnj_26854165',\n",
       " 'jnj_7706621',\n",
       " 'ki16425',\n",
       " 'ki8751',\n",
       " 'kw_2449',\n",
       " 'lapatinib_ditosylate',\n",
       " 'lenalidomide',\n",
       " 'linifanib',\n",
       " 'lomustine',\n",
       " 'luminespib',\n",
       " 'm344',\n",
       " 'maraviroc',\n",
       " 'mc1568',\n",
       " 'meprednisone',\n",
       " 'mercaptopurine',\n",
       " 'mesna',\n",
       " 'mk_0752',\n",
       " 'mk_5108',\n",
       " 'mln8054',\n",
       " 'mocetinostat',\n",
       " 'momelotinib',\n",
       " 'motesanib_diphosphate',\n",
       " 'navitoclax',\n",
       " 'nilotinib',\n",
       " 'nintedanib',\n",
       " 'nvp_bsk805_2hcl',\n",
       " 'obatoclax_mesylate',\n",
       " 'ofloxacin',\n",
       " 'panobinostat',\n",
       " 'patupilone',\n",
       " 'pci_34051',\n",
       " 'pd173074',\n",
       " 'pd98059',\n",
       " 'pelitinib',\n",
       " 'pf_3845',\n",
       " 'pf_573228',\n",
       " 'pfi_1',\n",
       " 'pha_680632',\n",
       " 'pirarubicin',\n",
       " 'pj34',\n",
       " 'pracinostat',\n",
       " 'prednisone',\n",
       " 'quercetin',\n",
       " 'quisinostat_2hcl',\n",
       " 'raltitrexed',\n",
       " 'ramelteon',\n",
       " 'regorafenib',\n",
       " 'resminostat',\n",
       " 'resveratrol',\n",
       " 'rg108',\n",
       " 'rigosertib',\n",
       " 'roscovitine',\n",
       " 'roxadustat',\n",
       " 'rucaparib_phosphate',\n",
       " 'ruxolitinib',\n",
       " 's3i_201',\n",
       " 's_ruxolitinib',\n",
       " 'sb431542',\n",
       " 'selisistat',\n",
       " 'sgi_1776_free_base',\n",
       " 'sirtinol',\n",
       " 'sl_327',\n",
       " 'sns_314',\n",
       " 'sodium_phenylbutyrate',\n",
       " 'sorafenib_tosylate',\n",
       " 'srt1720_hcl',\n",
       " 'srt2104',\n",
       " 'srt3025_hcl',\n",
       " 'streptozotocin',\n",
       " 'tacedinaline',\n",
       " 'tak_901',\n",
       " 'tanespimycin',\n",
       " 'tazemetostat',\n",
       " 'temsirolimus',\n",
       " 'tg101209',\n",
       " 'tgx_221',\n",
       " 'thalidomide',\n",
       " 'thiotepa',\n",
       " 'tie2_kinase_inhibitor',\n",
       " 'tmp195',\n",
       " 'tofacitinib_citrate',\n",
       " 'toremifene_citrate',\n",
       " 'tozasertib',\n",
       " 'trametinib',\n",
       " 'tranylcypromine_hcl',\n",
       " 'triamcinolone_acetonide',\n",
       " 'trichostatin_a',\n",
       " 'tubastatin_a_hcl',\n",
       " 'tucidinostat',\n",
       " 'unc0379',\n",
       " 'unc0631',\n",
       " 'unc1999',\n",
       " 'valproic_acid_sodium_salt',\n",
       " 'vandetanib',\n",
       " 'veliparib',\n",
       " 'whi_p154',\n",
       " 'wp1066',\n",
       " 'xav_939',\n",
       " 'ym155',\n",
       " 'zileuton',\n",
       " 'zm_447439']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t.adata.obs['drug'].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set()\n",
    "for x in cond_datasets.test:\n",
    "    y_set.add(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
