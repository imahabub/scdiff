{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from absl import logging\n",
    "from absl.flags import FLAGS\n",
    "from cellot import losses\n",
    "from cellot.utils.loaders import load\n",
    "from cellot.models.cellot import compute_loss_f, compute_loss_g, compute_w2_distance\n",
    "from cellot.train.summary import Logger\n",
    "from cellot.data.utils import cast_loader_to_iterator\n",
    "from cellot.models.ae import compute_scgen_shift\n",
    "from tqdm import trange\n",
    "\n",
    "from cellot.models.ae import AutoEncoder\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "logger = logging.getLogger(\"data_logger\")\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "TARGET = 'all' if not DEBUG else 'abexinostat'\n",
    "LATENT_DIM = 50\n",
    "\n",
    "from pathlib import Path\n",
    "outdir_path = '/Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/full_ae'\n",
    "outdir = Path(outdir_path)\n",
    "\n",
    "# %%\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "cachedir = outdir / \"cache\"\n",
    "cachedir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import GPUtil\n",
    "import os\n",
    "\n",
    "def get_free_gpu():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "    # Set environment variables for which GPUs to use.\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    chosen_gpu = ''.join(\n",
    "        [str(x) for x in GPUtil.getAvailable(order='memory')])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = chosen_gpu\n",
    "    print(f\"Using GPUs: {chosen_gpu}\")\n",
    "    return chosen_gpu\n",
    "\n",
    "status = cachedir / \"status\"\n",
    "status.write_text(\"running\")\n",
    "\n",
    "device = f'cuda:{get_free_gpu()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "import omegaconf\n",
    "\n",
    "if DEBUG:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "else:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "\n",
    "yaml_str = f\"\"\"\n",
    "model:\n",
    "   name: scgen\n",
    "   beta: 0.0\n",
    "   dropout: 0.0\n",
    "   hidden_units: [512, 512]\n",
    "   latent_dim: 50\n",
    "\n",
    "optim:\n",
    "   lr: 0.001\n",
    "   optimizer: Adam\n",
    "   weight_decay: 1.0e-05\n",
    "\n",
    "scheduler:\n",
    "   gamma: 0.5\n",
    "   step_size: 100000\n",
    "\n",
    "training:\n",
    "  cache_freq: 10000\n",
    "  eval_freq: 2500\n",
    "  logs_freq: 250\n",
    "  n_iters: {n_iters}\n",
    "\n",
    "data:\n",
    "  type: cell\n",
    "  source: control\n",
    "  condition: drug\n",
    "  path: /Mounts/rbg-storage1/users/johnyang/cellot/datasets/scrna-sciplex3/hvg.h5ad\n",
    "  target: {TARGET}\n",
    "\n",
    "datasplit:\n",
    "    groupby: drug   \n",
    "    name: train_test\n",
    "    test_size: 0.2\n",
    "    random_state: 0\n",
    "\n",
    "dataloader:\n",
    "    batch_size: {batch_size}\n",
    "    shuffle: true\n",
    "\"\"\"\n",
    "\n",
    "config = omegaconf.OmegaConf.create(yaml_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ### Utils\n",
    "\n",
    "# %%\n",
    "def load_lr_scheduler(optim, config):\n",
    "    if \"scheduler\" not in config:\n",
    "        return None\n",
    "\n",
    "    return torch.optim.lr_scheduler.StepLR(optim, **config.scheduler)\n",
    "\n",
    "def check_loss(*args):\n",
    "    for arg in args:\n",
    "        if torch.isnan(arg):\n",
    "            raise ValueError\n",
    "\n",
    "\n",
    "def load_item_from_save(path, key, default):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return default\n",
    "\n",
    "    ckpt = torch.load(path)\n",
    "    if key not in ckpt:\n",
    "        logging.warn(f\"'{key}' not found in ckpt: {str(path)}\")\n",
    "        return default\n",
    "\n",
    "    return ckpt[key]\n",
    "\n",
    "# %%\n",
    "import cellot.models\n",
    "from cellot.data.cell import load_cell_data\n",
    "\n",
    "\n",
    "def load_data(config, **kwargs):\n",
    "    data_type = config.get(\"data.type\", \"cell\")\n",
    "    if data_type in [\"cell\", \"cell-merged\", \"tupro-cohort\"]:\n",
    "        loadfxn = load_cell_data\n",
    "\n",
    "    elif data_type == \"toy\":\n",
    "        loadfxn = load_toy_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return loadfxn(config, **kwargs)\n",
    "\n",
    "\n",
    "def load_model(config, device, restore=None, **kwargs):\n",
    "    # def load_autoencoder_model(config, restore=None, **kwargs):\n",
    "    \n",
    "    def load_optimizer(config, params):\n",
    "        kwargs = dict(config.get(\"optim\", {}))\n",
    "        assert kwargs.pop(\"optimizer\", \"Adam\") == \"Adam\"\n",
    "        optim = torch.optim.Adam(params, **kwargs)\n",
    "        return optim\n",
    "\n",
    "\n",
    "    def load_networks(config, **kwargs):\n",
    "        kwargs = kwargs.copy()\n",
    "        kwargs.update(dict(config.get(\"model\", {})))\n",
    "        name = kwargs.pop(\"name\")\n",
    "\n",
    "        if name == \"scgen\":\n",
    "            model = AutoEncoder\n",
    "\n",
    "        # elif name == \"cae\":\n",
    "        #     model = ConditionalAutoEncoder\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        return model(**kwargs)\n",
    "    \n",
    "    model = load_networks(config, **kwargs)\n",
    "    optim = load_optimizer(config, model.parameters())\n",
    "\n",
    "    if restore is not None and Path(restore).exists():\n",
    "        print('Loading model from checkpoint')\n",
    "        ckpt = torch.load(restore, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optim.load_state_dict(ckpt[\"optim_state\"])\n",
    "        if config.model.name == \"scgen\" and \"code_means\" in ckpt:\n",
    "            model.code_means = ckpt[\"code_means\"]\n",
    "            \n",
    "    # logger.info(f'Model on device {next(model.parameters()).device}')\n",
    "\n",
    "    return model, optim\n",
    "\n",
    "def load(config, device, restore=None, include_model_kwargs=False, **kwargs):\n",
    "\n",
    "    loader, model_kwargs = load_data(config, include_model_kwargs=True, **kwargs)\n",
    "\n",
    "    model, opt = load_model(config, device, restore=restore, **model_kwargs)\n",
    "\n",
    "    # if include_model_kwargs:\n",
    "    #     return model, opt, loader, model_kwargs\n",
    "\n",
    "    return model, opt, loader\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_dict(model, optim, **kwargs):\n",
    "    state = {\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optim.state_dict(),\n",
    "    }\n",
    "\n",
    "    if hasattr(model, \"code_means\"):\n",
    "        state[\"code_means\"] = model.code_means\n",
    "\n",
    "    state.update(kwargs)\n",
    "\n",
    "    return state\n",
    "\n",
    "def evaluate(vinputs):\n",
    "    with torch.no_grad():\n",
    "        loss, comps, _ = model(vinputs)\n",
    "        loss = loss.mean()\n",
    "        comps = {k: v.mean().item() for k, v in comps._asdict().items()}\n",
    "        check_loss(loss)\n",
    "        logger.log(\"eval\", loss=loss.item(), step=step, **comps)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 17:10:15,450 Loaded cell data with TARGET all and OBS SHAPE (762039, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint\n"
     ]
    }
   ],
   "source": [
    "ae, _, loader = load(config, 'cuda', restore=cachedir / \"last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"R^3 diffusion methods.\"\"\"\n",
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "import torch\n",
    "\n",
    "\n",
    "class R3Diffuser:\n",
    "    \"\"\"VP-SDE diffuser class for translations.\"\"\"\n",
    "\n",
    "    def __init__(self, r3_conf):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            min_b: starting value in variance schedule.\n",
    "            max_b: ending value in variance schedule.\n",
    "        \"\"\"\n",
    "        self._r3_conf = r3_conf\n",
    "        self.min_b = r3_conf.min_b\n",
    "        self.max_b = r3_conf.max_b\n",
    "        self.schedule = r3_conf.schedule\n",
    "        self._score_scaling = r3_conf.score_scaling\n",
    "        self.latent_dim = r3_conf.latent_dim\n",
    "\n",
    "    def _scale(self, x):\n",
    "        return x * self._r3_conf.coordinate_scaling\n",
    "\n",
    "    def _unscale(self, x):\n",
    "        return x / self._r3_conf.coordinate_scaling\n",
    "\n",
    "    def b_t(self, t):\n",
    "        if np.any(t < 0) or np.any(t > 1):\n",
    "            raise ValueError(f'Invalid t={t}')\n",
    "        if self.schedule == 'linear': \n",
    "            return self.min_b + t*(self.max_b - self.min_b)\n",
    "        elif self.schedule == 'cosine':\n",
    "            return self.max_b + 0.5*(self.min_b - self.max_b)*(1 + np.cos(t*np.pi))\n",
    "        elif self.schedule == 'exponential':\n",
    "            sigma = t * np.log10(self.max_b) + (1 - t) * np.log10(self.min_b)\n",
    "            return 10 ** sigma\n",
    "        else:\n",
    "            raise ValueError(f'Unknown schedule {self.schedule}')\n",
    "    \n",
    "    def diffusion_coef(self, t):\n",
    "        \"\"\"Time-dependent diffusion coefficient.\"\"\"\n",
    "        return np.sqrt(self.b_t(t))\n",
    "\n",
    "    def drift_coef(self, x, t):\n",
    "        \"\"\"Time-dependent drift coefficient.\"\"\"\n",
    "        return -1/2 * self.b_t(t) * x\n",
    "\n",
    "    def sample_ref(self, n_samples: float=1):\n",
    "        return np.random.normal(size=(n_samples, self.latent_dim))\n",
    "\n",
    "    def marginal_b_t(self, t):\n",
    "        if self.schedule == 'linear':\n",
    "            return t*self.min_b + (1/2)*(t**2)*(self.max_b-self.min_b)\n",
    "        elif self.schedule == 'exponential': \n",
    "            return (self.max_b**t * self.min_b**(1-t) - self.min_b) / (\n",
    "                np.log(self.max_b) - np.log(self.min_b))\n",
    "        else:\n",
    "            raise ValueError(f'Unknown schedule {self.schedule}')\n",
    "\n",
    "    def calc_trans_0(self, score_t, x_t, t, use_torch=True):\n",
    "        beta_t = self.marginal_b_t(t)\n",
    "        beta_t = beta_t[..., None, None]\n",
    "        exp_fn = torch.exp if use_torch else np.exp\n",
    "        cond_var = 1 - exp_fn(-beta_t)\n",
    "        return (score_t * cond_var + x_t) / exp_fn(-1/2*beta_t)\n",
    "\n",
    "    def forward(self, x_t_1: np.ndarray, t: float, num_t: int):\n",
    "        \"\"\"Samples marginal p(x(t) | x(t-1)).\n",
    "\n",
    "        Args:\n",
    "            x_0: [..., n, 3] initial positions in Angstroms.\n",
    "            t: continuous time in [0, 1]. \n",
    "\n",
    "        Returns:\n",
    "            x_t: [..., n, 3] positions at time t in Angstroms.\n",
    "            score_t: [..., n, 3] score at time t in scaled Angstroms.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_t_1 = self._scale(x_t_1)\n",
    "        b_t = torch.tensor(self.marginal_b_t(t) / num_t).to(x_t_1.device)\n",
    "        z_t_1 = torch.tensor(np.random.normal(size=x_t_1.shape)).to(x_t_1.device)\n",
    "        x_t = torch.sqrt(1 - b_t) * x_t_1 + torch.sqrt(b_t) * z_t_1\n",
    "        return x_t\n",
    "    \n",
    "    def distribution(self, x_t, score_t, t, mask, dt):\n",
    "        x_t = self._scale(x_t)\n",
    "        g_t = self.diffusion_coef(t)\n",
    "        f_t = self.drift_coef(x_t, t)\n",
    "        std = g_t * np.sqrt(dt)\n",
    "        mu = x_t - (f_t - g_t**2 * score_t) * dt\n",
    "        if mask is not None:\n",
    "            mu *= mask[..., None]\n",
    "        return mu, std\n",
    "\n",
    "    def forward_marginal(self, x_0: np.ndarray, t: float):\n",
    "        \"\"\"Samples marginal p(x(t) | x(0)).\n",
    "\n",
    "        Args:\n",
    "            x_0: [..., n, 3] initial positions in Angstroms.\n",
    "            t: continuous time in [0, 1]. \n",
    "\n",
    "        Returns:\n",
    "            x_t: [..., n, 3] positions at time t in Angstroms.\n",
    "            score_t: [..., n, 3] score at time t in scaled Angstroms.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_0 = self._scale(x_0)\n",
    "        x_t = np.random.normal(\n",
    "            loc=np.exp(-1/2*self.marginal_b_t(t)) * x_0,\n",
    "            scale=np.sqrt(1 - np.exp(-self.marginal_b_t(t)))\n",
    "        )\n",
    "        score_t = self.score(x_t, x_0, t)\n",
    "        x_t = self._unscale(x_t)\n",
    "        return x_t, score_t\n",
    "\n",
    "    def score_scaling(self, t: float):\n",
    "        if self._score_scaling == 'var':\n",
    "            return 1 / self.conditional_var(t)\n",
    "        elif self._score_scaling == 'std':\n",
    "            return 1 / np.sqrt(self.conditional_var(t))\n",
    "        elif self._score_scaling == 'expected_norm':\n",
    "            return np.sqrt(2) / (gamma(1.5) * np.sqrt(self.conditional_var(t)))\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized scaling {self._score_scaling}')\n",
    "\n",
    "    def reverse(\n",
    "            self,\n",
    "            *,\n",
    "            x_t: np.ndarray,\n",
    "            score_t: np.ndarray,\n",
    "            t: float,\n",
    "            dt: float,\n",
    "            mask: np.ndarray=None,\n",
    "            center: bool=True,\n",
    "            ode: bool=False,\n",
    "            noise_scale: float=1.0,\n",
    "        ):\n",
    "        \"\"\"Simulates the reverse SDE for 1 step\n",
    "\n",
    "        Args:\n",
    "            x_t: [..., 3] current positions at time t in angstroms.\n",
    "            score_t: [..., 3] rotation score at time t.\n",
    "            t: continuous time in [0, 1].\n",
    "            dt: continuous step size in [0, 1].\n",
    "            mask: True indicates which residues to diffuse.\n",
    "\n",
    "        Returns:\n",
    "            [..., 3] positions at next step t-1.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_t = self._scale(x_t)\n",
    "        g_t = self.diffusion_coef(t)\n",
    "        f_t = self.drift_coef(x_t, t)\n",
    "        if ode:\n",
    "            # Probability flow ODE\n",
    "            perturb = (f_t - (1/2)*(g_t**2) * score_t) * dt\n",
    "        else:\n",
    "            # Usual stochastic dynamics\n",
    "            z = noise_scale * np.random.normal(size=score_t.shape)\n",
    "            perturb = (f_t - g_t**2 * score_t) * dt + g_t * np.sqrt(dt) * z\n",
    "\n",
    "        if mask is not None:\n",
    "            perturb *= mask[..., None]\n",
    "        else:\n",
    "            mask = np.ones(x_t.shape[:-1])\n",
    "        x_t_1 = x_t - perturb\n",
    "        if center:\n",
    "            com = np.sum(x_t_1, axis=-2) / np.sum(mask, axis=-1)[..., None]\n",
    "            x_t_1 -= com[..., None, :]\n",
    "        x_t_1 = self._unscale(x_t_1)\n",
    "        return x_t_1\n",
    "\n",
    "    def conditional_var(self, t, use_torch=False):\n",
    "        \"\"\"Conditional variance of p(xt|x0).\n",
    "\n",
    "        Var[x_t|x_0] = conditional_var(t)*I\n",
    "\n",
    "        \"\"\"\n",
    "        if use_torch:\n",
    "            return 1 - torch.exp(-self.marginal_b_t(t))\n",
    "        return 1 - np.exp(-self.marginal_b_t(t))\n",
    "\n",
    "    def score(self, x_t, x_0, t, use_torch=False, scale=False):\n",
    "        if use_torch:\n",
    "            exp_fn = torch.exp\n",
    "        else:\n",
    "            exp_fn = np.exp\n",
    "        if scale:\n",
    "            x_t = self._scale(x_t)\n",
    "            x_0 = self._scale(x_0)\n",
    "        return -(x_t - exp_fn(-1/2*self.marginal_b_t(t)) * x_0) / self.conditional_var(t, use_torch=use_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "r3_conf = OmegaConf.create({\n",
    "    'min_b': 0.01,\n",
    "    'max_b': 1.0,\n",
    "    'schedule': 'linear',\n",
    "    'score_scaling': 'var',\n",
    "    'coordinate_scaling': 1.0,\n",
    "    'latent_dim': LATENT_DIM,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuser = R3Diffuser(r3_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, Linear\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dim = 64\n",
    "num_layers = 2\n",
    "nhead = 1\n",
    "dim_feedforward = 128\n",
    "dropout = 0.1 if not DEBUG else 0.0\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import functools as fn\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim=64, output_dim=50):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def get_timestep_embedding(timesteps, embedding_dim, max_positions=10000):\n",
    "    # Code from https://github.com/hojonathanho/diffusion/blob/master/diffusion_tf/nn.py\n",
    "    assert len(timesteps.shape) == 1\n",
    "    timesteps = timesteps * max_positions\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(max_positions) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32, device=timesteps.device) * -emb)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = F.pad(emb, (0, 1), mode='constant')\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return emb\n",
    "\n",
    "class ScoreNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScoreNetwork, self).__init__()\n",
    "        \n",
    "        self.latent_dim = LATENT_DIM\n",
    "        self.model_dim = model_dim\n",
    "        self.dropout = dropout\n",
    "        print(f'Dropout is {self.dropout}')\n",
    "        self.embed_code_and_t = nn.Linear(LATENT_DIM + model_dim, model_dim)\n",
    "        self.trmr_layer = TransformerEncoderLayer(d_model=model_dim, nhead=8, dim_feedforward=2048, dropout=dropout)\n",
    "        self.pred_score = FeedForward(input_dim=model_dim, hidden_dim=64, output_dim=LATENT_DIM)\n",
    "        self.model = nn.ModuleList([self.embed_code_and_t, *[self.trmr_layer for _ in range(num_layers)], self.pred_score])\n",
    "        \n",
    "        self.timestep_embedder = fn.partial(\n",
    "            get_timestep_embedding,\n",
    "            embedding_dim=self.model_dim,\n",
    "            # max_positions=100\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        device = x.device\n",
    "        B, C = x.shape\n",
    "        t_embed = torch.tile(self.timestep_embedder(torch.tensor([t]).to(device)), dims=[B, 1])\n",
    "        \n",
    "        x = torch.cat([x, t_embed], dim=-1).to(device)\n",
    "        \n",
    "        for module in self.model[:-1]:  # iterate over all modules except the last one\n",
    "            x = module(x)\n",
    "        x = self.model[-1](x.squeeze(0))  # pass through the last module (FeedForward)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout is 0.1\n"
     ]
    }
   ],
   "source": [
    "score_network = ScoreNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295922"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in score_network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(score_network.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "STEP = 0\n",
    "ticker = trange(STEP, n_iters, initial=STEP, total=n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = cast_loader_to_iterator(loader, cycle_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = next(iterator.train).to(device)\n",
    "# inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder_net): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=50, bias=True)\n",
       "  )\n",
       "  (decoder_net): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (mse): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     ex_code = ae.encode(ex_batch).to(device)[None, 0, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_t = 0.0\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/6.29.23_latent_diff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(dt=0.001):\n",
    "    score_network.eval()\n",
    "    # log_freq = (1 / dt) / 100\n",
    "    # ex_code_np = ex_code.detach().cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        x_t, _ = diffuser.forward_marginal(ex_code_np, t=1.0)\n",
    "        \n",
    "        for i, t in enumerate(np.arange(1.0, 0, -dt)):\n",
    "            # if i % log_freq == 0:\n",
    "                # print(x_t)\n",
    "            x_t = torch.tensor(x_t).float().to(device)\n",
    "            pred_score = score_network(x_t, t)\n",
    "            \n",
    "            # pred_scores.append(pred_score)\n",
    "            # gt_scores.append(gt_score)\n",
    "            \n",
    "            # _, gt_score = diffuser.forward_marginal(ex_code_np.detach().cpu().numpy(), t=t)\n",
    "\n",
    "            # print(pred_score, gt_score)\n",
    "            \n",
    "            x_t = diffuser.reverse(x_t=x_t.detach().cpu().numpy(), score_t=pred_score.detach().cpu().numpy(), t=t, dt=dt, center=False)\n",
    "        \n",
    "        x_0 = x_t\n",
    "        writer.add_embedding(x_0, global_step=step, tag='reverse_sampled_x_0')\n",
    "        writer.add_embedding(ex_code_np, global_step=step, tag='gt_x_0')\n",
    "        euclidean_distance = np.linalg.norm(x_0 - ex_code_np)\n",
    "        writer.add_scalar('sampled_gt_dist', euclidean_distance, global_step=step)\n",
    "        \n",
    "        return x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250000 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ex_code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# '''\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# Get encoded representation\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# '''\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[39m# code = ae.encode(inputs)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m t \u001b[39m=\u001b[39m rng\u001b[39m.\u001b[39muniform(min_t, \u001b[39m1.0\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m x_t, gt_score_t \u001b[39m=\u001b[39m diffuser\u001b[39m.\u001b[39mforward_marginal(ex_code\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(), t\u001b[39m=\u001b[39mt)\n\u001b[1;32m     24\u001b[0m score_scaling \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(diffuser\u001b[39m.\u001b[39mscore_scaling(t))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m gt_score_t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(gt_score_t)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ex_code' is not defined"
     ]
    }
   ],
   "source": [
    "eval_freq=1000\n",
    "for step in ticker:\n",
    "\n",
    "    score_network.train()\n",
    "    \n",
    "    # if DEBUG:\n",
    "    #     inputs = ex_batch\n",
    "    # else:\n",
    "    inputs = next(iterator.train)\n",
    "    inputs = inputs.to(device)\n",
    "        \n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    # '''\n",
    "    # Get encoded representation\n",
    "    # '''\n",
    "    \n",
    "    code = ae.encode(inputs)\n",
    "    \n",
    "    t = rng.uniform(min_t, 1.0)\n",
    "    x_t, gt_score_t = diffuser.forward_marginal(code.detach().cpu().numpy(), t=t)\n",
    "    \n",
    "    score_scaling = torch.tensor(diffuser.score_scaling(t)).to(device)\n",
    "    gt_score_t = torch.tensor(gt_score_t).to(device)\n",
    "    \n",
    "    pred_score_t = score_network(torch.tensor(x_t).float().to(device), t)\n",
    "\n",
    "    score_mse = (gt_score_t - pred_score_t)**2\n",
    "    score_loss = torch.sum(\n",
    "        score_mse / score_scaling[None, None]**2,\n",
    "        dim=(-1, -2)\n",
    "    ) #/ (loss_mask.sum(dim=-1) + 1e-10)    \n",
    "    \n",
    "    # comps = {k: v.mean().item() for k, v in comps._asdict().items()}\n",
    "    score_loss.backward()\n",
    "    optimizer.step()\n",
    "    # check_loss(score_)\n",
    "\n",
    "    if step % config.training.logs_freq == 0:\n",
    "        # log to logger object\n",
    "        # logger.log(\"train\", loss=loss.item(), step=step, **comps)\n",
    "        writer.add_scalar('Training loss', score_loss.item(), global_step=step)\n",
    "        print(f'At step {step}, TRAINING loss is {score_loss.item()}')\n",
    "        \n",
    "    if step % eval_freq == 0:\n",
    "        sampled_x_0 = eval(dt=0.01)\n",
    "        print(f'At step {step}, sampled x_0 is {sampled_x_0[:, :2]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(score_network, '6.29.23.1D_mlp_score_network.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sns\u001b[39m.\u001b[39mscatterplot(\u001b[39mreversed\u001b[39m([x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(x_t_list))]), x_t_list)\n\u001b[1;32m      2\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mTime Step (dt = 0.001)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mx_t Value\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.scatterplot([x for x in range(len(x_t_list))], x_t_list)\n",
    "plt.xlabel('Time Step (dt = 0.001)')\n",
    "plt.ylabel('x_t Value')\n",
    "plt.title('Sampling x_t from learned reverse process, gt x_0 = 1.0, random init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
