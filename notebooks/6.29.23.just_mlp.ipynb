{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from absl import logging\n",
    "from absl.flags import FLAGS\n",
    "from cellot import losses\n",
    "from cellot.utils.loaders import load\n",
    "from cellot.models.cellot import compute_loss_f, compute_loss_g, compute_w2_distance\n",
    "from cellot.train.summary import Logger\n",
    "from cellot.data.utils import cast_loader_to_iterator\n",
    "from cellot.models.ae import compute_scgen_shift\n",
    "from tqdm import trange\n",
    "\n",
    "from cellot.models.ae import AutoEncoder\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "logger = logging.getLogger(\"data_logger\")\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "TARGET = 'all' if not DEBUG else 'abexinostat'\n",
    "LATENT_DIM = 1\n",
    "\n",
    "from pathlib import Path\n",
    "outdir_path = '/Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/full_ae'\n",
    "outdir = Path(outdir_path)\n",
    "\n",
    "# %%\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "cachedir = outdir / \"cache\"\n",
    "cachedir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import GPUtil\n",
    "import os\n",
    "\n",
    "def get_free_gpu():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "    # Set environment variables for which GPUs to use.\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    chosen_gpu = ''.join(\n",
    "        [str(x) for x in GPUtil.getAvailable(order='memory')])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = chosen_gpu\n",
    "    print(f\"Using GPUs: {chosen_gpu}\")\n",
    "    return chosen_gpu\n",
    "\n",
    "status = cachedir / \"status\"\n",
    "status.write_text(\"running\")\n",
    "\n",
    "device = f'cuda:{get_free_gpu()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "import omegaconf\n",
    "\n",
    "if DEBUG:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "else:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "\n",
    "yaml_str = f\"\"\"\n",
    "model:\n",
    "   name: scgen\n",
    "   beta: 0.0\n",
    "   dropout: 0.0\n",
    "   hidden_units: [512, 512]\n",
    "   latent_dim: 50\n",
    "\n",
    "optim:\n",
    "   lr: 0.001\n",
    "   optimizer: Adam\n",
    "   weight_decay: 1.0e-05\n",
    "\n",
    "scheduler:\n",
    "   gamma: 0.5\n",
    "   step_size: 100000\n",
    "\n",
    "training:\n",
    "  cache_freq: 10000\n",
    "  eval_freq: 2500\n",
    "  logs_freq: 250\n",
    "  n_iters: {n_iters}\n",
    "\n",
    "data:\n",
    "  type: cell\n",
    "  source: control\n",
    "  condition: drug\n",
    "  path: /Mounts/rbg-storage1/users/johnyang/cellot/datasets/scrna-sciplex3/hvg.h5ad\n",
    "  target: {TARGET}\n",
    "\n",
    "datasplit:\n",
    "    groupby: drug   \n",
    "    name: train_test\n",
    "    test_size: 0.2\n",
    "    random_state: 0\n",
    "\n",
    "dataloader:\n",
    "    batch_size: {batch_size}\n",
    "    shuffle: true\n",
    "\"\"\"\n",
    "\n",
    "config = omegaconf.OmegaConf.create(yaml_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ### Utils\n",
    "\n",
    "# %%\n",
    "def load_lr_scheduler(optim, config):\n",
    "    if \"scheduler\" not in config:\n",
    "        return None\n",
    "\n",
    "    return torch.optim.lr_scheduler.StepLR(optim, **config.scheduler)\n",
    "\n",
    "def check_loss(*args):\n",
    "    for arg in args:\n",
    "        if torch.isnan(arg):\n",
    "            raise ValueError\n",
    "\n",
    "\n",
    "def load_item_from_save(path, key, default):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return default\n",
    "\n",
    "    ckpt = torch.load(path)\n",
    "    if key not in ckpt:\n",
    "        logging.warn(f\"'{key}' not found in ckpt: {str(path)}\")\n",
    "        return default\n",
    "\n",
    "    return ckpt[key]\n",
    "\n",
    "# %%\n",
    "import cellot.models\n",
    "from cellot.data.cell import load_cell_data\n",
    "\n",
    "\n",
    "def load_data(config, **kwargs):\n",
    "    data_type = config.get(\"data.type\", \"cell\")\n",
    "    if data_type in [\"cell\", \"cell-merged\", \"tupro-cohort\"]:\n",
    "        loadfxn = load_cell_data\n",
    "\n",
    "    elif data_type == \"toy\":\n",
    "        loadfxn = load_toy_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return loadfxn(config, **kwargs)\n",
    "\n",
    "\n",
    "def load_model(config, device, restore=None, **kwargs):\n",
    "    # def load_autoencoder_model(config, restore=None, **kwargs):\n",
    "    \n",
    "    def load_optimizer(config, params):\n",
    "        kwargs = dict(config.get(\"optim\", {}))\n",
    "        assert kwargs.pop(\"optimizer\", \"Adam\") == \"Adam\"\n",
    "        optim = torch.optim.Adam(params, **kwargs)\n",
    "        return optim\n",
    "\n",
    "\n",
    "    def load_networks(config, **kwargs):\n",
    "        kwargs = kwargs.copy()\n",
    "        kwargs.update(dict(config.get(\"model\", {})))\n",
    "        name = kwargs.pop(\"name\")\n",
    "\n",
    "        if name == \"scgen\":\n",
    "            model = AutoEncoder\n",
    "\n",
    "        # elif name == \"cae\":\n",
    "        #     model = ConditionalAutoEncoder\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        return model(**kwargs)\n",
    "    \n",
    "    model = load_networks(config, **kwargs)\n",
    "    optim = load_optimizer(config, model.parameters())\n",
    "\n",
    "    if restore is not None and Path(restore).exists():\n",
    "        print('Loading model from checkpoint')\n",
    "        ckpt = torch.load(restore, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optim.load_state_dict(ckpt[\"optim_state\"])\n",
    "        if config.model.name == \"scgen\" and \"code_means\" in ckpt:\n",
    "            model.code_means = ckpt[\"code_means\"]\n",
    "            \n",
    "    # logger.info(f'Model on device {next(model.parameters()).device}')\n",
    "\n",
    "    return model, optim\n",
    "\n",
    "def load(config, device, restore=None, include_model_kwargs=False, **kwargs):\n",
    "\n",
    "    loader, model_kwargs = load_data(config, include_model_kwargs=True, **kwargs)\n",
    "\n",
    "    model, opt = load_model(config, device, restore=restore, **model_kwargs)\n",
    "\n",
    "    # if include_model_kwargs:\n",
    "    #     return model, opt, loader, model_kwargs\n",
    "\n",
    "    return model, opt, loader\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_dict(model, optim, **kwargs):\n",
    "    state = {\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optim.state_dict(),\n",
    "    }\n",
    "\n",
    "    if hasattr(model, \"code_means\"):\n",
    "        state[\"code_means\"] = model.code_means\n",
    "\n",
    "    state.update(kwargs)\n",
    "\n",
    "    return state\n",
    "\n",
    "def evaluate(vinputs):\n",
    "    with torch.no_grad():\n",
    "        loss, comps, _ = model(vinputs)\n",
    "        loss = loss.mean()\n",
    "        comps = {k: v.mean().item() for k, v in comps._asdict().items()}\n",
    "        check_loss(loss)\n",
    "        logger.log(\"eval\", loss=loss.item(), step=step, **comps)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 14:01:26,554 Loaded cell data with TARGET abexinostat and OBS SHAPE (22070, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint\n"
     ]
    }
   ],
   "source": [
    "_, _, loader = load(config, 'cuda', restore=cachedir / \"last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"R^3 diffusion methods.\"\"\"\n",
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "import torch\n",
    "\n",
    "\n",
    "class R3Diffuser:\n",
    "    \"\"\"VP-SDE diffuser class for translations.\"\"\"\n",
    "\n",
    "    def __init__(self, r3_conf):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            min_b: starting value in variance schedule.\n",
    "            max_b: ending value in variance schedule.\n",
    "        \"\"\"\n",
    "        self._r3_conf = r3_conf\n",
    "        self.min_b = r3_conf.min_b\n",
    "        self.max_b = r3_conf.max_b\n",
    "        self.schedule = r3_conf.schedule\n",
    "        self._score_scaling = r3_conf.score_scaling\n",
    "        self.latent_dim = r3_conf.latent_dim\n",
    "\n",
    "    def _scale(self, x):\n",
    "        return x * self._r3_conf.coordinate_scaling\n",
    "\n",
    "    def _unscale(self, x):\n",
    "        return x / self._r3_conf.coordinate_scaling\n",
    "\n",
    "    def b_t(self, t):\n",
    "        if np.any(t < 0) or np.any(t > 1):\n",
    "            raise ValueError(f'Invalid t={t}')\n",
    "        if self.schedule == 'linear': \n",
    "            return self.min_b + t*(self.max_b - self.min_b)\n",
    "        elif self.schedule == 'cosine':\n",
    "            return self.max_b + 0.5*(self.min_b - self.max_b)*(1 + np.cos(t*np.pi))\n",
    "        elif self.schedule == 'exponential':\n",
    "            sigma = t * np.log10(self.max_b) + (1 - t) * np.log10(self.min_b)\n",
    "            return 10 ** sigma\n",
    "        else:\n",
    "            raise ValueError(f'Unknown schedule {self.schedule}')\n",
    "    \n",
    "    def diffusion_coef(self, t):\n",
    "        \"\"\"Time-dependent diffusion coefficient.\"\"\"\n",
    "        return np.sqrt(self.b_t(t))\n",
    "\n",
    "    def drift_coef(self, x, t):\n",
    "        \"\"\"Time-dependent drift coefficient.\"\"\"\n",
    "        return -1/2 * self.b_t(t) * x\n",
    "\n",
    "    def sample_ref(self, n_samples: float=1):\n",
    "        return np.random.normal(size=(n_samples, self.latent_dim))\n",
    "\n",
    "    def marginal_b_t(self, t):\n",
    "        if self.schedule == 'linear':\n",
    "            return t*self.min_b + (1/2)*(t**2)*(self.max_b-self.min_b)\n",
    "        elif self.schedule == 'exponential': \n",
    "            return (self.max_b**t * self.min_b**(1-t) - self.min_b) / (\n",
    "                np.log(self.max_b) - np.log(self.min_b))\n",
    "        else:\n",
    "            raise ValueError(f'Unknown schedule {self.schedule}')\n",
    "\n",
    "    def calc_trans_0(self, score_t, x_t, t, use_torch=True):\n",
    "        beta_t = self.marginal_b_t(t)\n",
    "        beta_t = beta_t[..., None, None]\n",
    "        exp_fn = torch.exp if use_torch else np.exp\n",
    "        cond_var = 1 - exp_fn(-beta_t)\n",
    "        return (score_t * cond_var + x_t) / exp_fn(-1/2*beta_t)\n",
    "\n",
    "    def forward(self, x_t_1: np.ndarray, t: float, num_t: int):\n",
    "        \"\"\"Samples marginal p(x(t) | x(t-1)).\n",
    "\n",
    "        Args:\n",
    "            x_0: [..., n, 3] initial positions in Angstroms.\n",
    "            t: continuous time in [0, 1]. \n",
    "\n",
    "        Returns:\n",
    "            x_t: [..., n, 3] positions at time t in Angstroms.\n",
    "            score_t: [..., n, 3] score at time t in scaled Angstroms.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_t_1 = self._scale(x_t_1)\n",
    "        b_t = torch.tensor(self.marginal_b_t(t) / num_t).to(x_t_1.device)\n",
    "        z_t_1 = torch.tensor(np.random.normal(size=x_t_1.shape)).to(x_t_1.device)\n",
    "        x_t = torch.sqrt(1 - b_t) * x_t_1 + torch.sqrt(b_t) * z_t_1\n",
    "        return x_t\n",
    "    \n",
    "    def distribution(self, x_t, score_t, t, mask, dt):\n",
    "        x_t = self._scale(x_t)\n",
    "        g_t = self.diffusion_coef(t)\n",
    "        f_t = self.drift_coef(x_t, t)\n",
    "        std = g_t * np.sqrt(dt)\n",
    "        mu = x_t - (f_t - g_t**2 * score_t) * dt\n",
    "        if mask is not None:\n",
    "            mu *= mask[..., None]\n",
    "        return mu, std\n",
    "\n",
    "    def forward_marginal(self, x_0: np.ndarray, t: float):\n",
    "        \"\"\"Samples marginal p(x(t) | x(0)).\n",
    "\n",
    "        Args:\n",
    "            x_0: [..., n, 3] initial positions in Angstroms.\n",
    "            t: continuous time in [0, 1]. \n",
    "\n",
    "        Returns:\n",
    "            x_t: [..., n, 3] positions at time t in Angstroms.\n",
    "            score_t: [..., n, 3] score at time t in scaled Angstroms.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_0 = self._scale(x_0)\n",
    "        x_t = np.random.normal(\n",
    "            loc=np.exp(-1/2*self.marginal_b_t(t)) * x_0,\n",
    "            scale=np.sqrt(1 - np.exp(-self.marginal_b_t(t)))\n",
    "        )\n",
    "        score_t = self.score(x_t, x_0, t)\n",
    "        x_t = self._unscale(x_t)\n",
    "        return x_t, score_t\n",
    "\n",
    "    def score_scaling(self, t: float):\n",
    "        if self._score_scaling == 'var':\n",
    "            return 1 / self.conditional_var(t)\n",
    "        elif self._score_scaling == 'std':\n",
    "            return 1 / np.sqrt(self.conditional_var(t))\n",
    "        elif self._score_scaling == 'expected_norm':\n",
    "            return np.sqrt(2) / (gamma(1.5) * np.sqrt(self.conditional_var(t)))\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized scaling {self._score_scaling}')\n",
    "\n",
    "    def reverse(\n",
    "            self,\n",
    "            *,\n",
    "            x_t: np.ndarray,\n",
    "            score_t: np.ndarray,\n",
    "            t: float,\n",
    "            dt: float,\n",
    "            mask: np.ndarray=None,\n",
    "            center: bool=True,\n",
    "            ode: bool=False,\n",
    "            noise_scale: float=1.0,\n",
    "        ):\n",
    "        \"\"\"Simulates the reverse SDE for 1 step\n",
    "\n",
    "        Args:\n",
    "            x_t: [..., 3] current positions at time t in angstroms.\n",
    "            score_t: [..., 3] rotation score at time t.\n",
    "            t: continuous time in [0, 1].\n",
    "            dt: continuous step size in [0, 1].\n",
    "            mask: True indicates which residues to diffuse.\n",
    "\n",
    "        Returns:\n",
    "            [..., 3] positions at next step t-1.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_t = self._scale(x_t)\n",
    "        g_t = self.diffusion_coef(t)\n",
    "        f_t = self.drift_coef(x_t, t)\n",
    "        if ode:\n",
    "            # Probability flow ODE\n",
    "            perturb = (f_t - (1/2)*(g_t**2) * score_t) * dt\n",
    "        else:\n",
    "            # Usual stochastic dynamics\n",
    "            z = noise_scale * np.random.normal(size=score_t.shape)\n",
    "            perturb = (f_t - g_t**2 * score_t) * dt + g_t * np.sqrt(dt) * z\n",
    "\n",
    "        if mask is not None:\n",
    "            perturb *= mask[..., None]\n",
    "        else:\n",
    "            mask = np.ones(x_t.shape[:-1])\n",
    "        x_t_1 = x_t - perturb\n",
    "        if center:\n",
    "            com = np.sum(x_t_1, axis=-2) / np.sum(mask, axis=-1)[..., None]\n",
    "            x_t_1 -= com[..., None, :]\n",
    "        x_t_1 = self._unscale(x_t_1)\n",
    "        return x_t_1\n",
    "\n",
    "    def conditional_var(self, t, use_torch=False):\n",
    "        \"\"\"Conditional variance of p(xt|x0).\n",
    "\n",
    "        Var[x_t|x_0] = conditional_var(t)*I\n",
    "\n",
    "        \"\"\"\n",
    "        if use_torch:\n",
    "            return 1 - torch.exp(-self.marginal_b_t(t))\n",
    "        return 1 - np.exp(-self.marginal_b_t(t))\n",
    "\n",
    "    def score(self, x_t, x_0, t, use_torch=False, scale=False):\n",
    "        if use_torch:\n",
    "            exp_fn = torch.exp\n",
    "        else:\n",
    "            exp_fn = np.exp\n",
    "        if scale:\n",
    "            x_t = self._scale(x_t)\n",
    "            x_0 = self._scale(x_0)\n",
    "        return -(x_t - exp_fn(-1/2*self.marginal_b_t(t)) * x_0) / self.conditional_var(t, use_torch=use_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "r3_conf = OmegaConf.create({\n",
    "    'min_b': 0.01,\n",
    "    'max_b': 1.0,\n",
    "    'schedule': 'linear',\n",
    "    'score_scaling': 'var',\n",
    "    'coordinate_scaling': 1.0,\n",
    "    'latent_dim': LATENT_DIM,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuser = R3Diffuser(r3_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, Linear\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dim = 64\n",
    "num_layers = 2\n",
    "nhead = 1\n",
    "dim_feedforward = 128\n",
    "dropout = 0.1 if not DEBUG else 0.0\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import functools as fn\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim=64, output_dim=50):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def get_timestep_embedding(timesteps, embedding_dim, max_positions=10000):\n",
    "    # Code from https://github.com/hojonathanho/diffusion/blob/master/diffusion_tf/nn.py\n",
    "    assert len(timesteps.shape) == 1\n",
    "    timesteps = timesteps * max_positions\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(max_positions) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32, device=timesteps.device) * -emb)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = F.pad(emb, (0, 1), mode='constant')\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return emb\n",
    "\n",
    "class ScoreNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScoreNetwork, self).__init__()\n",
    "        \n",
    "        self.latent_dim = LATENT_DIM\n",
    "        self.model_dim = model_dim\n",
    "        self.dropout = dropout\n",
    "        print(f'Dropout is {self.dropout}')\n",
    "        self.embed_code_and_t = nn.Linear(LATENT_DIM + model_dim, model_dim)\n",
    "        # self.trmr_layer = TransformerEncoderLayer(d_model=model_dim, nhead=8, dim_feedforward=2048, dropout=dropout)\n",
    "        self.pred_score = FeedForward(input_dim=model_dim, hidden_dim=64, output_dim=LATENT_DIM)\n",
    "        self.model = nn.ModuleList([self.embed_code_and_t, self.pred_score]) #*[self.trmr_layer for _ in range(num_layers)], self.pred_score])\n",
    "        \n",
    "        self.timestep_embedder = fn.partial(\n",
    "            get_timestep_embedding,\n",
    "            embedding_dim=self.model_dim,\n",
    "            # max_positions=100\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        device = x.device\n",
    "        B, C = x.shape\n",
    "        t_embed = torch.tile(self.timestep_embedder(torch.tensor([t]).to(device)), dims=[B, 1])\n",
    "        \n",
    "        x = torch.cat([x, t_embed], dim=-1).to(device)\n",
    "        \n",
    "        for module in self.model[:-1]:  # iterate over all modules except the last one\n",
    "            x = module(x)\n",
    "        x = self.model[-1](x.squeeze(0))  # pass through the last module (FeedForward)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout is 0.0\n"
     ]
    }
   ],
   "source": [
    "score_network = ScoreNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8449"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in score_network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(score_network.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "STEP = 0\n",
    "ticker = trange(STEP, n_iters, initial=STEP, total=n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = cast_loader_to_iterator(loader, cycle_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = next(iterator.train).to(device)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     ex_code = ae.encode(ex_batch).to(device)[None, 0, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_code = torch.ones((1, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_t = 0.0\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/6.29.23_just_mlp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(dt=0.001):\n",
    "    score_network.eval()\n",
    "    # log_freq = (1 / dt) / 100\n",
    "    with torch.no_grad():\n",
    "        x_t, _ = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=1.0)\n",
    "        \n",
    "        for i, t in enumerate(np.arange(1.0, 0, -dt)):\n",
    "            # if i % log_freq == 0:\n",
    "                # print(x_t)\n",
    "            x_t = torch.tensor(x_t).float().to(device)\n",
    "            pred_score = score_network(x_t, t)\n",
    "            \n",
    "            # pred_scores.append(pred_score)\n",
    "            # gt_scores.append(gt_score)\n",
    "            \n",
    "            # _, gt_score = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=t)\n",
    "\n",
    "            # print(pred_score, gt_score)\n",
    "            \n",
    "            x_t = diffuser.reverse(x_t=x_t.detach().cpu().numpy(), score_t=pred_score.detach().cpu().numpy(), t=t, dt=dt, center=False)\n",
    "        \n",
    "        x_0 = x_t\n",
    "        writer.add_embedding(x_0, global_step=step, tag='reverse_sampled_x_0')\n",
    "        writer.add_embedding(ex_code, global_step=step, tag='gt_x_0')\n",
    "        writer.add_scalar('sampled x_0', x_0.item(), global_step=step)\n",
    "        return x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 0, TRAINING loss is 0.016103996297957106\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "At step 0, sampled x_0 is 1.9832672796580197\n",
      "At step 250, TRAINING loss is 0.008250040702373312\n",
      "At step 500, TRAINING loss is 0.0732137037903677\n",
      "At step 750, TRAINING loss is 0.0011258302791026806\n",
      "At step 1000, TRAINING loss is 0.04988190783921049\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "At step 1000, sampled x_0 is 1.592369857489077\n",
      "At step 1250, TRAINING loss is 0.1281285749871976\n",
      "At step 1500, TRAINING loss is 1.1020548745167327e-05\n",
      "At step 1750, TRAINING loss is 0.18820603388961382\n",
      "At step 2000, TRAINING loss is 0.009796415472672725\n",
      "At step 2000, sampled x_0 is 1.2410071643520184\n",
      "At step 2250, TRAINING loss is 0.09113424806799422\n",
      "At step 2500, TRAINING loss is 0.029481715600925846\n",
      "At step 2750, TRAINING loss is 4.2755060424247e-05\n",
      "At step 3000, TRAINING loss is 0.016949549770040595\n",
      "At step 3000, sampled x_0 is 1.0413411437013247\n",
      "At step 3250, TRAINING loss is 0.003222761950755341\n",
      "At step 3500, TRAINING loss is 6.333223921422762e-05\n",
      "At step 3750, TRAINING loss is 0.0002824990365994052\n",
      "At step 4000, TRAINING loss is 3.0558326999542225e-05\n",
      "At step 4000, sampled x_0 is 1.6978931044887549\n",
      "At step 4250, TRAINING loss is 0.004117070992033519\n",
      "At step 4500, TRAINING loss is 0.033022378736523056\n",
      "At step 4750, TRAINING loss is 0.001073332499286703\n",
      "At step 5000, TRAINING loss is 0.1412661864757881\n",
      "At step 5000, sampled x_0 is 0.4899196943939815\n",
      "At step 5250, TRAINING loss is 0.0016631254192185792\n",
      "At step 5500, TRAINING loss is 0.01967556388874046\n",
      "At step 5750, TRAINING loss is 1.4045386683889714e-05\n",
      "At step 6000, TRAINING loss is 0.005799978589957889\n",
      "At step 6000, sampled x_0 is 1.021512303835779\n",
      "At step 6250, TRAINING loss is 0.0002766126395226713\n",
      "At step 6500, TRAINING loss is 0.0008529209425962587\n",
      "At step 6750, TRAINING loss is 7.551379464171595e-05\n",
      "At step 7000, TRAINING loss is 0.005748765669193008\n",
      "At step 7000, sampled x_0 is 0.6352271984957326\n",
      "At step 7250, TRAINING loss is 0.002552895564493405\n",
      "At step 7500, TRAINING loss is 0.0159130288257384\n",
      "At step 7750, TRAINING loss is 0.022983428145344837\n",
      "At step 8000, TRAINING loss is 0.0020644267210931998\n",
      "At step 8000, sampled x_0 is 0.8493559051868016\n",
      "At step 8250, TRAINING loss is 0.0014491742426468973\n",
      "At step 8500, TRAINING loss is 0.00428593180028842\n",
      "At step 8750, TRAINING loss is 0.07090865803600824\n",
      "At step 9000, TRAINING loss is 0.004256100991691224\n",
      "At step 9000, sampled x_0 is 0.9351032088045602\n",
      "At step 9250, TRAINING loss is 0.036566706340008366\n",
      "At step 9500, TRAINING loss is 0.021613772071856257\n",
      "At step 9750, TRAINING loss is 0.0035167637995920363\n",
      "At step 10000, TRAINING loss is 0.0015761040106588363\n",
      "At step 10000, sampled x_0 is 1.3400764362537871\n",
      "At step 10250, TRAINING loss is 0.13108077006620567\n",
      "At step 10500, TRAINING loss is 0.0024494972867819273\n",
      "At step 10750, TRAINING loss is 0.003535872497460119\n",
      "At step 11000, TRAINING loss is 0.0004952904904587619\n",
      "At step 11000, sampled x_0 is 1.0796051646150995\n",
      "At step 11250, TRAINING loss is 0.019014683008592843\n",
      "At step 11500, TRAINING loss is 0.001428383601224576\n",
      "At step 11750, TRAINING loss is 0.00011857548285163354\n",
      "At step 12000, TRAINING loss is 0.039663002151814175\n",
      "At step 12000, sampled x_0 is 1.6219410441517024\n",
      "At step 12250, TRAINING loss is 0.03986139423040998\n",
      "At step 12500, TRAINING loss is 7.285629439368353e-05\n",
      "At step 12750, TRAINING loss is 0.0013269596917848436\n",
      "At step 13000, TRAINING loss is 0.0009371141915627536\n",
      "At step 13000, sampled x_0 is 0.9532266508746092\n",
      "At step 13250, TRAINING loss is 0.10399993423082263\n",
      "At step 13500, TRAINING loss is 1.7794378938346264e-05\n",
      "At step 13750, TRAINING loss is 0.00028598996275851576\n",
      "At step 14000, TRAINING loss is 0.0002787711723056895\n",
      "At step 14000, sampled x_0 is 0.6958073113024642\n",
      "At step 14250, TRAINING loss is 1.5445271566130594e-05\n",
      "At step 14500, TRAINING loss is 0.003629779413027339\n",
      "At step 14750, TRAINING loss is 0.0001344635767107133\n",
      "At step 15000, TRAINING loss is 0.008259409334017592\n",
      "At step 15000, sampled x_0 is 0.5412363585856781\n",
      "At step 15250, TRAINING loss is 0.0069682669652341885\n",
      "At step 15500, TRAINING loss is 0.02483660317382086\n",
      "At step 15750, TRAINING loss is 0.009840500938215757\n",
      "At step 16000, TRAINING loss is 0.0004097410086896993\n",
      "At step 16000, sampled x_0 is 0.3603257439668498\n",
      "At step 16250, TRAINING loss is 0.0007078444301091879\n",
      "At step 16500, TRAINING loss is 0.004505640170987817\n",
      "At step 16750, TRAINING loss is 0.07570499281538019\n",
      "At step 17000, TRAINING loss is 0.0008009002276962609\n",
      "At step 17000, sampled x_0 is 0.9684688878041752\n",
      "At step 17250, TRAINING loss is 6.151671839349591e-05\n",
      "At step 17500, TRAINING loss is 0.0009377211501206098\n",
      "At step 17750, TRAINING loss is 0.0007011609101048724\n",
      "At step 18000, TRAINING loss is 0.00023607142730801175\n",
      "At step 18000, sampled x_0 is 1.1255720370991225\n",
      "At step 18250, TRAINING loss is 0.0004799529880549755\n",
      "At step 18500, TRAINING loss is 0.00046612145234219517\n",
      "At step 18750, TRAINING loss is 0.0170900970729878\n",
      "At step 19000, TRAINING loss is 0.01839214003515815\n",
      "At step 19000, sampled x_0 is 0.8898940299763355\n",
      "At step 19250, TRAINING loss is 0.005441624357294359\n",
      "At step 19500, TRAINING loss is 0.000395090799651365\n",
      "At step 19750, TRAINING loss is 0.000718260043889497\n",
      "At step 20000, TRAINING loss is 0.0011726010920065798\n",
      "At step 20000, sampled x_0 is 0.5412256792176292\n",
      "At step 20250, TRAINING loss is 0.004738738936026825\n",
      "At step 20500, TRAINING loss is 0.004396698103339465\n",
      "At step 20750, TRAINING loss is 0.0007863251205329689\n",
      "At step 21000, TRAINING loss is 0.0006291009296686711\n",
      "At step 21000, sampled x_0 is 1.1796361388957448\n",
      "At step 21250, TRAINING loss is 0.0024777166636326194\n",
      "At step 21500, TRAINING loss is 0.0003314644764761855\n",
      "At step 21750, TRAINING loss is 0.010326018627498613\n",
      "At step 22000, TRAINING loss is 0.0007834275662322505\n",
      "At step 22000, sampled x_0 is 0.9703079040190282\n",
      "At step 22250, TRAINING loss is 9.965441939336525e-11\n",
      "At step 22500, TRAINING loss is 0.0010200429956585628\n",
      "At step 22750, TRAINING loss is 0.0002284642087351695\n",
      "At step 23000, TRAINING loss is 2.695784314779032e-05\n",
      "At step 23000, sampled x_0 is 0.7417261096969618\n",
      "At step 23250, TRAINING loss is 0.0002950135239058017\n",
      "At step 23500, TRAINING loss is 0.0011497520680685044\n",
      "At step 23750, TRAINING loss is 0.0009272671158350289\n",
      "At step 24000, TRAINING loss is 0.003505093683647869\n",
      "At step 24000, sampled x_0 is 1.5924821688061803\n",
      "At step 24250, TRAINING loss is 0.00033718690045421337\n",
      "At step 24500, TRAINING loss is 5.936553837107157e-05\n",
      "At step 24750, TRAINING loss is 0.00015532276278243387\n",
      "At step 25000, TRAINING loss is 0.0005264302535231425\n",
      "At step 25000, sampled x_0 is 1.0085479454390944\n",
      "At step 25250, TRAINING loss is 0.01081745966654292\n",
      "At step 25500, TRAINING loss is 0.00012019279036779285\n",
      "At step 25750, TRAINING loss is 1.912016062494304e-06\n",
      "At step 26000, TRAINING loss is 4.995184960584583e-06\n",
      "At step 26000, sampled x_0 is 0.6983351603268232\n",
      "At step 26250, TRAINING loss is 0.0004461818522812919\n",
      "At step 26500, TRAINING loss is 2.1225868759153982e-05\n",
      "At step 26750, TRAINING loss is 0.03302005282289712\n",
      "At step 27000, TRAINING loss is 0.012320815398949327\n",
      "At step 27000, sampled x_0 is 0.905924267222773\n",
      "At step 27250, TRAINING loss is 1.5027504264659518e-05\n",
      "At step 27500, TRAINING loss is 0.00018227744777530748\n",
      "At step 27750, TRAINING loss is 0.0009545106197114418\n",
      "At step 28000, TRAINING loss is 0.0254600393594687\n",
      "At step 28000, sampled x_0 is 0.9372632633416031\n",
      "At step 28250, TRAINING loss is 0.0006985306018690733\n",
      "At step 28500, TRAINING loss is 0.00042093612953003786\n",
      "At step 28750, TRAINING loss is 0.00025519671971115565\n",
      "At step 29000, TRAINING loss is 0.00042745508393339293\n",
      "At step 29000, sampled x_0 is 0.7567748971113419\n",
      "At step 29250, TRAINING loss is 1.457712296768846e-05\n",
      "At step 29500, TRAINING loss is 0.0012671598701612743\n",
      "At step 29750, TRAINING loss is 0.0005588895524971266\n",
      "At step 30000, TRAINING loss is 0.0003492574823974124\n",
      "At step 30000, sampled x_0 is 0.8019127461001725\n",
      "At step 30250, TRAINING loss is 0.0022697109096688492\n",
      "At step 30500, TRAINING loss is 0.00016774375518578683\n",
      "At step 30750, TRAINING loss is 2.9384944162072356e-05\n",
      "At step 31000, TRAINING loss is 0.0016526324148292818\n",
      "At step 31000, sampled x_0 is 0.7934642097000069\n",
      "At step 31250, TRAINING loss is 2.241918589638037e-07\n",
      "At step 31500, TRAINING loss is 0.0014381177919855278\n",
      "At step 31750, TRAINING loss is 4.277405556304195e-05\n",
      "At step 32000, TRAINING loss is 0.005476809430475628\n",
      "At step 32000, sampled x_0 is 1.318837563669213\n",
      "At step 32250, TRAINING loss is 0.01050915414179116\n",
      "At step 32500, TRAINING loss is 0.000533521194937656\n",
      "At step 32750, TRAINING loss is 0.020965241946226454\n",
      "At step 33000, TRAINING loss is 0.00393920337640927\n",
      "At step 33000, sampled x_0 is 1.1510409868631553\n",
      "At step 33250, TRAINING loss is 5.396639262714009e-05\n",
      "At step 33500, TRAINING loss is 0.0013262066890103732\n",
      "At step 33750, TRAINING loss is 6.095720381206042e-05\n",
      "At step 34000, TRAINING loss is 0.0013990561575914194\n",
      "At step 34000, sampled x_0 is 1.056166837129904\n",
      "At step 34250, TRAINING loss is 0.0003921931676670608\n",
      "At step 34500, TRAINING loss is 0.00035776809532869097\n",
      "At step 34750, TRAINING loss is 0.0004818852924063159\n",
      "At step 35000, TRAINING loss is 0.00023036859469319662\n",
      "At step 35000, sampled x_0 is 1.0026161493217463\n",
      "At step 35250, TRAINING loss is 0.0001655084156972649\n",
      "At step 35500, TRAINING loss is 0.0009857486682162042\n",
      "At step 35750, TRAINING loss is 0.00019052298333289896\n",
      "At step 36000, TRAINING loss is 0.0023826498942499798\n",
      "At step 36000, sampled x_0 is 0.8307023510415721\n",
      "At step 36250, TRAINING loss is 1.3337921433742916e-05\n",
      "At step 36500, TRAINING loss is 0.0012369192220412796\n",
      "At step 36750, TRAINING loss is 0.005268696292934749\n",
      "At step 37000, TRAINING loss is 6.134673866898455e-05\n",
      "At step 37000, sampled x_0 is 0.8037103304159645\n",
      "At step 37250, TRAINING loss is 0.03195738300172327\n",
      "At step 37500, TRAINING loss is 1.1422415232106245e-05\n",
      "At step 37750, TRAINING loss is 0.00017105119789288285\n",
      "At step 38000, TRAINING loss is 0.0012555046546124397\n",
      "At step 38000, sampled x_0 is 0.9346763914609922\n",
      "At step 38250, TRAINING loss is 0.023566161903373493\n",
      "At step 38500, TRAINING loss is 0.00036588081195669975\n",
      "At step 38750, TRAINING loss is 0.0013945415251722596\n",
      "At step 39000, TRAINING loss is 0.00019682777686194536\n",
      "At step 39000, sampled x_0 is 0.8690325947392785\n",
      "At step 39250, TRAINING loss is 2.8473504211797463e-05\n",
      "At step 39500, TRAINING loss is 5.855438940578079e-05\n",
      "At step 39750, TRAINING loss is 0.0021145599610237695\n",
      "At step 40000, TRAINING loss is 0.00010207948881335981\n",
      "At step 40000, sampled x_0 is 0.5204324059033033\n",
      "At step 40250, TRAINING loss is 1.7978732319933697e-05\n",
      "At step 40500, TRAINING loss is 0.010288225064259733\n",
      "At step 40750, TRAINING loss is 0.00044522307494607345\n",
      "At step 41000, TRAINING loss is 0.0002791792263029664\n",
      "At step 41000, sampled x_0 is 0.8213531477981396\n",
      "At step 41250, TRAINING loss is 0.0035068188510829455\n",
      "At step 41500, TRAINING loss is 2.1657986846207852e-05\n",
      "At step 41750, TRAINING loss is 4.712719097905687e-05\n",
      "At step 42000, TRAINING loss is 0.0034973656484228034\n",
      "At step 42000, sampled x_0 is 1.072468005864871\n",
      "At step 42250, TRAINING loss is 0.0005105493763539113\n",
      "At step 42500, TRAINING loss is 1.4284233613009895e-05\n",
      "At step 42750, TRAINING loss is 0.0003726295518847064\n",
      "At step 43000, TRAINING loss is 0.002663701162761167\n",
      "At step 43000, sampled x_0 is 0.73711019405798\n",
      "At step 43250, TRAINING loss is 0.00022652313194132794\n",
      "At step 43500, TRAINING loss is 0.013330884573916483\n",
      "At step 43750, TRAINING loss is 0.012195765712144086\n",
      "At step 44000, TRAINING loss is 0.0007053813100103466\n",
      "At step 44000, sampled x_0 is 1.0093248454291108\n",
      "At step 44250, TRAINING loss is 6.538683254367159e-08\n",
      "At step 44500, TRAINING loss is 0.00014063464188218103\n",
      "At step 44750, TRAINING loss is 0.0008514082976829908\n",
      "At step 45000, TRAINING loss is 4.2503283305813584e-07\n",
      "At step 45000, sampled x_0 is 0.6548591484929509\n",
      "At step 45250, TRAINING loss is 2.2043102633665247e-05\n",
      "At step 45500, TRAINING loss is 0.00374376918042707\n",
      "At step 45750, TRAINING loss is 0.0003938919572388059\n",
      "At step 46000, TRAINING loss is 0.0004603700175868652\n",
      "At step 46000, sampled x_0 is 1.2443275793108404\n",
      "At step 46250, TRAINING loss is 0.0014237658931002522\n",
      "At step 46500, TRAINING loss is 0.00635574819535342\n",
      "At step 46750, TRAINING loss is 9.782936401737912e-05\n",
      "At step 47000, TRAINING loss is 0.0008182950541027923\n",
      "At step 47000, sampled x_0 is 1.1779486259657777\n",
      "At step 47250, TRAINING loss is 0.005126528587313191\n",
      "At step 47500, TRAINING loss is 7.315775614866165e-05\n",
      "At step 47750, TRAINING loss is 2.8588170425699877e-05\n",
      "At step 48000, TRAINING loss is 0.00014251033088680964\n",
      "At step 48000, sampled x_0 is 1.4029872482566823\n",
      "At step 48250, TRAINING loss is 0.002680408867991956\n",
      "At step 48500, TRAINING loss is 0.001751467722865685\n",
      "At step 48750, TRAINING loss is 8.273379466359944e-06\n",
      "At step 49000, TRAINING loss is 0.0001335122147594443\n",
      "At step 49000, sampled x_0 is 0.9676611306180244\n",
      "At step 49250, TRAINING loss is 6.676441058443438e-06\n",
      "At step 49500, TRAINING loss is 0.00034569789164190956\n",
      "At step 49750, TRAINING loss is 2.2482130338153955e-05\n",
      "At step 50000, TRAINING loss is 6.689904975833982e-05\n",
      "At step 50000, sampled x_0 is 0.9826915180051115\n",
      "At step 50250, TRAINING loss is 0.003226459256551884\n",
      "At step 50500, TRAINING loss is 0.013821301811355493\n",
      "At step 50750, TRAINING loss is 2.4950703045675994e-05\n",
      "At step 51000, TRAINING loss is 5.176866213853868e-07\n",
      "At step 51000, sampled x_0 is 0.8755333548264522\n",
      "At step 51250, TRAINING loss is 0.0003780082505690851\n",
      "At step 51500, TRAINING loss is 0.0004296413922918462\n",
      "At step 51750, TRAINING loss is 0.0003172384141901996\n",
      "At step 52000, TRAINING loss is 0.00032399066399615447\n",
      "At step 52000, sampled x_0 is 1.140579966803981\n",
      "At step 52250, TRAINING loss is 0.004145828812535555\n",
      "At step 52500, TRAINING loss is 0.0006117249328901398\n",
      "At step 52750, TRAINING loss is 0.0001519029137323745\n",
      "At step 53000, TRAINING loss is 0.011522557375270795\n",
      "At step 53000, sampled x_0 is 0.9866924238477409\n",
      "At step 53250, TRAINING loss is 0.00011374080897657544\n",
      "At step 53500, TRAINING loss is 0.00012664980152545788\n",
      "At step 53750, TRAINING loss is 0.0009629205199710003\n",
      "At step 54000, TRAINING loss is 0.004862821253541963\n",
      "At step 54000, sampled x_0 is 0.6248549628119384\n",
      "At step 54250, TRAINING loss is 0.00046399749293844273\n",
      "At step 54500, TRAINING loss is 2.9606802772804367e-06\n",
      "At step 54750, TRAINING loss is 0.004889385715708836\n",
      "At step 55000, TRAINING loss is 0.005709358362399956\n",
      "At step 55000, sampled x_0 is 0.9541141330512081\n",
      "At step 55250, TRAINING loss is 0.0023194697798389293\n",
      "At step 55500, TRAINING loss is 8.924300406884514e-05\n",
      "At step 55750, TRAINING loss is 5.549608321791766e-10\n",
      "At step 56000, TRAINING loss is 0.0009977102152230232\n",
      "At step 56000, sampled x_0 is 0.9071235386322541\n",
      "At step 56250, TRAINING loss is 1.1606487325843332e-05\n",
      "At step 56500, TRAINING loss is 0.00011029296934812329\n",
      "At step 56750, TRAINING loss is 0.03560050805810777\n",
      "At step 57000, TRAINING loss is 0.006317192330096992\n",
      "At step 57000, sampled x_0 is 0.9692697956775722\n",
      "At step 57250, TRAINING loss is 6.30914248488075e-07\n",
      "At step 57500, TRAINING loss is 0.0002819697162164207\n",
      "At step 57750, TRAINING loss is 2.3142389937353258e-10\n",
      "At step 58000, TRAINING loss is 0.00016476224797966945\n",
      "At step 58000, sampled x_0 is 1.018526886838134\n",
      "At step 58250, TRAINING loss is 0.0007592482683051353\n",
      "At step 58500, TRAINING loss is 0.0004958633048378092\n",
      "At step 58750, TRAINING loss is 9.851382801232942e-06\n",
      "At step 59000, TRAINING loss is 0.0001343180468980327\n",
      "At step 59000, sampled x_0 is 1.0999792713986865\n",
      "At step 59250, TRAINING loss is 0.002551374725411936\n",
      "At step 59500, TRAINING loss is 1.776803165260228e-05\n",
      "At step 59750, TRAINING loss is 0.00011255494807240717\n",
      "At step 60000, TRAINING loss is 0.0007264303781046345\n",
      "At step 60000, sampled x_0 is 0.9606129032844941\n",
      "At step 60250, TRAINING loss is 8.78083707617783e-06\n",
      "At step 60500, TRAINING loss is 0.00011419330225428129\n",
      "At step 60750, TRAINING loss is 0.00021777476848238816\n",
      "At step 61000, TRAINING loss is 8.744633419038505e-06\n",
      "At step 61000, sampled x_0 is 0.9843044025309159\n",
      "At step 61250, TRAINING loss is 0.00042482848112378787\n",
      "At step 61500, TRAINING loss is 9.411575635148448e-05\n",
      "At step 61750, TRAINING loss is 0.0003200104371278097\n",
      "At step 62000, TRAINING loss is 0.00012105191720045445\n",
      "At step 62000, sampled x_0 is 0.6552562287829354\n",
      "At step 62250, TRAINING loss is 0.0002676244754299777\n",
      "At step 62500, TRAINING loss is 0.00014139900074751097\n",
      "At step 62750, TRAINING loss is 0.0007903467837104126\n",
      "At step 63000, TRAINING loss is 0.00033302110137108364\n",
      "At step 63000, sampled x_0 is 0.8879964327235436\n",
      "At step 63250, TRAINING loss is 0.0014589331153221246\n",
      "At step 63500, TRAINING loss is 0.0010693246828928239\n",
      "At step 63750, TRAINING loss is 0.0006524965752107728\n",
      "At step 64000, TRAINING loss is 5.970105640957764e-05\n",
      "At step 64000, sampled x_0 is 0.945014662140434\n",
      "At step 64250, TRAINING loss is 0.00033987531673202955\n",
      "At step 64500, TRAINING loss is 3.518312127448685e-05\n",
      "At step 64750, TRAINING loss is 4.631314633286891e-05\n",
      "At step 65000, TRAINING loss is 0.0008175110604092295\n",
      "At step 65000, sampled x_0 is 0.961325878486952\n",
      "At step 65250, TRAINING loss is 0.0012870068506219353\n",
      "At step 65500, TRAINING loss is 0.00045104384492724583\n",
      "At step 65750, TRAINING loss is 0.000514062966324044\n",
      "At step 66000, TRAINING loss is 0.00493927385870775\n",
      "At step 66000, sampled x_0 is 0.9113896345947693\n",
      "At step 66250, TRAINING loss is 0.00293326699093345\n",
      "At step 66500, TRAINING loss is 0.003732091130344599\n",
      "At step 66750, TRAINING loss is 2.1458632100339627e-05\n",
      "At step 67000, TRAINING loss is 8.70385029110048e-07\n",
      "At step 67000, sampled x_0 is 1.1923481737542196\n",
      "At step 67250, TRAINING loss is 0.0013685611869358751\n",
      "At step 67500, TRAINING loss is 0.0004645262467424208\n",
      "At step 67750, TRAINING loss is 1.5117331266872128e-06\n",
      "At step 68000, TRAINING loss is 0.00027693075819664636\n",
      "At step 68000, sampled x_0 is 0.9009215043680155\n",
      "At step 68250, TRAINING loss is 0.0033062257273373074\n",
      "At step 68500, TRAINING loss is 0.00235592528797051\n",
      "At step 68750, TRAINING loss is 6.638552532417051e-05\n",
      "At step 69000, TRAINING loss is 2.5528289691551235e-05\n",
      "At step 69000, sampled x_0 is 0.871323747695462\n",
      "At step 69250, TRAINING loss is 6.572924865542349e-05\n",
      "At step 69500, TRAINING loss is 6.932081284899994e-05\n",
      "At step 69750, TRAINING loss is 0.0013683267144472108\n",
      "At step 70000, TRAINING loss is 0.0006309477840936894\n",
      "At step 70000, sampled x_0 is 0.9712273129283666\n",
      "At step 70250, TRAINING loss is 0.0001078527770716711\n",
      "At step 70500, TRAINING loss is 0.0002924293858791337\n",
      "At step 70750, TRAINING loss is 2.0291560432208354e-05\n",
      "At step 71000, TRAINING loss is 0.0033917141601531734\n",
      "At step 71000, sampled x_0 is 0.9273620320470384\n",
      "At step 71250, TRAINING loss is 0.00027222083512921886\n",
      "At step 71500, TRAINING loss is 0.0009288686072210831\n",
      "At step 71750, TRAINING loss is 0.0013235987118827867\n",
      "At step 72000, TRAINING loss is 0.00017470014492370484\n",
      "At step 72000, sampled x_0 is 1.0031545418621663\n",
      "At step 72250, TRAINING loss is 0.00010053845536515496\n",
      "At step 72500, TRAINING loss is 0.0003703619530226307\n",
      "At step 72750, TRAINING loss is 0.0006826374750479531\n",
      "At step 73000, TRAINING loss is 0.0009831979011026956\n",
      "At step 73000, sampled x_0 is 0.7737377262626377\n",
      "At step 73250, TRAINING loss is 6.2674463125068855e-06\n",
      "At step 73500, TRAINING loss is 6.886125423846854e-05\n",
      "At step 73750, TRAINING loss is 3.86987945776535e-05\n",
      "At step 74000, TRAINING loss is 3.439098977183915e-05\n",
      "At step 74000, sampled x_0 is 1.0770553940440628\n",
      "At step 74250, TRAINING loss is 3.2034033680228344e-05\n",
      "At step 74500, TRAINING loss is 0.00010914893422025134\n",
      "At step 74750, TRAINING loss is 3.75657494375942e-06\n",
      "At step 75000, TRAINING loss is 5.589595034654465e-05\n",
      "At step 75000, sampled x_0 is 0.957618967023777\n",
      "At step 75250, TRAINING loss is 0.0002956486991713505\n",
      "At step 75500, TRAINING loss is 0.00017300039044932167\n",
      "At step 75750, TRAINING loss is 1.4025547126682422e-05\n",
      "At step 76000, TRAINING loss is 0.002853572869038684\n",
      "At step 76000, sampled x_0 is 1.2495722548744526\n",
      "At step 76250, TRAINING loss is 0.001695589264055653\n",
      "At step 76500, TRAINING loss is 2.331735231170417e-05\n",
      "At step 76750, TRAINING loss is 3.770042153732571e-05\n",
      "At step 77000, TRAINING loss is 9.827339066906661e-05\n",
      "At step 77000, sampled x_0 is 0.9878156200373064\n",
      "At step 77250, TRAINING loss is 6.40588503403714e-05\n",
      "At step 77500, TRAINING loss is 0.0004017279872758341\n",
      "At step 77750, TRAINING loss is 3.869349214624177e-05\n",
      "At step 78000, TRAINING loss is 4.859349483324278e-05\n",
      "At step 78000, sampled x_0 is 1.1951325523406235\n",
      "At step 78250, TRAINING loss is 8.52070497152872e-06\n",
      "At step 78500, TRAINING loss is 5.82071781536286e-05\n",
      "At step 78750, TRAINING loss is 0.0011052420282689943\n",
      "At step 79000, TRAINING loss is 5.216349264845028e-05\n",
      "At step 79000, sampled x_0 is 0.9144416323984519\n",
      "At step 79250, TRAINING loss is 0.0003244370845350448\n",
      "At step 79500, TRAINING loss is 0.00011694103557849403\n",
      "At step 79750, TRAINING loss is 0.004579298078419434\n",
      "At step 80000, TRAINING loss is 0.0007172032779750734\n",
      "At step 80000, sampled x_0 is 0.9301502130447417\n",
      "At step 80250, TRAINING loss is 0.0009000876174260131\n",
      "At step 80500, TRAINING loss is 2.2956977013102548e-07\n",
      "At step 80750, TRAINING loss is 1.908440454934481e-06\n",
      "At step 81000, TRAINING loss is 0.0008869529604594892\n",
      "At step 81000, sampled x_0 is 1.0330389588423632\n",
      "At step 81250, TRAINING loss is 6.12041991931111e-07\n",
      "At step 81500, TRAINING loss is 2.1486483447062094e-05\n",
      "At step 81750, TRAINING loss is 6.353160637429255e-07\n",
      "At step 82000, TRAINING loss is 6.747108976495577e-05\n",
      "At step 82000, sampled x_0 is 1.0368726502193146\n",
      "At step 82250, TRAINING loss is 0.001618116723913608\n",
      "At step 82500, TRAINING loss is 0.00036939781807539837\n",
      "At step 82750, TRAINING loss is 3.9471284938973534e-05\n",
      "At step 83000, TRAINING loss is 0.0007620744317043485\n",
      "At step 83000, sampled x_0 is 0.9725181537854029\n",
      "At step 83250, TRAINING loss is 0.0008355122754635926\n",
      "At step 83500, TRAINING loss is 3.0175438345607607e-06\n",
      "At step 83750, TRAINING loss is 2.387751954916623e-05\n",
      "At step 84000, TRAINING loss is 3.1787651102222735e-05\n",
      "At step 84000, sampled x_0 is 0.9695785420528721\n",
      "At step 84250, TRAINING loss is 0.00029163142417710705\n",
      "At step 84500, TRAINING loss is 1.8768912687561635e-06\n",
      "At step 84750, TRAINING loss is 0.0011593817949736831\n",
      "At step 85000, TRAINING loss is 2.0903422350228863e-05\n",
      "At step 85000, sampled x_0 is 0.4976976397549386\n",
      "At step 85250, TRAINING loss is 7.831425124703737e-05\n",
      "At step 85500, TRAINING loss is 7.634875311631243e-10\n",
      "At step 85750, TRAINING loss is 0.0001525993842204617\n",
      "At step 86000, TRAINING loss is 0.0006001623966046021\n",
      "At step 86000, sampled x_0 is 1.058833549514317\n",
      "At step 86250, TRAINING loss is 0.00048217846497287454\n",
      "At step 86500, TRAINING loss is 0.0002092632014407318\n",
      "At step 86750, TRAINING loss is 0.0002924971726594794\n",
      "At step 87000, TRAINING loss is 0.0039812236601437555\n",
      "At step 87000, sampled x_0 is 1.092134850646342\n",
      "At step 87250, TRAINING loss is 0.0005027615257349235\n",
      "At step 87500, TRAINING loss is 0.0033065652732171455\n",
      "At step 87750, TRAINING loss is 5.663961746985439e-05\n",
      "At step 88000, TRAINING loss is 0.0005762797756040738\n",
      "At step 88000, sampled x_0 is 0.9109017616085868\n",
      "At step 88250, TRAINING loss is 7.190732609264133e-06\n",
      "At step 88500, TRAINING loss is 0.000853704795147156\n",
      "At step 88750, TRAINING loss is 0.00019858142628186696\n",
      "At step 89000, TRAINING loss is 2.1674843448147455e-05\n",
      "At step 89000, sampled x_0 is 1.0438049506265843\n",
      "At step 89250, TRAINING loss is 8.324200471919827e-05\n",
      "At step 89500, TRAINING loss is 0.0003805446423420408\n",
      "At step 89750, TRAINING loss is 8.605204057255539e-06\n",
      "At step 90000, TRAINING loss is 0.00044802293405332965\n",
      "At step 90000, sampled x_0 is 0.9315040545968957\n",
      "At step 90250, TRAINING loss is 0.000836766258084229\n",
      "At step 90500, TRAINING loss is 3.860848358170588e-05\n",
      "At step 90750, TRAINING loss is 0.00022272337330940197\n",
      "At step 91000, TRAINING loss is 3.472234773909059e-06\n",
      "At step 91000, sampled x_0 is 1.1726351617276944\n",
      "At step 91250, TRAINING loss is 0.00023276639520705415\n",
      "At step 91500, TRAINING loss is 2.031204041330423e-05\n",
      "At step 91750, TRAINING loss is 0.004255583531063454\n",
      "At step 92000, TRAINING loss is 0.0004287621496759269\n",
      "At step 92000, sampled x_0 is 1.0667456474998938\n",
      "At step 92250, TRAINING loss is 0.0001997889610899129\n",
      "At step 92500, TRAINING loss is 1.2228419853800917e-05\n",
      "At step 92750, TRAINING loss is 7.883904678378672e-05\n",
      "At step 93000, TRAINING loss is 6.6444660986713e-05\n",
      "At step 93000, sampled x_0 is 0.9541935362943805\n",
      "At step 93250, TRAINING loss is 0.00014298689496287413\n",
      "At step 93500, TRAINING loss is 0.003665983520052024\n",
      "At step 93750, TRAINING loss is 0.001890180842930391\n",
      "At step 94000, TRAINING loss is 0.00013899221363667638\n",
      "At step 94000, sampled x_0 is 0.9212952392262317\n",
      "At step 94250, TRAINING loss is 0.00010476358843136943\n",
      "At step 94500, TRAINING loss is 3.757713456690073e-06\n",
      "At step 94750, TRAINING loss is 0.0007994463826056894\n",
      "At step 95000, TRAINING loss is 9.59479556399665e-06\n",
      "At step 95000, sampled x_0 is 0.7727619867572041\n",
      "At step 95250, TRAINING loss is 0.002063974958202803\n",
      "At step 95500, TRAINING loss is 5.099166899921937e-05\n",
      "At step 95750, TRAINING loss is 0.0010335494197625254\n",
      "At step 96000, TRAINING loss is 0.0001736976759884531\n",
      "At step 96000, sampled x_0 is 0.9470621181597079\n",
      "At step 96250, TRAINING loss is 0.0035781067683405446\n",
      "At step 96500, TRAINING loss is 5.681707794324001e-05\n",
      "At step 96750, TRAINING loss is 5.1080354057112075e-08\n",
      "At step 97000, TRAINING loss is 2.5122812763333425e-07\n",
      "At step 97000, sampled x_0 is 0.9843545616803457\n",
      "At step 97250, TRAINING loss is 0.0007056854119786014\n",
      "At step 97500, TRAINING loss is 0.00016481029877969016\n",
      "At step 97750, TRAINING loss is 0.00017683285198680007\n",
      "At step 98000, TRAINING loss is 4.583683507202858e-06\n",
      "At step 98000, sampled x_0 is 0.7562770424738154\n",
      "At step 98250, TRAINING loss is 0.00027751968369874773\n",
      "At step 98500, TRAINING loss is 6.215012451650541e-07\n",
      "At step 98750, TRAINING loss is 1.6336997164980735e-05\n",
      "At step 99000, TRAINING loss is 4.128477605639155e-06\n",
      "At step 99000, sampled x_0 is 0.850918435612502\n",
      "At step 99250, TRAINING loss is 0.00023702830128763942\n",
      "At step 99500, TRAINING loss is 9.038533951449299e-05\n",
      "At step 99750, TRAINING loss is 6.816862666028837e-05\n",
      "At step 100000, TRAINING loss is 0.011760751149029799\n",
      "At step 100000, sampled x_0 is 1.1441886035494422\n",
      "At step 100250, TRAINING loss is 0.00046102324128237913\n",
      "At step 100500, TRAINING loss is 0.0007648489729380238\n",
      "At step 100750, TRAINING loss is 2.107917310455587e-06\n",
      "At step 101000, TRAINING loss is 0.00015039590613935674\n",
      "At step 101000, sampled x_0 is 0.8348179739289414\n",
      "At step 101250, TRAINING loss is 1.469874502177987e-06\n",
      "At step 101500, TRAINING loss is 0.0001788023503608806\n",
      "At step 101750, TRAINING loss is 5.816790009386951e-06\n",
      "At step 102000, TRAINING loss is 0.0002972539578740321\n",
      "At step 102000, sampled x_0 is 1.1331514803000833\n",
      "At step 102250, TRAINING loss is 0.00017578706817030366\n",
      "At step 102500, TRAINING loss is 0.00027411438020696454\n",
      "At step 102750, TRAINING loss is 1.61669309128765e-08\n",
      "At step 103000, TRAINING loss is 0.0005268923006053056\n",
      "At step 103000, sampled x_0 is 0.9825265679514325\n",
      "At step 103250, TRAINING loss is 7.859106811364526e-05\n",
      "At step 103500, TRAINING loss is 4.481341388554885e-06\n",
      "At step 103750, TRAINING loss is 2.824775202203961e-06\n",
      "At step 104000, TRAINING loss is 0.000524446276821474\n",
      "At step 104000, sampled x_0 is 0.9981549165357171\n",
      "At step 104250, TRAINING loss is 0.00022291188433619892\n",
      "At step 104500, TRAINING loss is 0.0017842250499387727\n",
      "At step 104750, TRAINING loss is 0.0003527353838010058\n",
      "At step 105000, TRAINING loss is 3.5803052315252746e-05\n",
      "At step 105000, sampled x_0 is 1.0999580540314078\n",
      "At step 105250, TRAINING loss is 6.16561925253948e-05\n",
      "At step 105500, TRAINING loss is 0.0001603489166907581\n",
      "At step 105750, TRAINING loss is 0.00154458014132212\n",
      "At step 106000, TRAINING loss is 3.3322916943315145e-05\n",
      "At step 106000, sampled x_0 is 1.009753343881665\n",
      "At step 106250, TRAINING loss is 9.372191399810716e-05\n",
      "At step 106500, TRAINING loss is 0.00014706271394436556\n",
      "At step 106750, TRAINING loss is 1.1632080047366926e-05\n",
      "At step 107000, TRAINING loss is 4.405149398378646e-05\n",
      "At step 107000, sampled x_0 is 1.054604963965471\n",
      "At step 107250, TRAINING loss is 6.239930801363943e-05\n",
      "At step 107500, TRAINING loss is 0.00015988877881782255\n",
      "At step 107750, TRAINING loss is 1.480737084715845e-05\n",
      "At step 108000, TRAINING loss is 1.3520375186736731e-05\n",
      "At step 108000, sampled x_0 is 1.1318625633075239\n",
      "At step 108250, TRAINING loss is 4.789112210929711e-05\n",
      "At step 108500, TRAINING loss is 4.805136216345155e-05\n",
      "At step 108750, TRAINING loss is 0.00013648004357278332\n",
      "At step 109000, TRAINING loss is 0.00015211918754690301\n",
      "At step 109000, sampled x_0 is 1.0770888145043451\n",
      "At step 109250, TRAINING loss is 0.00012732993247420956\n",
      "At step 109500, TRAINING loss is 4.3622690597953323e-07\n",
      "At step 109750, TRAINING loss is 0.0003539590795789461\n",
      "At step 110000, TRAINING loss is 0.00615761720459243\n",
      "At step 110000, sampled x_0 is 0.9568957828407773\n",
      "At step 110250, TRAINING loss is 3.1286938288999663e-05\n",
      "At step 110500, TRAINING loss is 0.00017943083848364459\n",
      "At step 110750, TRAINING loss is 0.00038717784909634304\n",
      "At step 111000, TRAINING loss is 8.811599452783927e-05\n",
      "At step 111000, sampled x_0 is 0.8941078660751947\n",
      "At step 111250, TRAINING loss is 0.000443990643058159\n",
      "At step 111500, TRAINING loss is 5.999349611878615e-06\n",
      "At step 111750, TRAINING loss is 0.0003678964579938818\n",
      "At step 112000, TRAINING loss is 1.977644085169571e-05\n",
      "At step 112000, sampled x_0 is 0.9333942190723101\n",
      "At step 112250, TRAINING loss is 0.00014485799728401584\n",
      "At step 112500, TRAINING loss is 4.227261792232795e-05\n",
      "At step 112750, TRAINING loss is 0.0007420411674344223\n",
      "At step 113000, TRAINING loss is 6.314365911063306e-05\n",
      "At step 113000, sampled x_0 is 0.9766216021928394\n",
      "At step 113250, TRAINING loss is 7.418308741261785e-05\n",
      "At step 113500, TRAINING loss is 0.000106639083206649\n",
      "At step 113750, TRAINING loss is 1.3591900349174726e-05\n",
      "At step 114000, TRAINING loss is 0.0003450827043040688\n",
      "At step 114000, sampled x_0 is 0.961878348283943\n",
      "At step 114250, TRAINING loss is 0.00012306137530256625\n",
      "At step 114500, TRAINING loss is 9.071105219652637e-06\n",
      "At step 114750, TRAINING loss is 6.972112057573281e-07\n",
      "At step 115000, TRAINING loss is 0.001174884885362829\n",
      "At step 115000, sampled x_0 is 0.9556122929116787\n",
      "At step 115250, TRAINING loss is 5.0646301219366394e-05\n",
      "At step 115500, TRAINING loss is 8.601432892316616e-05\n",
      "At step 115750, TRAINING loss is 0.0005333866483250195\n",
      "At step 116000, TRAINING loss is 0.0001904919782631109\n",
      "At step 116000, sampled x_0 is 0.9954153302658689\n",
      "At step 116250, TRAINING loss is 0.00023258511158911766\n",
      "At step 116500, TRAINING loss is 0.0001826213172983229\n",
      "At step 116750, TRAINING loss is 3.356932115579083e-05\n",
      "At step 117000, TRAINING loss is 0.00011020636059944553\n",
      "At step 117000, sampled x_0 is 1.03170162072881\n",
      "At step 117250, TRAINING loss is 0.004826571612101918\n",
      "At step 117500, TRAINING loss is 1.978910795534824e-05\n",
      "At step 117750, TRAINING loss is 2.3662863453882905e-05\n",
      "At step 118000, TRAINING loss is 3.562819987229977e-05\n",
      "At step 118000, sampled x_0 is 1.0346110615823167\n",
      "At step 118250, TRAINING loss is 0.0003495522450990057\n",
      "At step 118500, TRAINING loss is 0.002051006475223659\n",
      "At step 118750, TRAINING loss is 3.0841924067113135e-06\n",
      "At step 119000, TRAINING loss is 0.00018939634406167782\n",
      "At step 119000, sampled x_0 is 0.9417488623872604\n",
      "At step 119250, TRAINING loss is 0.0001226445008405971\n",
      "At step 119500, TRAINING loss is 3.300454265539549e-05\n",
      "At step 119750, TRAINING loss is 5.416623437140303e-07\n",
      "At step 120000, TRAINING loss is 0.00014515366118453683\n",
      "At step 120000, sampled x_0 is 0.9927526554670024\n",
      "At step 120250, TRAINING loss is 4.480780164926425e-05\n",
      "At step 120500, TRAINING loss is 2.54855925132477e-06\n",
      "At step 120750, TRAINING loss is 7.3463835010576565e-06\n",
      "At step 121000, TRAINING loss is 9.83185008514502e-05\n",
      "At step 121000, sampled x_0 is 0.7871558069469018\n",
      "At step 121250, TRAINING loss is 3.51491010562394e-05\n",
      "At step 121500, TRAINING loss is 0.00018401033395718712\n",
      "At step 121750, TRAINING loss is 3.723519468676324e-05\n",
      "At step 122000, TRAINING loss is 0.00021244344081387887\n",
      "At step 122000, sampled x_0 is 0.9835626276513393\n",
      "At step 122250, TRAINING loss is 6.586456682921708e-06\n",
      "At step 122500, TRAINING loss is 0.00046529629256199495\n",
      "At step 122750, TRAINING loss is 1.0665643878843001e-05\n",
      "At step 123000, TRAINING loss is 0.0002182125266315959\n",
      "At step 123000, sampled x_0 is 1.2711795368102496\n",
      "At step 123250, TRAINING loss is 0.00048475701253122887\n",
      "At step 123500, TRAINING loss is 0.0008917281390477263\n",
      "At step 123750, TRAINING loss is 0.0004500363405841851\n",
      "At step 124000, TRAINING loss is 0.00028323581585107225\n",
      "At step 124000, sampled x_0 is 1.0503717167352205\n",
      "At step 124250, TRAINING loss is 0.001853890077816115\n",
      "At step 124500, TRAINING loss is 2.519052090217563e-05\n",
      "At step 124750, TRAINING loss is 0.00016284800065261877\n",
      "At step 125000, TRAINING loss is 0.0004498045215821357\n",
      "At step 125000, sampled x_0 is 0.9646350510721545\n",
      "At step 125250, TRAINING loss is 0.00045497886567615574\n",
      "At step 125500, TRAINING loss is 3.1322805397236644e-05\n",
      "At step 125750, TRAINING loss is 0.00042058966443359795\n",
      "At step 126000, TRAINING loss is 0.0022304095669985788\n",
      "At step 126000, sampled x_0 is 0.9383438127107689\n",
      "At step 126250, TRAINING loss is 0.0004276823716558077\n",
      "At step 126500, TRAINING loss is 0.0003606643558908047\n",
      "At step 126750, TRAINING loss is 4.631862375968681e-05\n",
      "At step 127000, TRAINING loss is 0.0003914248975657702\n",
      "At step 127000, sampled x_0 is 0.9997608651499638\n",
      "At step 127250, TRAINING loss is 0.0018003216987706237\n",
      "At step 127500, TRAINING loss is 5.1658163733505716e-05\n",
      "At step 127750, TRAINING loss is 1.9986102550808443e-07\n",
      "At step 128000, TRAINING loss is 0.0017019642190198284\n",
      "At step 128000, sampled x_0 is 1.174928902416994\n",
      "At step 128250, TRAINING loss is 3.214852345716595e-06\n",
      "At step 128500, TRAINING loss is 0.00020170728954321162\n",
      "At step 128750, TRAINING loss is 0.00016373162791235297\n",
      "At step 129000, TRAINING loss is 4.3336474549014945e-05\n",
      "At step 129000, sampled x_0 is 1.1657458962774512\n",
      "At step 129250, TRAINING loss is 3.886933905057017e-07\n",
      "At step 129500, TRAINING loss is 1.9303173813579572e-05\n",
      "At step 129750, TRAINING loss is 2.497358158420844e-05\n",
      "At step 130000, TRAINING loss is 0.0006235008468013756\n",
      "At step 130000, sampled x_0 is 0.9047778207484237\n",
      "At step 130250, TRAINING loss is 0.0015958771248942517\n",
      "At step 130500, TRAINING loss is 0.00028765843796747147\n",
      "At step 130750, TRAINING loss is 9.236431606306609e-06\n",
      "At step 131000, TRAINING loss is 1.2563904307628093e-07\n",
      "At step 131000, sampled x_0 is 0.9461634959354438\n",
      "At step 131250, TRAINING loss is 4.0611903180704144e-05\n",
      "At step 131500, TRAINING loss is 0.00069237619700497\n",
      "At step 131750, TRAINING loss is 0.000137160123413511\n",
      "At step 132000, TRAINING loss is 0.0009598749503723473\n",
      "At step 132000, sampled x_0 is 1.0097987906471577\n",
      "At step 132250, TRAINING loss is 7.416568737685736e-05\n",
      "At step 132500, TRAINING loss is 0.0005061683575756387\n",
      "At step 132750, TRAINING loss is 0.00012324910206962467\n",
      "At step 133000, TRAINING loss is 0.0002592222033994801\n",
      "At step 133000, sampled x_0 is 1.0064092960055233\n",
      "At step 133250, TRAINING loss is 4.4381034571533354e-05\n",
      "At step 133500, TRAINING loss is 0.004235203925877765\n",
      "At step 133750, TRAINING loss is 0.00022017955052268176\n",
      "At step 134000, TRAINING loss is 0.003709416696098239\n",
      "At step 134000, sampled x_0 is 0.9788742311599263\n",
      "At step 134250, TRAINING loss is 0.000564290828179908\n",
      "At step 134500, TRAINING loss is 6.547999964722439e-05\n",
      "At step 134750, TRAINING loss is 1.952088106664707e-06\n",
      "At step 135000, TRAINING loss is 2.396156738319585e-06\n",
      "At step 135000, sampled x_0 is 1.0106100732337984\n",
      "At step 135250, TRAINING loss is 0.0007717934457256597\n",
      "At step 135500, TRAINING loss is 0.0051673124135125925\n",
      "At step 135750, TRAINING loss is 9.710309051866476e-05\n",
      "At step 136000, TRAINING loss is 0.007581329245448816\n",
      "At step 136000, sampled x_0 is 0.8782178857989429\n",
      "At step 136250, TRAINING loss is 0.0001743133575720551\n",
      "At step 136500, TRAINING loss is 0.0002640628974150828\n",
      "At step 136750, TRAINING loss is 0.00010839848061986197\n",
      "At step 137000, TRAINING loss is 0.00012969178848424638\n",
      "At step 137000, sampled x_0 is 0.9509363565432163\n",
      "At step 137250, TRAINING loss is 2.4505342626526028e-05\n",
      "At step 137500, TRAINING loss is 0.0003884414279748224\n",
      "At step 137750, TRAINING loss is 4.546214892057805e-05\n",
      "At step 138000, TRAINING loss is 2.3836383679462198e-05\n",
      "At step 138000, sampled x_0 is 1.0399777396229302\n",
      "At step 138250, TRAINING loss is 1.327746101015629e-05\n",
      "At step 138500, TRAINING loss is 8.893796781740165e-06\n",
      "At step 138750, TRAINING loss is 0.00022171565429644405\n",
      "At step 139000, TRAINING loss is 0.00037445854371439175\n",
      "At step 139000, sampled x_0 is 1.153689397495712\n",
      "At step 139250, TRAINING loss is 0.00021297970402322936\n",
      "At step 139500, TRAINING loss is 0.00042230974726149265\n",
      "At step 139750, TRAINING loss is 0.0007098447752402489\n",
      "At step 140000, TRAINING loss is 0.0001413982819881143\n",
      "At step 140000, sampled x_0 is 1.0831191562867826\n",
      "At step 140250, TRAINING loss is 0.00020382194747615873\n",
      "At step 140500, TRAINING loss is 0.0001834440334092201\n",
      "At step 140750, TRAINING loss is 0.003103384704860467\n",
      "At step 141000, TRAINING loss is 0.0001208863048017933\n",
      "At step 141000, sampled x_0 is 1.077430039291176\n",
      "At step 141250, TRAINING loss is 5.71558529280508e-07\n",
      "At step 141500, TRAINING loss is 0.00259578880469691\n",
      "At step 141750, TRAINING loss is 0.0012374370522788183\n",
      "At step 142000, TRAINING loss is 0.00027912275641594255\n",
      "At step 142000, sampled x_0 is 0.9525748129455791\n",
      "At step 142250, TRAINING loss is 7.99572852818658e-05\n",
      "At step 142500, TRAINING loss is 6.539472972000368e-07\n",
      "At step 142750, TRAINING loss is 4.0744971206203555e-05\n",
      "At step 143000, TRAINING loss is 2.8441479747480275e-05\n",
      "At step 143000, sampled x_0 is 0.8079481844202634\n",
      "At step 143250, TRAINING loss is 0.0022428133999090783\n",
      "At step 143500, TRAINING loss is 8.221673073651622e-05\n",
      "At step 143750, TRAINING loss is 0.009007127777475924\n",
      "At step 144000, TRAINING loss is 1.313301398449306e-05\n",
      "At step 144000, sampled x_0 is 1.057239709826435\n",
      "At step 144250, TRAINING loss is 0.00038849039026649313\n",
      "At step 144500, TRAINING loss is 4.375987724788224e-05\n",
      "At step 144750, TRAINING loss is 5.802577555700828e-05\n",
      "At step 145000, TRAINING loss is 0.0001811621988483388\n",
      "At step 145000, sampled x_0 is 1.0809107539930505\n",
      "At step 145250, TRAINING loss is 5.86093038806213e-05\n",
      "At step 145500, TRAINING loss is 0.00012163262814609607\n",
      "At step 145750, TRAINING loss is 0.001400665144653421\n",
      "At step 146000, TRAINING loss is 0.002014660801200597\n",
      "At step 146000, sampled x_0 is 1.1059882163914037\n",
      "At step 146250, TRAINING loss is 4.667769779207564e-07\n",
      "At step 146500, TRAINING loss is 0.00020051672504768127\n",
      "At step 146750, TRAINING loss is 1.347652683828786e-05\n",
      "At step 147000, TRAINING loss is 0.0015327857036228872\n",
      "At step 147000, sampled x_0 is 1.1041618333833205\n",
      "At step 147250, TRAINING loss is 3.394840699168865e-05\n",
      "At step 147500, TRAINING loss is 3.7568684347645206e-05\n",
      "At step 147750, TRAINING loss is 0.00016123019935034417\n",
      "At step 148000, TRAINING loss is 7.835734328048494e-07\n",
      "At step 148000, sampled x_0 is 1.0475476635351764\n",
      "At step 148250, TRAINING loss is 4.927568856072423e-05\n",
      "At step 148500, TRAINING loss is 4.911177850252712e-05\n",
      "At step 148750, TRAINING loss is 4.1992541283590514e-05\n",
      "At step 149000, TRAINING loss is 0.0016196710528008334\n",
      "At step 149000, sampled x_0 is 0.9800468349739756\n",
      "At step 149250, TRAINING loss is 7.905069764286304e-06\n",
      "At step 149500, TRAINING loss is 3.3855428147532944e-05\n",
      "At step 149750, TRAINING loss is 2.9422289206124004e-06\n",
      "At step 150000, TRAINING loss is 1.6044902374679903e-05\n",
      "At step 150000, sampled x_0 is 1.0422821139200824\n",
      "At step 150250, TRAINING loss is 7.839009133647465e-05\n",
      "At step 150500, TRAINING loss is 0.0001134685598207658\n",
      "At step 150750, TRAINING loss is 4.006781432017906e-05\n",
      "At step 151000, TRAINING loss is 7.443606328169984e-05\n",
      "At step 151000, sampled x_0 is 1.1093157422053088\n",
      "At step 151250, TRAINING loss is 0.00029963724630676313\n",
      "At step 151500, TRAINING loss is 0.00038509787946455374\n",
      "At step 151750, TRAINING loss is 1.1791891954926302e-05\n",
      "At step 152000, TRAINING loss is 9.381286810889701e-05\n",
      "At step 152000, sampled x_0 is 0.9237524965041897\n",
      "At step 152250, TRAINING loss is 1.4908483083792936e-06\n",
      "At step 152500, TRAINING loss is 0.0019093028069627855\n",
      "At step 152750, TRAINING loss is 0.0007114203726761082\n",
      "At step 153000, TRAINING loss is 3.942027969648089e-06\n",
      "At step 153000, sampled x_0 is 1.1574655148554374\n",
      "At step 153250, TRAINING loss is 0.0002870426828471025\n",
      "At step 153500, TRAINING loss is 0.0004212906276138884\n",
      "At step 153750, TRAINING loss is 4.995782891256378e-05\n",
      "At step 154000, TRAINING loss is 1.6809367290776567e-08\n",
      "At step 154000, sampled x_0 is 0.974159019771986\n",
      "At step 154250, TRAINING loss is 0.0003445769163648878\n",
      "At step 154500, TRAINING loss is 6.9486978149851095e-06\n",
      "At step 154750, TRAINING loss is 1.552160161364895e-06\n",
      "At step 155000, TRAINING loss is 0.0003414213842277118\n",
      "At step 155000, sampled x_0 is 0.8491721471080168\n",
      "At step 155250, TRAINING loss is 0.002904029413571795\n",
      "At step 155500, TRAINING loss is 6.498881223061716e-05\n",
      "At step 155750, TRAINING loss is 0.00011256191853726023\n",
      "At step 156000, TRAINING loss is 4.73365684749467e-05\n",
      "At step 156000, sampled x_0 is 0.973230720456409\n",
      "At step 156250, TRAINING loss is 1.4143345606927314e-07\n",
      "At step 156500, TRAINING loss is 3.951668354342029e-05\n",
      "At step 156750, TRAINING loss is 3.4639941092792445e-05\n",
      "At step 157000, TRAINING loss is 0.0005804013536181989\n",
      "At step 157000, sampled x_0 is 0.9030069149943561\n",
      "At step 157250, TRAINING loss is 0.0004278577822281878\n",
      "At step 157500, TRAINING loss is 0.0006659673872411721\n",
      "At step 157750, TRAINING loss is 0.00041711993206264416\n",
      "At step 158000, TRAINING loss is 0.00036916656308574175\n",
      "At step 158000, sampled x_0 is 0.9440915047549522\n",
      "At step 158250, TRAINING loss is 0.00013265610269688524\n",
      "At step 158500, TRAINING loss is 0.00041588129303681167\n",
      "At step 158750, TRAINING loss is 3.0556217259594778e-06\n",
      "At step 159000, TRAINING loss is 0.00013004396464852834\n",
      "At step 159000, sampled x_0 is 1.034425491497666\n",
      "At step 159250, TRAINING loss is 0.0015698740870856728\n",
      "At step 159500, TRAINING loss is 1.9225202649122905e-05\n",
      "At step 159750, TRAINING loss is 1.3430971455002279e-05\n",
      "At step 160000, TRAINING loss is 5.487704158365726e-07\n",
      "At step 160000, sampled x_0 is 1.0003065432217428\n",
      "At step 160250, TRAINING loss is 0.00024286164805414155\n",
      "At step 160500, TRAINING loss is 0.00018942837498024765\n",
      "At step 160750, TRAINING loss is 0.00016388356898092428\n",
      "At step 161000, TRAINING loss is 0.0002525849613620918\n",
      "At step 161000, sampled x_0 is 0.9422030852755197\n",
      "At step 161250, TRAINING loss is 4.32114253494325e-05\n",
      "At step 161500, TRAINING loss is 1.6941627975125567e-05\n",
      "At step 161750, TRAINING loss is 0.0003463811701165578\n",
      "At step 162000, TRAINING loss is 9.530265529552638e-05\n",
      "At step 162000, sampled x_0 is 1.041408967696142\n",
      "At step 162250, TRAINING loss is 0.00017698970754388474\n",
      "At step 162500, TRAINING loss is 2.8526167491537988e-05\n",
      "At step 162750, TRAINING loss is 7.142204616395181e-09\n",
      "At step 163000, TRAINING loss is 7.366367545278563e-06\n",
      "At step 163000, sampled x_0 is 1.0925120407469189\n",
      "At step 163250, TRAINING loss is 0.0005226284424683135\n",
      "At step 163500, TRAINING loss is 3.484283586124943e-05\n",
      "At step 163750, TRAINING loss is 7.659453894974645e-05\n",
      "At step 164000, TRAINING loss is 3.0408241526241807e-05\n",
      "At step 164000, sampled x_0 is 1.051296170994571\n",
      "At step 164250, TRAINING loss is 0.00013904729366142338\n",
      "At step 164500, TRAINING loss is 0.00023199363058505536\n",
      "At step 164750, TRAINING loss is 3.9862865161895906e-05\n",
      "At step 165000, TRAINING loss is 2.8852782572582173e-05\n",
      "At step 165000, sampled x_0 is 0.9772896656613004\n",
      "At step 165250, TRAINING loss is 8.35808141859747e-06\n",
      "At step 165500, TRAINING loss is 1.8463150571783087e-07\n",
      "At step 165750, TRAINING loss is 4.080334774719881e-05\n",
      "At step 166000, TRAINING loss is 0.00019428453663684293\n",
      "At step 166000, sampled x_0 is 0.948399379530927\n",
      "At step 166250, TRAINING loss is 1.6219731318521652e-05\n",
      "At step 166500, TRAINING loss is 2.906181734662804e-05\n",
      "At step 166750, TRAINING loss is 1.0574413448706702e-05\n",
      "At step 167000, TRAINING loss is 0.0006047397690008073\n",
      "At step 167000, sampled x_0 is 1.0870064896839533\n",
      "At step 167250, TRAINING loss is 0.0025346294514411484\n",
      "At step 167500, TRAINING loss is 0.0004338737206423377\n",
      "At step 167750, TRAINING loss is 0.0006117786405509675\n",
      "At step 168000, TRAINING loss is 0.00022420363554599224\n",
      "At step 168000, sampled x_0 is 1.005135116151145\n",
      "At step 168250, TRAINING loss is 0.00017274352905971834\n",
      "At step 168500, TRAINING loss is 2.3327447032909193e-05\n",
      "At step 168750, TRAINING loss is 0.00013207698093585377\n",
      "At step 169000, TRAINING loss is 0.0011508970123237066\n",
      "At step 169000, sampled x_0 is 1.0904795492419834\n",
      "At step 169250, TRAINING loss is 0.00020760873025023595\n",
      "At step 169500, TRAINING loss is 0.0012488054565348464\n",
      "At step 169750, TRAINING loss is 0.00029206139297903287\n",
      "At step 170000, TRAINING loss is 0.00021293549826425064\n",
      "At step 170000, sampled x_0 is 0.9421477459399062\n",
      "At step 170250, TRAINING loss is 0.00019407696145394833\n",
      "At step 170500, TRAINING loss is 0.00014405645309606904\n",
      "At step 170750, TRAINING loss is 0.0002990705609644721\n",
      "At step 171000, TRAINING loss is 0.00028882795845271923\n",
      "At step 171000, sampled x_0 is 0.8167172714103409\n",
      "At step 171250, TRAINING loss is 0.00010710400798114202\n",
      "At step 171500, TRAINING loss is 0.00012978673239541068\n",
      "At step 171750, TRAINING loss is 2.989475533890763e-05\n",
      "At step 172000, TRAINING loss is 7.529911305394017e-08\n",
      "At step 172000, sampled x_0 is 0.8975189168101994\n",
      "At step 172250, TRAINING loss is 0.0004071963099764909\n",
      "At step 172500, TRAINING loss is 0.0002410196068214659\n",
      "At step 172750, TRAINING loss is 6.969273889933905e-05\n",
      "At step 173000, TRAINING loss is 1.2241182869593534e-05\n",
      "At step 173000, sampled x_0 is 1.012063223407074\n",
      "At step 173250, TRAINING loss is 0.00012213886730139137\n",
      "At step 173500, TRAINING loss is 0.0009433552314516994\n",
      "At step 173750, TRAINING loss is 9.808698428987865e-07\n",
      "At step 174000, TRAINING loss is 0.00031279672277451727\n",
      "At step 174000, sampled x_0 is 0.9103451805275432\n",
      "At step 174250, TRAINING loss is 1.2702769265040455e-06\n",
      "At step 174500, TRAINING loss is 1.630637833224719e-05\n",
      "At step 174750, TRAINING loss is 5.690815720301793e-07\n",
      "At step 175000, TRAINING loss is 1.2080500071101811e-06\n",
      "At step 175000, sampled x_0 is 1.033182861391056\n",
      "At step 175250, TRAINING loss is 0.00028482963096080444\n",
      "At step 175500, TRAINING loss is 0.0022456718164143145\n",
      "At step 175750, TRAINING loss is 0.0008622392795228031\n",
      "At step 176000, TRAINING loss is 0.00015754075434403625\n",
      "At step 176000, sampled x_0 is 1.1373062979504225\n",
      "At step 176250, TRAINING loss is 0.00026326900653403216\n",
      "At step 176500, TRAINING loss is 0.001637827459492722\n",
      "At step 176750, TRAINING loss is 9.608782611705636e-05\n",
      "At step 177000, TRAINING loss is 1.2231997857936946e-05\n",
      "At step 177000, sampled x_0 is 1.0217816901090742\n",
      "At step 177250, TRAINING loss is 1.1303437765483243e-05\n",
      "At step 177500, TRAINING loss is 2.6444542790647098e-05\n",
      "At step 177750, TRAINING loss is 1.8397396874765514e-05\n",
      "At step 178000, TRAINING loss is 0.00014507737643054417\n",
      "At step 178000, sampled x_0 is 0.9381137567256184\n",
      "At step 178250, TRAINING loss is 0.00017959237152033973\n",
      "At step 178500, TRAINING loss is 5.217894787599553e-05\n",
      "At step 178750, TRAINING loss is 3.50351164687541e-05\n",
      "At step 179000, TRAINING loss is 3.0263053370674912e-05\n",
      "At step 179000, sampled x_0 is 1.0089553377367744\n",
      "At step 179250, TRAINING loss is 0.00010658731423065808\n",
      "At step 179500, TRAINING loss is 2.9185141696596276e-05\n",
      "At step 179750, TRAINING loss is 1.1963417633824416e-06\n",
      "At step 180000, TRAINING loss is 5.1843726445191414e-05\n",
      "At step 180000, sampled x_0 is 0.9593804023679895\n",
      "At step 180250, TRAINING loss is 1.1241283014427076e-05\n",
      "At step 180500, TRAINING loss is 0.0004086656082697287\n",
      "At step 180750, TRAINING loss is 4.432716097491878e-05\n",
      "At step 181000, TRAINING loss is 4.4820442395321515e-06\n",
      "At step 181000, sampled x_0 is 1.0731077174581862\n",
      "At step 181250, TRAINING loss is 0.000161499549310435\n",
      "At step 181500, TRAINING loss is 0.00017107817320482314\n",
      "At step 181750, TRAINING loss is 0.00018627397815682684\n",
      "At step 182000, TRAINING loss is 2.0371670253020974e-05\n",
      "At step 182000, sampled x_0 is 0.8846801131032614\n",
      "At step 182250, TRAINING loss is 3.4452868813262585e-06\n",
      "At step 182500, TRAINING loss is 3.490897771136191e-05\n",
      "At step 182750, TRAINING loss is 0.0003432492784944039\n",
      "At step 183000, TRAINING loss is 1.186310425879924e-05\n",
      "At step 183000, sampled x_0 is 1.0525172004594316\n",
      "At step 183250, TRAINING loss is 0.00010431862952862679\n",
      "At step 183500, TRAINING loss is 0.0019982549541524078\n",
      "At step 183750, TRAINING loss is 1.361522938111397e-05\n",
      "At step 184000, TRAINING loss is 5.016323618755222e-06\n",
      "At step 184000, sampled x_0 is 1.045081495234904\n",
      "At step 184250, TRAINING loss is 0.00016494333399612521\n",
      "At step 184500, TRAINING loss is 2.709953113673251e-06\n",
      "At step 184750, TRAINING loss is 2.0793603951697835e-07\n",
      "At step 185000, TRAINING loss is 2.475355284647551e-05\n",
      "At step 185000, sampled x_0 is 0.9396540078476253\n",
      "At step 185250, TRAINING loss is 5.010679532590766e-05\n",
      "At step 185500, TRAINING loss is 0.001749201889625093\n",
      "At step 185750, TRAINING loss is 0.00021152375596229623\n",
      "At step 186000, TRAINING loss is 0.00015845067314108094\n",
      "At step 186000, sampled x_0 is 1.0089500763105654\n",
      "At step 186250, TRAINING loss is 0.00018370139351512623\n",
      "At step 186500, TRAINING loss is 0.0006033973314658245\n",
      "At step 186750, TRAINING loss is 0.00019481020823919226\n",
      "At step 187000, TRAINING loss is 4.595427313062111e-05\n",
      "At step 187000, sampled x_0 is 1.0787845630917923\n",
      "At step 187250, TRAINING loss is 0.0014190310765206386\n",
      "At step 187500, TRAINING loss is 3.200354525992163e-05\n",
      "At step 187750, TRAINING loss is 8.183718667415116e-07\n",
      "At step 188000, TRAINING loss is 0.0006814586221918919\n",
      "At step 188000, sampled x_0 is 1.0491187989774546\n",
      "At step 188250, TRAINING loss is 1.708667698367546e-07\n",
      "At step 188500, TRAINING loss is 1.8382167614783126e-07\n",
      "At step 188750, TRAINING loss is 5.803924034292827e-06\n",
      "At step 189000, TRAINING loss is 7.244836571408318e-07\n",
      "At step 189000, sampled x_0 is 0.9983504309034007\n",
      "At step 189250, TRAINING loss is 0.0001412415074410366\n",
      "At step 189500, TRAINING loss is 3.522321390783246e-05\n",
      "At step 189750, TRAINING loss is 1.7626429321954794e-05\n",
      "At step 190000, TRAINING loss is 4.143392395533738e-05\n",
      "At step 190000, sampled x_0 is 1.0640030902096058\n",
      "At step 190250, TRAINING loss is 0.0005258054729058918\n",
      "At step 190500, TRAINING loss is 5.181137929182437e-06\n",
      "At step 190750, TRAINING loss is 0.0001287884107035355\n",
      "At step 191000, TRAINING loss is 9.17688404513582e-05\n",
      "At step 191000, sampled x_0 is 1.047951803589546\n",
      "At step 191250, TRAINING loss is 0.00015601113682487953\n",
      "At step 191500, TRAINING loss is 0.0006336958429763793\n",
      "At step 191750, TRAINING loss is 7.848330540857629e-05\n",
      "At step 192000, TRAINING loss is 3.2590399317248414e-05\n",
      "At step 192000, sampled x_0 is 1.0950696974910787\n",
      "At step 192250, TRAINING loss is 0.00022244327797673813\n",
      "At step 192500, TRAINING loss is 5.122665404926633e-05\n",
      "At step 192750, TRAINING loss is 0.00031615260252562444\n",
      "At step 193000, TRAINING loss is 0.00021980791334628693\n",
      "At step 193000, sampled x_0 is 1.1605661589070162\n",
      "At step 193250, TRAINING loss is 0.00013675200092026156\n",
      "At step 193500, TRAINING loss is 6.754614853274868e-07\n",
      "At step 193750, TRAINING loss is 0.00018795604153619755\n",
      "At step 194000, TRAINING loss is 0.00011516961987770344\n",
      "At step 194000, sampled x_0 is 0.9990038619798498\n",
      "At step 194250, TRAINING loss is 4.281720283639146e-05\n",
      "At step 194500, TRAINING loss is 6.310122117427431e-05\n",
      "At step 194750, TRAINING loss is 0.00011749855719068115\n",
      "At step 195000, TRAINING loss is 0.0013067039568721282\n",
      "At step 195000, sampled x_0 is 0.8750946046629504\n",
      "At step 195250, TRAINING loss is 0.001021837996948764\n",
      "At step 195500, TRAINING loss is 5.0867018294724133e-05\n",
      "At step 195750, TRAINING loss is 1.3231021985478585e-05\n",
      "At step 196000, TRAINING loss is 2.3956915530472742e-05\n",
      "At step 196000, sampled x_0 is 1.1028610315349527\n",
      "At step 196250, TRAINING loss is 1.709848786479161e-07\n",
      "At step 196500, TRAINING loss is 1.038265771093667e-05\n",
      "At step 196750, TRAINING loss is 2.526611802934306e-05\n",
      "At step 197000, TRAINING loss is 1.2102072829498007e-06\n",
      "At step 197000, sampled x_0 is 1.0617553458370677\n",
      "At step 197250, TRAINING loss is 2.919273915949218e-05\n",
      "At step 197500, TRAINING loss is 1.3217106310151609e-05\n",
      "At step 197750, TRAINING loss is 3.787852562521585e-05\n",
      "At step 198000, TRAINING loss is 2.289241941453463e-05\n",
      "At step 198000, sampled x_0 is 1.0325374647234766\n",
      "At step 198250, TRAINING loss is 9.596831689807586e-05\n",
      "At step 198500, TRAINING loss is 5.717529043122585e-05\n",
      "At step 198750, TRAINING loss is 2.4634615973402305e-07\n",
      "At step 199000, TRAINING loss is 6.324511946591646e-05\n",
      "At step 199000, sampled x_0 is 1.0382848287832471\n",
      "At step 199250, TRAINING loss is 2.8569077877747905e-05\n",
      "At step 199500, TRAINING loss is 9.789068454794754e-06\n",
      "At step 199750, TRAINING loss is 0.00028083975912216743\n",
      "At step 200000, TRAINING loss is 0.0012777817549041936\n",
      "At step 200000, sampled x_0 is 0.961402836123648\n",
      "At step 200250, TRAINING loss is 2.5055868503948474e-07\n",
      "At step 200500, TRAINING loss is 0.002090757690888523\n",
      "At step 200750, TRAINING loss is 0.0001855908353832707\n",
      "At step 201000, TRAINING loss is 0.000391076348963823\n",
      "At step 201000, sampled x_0 is 1.0603275920865176\n",
      "At step 201250, TRAINING loss is 0.00024680559215619897\n",
      "At step 201500, TRAINING loss is 1.2677250463687389e-05\n",
      "At step 201750, TRAINING loss is 6.951890100205754e-06\n",
      "At step 202000, TRAINING loss is 0.00030308800130249215\n",
      "At step 202000, sampled x_0 is 0.936469035393671\n",
      "At step 202250, TRAINING loss is 0.0001455242137316366\n",
      "At step 202500, TRAINING loss is 3.6631732102297434e-05\n",
      "At step 202750, TRAINING loss is 6.001214446924298e-05\n",
      "At step 203000, TRAINING loss is 1.2650171640537116e-05\n",
      "At step 203000, sampled x_0 is 0.8593919362550887\n",
      "At step 203250, TRAINING loss is 8.901734367022247e-06\n",
      "At step 203500, TRAINING loss is 0.000649070018698358\n",
      "At step 203750, TRAINING loss is 0.00023733166125515363\n",
      "At step 204000, TRAINING loss is 2.967832996463392e-05\n",
      "At step 204000, sampled x_0 is 0.9695790269864782\n",
      "At step 204250, TRAINING loss is 5.291134204628235e-06\n",
      "At step 204500, TRAINING loss is 1.0762806366547761e-05\n",
      "At step 204750, TRAINING loss is 0.00042122549162250893\n",
      "At step 205000, TRAINING loss is 2.5199109178229653e-06\n",
      "At step 205000, sampled x_0 is 1.0466083021636787\n",
      "At step 205250, TRAINING loss is 4.1385176468818004e-05\n",
      "At step 205500, TRAINING loss is 5.425333560168409e-07\n",
      "At step 205750, TRAINING loss is 6.728898327019412e-06\n",
      "At step 206000, TRAINING loss is 1.578884780096155e-05\n",
      "At step 206000, sampled x_0 is 1.0038149684329465\n",
      "At step 206250, TRAINING loss is 0.0005018083157998009\n",
      "At step 206500, TRAINING loss is 6.308429885018724e-06\n",
      "At step 206750, TRAINING loss is 0.0002742205963960935\n",
      "At step 207000, TRAINING loss is 0.000333550601678944\n",
      "At step 207000, sampled x_0 is 0.8620378953383219\n",
      "At step 207250, TRAINING loss is 0.0005475353421744263\n",
      "At step 207500, TRAINING loss is 0.005493072217335211\n",
      "At step 207750, TRAINING loss is 0.0004918343890393863\n",
      "At step 208000, TRAINING loss is 0.00022793406131298472\n",
      "At step 208000, sampled x_0 is 1.0603740505786985\n",
      "At step 208250, TRAINING loss is 2.567406889876663e-05\n",
      "At step 208500, TRAINING loss is 0.0016912836177751121\n",
      "At step 208750, TRAINING loss is 0.000925835567947548\n",
      "At step 209000, TRAINING loss is 0.0005972025579729832\n",
      "At step 209000, sampled x_0 is 1.0021424535852388\n",
      "At step 209250, TRAINING loss is 1.5849901924369293e-08\n",
      "At step 209500, TRAINING loss is 0.00022276928906928906\n",
      "At step 209750, TRAINING loss is 0.0018386322667433726\n",
      "At step 210000, TRAINING loss is 0.00035999864867612317\n",
      "At step 210000, sampled x_0 is 0.8867828879888274\n",
      "At step 210250, TRAINING loss is 8.975918619848749e-06\n",
      "At step 210500, TRAINING loss is 7.961893433829983e-05\n",
      "At step 210750, TRAINING loss is 0.00060024094860618\n",
      "At step 211000, TRAINING loss is 9.022285973193382e-05\n",
      "At step 211000, sampled x_0 is 1.0043032081815153\n",
      "At step 211250, TRAINING loss is 0.00010285246352362775\n",
      "At step 211500, TRAINING loss is 1.05852161774035e-05\n",
      "At step 211750, TRAINING loss is 0.001272421856439886\n",
      "At step 212000, TRAINING loss is 0.00037816921599395984\n",
      "At step 212000, sampled x_0 is 0.9620806523956924\n",
      "At step 212250, TRAINING loss is 0.0001707770259032093\n",
      "At step 212500, TRAINING loss is 0.0005697552077387376\n",
      "At step 212750, TRAINING loss is 9.149211484414004e-07\n",
      "At step 213000, TRAINING loss is 7.355392805982986e-07\n",
      "At step 213000, sampled x_0 is 1.02688171221593\n",
      "At step 213250, TRAINING loss is 2.42681606260995e-05\n",
      "At step 213500, TRAINING loss is 8.952911164958293e-05\n",
      "At step 213750, TRAINING loss is 3.895589499256139e-05\n",
      "At step 214000, TRAINING loss is 1.4897416834621678e-05\n",
      "At step 214000, sampled x_0 is 1.071802386481941\n",
      "At step 214250, TRAINING loss is 0.0003327693583559091\n",
      "At step 214500, TRAINING loss is 2.5170676051004875e-05\n",
      "At step 214750, TRAINING loss is 0.0001012075936690195\n",
      "At step 215000, TRAINING loss is 1.7921329480443647e-05\n",
      "At step 215000, sampled x_0 is 0.9311345446610475\n",
      "At step 215250, TRAINING loss is 4.610467817091826e-09\n",
      "At step 215500, TRAINING loss is 0.00013785854499288942\n",
      "At step 215750, TRAINING loss is 1.258153047379905e-07\n",
      "At step 216000, TRAINING loss is 4.176908296854871e-05\n",
      "At step 216000, sampled x_0 is 1.1299461616511308\n",
      "At step 216250, TRAINING loss is 8.244177032988429e-05\n",
      "At step 216500, TRAINING loss is 1.2578588882901727e-06\n",
      "At step 216750, TRAINING loss is 6.568419082913852e-05\n",
      "At step 217000, TRAINING loss is 0.000371299909367559\n",
      "At step 217000, sampled x_0 is 1.02689931044377\n",
      "At step 217250, TRAINING loss is 0.00014521554992792134\n",
      "At step 217500, TRAINING loss is 8.456643334772368e-05\n",
      "At step 217750, TRAINING loss is 0.0001798817570867879\n",
      "At step 218000, TRAINING loss is 6.675697230085713e-05\n",
      "At step 218000, sampled x_0 is 1.049808665795897\n",
      "At step 218250, TRAINING loss is 0.00013053831462777701\n",
      "At step 218500, TRAINING loss is 8.56329609635873e-07\n",
      "At step 218750, TRAINING loss is 0.00017581990624055348\n",
      "At step 219000, TRAINING loss is 2.193876399235502e-05\n",
      "At step 219000, sampled x_0 is 0.9622197103904322\n",
      "At step 219250, TRAINING loss is 2.9950579517001576e-05\n",
      "At step 219500, TRAINING loss is 0.00012722983935935592\n",
      "At step 219750, TRAINING loss is 7.806943822066173e-05\n",
      "At step 220000, TRAINING loss is 7.951426246423254e-05\n",
      "At step 220000, sampled x_0 is 0.9683277843343134\n",
      "At step 220250, TRAINING loss is 0.00013351950764198104\n",
      "At step 220500, TRAINING loss is 3.430287990519962e-05\n",
      "At step 220750, TRAINING loss is 0.00021497447068642911\n",
      "At step 221000, TRAINING loss is 2.583268736384031e-06\n",
      "At step 221000, sampled x_0 is 1.047403849277161\n",
      "At step 221250, TRAINING loss is 0.00016961810169499562\n",
      "At step 221500, TRAINING loss is 0.00013870876300639141\n",
      "At step 221750, TRAINING loss is 7.32526383705516e-06\n",
      "At step 222000, TRAINING loss is 0.0002144115830293629\n",
      "At step 222000, sampled x_0 is 0.9792658789093984\n",
      "At step 222250, TRAINING loss is 0.0001266712860212448\n",
      "At step 222500, TRAINING loss is 2.8956015632452356e-05\n",
      "At step 222750, TRAINING loss is 4.070381741846994e-05\n",
      "At step 223000, TRAINING loss is 5.024553399736576e-05\n",
      "At step 223000, sampled x_0 is 1.0663444288481756\n",
      "At step 223250, TRAINING loss is 6.42116710067762e-05\n",
      "At step 223500, TRAINING loss is 0.00014846958397949535\n",
      "At step 223750, TRAINING loss is 2.3845800734553e-05\n",
      "At step 224000, TRAINING loss is 5.7955075230061536e-05\n",
      "At step 224000, sampled x_0 is 0.9529347031982945\n",
      "At step 224250, TRAINING loss is 3.812289054411311e-05\n",
      "At step 224500, TRAINING loss is 1.7062242936551306e-06\n",
      "At step 224750, TRAINING loss is 1.905178700537828e-05\n",
      "At step 225000, TRAINING loss is 0.00016476927595418755\n",
      "At step 225000, sampled x_0 is 1.0069557978792036\n",
      "At step 225250, TRAINING loss is 5.112357813041468e-05\n",
      "At step 225500, TRAINING loss is 0.00018344477382222865\n",
      "At step 225750, TRAINING loss is 2.9486899607987773e-06\n",
      "At step 226000, TRAINING loss is 0.00016520703288699841\n",
      "At step 226000, sampled x_0 is 0.8722642772762372\n",
      "At step 226250, TRAINING loss is 3.962351625789972e-05\n",
      "At step 226500, TRAINING loss is 0.00018272589679378814\n",
      "At step 226750, TRAINING loss is 3.5987718058127594e-07\n",
      "At step 227000, TRAINING loss is 3.9541266596632357e-05\n",
      "At step 227000, sampled x_0 is 0.8509722127023241\n",
      "At step 227250, TRAINING loss is 2.9541069574979764e-07\n",
      "At step 227500, TRAINING loss is 8.43241911755771e-06\n",
      "At step 227750, TRAINING loss is 1.223669839450487e-05\n",
      "At step 228000, TRAINING loss is 0.0014432548806159714\n",
      "At step 228000, sampled x_0 is 1.0455331907309522\n",
      "At step 228250, TRAINING loss is 0.00012074982527599275\n",
      "At step 228500, TRAINING loss is 0.00053614393904354\n",
      "At step 228750, TRAINING loss is 0.00015797680256710568\n",
      "At step 229000, TRAINING loss is 0.00280421007929379\n",
      "At step 229000, sampled x_0 is 1.1597110710086524\n",
      "At step 229250, TRAINING loss is 9.106329722568046e-05\n",
      "At step 229500, TRAINING loss is 2.401396657318938e-06\n",
      "At step 229750, TRAINING loss is 0.00024283616519171417\n",
      "At step 230000, TRAINING loss is 5.229677374052207e-06\n",
      "At step 230000, sampled x_0 is 1.0263675443020972\n",
      "At step 230250, TRAINING loss is 0.0001899734985841309\n",
      "At step 230500, TRAINING loss is 0.0003593638599964477\n",
      "At step 230750, TRAINING loss is 5.048983053537408e-06\n",
      "At step 231000, TRAINING loss is 0.00010613881184622404\n",
      "At step 231000, sampled x_0 is 1.1727560187014523\n",
      "At step 231250, TRAINING loss is 0.006446167381429945\n",
      "At step 231500, TRAINING loss is 0.0039887787310401756\n",
      "At step 231750, TRAINING loss is 5.742714396276671e-05\n",
      "At step 232000, TRAINING loss is 0.0011124766889318003\n",
      "At step 232000, sampled x_0 is 0.9716023114725467\n",
      "At step 232250, TRAINING loss is 0.00035195151328185347\n",
      "At step 232500, TRAINING loss is 0.003560585721898953\n",
      "At step 232750, TRAINING loss is 0.0004013842647393083\n",
      "At step 233000, TRAINING loss is 0.00012372352213168653\n",
      "At step 233000, sampled x_0 is 0.8522243808173352\n",
      "At step 233250, TRAINING loss is 0.0005415613401904325\n",
      "At step 233500, TRAINING loss is 0.0014356018675100314\n",
      "At step 233750, TRAINING loss is 0.0005846224215947933\n",
      "At step 234000, TRAINING loss is 1.0186612649171017e-05\n",
      "At step 234000, sampled x_0 is 0.8324962889968767\n",
      "At step 234250, TRAINING loss is 3.4153518605356246e-05\n",
      "At step 234500, TRAINING loss is 6.558123665634533e-05\n",
      "At step 234750, TRAINING loss is 1.0829500188216482e-06\n",
      "At step 235000, TRAINING loss is 0.001036096662084989\n",
      "At step 235000, sampled x_0 is 1.0515773196697815\n",
      "At step 235250, TRAINING loss is 8.063534441612786e-05\n",
      "At step 235500, TRAINING loss is 6.612805532767535e-08\n",
      "At step 235750, TRAINING loss is 2.7560324923267454e-05\n",
      "At step 236000, TRAINING loss is 9.525726125101073e-06\n",
      "At step 236000, sampled x_0 is 0.9249549909309306\n",
      "At step 236250, TRAINING loss is 1.0600555991860216e-05\n",
      "At step 236500, TRAINING loss is 7.122856204406687e-07\n",
      "At step 236750, TRAINING loss is 4.4002031702218124e-05\n",
      "At step 237000, TRAINING loss is 5.264014828969547e-05\n",
      "At step 237000, sampled x_0 is 1.0599797823260044\n",
      "At step 237250, TRAINING loss is 1.3980381216471146e-05\n",
      "At step 237500, TRAINING loss is 3.0484904817240824e-05\n",
      "At step 237750, TRAINING loss is 8.392833517458794e-06\n",
      "At step 238000, TRAINING loss is 4.951291000907124e-06\n",
      "At step 238000, sampled x_0 is 1.0386618613527532\n",
      "At step 238250, TRAINING loss is 0.00021489024045526426\n",
      "At step 238500, TRAINING loss is 5.917352906442064e-06\n",
      "At step 238750, TRAINING loss is 1.834877057270781e-05\n",
      "At step 239000, TRAINING loss is 0.0006467520340638356\n",
      "At step 239000, sampled x_0 is 0.972405385810734\n",
      "At step 239250, TRAINING loss is 1.6324031684509393e-06\n",
      "At step 239500, TRAINING loss is 8.432098179066205e-05\n",
      "At step 239750, TRAINING loss is 1.2510081484836127e-05\n",
      "At step 240000, TRAINING loss is 9.909676060908799e-05\n",
      "At step 240000, sampled x_0 is 0.9417319759733163\n",
      "At step 240250, TRAINING loss is 1.776102295524367e-05\n",
      "At step 240500, TRAINING loss is 5.187842148637576e-05\n",
      "At step 240750, TRAINING loss is 2.997666735359136e-05\n",
      "At step 241000, TRAINING loss is 5.492292776654403e-06\n",
      "At step 241000, sampled x_0 is 0.9240875240368615\n",
      "At step 241250, TRAINING loss is 7.752051399292705e-05\n",
      "At step 241500, TRAINING loss is 0.00044482758867554707\n",
      "At step 241750, TRAINING loss is 3.4518028897323435e-05\n",
      "At step 242000, TRAINING loss is 0.00024388843560928163\n",
      "At step 242000, sampled x_0 is 0.9802053493514783\n",
      "At step 242250, TRAINING loss is 0.0002432901055115644\n",
      "At step 242500, TRAINING loss is 0.00018815464960290437\n",
      "At step 242750, TRAINING loss is 9.908334898084496e-06\n",
      "At step 243000, TRAINING loss is 1.1608933161358159e-05\n",
      "At step 243000, sampled x_0 is 1.0117074813838225\n",
      "At step 243250, TRAINING loss is 6.511596013790332e-05\n",
      "At step 243500, TRAINING loss is 4.438754250443312e-06\n",
      "At step 243750, TRAINING loss is 6.129320378740593e-06\n",
      "At step 244000, TRAINING loss is 0.000224955515538647\n",
      "At step 244000, sampled x_0 is 0.9338664306277226\n",
      "At step 244250, TRAINING loss is 0.0001283302150215181\n",
      "At step 244500, TRAINING loss is 0.00020459500437368613\n",
      "At step 244750, TRAINING loss is 0.0003831714738180836\n",
      "At step 245000, TRAINING loss is 0.00040185566639114236\n",
      "At step 245000, sampled x_0 is 0.9651813257346381\n",
      "At step 245250, TRAINING loss is 2.1371314246867957e-05\n",
      "At step 245500, TRAINING loss is 3.7618911086193207e-06\n",
      "At step 245750, TRAINING loss is 0.00017182652727911415\n",
      "At step 246000, TRAINING loss is 1.7331903509822803e-05\n",
      "At step 246000, sampled x_0 is 0.9632248667112857\n",
      "At step 246250, TRAINING loss is 0.001933083524885114\n",
      "At step 246500, TRAINING loss is 2.64960341942631e-06\n",
      "At step 246750, TRAINING loss is 0.0001930040862431618\n",
      "At step 247000, TRAINING loss is 7.285298071881104e-05\n",
      "At step 247000, sampled x_0 is 0.9765573109873589\n",
      "At step 247250, TRAINING loss is 8.335319479016977e-05\n",
      "At step 247500, TRAINING loss is 0.0027764141976225724\n",
      "At step 247750, TRAINING loss is 5.340358091488334e-05\n",
      "At step 248000, TRAINING loss is 7.484976657885573e-05\n",
      "At step 248000, sampled x_0 is 0.9771425463369406\n",
      "At step 248250, TRAINING loss is 2.344950620027671e-05\n",
      "At step 248500, TRAINING loss is 2.8657752302672686e-05\n",
      "At step 248750, TRAINING loss is 2.7058052158069246e-05\n",
      "At step 249000, TRAINING loss is 7.446896481958487e-05\n",
      "At step 249000, sampled x_0 is 1.0224739882962715\n",
      "At step 249250, TRAINING loss is 2.5845858303987204e-05\n",
      "At step 249500, TRAINING loss is 0.001135807306992857\n",
      "At step 249750, TRAINING loss is 8.631553945901843e-06\n"
     ]
    }
   ],
   "source": [
    "eval_freq=1000\n",
    "for step in ticker:\n",
    "\n",
    "    score_network.train()\n",
    "    \n",
    "    # if DEBUG:\n",
    "    #     inputs = ex_batch\n",
    "    # else:\n",
    "    #     raise NotImplementedError\n",
    "    #     inputs = next(iterator.train)\n",
    "    #     # inputs = inputs.to(device)\n",
    "        \n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    # '''\n",
    "    # Get encoded representation\n",
    "    # '''\n",
    "    \n",
    "    # code = ae.encode(inputs)\n",
    "    \n",
    "    t = rng.uniform(min_t, 1.0)\n",
    "    x_t, gt_score_t = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=t)\n",
    "    \n",
    "    score_scaling = torch.tensor(diffuser.score_scaling(t)).to(device)\n",
    "    gt_score_t = torch.tensor(gt_score_t).to(device)\n",
    "    \n",
    "    pred_score_t = score_network(torch.tensor(x_t).float().to(device), t)\n",
    "\n",
    "    score_mse = (gt_score_t - pred_score_t)**2\n",
    "    score_loss = torch.sum(\n",
    "        score_mse / score_scaling[None, None]**2,\n",
    "        dim=(-1, -2)\n",
    "    ) #/ (loss_mask.sum(dim=-1) + 1e-10)    \n",
    "    \n",
    "    # comps = {k: v.mean().item() for k, v in comps._asdict().items()}\n",
    "    score_loss.backward()\n",
    "    optimizer.step()\n",
    "    # check_loss(score_)\n",
    "\n",
    "    if step % config.training.logs_freq == 0:\n",
    "        # log to logger object\n",
    "        # logger.log(\"train\", loss=loss.item(), step=step, **comps)\n",
    "        writer.add_scalar('Training loss', score_loss.item(), global_step=step)\n",
    "        print(f'At step {step}, TRAINING loss is {score_loss.item()}')\n",
    "        \n",
    "    if step % eval_freq == 0:\n",
    "        sampled_x_0 = eval(dt=0.01)\n",
    "        print(f'At step {step}, sampled x_0 is {sampled_x_0.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(score_network, '6.29.23.1D_mlp_score_network.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04722174]] [[2.07840987]]\n"
     ]
    }
   ],
   "source": [
    "x_t, score = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=1.0)\n",
    "print(x_t, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02342059]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t_1 = diffuser.reverse(x_t=x_t, score_t=score, t=1.0, dt=0.001, center=False)\n",
    "x_t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_traj(x_0, min_t, num_t):\n",
    "    forward_steps = np.linspace(min_t, 1.0, num_t)[:-1]\n",
    "    x_traj = [x_0]\n",
    "    for t in forward_steps:\n",
    "        x_t = diffuser.forward(\n",
    "            x_traj[-1], t, num_t)\n",
    "        x_traj.append(x_t)\n",
    "    x_traj = torch.stack(x_traj, axis=0)\n",
    "    return x_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_traj(ex_code, 0, int(1 // dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_t at time 1.0: [[1.82766834]]\n",
      "x_t at time 0.8999999999999999: [[1.94588314]]\n",
      "x_t at time 0.7999999999999998: [[1.58082364]]\n",
      "x_t at time 0.6999999999999997: [[1.5707374]]\n",
      "x_t at time 0.5999999999999996: [[1.32685549]]\n",
      "x_t at time 0.49999999999999956: [[1.18496909]]\n",
      "x_t at time 0.39999999999999947: [[1.0508872]]\n",
      "x_t at time 0.2999999999999994: [[1.14108817]]\n",
      "x_t at time 0.1999999999999993: [[0.83235974]]\n",
      "x_t at time 0.0999999999999992: [[0.96681785]]\n",
      "tensor([[1.]], device='cuda:2') [[0.99958229]]\n"
     ]
    }
   ],
   "source": [
    "dt = 0.001\n",
    "log_freq = (1 / dt) / 10\n",
    "\n",
    "pred_scores = []\n",
    "gt_scores = []\n",
    "\n",
    "x_t_list = []  # list to store x_t at each step\n",
    "\n",
    "with torch.no_grad():\n",
    "    score_network.eval()\n",
    "    x_t, _ = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=1.0)\n",
    "    \n",
    "    for i, t in enumerate(np.arange(1.0, 0, -dt)):\n",
    "        if i % log_freq == 0:\n",
    "            print(f'x_t at time {t}: {x_t}')\n",
    "            ...\n",
    "        x_t = torch.tensor(x_t).float().to(device)\n",
    "        pred_score = score_network(x_t, t)\n",
    "        \n",
    "        # _, gt_score = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=t)\n",
    "\n",
    "        # pred_scores.append(pred_score)\n",
    "        # gt_scores.append(gt_score)\n",
    "        \n",
    "        # print(pred_score, gt_score)\n",
    "        \n",
    "        x_t = diffuser.reverse(x_t=x_t.detach().cpu().numpy(), score_t=pred_score.detach().cpu().numpy(), t=t, dt=dt, center=False)\n",
    "        x_t_list.append(x_t.item())  # append x_t to the list\n",
    "\n",
    "    x_0 = x_t\n",
    "    print(ex_code, x_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/rsg/chemistry/johnyang/miniconda3/envs/cellot/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sampling x_t from learned reverse process, gt x_0 = 1.0, random init')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot([x for x in range(len(x_t_list))], x_t_list)\n",
    "plt.xlabel('Time Step (dt = 0.001)')\n",
    "plt.ylabel('x_t Value')\n",
    "plt.title('Sampling x_t from learned reverse process, gt x_0 = 1.0, random init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/rsg/chemistry/johnyang/miniconda3/envs/cellot/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot([x.item() for x in gt_scores], [x.detach().cpu().numpy().item() for x in pred_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
