{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from absl import logging\n",
    "from absl.flags import FLAGS\n",
    "from cellot import losses\n",
    "from cellot.utils.loaders import load\n",
    "from cellot.models.cellot import compute_loss_f, compute_loss_g, compute_w2_distance\n",
    "from cellot.train.summary import Logger\n",
    "from cellot.data.utils import cast_loader_to_iterator\n",
    "from cellot.models.ae import compute_scgen_shift\n",
    "from tqdm import trange\n",
    "\n",
    "from cellot.models.ae import AutoEncoder\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "logger = logging.getLogger(\"data_logger\")\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "TARGET = 'all' if not DEBUG else 'abexinostat'\n",
    "LATENT_DIM = 1\n",
    "\n",
    "from pathlib import Path\n",
    "outdir_path = '/Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/full_ae'\n",
    "outdir = Path(outdir_path)\n",
    "\n",
    "# %%\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "cachedir = outdir / \"cache\"\n",
    "cachedir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import GPUtil\n",
    "import os\n",
    "\n",
    "def get_free_gpu():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "    # Set environment variables for which GPUs to use.\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    chosen_gpu = ''.join(\n",
    "        [str(x) for x in GPUtil.getAvailable(order='memory')])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = chosen_gpu\n",
    "    print(f\"Using GPUs: {chosen_gpu}\")\n",
    "    return chosen_gpu\n",
    "\n",
    "status = cachedir / \"status\"\n",
    "status.write_text(\"running\")\n",
    "\n",
    "device = f'cuda:{get_free_gpu()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "import omegaconf\n",
    "\n",
    "if DEBUG:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "else:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "\n",
    "yaml_str = f\"\"\"\n",
    "model:\n",
    "   name: scgen\n",
    "   beta: 0.0\n",
    "   dropout: 0.0\n",
    "   hidden_units: [512, 512]\n",
    "   latent_dim: 50\n",
    "\n",
    "optim:\n",
    "   lr: 0.001\n",
    "   optimizer: Adam\n",
    "   weight_decay: 1.0e-05\n",
    "\n",
    "scheduler:\n",
    "   gamma: 0.5\n",
    "   step_size: 100000\n",
    "\n",
    "training:\n",
    "  cache_freq: 10000\n",
    "  eval_freq: 2500\n",
    "  logs_freq: 250\n",
    "  n_iters: {n_iters}\n",
    "\n",
    "data:\n",
    "  type: cell\n",
    "  source: control\n",
    "  condition: drug\n",
    "  path: /Mounts/rbg-storage1/users/johnyang/cellot/datasets/scrna-sciplex3/hvg.h5ad\n",
    "  target: {TARGET}\n",
    "\n",
    "datasplit:\n",
    "    groupby: drug   \n",
    "    name: train_test\n",
    "    test_size: 0.2\n",
    "    random_state: 0\n",
    "\n",
    "dataloader:\n",
    "    batch_size: {batch_size}\n",
    "    shuffle: true\n",
    "\"\"\"\n",
    "\n",
    "config = omegaconf.OmegaConf.create(yaml_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ### Utils\n",
    "\n",
    "# %%\n",
    "def load_lr_scheduler(optim, config):\n",
    "    if \"scheduler\" not in config:\n",
    "        return None\n",
    "\n",
    "    return torch.optim.lr_scheduler.StepLR(optim, **config.scheduler)\n",
    "\n",
    "def check_loss(*args):\n",
    "    for arg in args:\n",
    "        if torch.isnan(arg):\n",
    "            raise ValueError\n",
    "\n",
    "\n",
    "def load_item_from_save(path, key, default):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return default\n",
    "\n",
    "    ckpt = torch.load(path)\n",
    "    if key not in ckpt:\n",
    "        logging.warn(f\"'{key}' not found in ckpt: {str(path)}\")\n",
    "        return default\n",
    "\n",
    "    return ckpt[key]\n",
    "\n",
    "# %%\n",
    "import cellot.models\n",
    "from cellot.data.cell import load_cell_data\n",
    "\n",
    "\n",
    "def load_data(config, **kwargs):\n",
    "    data_type = config.get(\"data.type\", \"cell\")\n",
    "    if data_type in [\"cell\", \"cell-merged\", \"tupro-cohort\"]:\n",
    "        loadfxn = load_cell_data\n",
    "\n",
    "    elif data_type == \"toy\":\n",
    "        loadfxn = load_toy_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return loadfxn(config, **kwargs)\n",
    "\n",
    "\n",
    "def load_model(config, device, restore=None, **kwargs):\n",
    "    # def load_autoencoder_model(config, restore=None, **kwargs):\n",
    "    \n",
    "    def load_optimizer(config, params):\n",
    "        kwargs = dict(config.get(\"optim\", {}))\n",
    "        assert kwargs.pop(\"optimizer\", \"Adam\") == \"Adam\"\n",
    "        optim = torch.optim.Adam(params, **kwargs)\n",
    "        return optim\n",
    "\n",
    "\n",
    "    def load_networks(config, **kwargs):\n",
    "        kwargs = kwargs.copy()\n",
    "        kwargs.update(dict(config.get(\"model\", {})))\n",
    "        name = kwargs.pop(\"name\")\n",
    "\n",
    "        if name == \"scgen\":\n",
    "            model = AutoEncoder\n",
    "\n",
    "        # elif name == \"cae\":\n",
    "        #     model = ConditionalAutoEncoder\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        return model(**kwargs)\n",
    "    \n",
    "    model = load_networks(config, **kwargs)\n",
    "    optim = load_optimizer(config, model.parameters())\n",
    "\n",
    "    if restore is not None and Path(restore).exists():\n",
    "        print('Loading model from checkpoint')\n",
    "        ckpt = torch.load(restore, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optim.load_state_dict(ckpt[\"optim_state\"])\n",
    "        if config.model.name == \"scgen\" and \"code_means\" in ckpt:\n",
    "            model.code_means = ckpt[\"code_means\"]\n",
    "            \n",
    "    # logger.info(f'Model on device {next(model.parameters()).device}')\n",
    "\n",
    "    return model, optim\n",
    "\n",
    "def load(config, device, restore=None, include_model_kwargs=False, **kwargs):\n",
    "\n",
    "    loader, model_kwargs = load_data(config, include_model_kwargs=True, **kwargs)\n",
    "\n",
    "    model, opt = load_model(config, device, restore=restore, **model_kwargs)\n",
    "\n",
    "    # if include_model_kwargs:\n",
    "    #     return model, opt, loader, model_kwargs\n",
    "\n",
    "    return model, opt, loader\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_dict(model, optim, **kwargs):\n",
    "    state = {\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optim.state_dict(),\n",
    "    }\n",
    "\n",
    "    if hasattr(model, \"code_means\"):\n",
    "        state[\"code_means\"] = model.code_means\n",
    "\n",
    "    state.update(kwargs)\n",
    "\n",
    "    return state\n",
    "\n",
    "def evaluate(vinputs):\n",
    "    with torch.no_grad():\n",
    "        loss, comps, _ = model(vinputs)\n",
    "        loss = loss.mean()\n",
    "        comps = {k: v.mean().item() for k, v in comps._asdict().items()}\n",
    "        check_loss(loss)\n",
    "        logger.log(\"eval\", loss=loss.item(), step=step, **comps)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 13:36:18,326 Loaded cell data with TARGET abexinostat and OBS SHAPE (22070, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint\n"
     ]
    }
   ],
   "source": [
    "_, _, loader = load(config, 'cuda', restore=cachedir / \"last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"R^3 diffusion methods.\"\"\"\n",
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "import torch\n",
    "\n",
    "\n",
    "class R3Diffuser:\n",
    "    \"\"\"VP-SDE diffuser class for translations.\"\"\"\n",
    "\n",
    "    def __init__(self, r3_conf):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            min_b: starting value in variance schedule.\n",
    "            max_b: ending value in variance schedule.\n",
    "        \"\"\"\n",
    "        self._r3_conf = r3_conf\n",
    "        self.min_b = r3_conf.min_b\n",
    "        self.max_b = r3_conf.max_b\n",
    "        self.schedule = r3_conf.schedule\n",
    "        self._score_scaling = r3_conf.score_scaling\n",
    "        self.latent_dim = r3_conf.latent_dim\n",
    "\n",
    "    def _scale(self, x):\n",
    "        return x * self._r3_conf.coordinate_scaling\n",
    "\n",
    "    def _unscale(self, x):\n",
    "        return x / self._r3_conf.coordinate_scaling\n",
    "\n",
    "    def b_t(self, t):\n",
    "        if np.any(t < 0) or np.any(t > 1):\n",
    "            raise ValueError(f'Invalid t={t}')\n",
    "        if self.schedule == 'linear': \n",
    "            return self.min_b + t*(self.max_b - self.min_b)\n",
    "        elif self.schedule == 'cosine':\n",
    "            return self.max_b + 0.5*(self.min_b - self.max_b)*(1 + np.cos(t*np.pi))\n",
    "        elif self.schedule == 'exponential':\n",
    "            sigma = t * np.log10(self.max_b) + (1 - t) * np.log10(self.min_b)\n",
    "            return 10 ** sigma\n",
    "        else:\n",
    "            raise ValueError(f'Unknown schedule {self.schedule}')\n",
    "    \n",
    "    def diffusion_coef(self, t):\n",
    "        \"\"\"Time-dependent diffusion coefficient.\"\"\"\n",
    "        return np.sqrt(self.b_t(t))\n",
    "\n",
    "    def drift_coef(self, x, t):\n",
    "        \"\"\"Time-dependent drift coefficient.\"\"\"\n",
    "        return -1/2 * self.b_t(t) * x\n",
    "\n",
    "    def sample_ref(self, n_samples: float=1):\n",
    "        return np.random.normal(size=(n_samples, self.latent_dim))\n",
    "\n",
    "    def marginal_b_t(self, t):\n",
    "        if self.schedule == 'linear':\n",
    "            return t*self.min_b + (1/2)*(t**2)*(self.max_b-self.min_b)\n",
    "        elif self.schedule == 'exponential': \n",
    "            return (self.max_b**t * self.min_b**(1-t) - self.min_b) / (\n",
    "                np.log(self.max_b) - np.log(self.min_b))\n",
    "        else:\n",
    "            raise ValueError(f'Unknown schedule {self.schedule}')\n",
    "\n",
    "    def calc_trans_0(self, score_t, x_t, t, use_torch=True):\n",
    "        beta_t = self.marginal_b_t(t)\n",
    "        beta_t = beta_t[..., None, None]\n",
    "        exp_fn = torch.exp if use_torch else np.exp\n",
    "        cond_var = 1 - exp_fn(-beta_t)\n",
    "        return (score_t * cond_var + x_t) / exp_fn(-1/2*beta_t)\n",
    "\n",
    "    def forward(self, x_t_1: np.ndarray, t: float, num_t: int):\n",
    "        \"\"\"Samples marginal p(x(t) | x(t-1)).\n",
    "\n",
    "        Args:\n",
    "            x_0: [..., n, 3] initial positions in Angstroms.\n",
    "            t: continuous time in [0, 1]. \n",
    "\n",
    "        Returns:\n",
    "            x_t: [..., n, 3] positions at time t in Angstroms.\n",
    "            score_t: [..., n, 3] score at time t in scaled Angstroms.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_t_1 = self._scale(x_t_1)\n",
    "        b_t = torch.tensor(self.marginal_b_t(t) / num_t).to(x_t_1.device)\n",
    "        z_t_1 = torch.tensor(np.random.normal(size=x_t_1.shape)).to(x_t_1.device)\n",
    "        x_t = torch.sqrt(1 - b_t) * x_t_1 + torch.sqrt(b_t) * z_t_1\n",
    "        return x_t\n",
    "    \n",
    "    def distribution(self, x_t, score_t, t, mask, dt):\n",
    "        x_t = self._scale(x_t)\n",
    "        g_t = self.diffusion_coef(t)\n",
    "        f_t = self.drift_coef(x_t, t)\n",
    "        std = g_t * np.sqrt(dt)\n",
    "        mu = x_t - (f_t - g_t**2 * score_t) * dt\n",
    "        if mask is not None:\n",
    "            mu *= mask[..., None]\n",
    "        return mu, std\n",
    "\n",
    "    def forward_marginal(self, x_0: np.ndarray, t: float):\n",
    "        \"\"\"Samples marginal p(x(t) | x(0)).\n",
    "\n",
    "        Args:\n",
    "            x_0: [..., n, 3] initial positions in Angstroms.\n",
    "            t: continuous time in [0, 1]. \n",
    "\n",
    "        Returns:\n",
    "            x_t: [..., n, 3] positions at time t in Angstroms.\n",
    "            score_t: [..., n, 3] score at time t in scaled Angstroms.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_0 = self._scale(x_0)\n",
    "        x_t = np.random.normal(\n",
    "            loc=np.exp(-1/2*self.marginal_b_t(t)) * x_0,\n",
    "            scale=np.sqrt(1 - np.exp(-self.marginal_b_t(t)))\n",
    "        )\n",
    "        score_t = self.score(x_t, x_0, t)\n",
    "        x_t = self._unscale(x_t)\n",
    "        return x_t, score_t\n",
    "\n",
    "    def score_scaling(self, t: float):\n",
    "        if self._score_scaling == 'var':\n",
    "            return 1 / self.conditional_var(t)\n",
    "        elif self._score_scaling == 'std':\n",
    "            return 1 / np.sqrt(self.conditional_var(t))\n",
    "        elif self._score_scaling == 'expected_norm':\n",
    "            return np.sqrt(2) / (gamma(1.5) * np.sqrt(self.conditional_var(t)))\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized scaling {self._score_scaling}')\n",
    "\n",
    "    def reverse(\n",
    "            self,\n",
    "            *,\n",
    "            x_t: np.ndarray,\n",
    "            score_t: np.ndarray,\n",
    "            t: float,\n",
    "            dt: float,\n",
    "            mask: np.ndarray=None,\n",
    "            center: bool=True,\n",
    "            ode: bool=False,\n",
    "            noise_scale: float=1.0,\n",
    "        ):\n",
    "        \"\"\"Simulates the reverse SDE for 1 step\n",
    "\n",
    "        Args:\n",
    "            x_t: [..., 3] current positions at time t in angstroms.\n",
    "            score_t: [..., 3] rotation score at time t.\n",
    "            t: continuous time in [0, 1].\n",
    "            dt: continuous step size in [0, 1].\n",
    "            mask: True indicates which residues to diffuse.\n",
    "\n",
    "        Returns:\n",
    "            [..., 3] positions at next step t-1.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_t = self._scale(x_t)\n",
    "        g_t = self.diffusion_coef(t)\n",
    "        f_t = self.drift_coef(x_t, t)\n",
    "        if ode:\n",
    "            # Probability flow ODE\n",
    "            perturb = (f_t - (1/2)*(g_t**2) * score_t) * dt\n",
    "        else:\n",
    "            # Usual stochastic dynamics\n",
    "            z = noise_scale * np.random.normal(size=score_t.shape)\n",
    "            perturb = (f_t - g_t**2 * score_t) * dt + g_t * np.sqrt(dt) * z\n",
    "\n",
    "        if mask is not None:\n",
    "            perturb *= mask[..., None]\n",
    "        else:\n",
    "            mask = np.ones(x_t.shape[:-1])\n",
    "        x_t_1 = x_t - perturb\n",
    "        if center:\n",
    "            com = np.sum(x_t_1, axis=-2) / np.sum(mask, axis=-1)[..., None]\n",
    "            x_t_1 -= com[..., None, :]\n",
    "        x_t_1 = self._unscale(x_t_1)\n",
    "        return x_t_1\n",
    "\n",
    "    def conditional_var(self, t, use_torch=False):\n",
    "        \"\"\"Conditional variance of p(xt|x0).\n",
    "\n",
    "        Var[x_t|x_0] = conditional_var(t)*I\n",
    "\n",
    "        \"\"\"\n",
    "        if use_torch:\n",
    "            return 1 - torch.exp(-self.marginal_b_t(t))\n",
    "        return 1 - np.exp(-self.marginal_b_t(t))\n",
    "\n",
    "    def score(self, x_t, x_0, t, use_torch=False, scale=False):\n",
    "        if use_torch:\n",
    "            exp_fn = torch.exp\n",
    "        else:\n",
    "            exp_fn = np.exp\n",
    "        if scale:\n",
    "            x_t = self._scale(x_t)\n",
    "            x_0 = self._scale(x_0)\n",
    "        return -(x_t - exp_fn(-1/2*self.marginal_b_t(t)) * x_0) / self.conditional_var(t, use_torch=use_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "r3_conf = OmegaConf.create({\n",
    "    'min_b': 0.01,\n",
    "    'max_b': 1.0,\n",
    "    'schedule': 'linear',\n",
    "    'score_scaling': 'var',\n",
    "    'coordinate_scaling': 1.0,\n",
    "    'latent_dim': LATENT_DIM,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuser = R3Diffuser(r3_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, Linear\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dim = 64\n",
    "num_layers = 2\n",
    "nhead = 1\n",
    "dim_feedforward = 128\n",
    "dropout = 0.1 if not DEBUG else 0.0\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import functools as fn\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim=64, output_dim=50):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def get_timestep_embedding(timesteps, embedding_dim, max_positions=10000):\n",
    "    # Code from https://github.com/hojonathanho/diffusion/blob/master/diffusion_tf/nn.py\n",
    "    assert len(timesteps.shape) == 1\n",
    "    timesteps = timesteps * max_positions\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(max_positions) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32, device=timesteps.device) * -emb)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = F.pad(emb, (0, 1), mode='constant')\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return emb\n",
    "\n",
    "class ScoreNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScoreNetwork, self).__init__()\n",
    "        \n",
    "        self.latent_dim = LATENT_DIM\n",
    "        self.model_dim = model_dim\n",
    "        self.dropout = dropout\n",
    "        print(f'Dropout is {self.dropout}')\n",
    "        self.embed_code_and_t = nn.Linear(LATENT_DIM + model_dim, model_dim)\n",
    "        self.trmr_layer = TransformerEncoderLayer(d_model=model_dim, nhead=8, dim_feedforward=2048, dropout=dropout)\n",
    "        self.pred_score = FeedForward(input_dim=model_dim, hidden_dim=64, output_dim=LATENT_DIM)\n",
    "        self.model = nn.ModuleList([self.embed_code_and_t, *[self.trmr_layer for _ in range(num_layers)], self.pred_score])\n",
    "        \n",
    "        self.timestep_embedder = fn.partial(\n",
    "            get_timestep_embedding,\n",
    "            embedding_dim=self.model_dim,\n",
    "            # max_positions=100\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        device = x.device\n",
    "        B, C = x.shape\n",
    "        t_embed = torch.tile(self.timestep_embedder(torch.tensor([t]).to(device)), dims=[B, 1])\n",
    "        \n",
    "        x = torch.cat([x, t_embed], dim=-1).to(device)\n",
    "        \n",
    "        for module in self.model[:-1]:  # iterate over all modules except the last one\n",
    "            x = module(x)\n",
    "        x = self.model[-1](x.squeeze(0))  # pass through the last module (FeedForward)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout is 0.0\n"
     ]
    }
   ],
   "source": [
    "score_network = ScoreNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289601"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in score_network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(score_network.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "STEP = 0\n",
    "ticker = trange(STEP, n_iters, initial=STEP, total=n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORIZING MODEEEE\n"
     ]
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    ex_batch = torch.load('/Mounts/rbg-storage1/users/johnyang/cellot/ex_batch_sciplex3.pt').to(device)\n",
    "    print('MEMORIZING MODEEEE')\n",
    "else:\n",
    "    print('NOT memorizing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = cast_loader_to_iterator(loader, cycle_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = next(iterator.train).to(device)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     ex_code = ae.encode(ex_batch).to(device)[None, 0, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_code = torch.ones((1, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_t = 0.0\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/6.29.23_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(dt=0.001):\n",
    "    score_network.eval()\n",
    "    # log_freq = (1 / dt) / 100\n",
    "    with torch.no_grad():\n",
    "        x_t, _ = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=1.0)\n",
    "        \n",
    "        for i, t in enumerate(np.arange(1.0, 0, -dt)):\n",
    "            # if i % log_freq == 0:\n",
    "                # print(x_t)\n",
    "            x_t = torch.tensor(x_t).float().to(device)\n",
    "            pred_score = score_network(x_t, t)\n",
    "            \n",
    "            # pred_scores.append(pred_score)\n",
    "            # gt_scores.append(gt_score)\n",
    "            \n",
    "            # _, gt_score = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=t)\n",
    "\n",
    "            # print(pred_score, gt_score)\n",
    "            \n",
    "            x_t = diffuser.reverse(x_t=x_t.detach().cpu().numpy(), score_t=pred_score.detach().cpu().numpy(), t=t, dt=dt, center=False)\n",
    "        \n",
    "        x_0 = x_t\n",
    "        writer.add_embedding(x_0, global_step=step, tag='reverse_sampled_x_0')\n",
    "        writer.add_embedding(ex_code, global_step=step, tag='gt_x_0')\n",
    "        writer.add_scalar('sampled x_0', x_0.item(), global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 0, TRAINING loss is 0.011111482239258421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 253/250000 [00:52<4:18:22, 16.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 250, TRAINING loss is 0.37572293911707505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 503/250000 [01:08<4:21:42, 15.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 500, TRAINING loss is 0.17507637523971165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 753/250000 [01:23<4:28:10, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 750, TRAINING loss is 0.029526436540580587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 999/250000 [01:39<4:15:43, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 1000, TRAINING loss is 0.001217812855422147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1253/250000 [02:13<4:19:13, 15.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 1250, TRAINING loss is 0.013575531799537613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1503/250000 [02:28<4:16:41, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 1500, TRAINING loss is 0.014520365294600369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1753/250000 [02:44<4:46:06, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 1750, TRAINING loss is 0.02478085084298618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1999/250000 [02:59<4:17:40, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 2000, TRAINING loss is 0.13039476028318395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2253/250000 [03:33<4:14:37, 16.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 2250, TRAINING loss is 0.0636031635752245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2503/250000 [03:49<4:24:02, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 2500, TRAINING loss is 0.0005059783987574045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2753/250000 [04:04<4:17:49, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 2750, TRAINING loss is 0.0004756541427235294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2999/250000 [04:20<4:06:39, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 3000, TRAINING loss is 0.014813143779099926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3253/250000 [04:53<4:09:47, 16.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 3250, TRAINING loss is 0.009368731167508243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3503/250000 [05:09<4:23:52, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 3500, TRAINING loss is 0.0003045278730302218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3753/250000 [05:24<4:19:09, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 3750, TRAINING loss is 0.001303702462982149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3999/250000 [05:40<4:12:42, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 4000, TRAINING loss is 0.02306755544244542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4253/250000 [06:14<4:25:48, 15.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 4250, TRAINING loss is 0.00933485526400987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4503/250000 [06:30<4:17:48, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 4500, TRAINING loss is 0.0013242062451352184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4753/250000 [06:46<4:14:55, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 4750, TRAINING loss is 0.01953714031599575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4999/250000 [07:01<4:09:46, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 5000, TRAINING loss is 0.0014811528461962055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5253/250000 [07:35<4:42:21, 14.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 5250, TRAINING loss is 0.0010363541446516693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5503/250000 [07:51<4:40:15, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 5500, TRAINING loss is 0.024411300494536454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5753/250000 [08:06<4:14:57, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 5750, TRAINING loss is 0.00014652052057393444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5999/250000 [08:21<4:13:43, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 6000, TRAINING loss is 0.008268362813106417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6253/250000 [08:55<4:06:01, 16.51it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 6250, TRAINING loss is 2.028032687811369e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6503/250000 [09:11<4:15:07, 15.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 6500, TRAINING loss is 0.012786273104211956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6753/250000 [09:26<4:14:30, 15.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 6750, TRAINING loss is 3.7580101098229225e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6999/250000 [09:41<4:06:06, 16.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 7000, TRAINING loss is 0.031609182492461176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7253/250000 [10:15<4:17:32, 15.71it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 7250, TRAINING loss is 0.0005112445788239207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7503/250000 [10:30<4:17:00, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 7500, TRAINING loss is 0.014435252953518577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7753/250000 [10:46<4:32:38, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 7750, TRAINING loss is 5.305579990213525e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7999/250000 [11:01<4:09:36, 16.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 8000, TRAINING loss is 0.0011592066436730377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8253/250000 [11:35<4:10:59, 16.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 8250, TRAINING loss is 0.0015834704960352014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8503/250000 [11:51<4:17:23, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 8500, TRAINING loss is 0.0001663793515276705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 8753/250000 [12:06<4:06:55, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 8750, TRAINING loss is 4.6154853319936204e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 8999/250000 [12:21<4:08:00, 16.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 9000, TRAINING loss is 0.0011810982660924619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 9253/250000 [12:56<4:39:20, 14.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 9250, TRAINING loss is 0.022225551720022215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9503/250000 [13:11<4:39:06, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 9500, TRAINING loss is 0.004505092842353885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9753/250000 [13:27<4:16:24, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 9750, TRAINING loss is 0.0005081966329232871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9999/250000 [13:43<4:20:28, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 10000, TRAINING loss is 0.004127806040756167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10253/250000 [14:17<4:28:37, 14.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 10250, TRAINING loss is 0.07428242879345912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10503/250000 [14:33<4:28:08, 14.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 10500, TRAINING loss is 0.003547777645333179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10753/250000 [14:49<4:14:03, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 10750, TRAINING loss is 0.0008002670072248381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10999/250000 [15:04<4:05:27, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 11000, TRAINING loss is 0.0002863266372625771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11253/250000 [15:38<4:14:11, 15.65it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 11250, TRAINING loss is 0.00028290518057874127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11503/250000 [15:54<4:06:30, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 11500, TRAINING loss is 0.0006930324105960256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11753/250000 [16:09<4:01:49, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 11750, TRAINING loss is 0.017460253056972054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11999/250000 [16:24<4:33:50, 14.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 12000, TRAINING loss is 0.047144699331589095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 12253/250000 [16:59<4:03:34, 16.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 12250, TRAINING loss is 0.00038898380309409006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 12503/250000 [17:14<4:11:03, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 12500, TRAINING loss is 0.005092034124714728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 12753/250000 [17:30<3:58:02, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 12750, TRAINING loss is 0.0004165825315902861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 12999/250000 [17:45<4:02:52, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 13000, TRAINING loss is 0.0035908852852204994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 13253/250000 [18:19<4:13:59, 15.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 13250, TRAINING loss is 0.00017719834061782327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 13503/250000 [18:35<4:12:10, 15.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 13500, TRAINING loss is 0.0007250443841188715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 13753/250000 [18:50<4:04:16, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 13750, TRAINING loss is 0.0006587041830623256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 13999/250000 [19:06<4:06:33, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 14000, TRAINING loss is 0.0007178569137961672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14253/250000 [19:40<4:21:45, 15.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 14250, TRAINING loss is 0.0013207520952683322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14503/250000 [19:56<3:59:34, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 14500, TRAINING loss is 6.3627098863797636e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14753/250000 [20:12<4:04:23, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 14750, TRAINING loss is 0.003833200006854065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14999/250000 [20:27<3:55:50, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 15000, TRAINING loss is 0.0005474591055964614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 15253/250000 [21:01<4:07:26, 15.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 15250, TRAINING loss is 0.003552610617097901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 15503/250000 [21:16<4:31:16, 14.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 15500, TRAINING loss is 0.00015488002739184808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 15753/250000 [21:32<4:12:12, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 15750, TRAINING loss is 3.2055280995834745e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 15999/250000 [21:47<3:53:08, 16.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 16000, TRAINING loss is 6.617802706671977e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 16253/250000 [22:21<4:21:21, 14.91it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 16250, TRAINING loss is 3.9903468970181185e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 16503/250000 [22:37<4:06:13, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 16500, TRAINING loss is 0.0074107718878833094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 16753/250000 [22:53<4:00:44, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 16750, TRAINING loss is 0.00029585911402061894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 16999/250000 [23:08<3:53:18, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 17000, TRAINING loss is 0.002904608821082689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17253/250000 [23:42<4:03:16, 15.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 17250, TRAINING loss is 0.0029576209458243258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17503/250000 [23:58<3:53:05, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 17500, TRAINING loss is 0.0035385680258424317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17753/250000 [24:13<4:05:49, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 17750, TRAINING loss is 0.0003665339301404792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17999/250000 [24:28<3:52:27, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18000, TRAINING loss is 0.0015528535588474636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 18253/250000 [25:02<4:00:56, 16.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18250, TRAINING loss is 1.577167773011318e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 18503/250000 [25:17<3:52:05, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18500, TRAINING loss is 0.008241432823483363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 18753/250000 [25:33<3:57:40, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18750, TRAINING loss is 0.00611592221832802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 18999/250000 [25:48<4:07:31, 15.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 19000, TRAINING loss is 5.865960861708434e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 19253/250000 [26:23<4:09:38, 15.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 19250, TRAINING loss is 0.004343487478956376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 19503/250000 [26:39<4:17:51, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 19500, TRAINING loss is 0.007786400634990083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 19753/250000 [26:55<4:28:05, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 19750, TRAINING loss is 2.4718300650645834e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 19999/250000 [27:11<4:08:26, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 20000, TRAINING loss is 0.00043191977199673716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20253/250000 [27:46<3:55:52, 16.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 20250, TRAINING loss is 0.0029272985564839623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20503/250000 [28:02<4:11:40, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 20500, TRAINING loss is 0.0009099619519931535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20753/250000 [28:18<4:02:34, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 20750, TRAINING loss is 0.0002191736232643566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20999/250000 [28:34<4:11:55, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 21000, TRAINING loss is 0.0051829758124050905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 21253/250000 [29:08<3:58:24, 15.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 21250, TRAINING loss is 4.08726838195794e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 21503/250000 [29:24<4:07:29, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 21500, TRAINING loss is 0.00029471408425556553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 21753/250000 [29:40<3:51:23, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 21750, TRAINING loss is 0.020178126376767896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 21999/250000 [29:55<3:58:48, 15.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 22000, TRAINING loss is 0.0023431797701951177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 22253/250000 [30:29<3:54:58, 16.15it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 22250, TRAINING loss is 0.0012011315475131026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 22503/250000 [30:45<3:57:59, 15.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 22500, TRAINING loss is 0.004701094190121871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 22753/250000 [31:01<4:12:14, 15.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 22750, TRAINING loss is 0.019439279215308327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 22999/250000 [31:17<3:52:09, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 23000, TRAINING loss is 0.00019422015380129523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 23253/250000 [31:51<4:21:11, 14.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 23250, TRAINING loss is 3.249531201213474e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 23503/250000 [32:06<3:47:17, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 23500, TRAINING loss is 0.0005894558453868713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 23753/250000 [32:22<4:02:01, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 23750, TRAINING loss is 0.002691674408682648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 23999/250000 [32:37<3:49:37, 16.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 24000, TRAINING loss is 0.0001752957854459698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 24253/250000 [33:11<4:04:44, 15.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 24250, TRAINING loss is 2.5016112410775552e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 24503/250000 [33:27<3:51:22, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 24500, TRAINING loss is 6.637384867961784e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 24753/250000 [33:42<3:58:29, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 24750, TRAINING loss is 0.002041872152692026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 24999/250000 [33:58<3:57:23, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 25000, TRAINING loss is 0.012301453407746295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 25253/250000 [34:33<3:53:51, 16.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 25250, TRAINING loss is 0.0006011290058233184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 25503/250000 [34:49<3:53:09, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 25500, TRAINING loss is 0.009965702298020589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 25753/250000 [35:05<4:00:41, 15.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 25750, TRAINING loss is 2.729417435898443e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 25999/250000 [35:21<3:56:23, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 26000, TRAINING loss is 0.0057989357321995465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 26254/250000 [35:55<3:59:12, 15.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 26250, TRAINING loss is 0.00797395905369817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 26504/250000 [36:11<3:50:52, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 26500, TRAINING loss is 0.006663004935922147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 26754/250000 [36:27<3:58:50, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 26750, TRAINING loss is 0.00025263694273131005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 27000/250000 [36:42<4:02:45, 15.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 27000, TRAINING loss is 0.0001676546907411563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 27253/250000 [37:17<3:48:07, 16.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 27250, TRAINING loss is 0.003262765962788794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 27503/250000 [37:32<3:44:28, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 27500, TRAINING loss is 0.00048415256042210896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 27753/250000 [37:48<3:48:10, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 27750, TRAINING loss is 0.004704954738127823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 27999/250000 [38:03<4:04:30, 15.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 28000, TRAINING loss is 0.02799731066442163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 28253/250000 [38:38<3:45:20, 16.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 28250, TRAINING loss is 0.003677192572024592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 28503/250000 [38:53<3:53:48, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 28500, TRAINING loss is 0.0019707413823039335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 28753/250000 [39:09<3:43:49, 16.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 28750, TRAINING loss is 0.0015610415825541893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 28999/250000 [39:24<3:41:29, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 29000, TRAINING loss is 0.0004239680347850038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 29253/250000 [39:58<3:50:55, 15.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 29250, TRAINING loss is 0.0010642345043611853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 29503/250000 [40:14<3:51:53, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 29500, TRAINING loss is 0.0003929730490936304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 29753/250000 [40:29<3:45:46, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 29750, TRAINING loss is 0.014578037149532557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 29999/250000 [40:44<3:48:50, 16.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 30000, TRAINING loss is 0.002474423336809756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 30253/250000 [41:19<4:10:05, 14.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 30250, TRAINING loss is 0.0017251169364356227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 30503/250000 [41:34<3:46:49, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 30500, TRAINING loss is 0.0011012538993381675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 30753/250000 [41:50<3:50:59, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 30750, TRAINING loss is 0.0011737135157232309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 30999/250000 [42:06<3:48:46, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 31000, TRAINING loss is 2.6030127066705424e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 31253/250000 [42:40<3:42:34, 16.38it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 31250, TRAINING loss is 0.0016127385245639323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 31503/250000 [42:55<4:08:20, 14.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 31500, TRAINING loss is 0.00023170000237380698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 31753/250000 [43:11<3:51:59, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 31750, TRAINING loss is 6.995289075321828e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 31999/250000 [43:26<3:47:14, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 32000, TRAINING loss is 0.0013997908443891475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 32253/250000 [44:01<3:51:27, 15.68it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 32250, TRAINING loss is 0.003985065972843781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 32503/250000 [44:17<3:45:49, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 32500, TRAINING loss is 8.21270792712765e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 32753/250000 [44:32<3:49:41, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 32750, TRAINING loss is 0.00033903806105142694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 32999/250000 [44:48<3:33:57, 16.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 33000, TRAINING loss is 1.0925831245930922e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 33253/250000 [45:22<3:48:18, 15.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 33250, TRAINING loss is 0.0004344682993149892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 33503/250000 [45:38<3:50:30, 15.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 33500, TRAINING loss is 0.00020966912046570073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 33753/250000 [45:53<3:55:50, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 33750, TRAINING loss is 0.00017210798721603788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 33999/250000 [46:09<3:51:26, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 34000, TRAINING loss is 0.004488977979781847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 34253/250000 [46:43<3:43:02, 16.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 34250, TRAINING loss is 0.0010407438542585422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 34503/250000 [46:58<3:35:57, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 34500, TRAINING loss is 0.00039113081067180947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 34753/250000 [47:14<3:48:57, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 34750, TRAINING loss is 0.0038030825341224305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 34999/250000 [47:29<3:39:11, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 35000, TRAINING loss is 9.504239589189426e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 35253/250000 [48:04<3:48:01, 15.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 35250, TRAINING loss is 0.002863822056650274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 35503/250000 [48:20<3:41:59, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 35500, TRAINING loss is 0.0006973598073504538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 35753/250000 [48:35<3:41:41, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 35750, TRAINING loss is 1.45915910760569e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 35999/250000 [48:51<3:41:54, 16.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 36000, TRAINING loss is 0.00026486453791083444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 36254/250000 [49:25<3:39:12, 16.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 36250, TRAINING loss is 0.0014481692937388664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 36504/250000 [49:41<3:43:52, 15.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 36500, TRAINING loss is 0.0026886878210016004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 36754/250000 [49:57<3:44:09, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 36750, TRAINING loss is 9.112202981963893e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 37000/250000 [50:12<3:57:53, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 37000, TRAINING loss is 0.0017004996280534969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 37253/250000 [50:47<3:39:40, 16.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 37250, TRAINING loss is 0.0013469391915215396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 37503/250000 [51:03<3:52:37, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 37500, TRAINING loss is 1.6619930192203917e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 37753/250000 [51:19<3:44:16, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 37750, TRAINING loss is 0.001915679155307768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 37999/250000 [51:34<3:37:24, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 38000, TRAINING loss is 0.0021105185056109295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 38253/250000 [52:09<3:46:37, 15.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 38250, TRAINING loss is 0.0010505969897472648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 38503/250000 [52:25<3:44:19, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 38500, TRAINING loss is 0.00047041282765398617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 38753/250000 [52:40<3:35:57, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 38750, TRAINING loss is 0.016896553224850848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 38999/250000 [52:56<3:38:47, 16.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 39000, TRAINING loss is 0.0015004639050630651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 39254/250000 [53:30<3:42:06, 15.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 39250, TRAINING loss is 0.0037095514025805207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 39504/250000 [53:46<3:34:13, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 39500, TRAINING loss is 0.001069536340804398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 39754/250000 [54:01<3:48:05, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 39750, TRAINING loss is 0.0011245391662596943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 40000/250000 [54:17<3:27:09, 16.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 40000, TRAINING loss is 0.0025406348038906636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 40253/250000 [54:51<3:48:15, 15.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 40250, TRAINING loss is 0.00013827628228602529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 40503/250000 [55:06<3:32:49, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 40500, TRAINING loss is 0.004357603636678461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 40753/250000 [55:22<3:37:24, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 40750, TRAINING loss is 0.0008422186482324061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 40999/250000 [55:37<3:28:45, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 41000, TRAINING loss is 5.775212034705874e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 41253/250000 [56:11<3:30:15, 16.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 41250, TRAINING loss is 0.004067010666921391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 41503/250000 [56:27<3:31:12, 16.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 41500, TRAINING loss is 0.00029532323319104965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 41753/250000 [56:42<3:47:35, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 41750, TRAINING loss is 0.0028854825827872455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 41999/250000 [56:58<3:30:08, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 42000, TRAINING loss is 0.0008242588635223384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 42254/250000 [57:33<3:37:57, 15.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 42250, TRAINING loss is 0.0003088743056324864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 42504/250000 [57:48<3:36:37, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 42500, TRAINING loss is 0.001374251015113105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 42754/250000 [58:04<3:36:08, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 42750, TRAINING loss is 0.015295410750760786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 43000/250000 [58:19<3:32:42, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 43000, TRAINING loss is 0.00022837591964997058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 43253/250000 [58:53<3:39:11, 15.72it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 43250, TRAINING loss is 0.00014948913733324457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 43503/250000 [59:08<3:27:18, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 43500, TRAINING loss is 7.284368920217869e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 43753/250000 [59:24<3:26:43, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 43750, TRAINING loss is 3.2876470329849084e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 43999/250000 [59:39<3:26:29, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 44000, TRAINING loss is 0.00046043563716056154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 44253/250000 [1:00:13<3:49:44, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 44250, TRAINING loss is 3.2108256254286176e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 44503/250000 [1:00:28<3:37:15, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 44500, TRAINING loss is 1.5483286002809198e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 44753/250000 [1:00:44<3:33:23, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 44750, TRAINING loss is 0.003255922575292254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 44999/250000 [1:00:59<3:26:57, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 45000, TRAINING loss is 0.0025015536104499017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 45252/250000 [1:01:33<3:58:28, 14.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 45250, TRAINING loss is 0.0008189584937584971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 45504/250000 [1:01:49<3:39:42, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 45500, TRAINING loss is 0.00547090979956161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 45754/250000 [1:02:05<3:27:48, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 45750, TRAINING loss is 0.002077597405906864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 46000/250000 [1:02:20<3:34:57, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 46000, TRAINING loss is 0.0005160971412700116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 46253/250000 [1:02:54<3:39:19, 15.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 46250, TRAINING loss is 0.000156366222567679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 46503/250000 [1:03:10<3:37:07, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 46500, TRAINING loss is 3.1442400496166126e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 46753/250000 [1:03:26<3:32:04, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 46750, TRAINING loss is 8.365643663040233e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 46999/250000 [1:03:41<3:40:07, 15.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 47000, TRAINING loss is 0.0009497148303850529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 47253/250000 [1:04:16<3:35:55, 15.65it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 47250, TRAINING loss is 1.058829989928907e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 47503/250000 [1:04:32<3:30:05, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 47500, TRAINING loss is 0.00023348265651332688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 47753/250000 [1:04:47<3:35:39, 15.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 47750, TRAINING loss is 4.1910174447476373e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 47999/250000 [1:05:03<3:33:13, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 48000, TRAINING loss is 8.088970893693538e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 48253/250000 [1:05:37<3:25:20, 16.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 48250, TRAINING loss is 0.000693661147001608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 48503/250000 [1:05:52<3:33:26, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 48500, TRAINING loss is 0.002051988720011077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 48753/250000 [1:06:08<3:27:06, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 48750, TRAINING loss is 6.094616084341926e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 48999/250000 [1:06:24<3:43:59, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 49000, TRAINING loss is 0.0001771571849480374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 49253/250000 [1:06:58<3:28:23, 16.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 49250, TRAINING loss is 0.00020385702051202125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 49503/250000 [1:07:13<3:29:20, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 49500, TRAINING loss is 0.025768906848421588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 49753/250000 [1:07:29<3:24:50, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 49750, TRAINING loss is 4.9584997402343156e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 49999/250000 [1:07:44<3:18:39, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 50000, TRAINING loss is 2.7531742613238763e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 50253/250000 [1:08:18<3:26:39, 16.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 50250, TRAINING loss is 7.439319538344173e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 50503/250000 [1:08:34<3:25:59, 16.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 50500, TRAINING loss is 3.331803692551376e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 50753/250000 [1:08:49<3:21:26, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 50750, TRAINING loss is 0.0016786358433542906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 50999/250000 [1:09:05<3:24:43, 16.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 51000, TRAINING loss is 0.0010952539680606549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 51253/250000 [1:09:39<3:24:11, 16.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 51250, TRAINING loss is 0.00013786229461434327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 51503/250000 [1:09:54<3:39:19, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 51500, TRAINING loss is 0.00026081375256590075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 51753/250000 [1:10:10<3:24:59, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 51750, TRAINING loss is 0.000310216907004717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 51999/250000 [1:10:25<3:27:40, 15.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 52000, TRAINING loss is 0.0016221961110657456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 52253/250000 [1:10:59<3:38:34, 15.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 52250, TRAINING loss is 0.00014356038123707876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 52503/250000 [1:11:15<3:23:53, 16.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 52500, TRAINING loss is 0.00034913595101913094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 52753/250000 [1:11:31<3:44:04, 14.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 52750, TRAINING loss is 0.004000350305017194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 52999/250000 [1:11:46<3:46:04, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 53000, TRAINING loss is 0.0015784529672804297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 53253/250000 [1:12:20<3:30:58, 15.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 53250, TRAINING loss is 0.0002620353439130939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 53503/250000 [1:12:36<3:21:15, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 53500, TRAINING loss is 0.0019079091854438232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 53753/250000 [1:12:51<3:21:02, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 53750, TRAINING loss is 0.005308457925183982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 53999/250000 [1:13:06<3:14:41, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 54000, TRAINING loss is 0.0001087715728210513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 54253/250000 [1:13:40<3:21:37, 16.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 54250, TRAINING loss is 0.0016885575878814365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 54503/250000 [1:13:56<3:28:16, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 54500, TRAINING loss is 0.0016082057138698794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 54753/250000 [1:14:11<3:21:01, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 54750, TRAINING loss is 0.0002246577520453397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 54999/250000 [1:14:26<3:16:41, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 55000, TRAINING loss is 0.0011601364559315813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 55253/250000 [1:15:00<3:17:54, 16.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 55250, TRAINING loss is 0.0002619538823465027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 55503/250000 [1:15:16<3:20:59, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 55500, TRAINING loss is 0.0008940303109244605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 55753/250000 [1:15:31<3:20:24, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 55750, TRAINING loss is 7.391523105054273e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 55999/250000 [1:15:47<3:23:06, 15.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 56000, TRAINING loss is 0.0035263933747731444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 56253/250000 [1:16:21<3:21:21, 16.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 56250, TRAINING loss is 0.0024057520587197744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 56503/250000 [1:16:36<3:31:17, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 56500, TRAINING loss is 1.622628852224387e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 56753/250000 [1:16:52<3:34:48, 14.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 56750, TRAINING loss is 0.0005354863231317158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 56999/250000 [1:17:08<3:15:52, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 57000, TRAINING loss is 0.0006014060515075143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 57253/250000 [1:17:42<3:26:45, 15.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 57250, TRAINING loss is 0.0015375216347757069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 57503/250000 [1:17:57<3:16:43, 16.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 57500, TRAINING loss is 0.0031624657568081367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 57753/250000 [1:18:13<3:24:02, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 57750, TRAINING loss is 6.038509711295113e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 57999/250000 [1:18:29<3:21:07, 15.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 58000, TRAINING loss is 0.0002909781435599587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 58253/250000 [1:19:03<3:17:50, 16.15it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 58250, TRAINING loss is 0.001254696500362024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 58503/250000 [1:19:18<3:24:44, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 58500, TRAINING loss is 0.0002670501864641927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 58753/250000 [1:19:34<3:43:42, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 58750, TRAINING loss is 0.0006169960711897964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 58999/250000 [1:19:50<3:17:00, 16.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 59000, TRAINING loss is 0.0003500438464946939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 59254/250000 [1:20:24<3:15:22, 16.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 59250, TRAINING loss is 0.0006316080375328875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 59504/250000 [1:20:40<3:16:52, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 59500, TRAINING loss is 0.0009064960572605631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 59754/250000 [1:20:55<3:15:47, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 59750, TRAINING loss is 0.0001652292935343664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 60000/250000 [1:21:10<3:08:47, 16.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 60000, TRAINING loss is 0.002117354963260127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 60253/250000 [1:21:44<3:13:55, 16.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 60250, TRAINING loss is 0.0011876190851668456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 60503/250000 [1:21:59<3:12:52, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 60500, TRAINING loss is 0.0059201555508528085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 60753/250000 [1:22:15<3:13:25, 16.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 60750, TRAINING loss is 0.0017498429117146625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 60999/250000 [1:22:30<3:08:18, 16.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 61000, TRAINING loss is 0.0006287687640462743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 61253/250000 [1:23:04<3:32:04, 14.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 61250, TRAINING loss is 0.001099871754888885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 61503/250000 [1:23:20<3:17:19, 15.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 61500, TRAINING loss is 0.001499808654515385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 61753/250000 [1:23:36<3:09:04, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 61750, TRAINING loss is 0.001022767715233378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 61999/250000 [1:23:51<3:14:02, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 62000, TRAINING loss is 3.9475247182868294e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 62253/250000 [1:24:26<3:14:13, 16.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 62250, TRAINING loss is 0.0004306425395537182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 62503/250000 [1:24:42<3:14:01, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 62500, TRAINING loss is 0.0021806288416374242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 62753/250000 [1:24:57<3:15:50, 15.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 62750, TRAINING loss is 0.0016900491549278892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 62999/250000 [1:25:13<3:10:08, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 63000, TRAINING loss is 0.00736995968524023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 63253/250000 [1:25:47<3:11:11, 16.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 63250, TRAINING loss is 1.8271782462383157e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 63503/250000 [1:26:03<3:15:25, 15.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 63500, TRAINING loss is 0.009200142728018662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 63753/250000 [1:26:18<3:29:56, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 63750, TRAINING loss is 0.00024230945307593816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 63999/250000 [1:26:34<3:13:09, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 64000, TRAINING loss is 1.6512809995213593e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 64253/250000 [1:27:08<3:06:15, 16.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 64250, TRAINING loss is 0.00019025587059334398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 64503/250000 [1:27:23<3:06:15, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 64500, TRAINING loss is 0.0009272116606992557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 64753/250000 [1:27:38<3:07:08, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 64750, TRAINING loss is 0.0002675276991167246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 64999/250000 [1:27:53<3:10:52, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 65000, TRAINING loss is 0.00025241731025235083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 65253/250000 [1:28:28<3:31:16, 14.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 65250, TRAINING loss is 0.0012078231520875273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 65503/250000 [1:28:44<3:16:28, 15.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 65500, TRAINING loss is 0.0008793743464714438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 65753/250000 [1:29:00<3:34:27, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 65750, TRAINING loss is 0.0001463146693486237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 65999/250000 [1:29:16<3:15:32, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 66000, TRAINING loss is 0.00010660274702016611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 66253/250000 [1:29:50<3:16:30, 15.58it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 66250, TRAINING loss is 9.048726248790628e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 66503/250000 [1:30:05<3:10:10, 16.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 66500, TRAINING loss is 1.4481428854791464e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 66753/250000 [1:30:20<3:11:09, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 66750, TRAINING loss is 0.000526943587345377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 66999/250000 [1:30:35<3:13:44, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 67000, TRAINING loss is 0.000617483612970867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 67253/250000 [1:31:09<3:06:48, 16.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 67250, TRAINING loss is 0.0004470163634408319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 67503/250000 [1:31:25<3:09:29, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 67500, TRAINING loss is 0.00281535760707512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 67753/250000 [1:31:41<3:19:05, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 67750, TRAINING loss is 0.00011352790231158898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 67999/250000 [1:31:56<3:13:31, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 68000, TRAINING loss is 0.001220289802235627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 68253/250000 [1:32:30<3:06:25, 16.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 68250, TRAINING loss is 0.00022603568250141934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 68503/250000 [1:32:45<3:20:29, 15.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 68500, TRAINING loss is 7.772615137401552e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 68753/250000 [1:33:01<3:12:55, 15.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 68750, TRAINING loss is 0.00018558939900367618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 68999/250000 [1:33:17<3:08:02, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 69000, TRAINING loss is 0.00033576319113086373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 69253/250000 [1:33:51<3:05:11, 16.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 69250, TRAINING loss is 0.0009877619458782299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 69503/250000 [1:34:06<3:01:35, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 69500, TRAINING loss is 0.0026601430980426532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 69753/250000 [1:34:22<3:06:49, 16.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 69750, TRAINING loss is 3.0358427420636007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 69999/250000 [1:34:38<2:57:20, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 70000, TRAINING loss is 0.0002533541059575347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 70253/250000 [1:35:12<3:07:38, 15.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 70250, TRAINING loss is 0.0002372899573410458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 70503/250000 [1:35:27<3:02:36, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 70500, TRAINING loss is 0.0021060239782401437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 70753/250000 [1:35:42<3:04:34, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 70750, TRAINING loss is 0.00014289369602818558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 70999/250000 [1:35:57<2:57:11, 16.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 71000, TRAINING loss is 0.0005418025256538935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 71253/250000 [1:36:31<3:06:49, 15.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 71250, TRAINING loss is 0.0002845696593619544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 71503/250000 [1:36:46<3:01:23, 16.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 71500, TRAINING loss is 0.0012901966347495014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 71753/250000 [1:37:02<2:57:37, 16.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 71750, TRAINING loss is 0.00023701016349327795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 71999/250000 [1:37:17<2:55:59, 16.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 72000, TRAINING loss is 0.0007696482127439409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 72253/250000 [1:37:51<3:07:35, 15.79it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 72250, TRAINING loss is 7.980349915342322e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 72503/250000 [1:38:06<3:03:26, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 72500, TRAINING loss is 9.645749435942648e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 72753/250000 [1:38:22<3:27:29, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 72750, TRAINING loss is 1.708105714915238e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 72999/250000 [1:38:38<3:03:07, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 73000, TRAINING loss is 0.0014113344227179065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 73253/250000 [1:39:12<3:04:53, 15.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 73250, TRAINING loss is 9.130263876990383e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 73503/250000 [1:39:28<3:12:30, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 73500, TRAINING loss is 9.345597845116698e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 73753/250000 [1:39:44<3:11:10, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 73750, TRAINING loss is 4.19474440581729e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 73999/250000 [1:39:59<3:02:39, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 74000, TRAINING loss is 0.004373627624749937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 74253/250000 [1:40:34<3:09:13, 15.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 74250, TRAINING loss is 0.0003223617976470237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 74503/250000 [1:40:50<3:05:21, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 74500, TRAINING loss is 0.00015615392025500568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 74753/250000 [1:41:05<3:05:38, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 74750, TRAINING loss is 0.00011049254903566522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 74999/250000 [1:41:21<3:02:19, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 75000, TRAINING loss is 0.0011158890699538243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 75253/250000 [1:41:55<2:59:41, 16.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 75250, TRAINING loss is 0.0002086129999537081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 75503/250000 [1:42:11<3:02:23, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 75500, TRAINING loss is 0.0001269622419204522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 75753/250000 [1:42:27<2:56:43, 16.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 75750, TRAINING loss is 0.0015555195761992983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 75999/250000 [1:42:42<2:55:36, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 76000, TRAINING loss is 0.0015355841464773847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 76253/250000 [1:43:16<3:03:05, 15.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 76250, TRAINING loss is 0.00442023487704472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 76503/250000 [1:43:31<3:03:15, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 76500, TRAINING loss is 5.1723242764940396e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 76753/250000 [1:43:47<2:54:36, 16.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 76750, TRAINING loss is 0.0004192888430309401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 76999/250000 [1:44:02<2:58:07, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 77000, TRAINING loss is 0.004161491560636751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 77253/250000 [1:44:36<3:01:58, 15.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 77250, TRAINING loss is 0.0011645927010117284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 77503/250000 [1:44:51<2:53:25, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 77500, TRAINING loss is 4.5584251246848364e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 77753/250000 [1:45:06<2:56:16, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 77750, TRAINING loss is 4.9274946418541684e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 77999/250000 [1:45:21<3:05:31, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 78000, TRAINING loss is 1.78701491298273e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 78253/250000 [1:45:55<2:59:17, 15.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 78250, TRAINING loss is 0.00037126804902224304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 78503/250000 [1:46:10<2:57:37, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 78500, TRAINING loss is 2.3144329614430436e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 78753/250000 [1:46:26<2:56:15, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 78750, TRAINING loss is 0.00021650306809224899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 78999/250000 [1:46:41<2:58:40, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 79000, TRAINING loss is 0.008689564734074957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 79253/250000 [1:47:14<2:58:29, 15.94it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 79250, TRAINING loss is 0.000567580099006465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 79503/250000 [1:47:30<3:01:28, 15.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 79500, TRAINING loss is 0.0012207660188377856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 79753/250000 [1:47:46<3:09:53, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 79750, TRAINING loss is 0.00046181898829816543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 79999/250000 [1:48:02<2:54:20, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 80000, TRAINING loss is 0.0013662901113506586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 80254/250000 [1:48:36<3:01:09, 15.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 80250, TRAINING loss is 0.0014877343984614163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 80504/250000 [1:48:52<2:49:59, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 80500, TRAINING loss is 0.0035114737226209633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 80754/250000 [1:49:07<2:51:50, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 80750, TRAINING loss is 4.374675273058455e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 81000/250000 [1:49:22<2:59:27, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 81000, TRAINING loss is 2.8155820347446197e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 81254/250000 [1:49:56<2:52:32, 16.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 81250, TRAINING loss is 0.0013935729007732856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 81504/250000 [1:50:12<2:56:28, 15.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 81500, TRAINING loss is 0.00015094339752098445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 81754/250000 [1:50:27<2:54:55, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 81750, TRAINING loss is 0.0011537711845675661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 82000/250000 [1:50:42<2:50:04, 16.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 82000, TRAINING loss is 0.00012146812213463874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 82254/250000 [1:51:17<2:57:01, 15.79it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 82250, TRAINING loss is 0.001134972009322391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 82504/250000 [1:51:32<2:50:42, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 82500, TRAINING loss is 0.0029035812106411626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 82754/250000 [1:51:47<2:46:43, 16.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 82750, TRAINING loss is 0.00047048486585688274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 83000/250000 [1:52:02<2:50:17, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 83000, TRAINING loss is 7.68037040761927e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 83254/250000 [1:52:36<2:49:50, 16.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 83250, TRAINING loss is 0.0023055110289154383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 83504/250000 [1:52:51<2:47:42, 16.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 83500, TRAINING loss is 0.0005345352960852642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 83754/250000 [1:53:07<2:54:28, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 83750, TRAINING loss is 0.0006464903968176276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 84000/250000 [1:53:22<2:54:27, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 84000, TRAINING loss is 0.00172756563714402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 84254/250000 [1:53:57<3:02:32, 15.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 84250, TRAINING loss is 8.098991477551358e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 84504/250000 [1:54:13<2:51:33, 16.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 84500, TRAINING loss is 0.00540263750843128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 84754/250000 [1:54:29<2:53:41, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 84750, TRAINING loss is 1.1359957284877835e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 85000/250000 [1:54:44<2:46:34, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 85000, TRAINING loss is 0.002254721549492121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 85253/250000 [1:55:18<2:49:01, 16.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 85250, TRAINING loss is 3.779712879282497e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 85503/250000 [1:55:34<2:47:20, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 85500, TRAINING loss is 1.6703215357091707e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 85753/250000 [1:55:50<2:51:51, 15.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 85750, TRAINING loss is 0.0004891285828735578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 85999/250000 [1:56:05<2:58:52, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 86000, TRAINING loss is 9.048523119666468e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 86253/250000 [1:56:40<2:53:57, 15.69it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 86250, TRAINING loss is 0.00023224476197878318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 86503/250000 [1:56:56<2:46:45, 16.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 86500, TRAINING loss is 0.00012425921583908173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 86753/250000 [1:57:11<2:54:57, 15.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 86750, TRAINING loss is 0.0008309329916543933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 86999/250000 [1:57:26<2:42:46, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 87000, TRAINING loss is 0.0007720048629016227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 87253/250000 [1:58:00<2:49:49, 15.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 87250, TRAINING loss is 0.00017501596569231048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 87503/250000 [1:58:16<2:45:57, 16.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 87500, TRAINING loss is 0.000257589943921263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 87753/250000 [1:58:31<2:53:26, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 87750, TRAINING loss is 0.0004166485661368488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 87999/250000 [1:58:46<2:51:58, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 88000, TRAINING loss is 0.001450871371704896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 88253/250000 [1:59:20<2:52:03, 15.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 88250, TRAINING loss is 0.0003341871264047189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 88503/250000 [1:59:36<2:46:25, 16.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 88500, TRAINING loss is 2.9969318905875774e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 88753/250000 [1:59:52<2:58:43, 15.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 88750, TRAINING loss is 0.02990079611450645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 88999/250000 [2:00:07<2:42:24, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 89000, TRAINING loss is 9.990119038612883e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 89253/250000 [2:00:41<2:50:47, 15.69it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 89250, TRAINING loss is 0.0007155460947823203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 89503/250000 [2:00:56<2:53:01, 15.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 89500, TRAINING loss is 0.0016207706886559642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 89753/250000 [2:01:12<2:44:46, 16.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 89750, TRAINING loss is 0.0009883826365012164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 89999/250000 [2:01:27<2:41:34, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 90000, TRAINING loss is 1.4894513982920328e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 90253/250000 [2:02:01<2:52:53, 15.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 90250, TRAINING loss is 3.5213666602016024e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 90503/250000 [2:02:16<2:40:18, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 90500, TRAINING loss is 0.0015333314509487234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 90753/250000 [2:02:32<2:48:39, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 90750, TRAINING loss is 0.005692385946152756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 90999/250000 [2:02:47<2:45:21, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 91000, TRAINING loss is 0.0001334630844240219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 91253/250000 [2:03:21<2:47:52, 15.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 91250, TRAINING loss is 0.0007711963141897771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 91503/250000 [2:03:37<2:47:44, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 91500, TRAINING loss is 0.0013737089520174128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 91753/250000 [2:03:52<2:42:27, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 91750, TRAINING loss is 0.0004568468515569539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 91999/250000 [2:04:08<2:45:35, 15.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 92000, TRAINING loss is 0.001988712912109528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 92253/250000 [2:04:41<2:45:14, 15.91it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 92250, TRAINING loss is 0.0006093521943142362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 92503/250000 [2:04:57<2:45:16, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 92500, TRAINING loss is 2.6419756868031545e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 92753/250000 [2:05:12<2:43:03, 16.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 92750, TRAINING loss is 0.0007487401707645572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 92999/250000 [2:05:27<2:38:47, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 93000, TRAINING loss is 0.0008436722460321217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 93253/250000 [2:06:01<2:40:42, 16.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 93250, TRAINING loss is 7.311992476730459e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 93503/250000 [2:06:16<2:39:49, 16.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 93500, TRAINING loss is 8.831908258394591e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 93753/250000 [2:06:32<2:43:00, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 93750, TRAINING loss is 9.619162371488714e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 93999/250000 [2:06:47<2:38:48, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 94000, TRAINING loss is 0.002301813994639534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 94253/250000 [2:07:20<2:50:39, 15.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 94250, TRAINING loss is 0.00013547554649828364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 94503/250000 [2:07:36<2:45:44, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 94500, TRAINING loss is 0.0026285185765081644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 94753/250000 [2:07:51<2:39:52, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 94750, TRAINING loss is 0.0009853246296095692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 94999/250000 [2:08:07<2:33:36, 16.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 95000, TRAINING loss is 0.00030062302250082274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 95253/250000 [2:08:41<2:43:44, 15.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 95250, TRAINING loss is 0.0027297308914702675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 95503/250000 [2:08:56<2:37:18, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 95500, TRAINING loss is 0.0015698027448613012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 95753/250000 [2:09:12<2:38:20, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 95750, TRAINING loss is 5.025423242042107e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 95999/250000 [2:09:27<2:41:12, 15.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 96000, TRAINING loss is 1.5479669881120913e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 96253/250000 [2:10:02<2:38:23, 16.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 96250, TRAINING loss is 3.6534766252674565e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 96503/250000 [2:10:17<2:37:17, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 96500, TRAINING loss is 0.0030474925131260292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 96753/250000 [2:10:33<2:33:28, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 96750, TRAINING loss is 0.0029871143354017245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 96999/250000 [2:10:48<2:33:46, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 97000, TRAINING loss is 0.00010110200570790608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 97253/250000 [2:11:22<2:35:42, 16.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 97250, TRAINING loss is 0.0003079153193881901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 97503/250000 [2:11:37<2:41:18, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 97500, TRAINING loss is 0.00019374912085033699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 97753/250000 [2:11:53<2:38:38, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 97750, TRAINING loss is 0.00032747722703343975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 97999/250000 [2:12:08<2:31:59, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 98000, TRAINING loss is 0.00041962907828931647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 98253/250000 [2:12:41<2:35:52, 16.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 98250, TRAINING loss is 0.00036952735549483634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 98503/250000 [2:12:57<2:32:25, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 98500, TRAINING loss is 0.00022172405919815654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 98753/250000 [2:13:12<2:35:07, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 98750, TRAINING loss is 0.0002113888041922464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 98999/250000 [2:13:27<2:33:06, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 99000, TRAINING loss is 3.806803774547009e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 99253/250000 [2:14:01<2:44:59, 15.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 99250, TRAINING loss is 8.270352443827715e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 99503/250000 [2:14:17<2:43:26, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 99500, TRAINING loss is 0.00031182625390495437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 99753/250000 [2:14:32<2:40:42, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 99750, TRAINING loss is 0.00026506214160893805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 99999/250000 [2:14:48<2:40:34, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 100000, TRAINING loss is 0.001111881594309798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 100253/250000 [2:15:22<2:41:28, 15.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 100250, TRAINING loss is 0.000436230829538345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 100503/250000 [2:15:37<2:35:43, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 100500, TRAINING loss is 0.00232958860816139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 100753/250000 [2:15:53<2:33:01, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 100750, TRAINING loss is 0.00013402917079369817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 100999/250000 [2:16:07<2:32:51, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 101000, TRAINING loss is 0.0019115397705485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 101253/250000 [2:16:42<2:41:56, 15.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 101250, TRAINING loss is 0.00044099832047333077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 101503/250000 [2:16:58<2:32:50, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 101500, TRAINING loss is 0.00022646216595691648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 101753/250000 [2:17:13<2:42:04, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 101750, TRAINING loss is 0.0007492710001253725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 101999/250000 [2:17:28<2:33:57, 16.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 102000, TRAINING loss is 0.0012540203825250778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 102253/250000 [2:18:03<2:33:38, 16.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 102250, TRAINING loss is 0.0023210449911286314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 102503/250000 [2:18:18<2:36:30, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 102500, TRAINING loss is 0.0013301886926601243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 102753/250000 [2:18:34<2:38:09, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 102750, TRAINING loss is 9.859058052281574e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 102999/250000 [2:18:49<2:28:40, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 103000, TRAINING loss is 1.9686739987946255e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 103253/250000 [2:19:23<2:30:58, 16.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 103250, TRAINING loss is 6.566984382693299e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 103503/250000 [2:19:38<2:30:12, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 103500, TRAINING loss is 0.002995886865539797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 103753/250000 [2:19:54<2:29:54, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 103750, TRAINING loss is 8.913711622659246e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 103999/250000 [2:20:09<2:33:28, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 104000, TRAINING loss is 0.0001376427097045245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 104253/250000 [2:20:44<2:31:04, 16.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 104250, TRAINING loss is 0.00030757449874906377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 104503/250000 [2:20:59<2:34:20, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 104500, TRAINING loss is 0.00010179104922435139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 104753/250000 [2:21:15<2:29:54, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 104750, TRAINING loss is 0.001841080792579332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 104999/250000 [2:21:30<2:23:44, 16.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 105000, TRAINING loss is 0.003676396911664091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 105253/250000 [2:22:04<2:29:29, 16.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 105250, TRAINING loss is 0.00033561240046308744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 105503/250000 [2:22:19<2:34:06, 15.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 105500, TRAINING loss is 0.0011091872014190505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 105753/250000 [2:22:35<2:28:46, 16.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 105750, TRAINING loss is 3.026897109170419e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 105999/250000 [2:22:50<2:28:39, 16.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 106000, TRAINING loss is 0.001800475346663474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 106253/250000 [2:23:24<2:32:59, 15.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 106250, TRAINING loss is 5.204493044044289e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 106503/250000 [2:23:39<2:26:15, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 106500, TRAINING loss is 1.742590575465828e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 106753/250000 [2:23:54<2:24:36, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 106750, TRAINING loss is 0.0023868143469063133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 106999/250000 [2:24:10<2:33:37, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 107000, TRAINING loss is 1.4585334151356602e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 107253/250000 [2:24:44<2:23:40, 16.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 107250, TRAINING loss is 0.006553179578566235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 107503/250000 [2:24:59<2:26:57, 16.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 107500, TRAINING loss is 0.00016553458823449977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 107753/250000 [2:25:14<2:28:41, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 107750, TRAINING loss is 9.735566461796853e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 107999/250000 [2:25:30<2:23:38, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 108000, TRAINING loss is 6.067871097782644e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 108253/250000 [2:26:04<2:33:48, 15.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 108250, TRAINING loss is 0.0019995371349394923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 108503/250000 [2:26:19<2:23:03, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 108500, TRAINING loss is 8.585619319446158e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 108753/250000 [2:26:34<2:26:01, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 108750, TRAINING loss is 2.8842534624726362e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 108999/250000 [2:26:49<2:21:49, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 109000, TRAINING loss is 0.003540203773727073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 109253/250000 [2:27:23<2:21:34, 16.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 109250, TRAINING loss is 2.7602253181126073e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 109503/250000 [2:27:38<2:21:53, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 109500, TRAINING loss is 0.0007446075824843288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 109753/250000 [2:27:54<2:30:00, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 109750, TRAINING loss is 2.8902846681202043e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 109999/250000 [2:28:09<2:20:32, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 110000, TRAINING loss is 0.007363437787492831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 110253/250000 [2:28:43<2:22:24, 16.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 110250, TRAINING loss is 0.0010755276972873112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 110503/250000 [2:28:58<2:23:36, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 110500, TRAINING loss is 0.0009409582355886137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 110753/250000 [2:29:13<2:26:24, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 110750, TRAINING loss is 0.00015649069301014524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 110999/250000 [2:29:29<2:19:28, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 111000, TRAINING loss is 0.000322042451901326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 111253/250000 [2:30:03<2:22:33, 16.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 111250, TRAINING loss is 4.741081635407728e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 111503/250000 [2:30:18<2:27:14, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 111500, TRAINING loss is 0.0009414242285674587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 111753/250000 [2:30:34<2:29:30, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 111750, TRAINING loss is 0.00014323599974118415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 111999/250000 [2:30:49<2:16:45, 16.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 112000, TRAINING loss is 2.796889421802832e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 112254/250000 [2:31:24<2:23:23, 16.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 112250, TRAINING loss is 0.000479098600177413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 112504/250000 [2:31:40<2:22:22, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 112500, TRAINING loss is 0.000342355993006136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 112754/250000 [2:31:55<2:20:49, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 112750, TRAINING loss is 0.009080801727223422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 113000/250000 [2:32:11<2:23:05, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 113000, TRAINING loss is 0.002055632732837711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 113253/250000 [2:32:45<2:29:31, 15.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 113250, TRAINING loss is 0.0018481680256942324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 113503/250000 [2:33:01<2:26:21, 15.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 113500, TRAINING loss is 0.00019093869759879593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 113753/250000 [2:33:16<2:22:59, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 113750, TRAINING loss is 0.0006615330221524946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 113999/250000 [2:33:31<2:15:41, 16.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 114000, TRAINING loss is 1.2267804916196967e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 114253/250000 [2:34:06<2:21:49, 15.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 114250, TRAINING loss is 0.0024437520058198767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 114503/250000 [2:34:21<2:22:36, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 114500, TRAINING loss is 0.004972022961527168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 114753/250000 [2:34:36<2:18:44, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 114750, TRAINING loss is 6.7958200466447e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 114999/250000 [2:34:52<2:21:47, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 115000, TRAINING loss is 0.0004280786973132661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 115253/250000 [2:35:26<2:21:51, 15.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 115250, TRAINING loss is 0.000735432005716258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 115503/250000 [2:35:41<2:16:33, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 115500, TRAINING loss is 0.0022105286208631155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 115753/250000 [2:35:56<2:20:12, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 115750, TRAINING loss is 0.006965059957418468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 115999/250000 [2:36:12<2:26:32, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 116000, TRAINING loss is 0.001966266997202982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 116253/250000 [2:36:46<2:21:07, 15.79it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 116250, TRAINING loss is 0.00031083429611284395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 116503/250000 [2:37:01<2:17:49, 16.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 116500, TRAINING loss is 0.0001345142315034857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 116753/250000 [2:37:17<2:21:02, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 116750, TRAINING loss is 3.60825908533723e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 116999/250000 [2:37:32<2:14:29, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 117000, TRAINING loss is 0.0001477233659529796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 117253/250000 [2:38:06<2:24:29, 15.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 117250, TRAINING loss is 0.007093112032675736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 117503/250000 [2:38:22<2:21:18, 15.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 117500, TRAINING loss is 0.0009665824856531573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 117753/250000 [2:38:37<2:14:28, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 117750, TRAINING loss is 0.00042872407225732855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 117999/250000 [2:38:53<2:18:15, 15.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 118000, TRAINING loss is 0.002319184147090732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 118253/250000 [2:39:27<2:14:30, 16.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 118250, TRAINING loss is 1.049935977224973e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 118503/250000 [2:39:42<2:11:32, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 118500, TRAINING loss is 0.0010326884509747542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 118753/250000 [2:39:57<2:14:58, 16.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 118750, TRAINING loss is 0.005660264345848571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 118999/250000 [2:40:13<2:16:54, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 119000, TRAINING loss is 0.000835784909650935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 119253/250000 [2:40:48<2:16:14, 15.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 119250, TRAINING loss is 0.0015315134979583542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 119294/250000 [2:40:50<2:56:13, 12.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 36\u001b[0m\n\u001b[1;32m     30\u001b[0m score_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(\n\u001b[1;32m     31\u001b[0m     score_mse \u001b[39m/\u001b[39m score_scaling[\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m]\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     32\u001b[0m     dim\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     33\u001b[0m ) \u001b[39m#/ (loss_mask.sum(dim=-1) + 1e-10)    \u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# comps = {k: v.mean().item() for k, v in comps._asdict().items()}\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m score_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     37\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     38\u001b[0m \u001b[39m# check_loss(score_)\u001b[39;00m\n",
      "File \u001b[0;32m/data/rsg/chemistry/johnyang/miniconda3/envs/cellot/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/data/rsg/chemistry/johnyang/miniconda3/envs/cellot/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_freq=1000\n",
    "for step in ticker:\n",
    "\n",
    "    score_network.train()\n",
    "    \n",
    "    # if DEBUG:\n",
    "    #     inputs = ex_batch\n",
    "    # else:\n",
    "    #     raise NotImplementedError\n",
    "    #     inputs = next(iterator.train)\n",
    "    #     # inputs = inputs.to(device)\n",
    "        \n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    # '''\n",
    "    # Get encoded representation\n",
    "    # '''\n",
    "    \n",
    "    # code = ae.encode(inputs)\n",
    "    \n",
    "    t = rng.uniform(min_t, 1.0)\n",
    "    x_t, gt_score_t = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=t)\n",
    "    \n",
    "    score_scaling = torch.tensor(diffuser.score_scaling(t)).to(device)\n",
    "    gt_score_t = torch.tensor(gt_score_t).to(device)\n",
    "    \n",
    "    pred_score_t = score_network(torch.tensor(x_t).float().to(device), t)\n",
    "\n",
    "    score_mse = (gt_score_t - pred_score_t)**2\n",
    "    score_loss = torch.sum(\n",
    "        score_mse / score_scaling[None, None]**2,\n",
    "        dim=(-1, -2)\n",
    "    ) #/ (loss_mask.sum(dim=-1) + 1e-10)    \n",
    "    \n",
    "    # comps = {k: v.mean().item() for k, v in comps._asdict().items()}\n",
    "    score_loss.backward()\n",
    "    optimizer.step()\n",
    "    # check_loss(score_)\n",
    "\n",
    "    if step % config.training.logs_freq == 0:\n",
    "        # log to logger object\n",
    "        # logger.log(\"train\", loss=loss.item(), step=step, **comps)\n",
    "        writer.add_scalar('Training loss', score_loss.item(), global_step=step)\n",
    "        print(f'At step {step}, TRAINING loss is {score_loss.item()}')\n",
    "        \n",
    "    if step % eval_freq == 0:\n",
    "        eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(score_network, '6.28.23.1D_score_network.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.51367713]] [[-1.85833874]]\n"
     ]
    }
   ],
   "source": [
    "x_t, score = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=1.0)\n",
    "print(x_t, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.504646]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t_1 = diffuser.reverse(x_t=x_t, score_t=score, t=1.0, dt=0.001, center=False)\n",
    "x_t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_traj(x_0, min_t, num_t):\n",
    "    forward_steps = np.linspace(min_t, 1.0, num_t)[:-1]\n",
    "    x_traj = [x_0]\n",
    "    for t in forward_steps:\n",
    "        x_t = diffuser.forward(\n",
    "            x_traj[-1], t, num_t)\n",
    "        x_traj.append(x_t)\n",
    "    x_traj = torch.stack(x_traj, axis=0)\n",
    "    return x_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_traj(ex_code, 0, int(1 // dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_t at time 1.0: [[0.71809757]]\n",
      "x_t at time 0.8999999999999999: [[0.74577532]]\n",
      "x_t at time 0.7999999999999998: [[0.71474696]]\n",
      "x_t at time 0.6999999999999997: [[0.90956592]]\n",
      "x_t at time 0.5999999999999996: [[1.24072934]]\n",
      "x_t at time 0.49999999999999956: [[0.89358941]]\n",
      "x_t at time 0.39999999999999947: [[0.90546495]]\n",
      "x_t at time 0.2999999999999994: [[0.71449458]]\n",
      "x_t at time 0.1999999999999993: [[0.85116622]]\n",
      "x_t at time 0.0999999999999992: [[0.96870796]]\n",
      "tensor([[1.]], device='cuda:1') [[1.00996966]]\n"
     ]
    }
   ],
   "source": [
    "dt = 0.001\n",
    "log_freq = (1 / dt) / 10\n",
    "\n",
    "pred_scores = []\n",
    "gt_scores = []\n",
    "\n",
    "x_t_list = []  # list to store x_t at each step\n",
    "\n",
    "with torch.no_grad():\n",
    "    score_network.eval()\n",
    "    x_t, _ = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=1.0)\n",
    "    \n",
    "    for i, t in enumerate(np.arange(1.0, 0, -dt)):\n",
    "        if i % log_freq == 0:\n",
    "            print(f'x_t at time {t}: {x_t}')\n",
    "            ...\n",
    "        x_t = torch.tensor(x_t).float().to(device)\n",
    "        pred_score = score_network(x_t, t)\n",
    "        \n",
    "        _, gt_score = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=t)\n",
    "\n",
    "        pred_scores.append(pred_score)\n",
    "        gt_scores.append(gt_score)\n",
    "        \n",
    "        # print(pred_score, gt_score)\n",
    "        \n",
    "        x_t = diffuser.reverse(x_t=x_t.detach().cpu().numpy(), score_t=pred_score.detach().cpu().numpy(), t=t, dt=dt, center=False)\n",
    "        x_t_list.append(x_t.item())  # append x_t to the list\n",
    "\n",
    "    x_0 = x_t\n",
    "    print(ex_code, x_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/rsg/chemistry/johnyang/miniconda3/envs/cellot/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sampling x_t from learned reverse process, gt x_0 = 1.0, random init')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAHHCAYAAACBYj2uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAA9hAAAPYQGoP6dpAADkaElEQVR4nOydd3xTZfv/P1kno22SblropEDLLhtaNoqIIMqQ4qAUFB8p+OjPhcp0IDi/gAsVUB9BRVAQERVBoYADqMwySmvL7E7SNONknN8f6TlkNy1NS9v7/Xrx0p6cnHPnzOu+xufiMQzDgEAgEAgEAoHQJPCbewAEAoFAIBAIbQlifBEIBAKBQCA0IcT4IhAIBAKBQGhCiPFFIBAIBAKB0IQQ44tAIBAIBAKhCSHGF4FAIBAIBEITQowvAoFAIBAIhCaEGF8EAoFAIBAITQgxvggEAoFAIBCaEGJ8eYDH42Hp0qXc3xs3bgSPx8O///7bbGNqDnbv3o3evXtDIpGAx+NBpVI195A8snTpUvB4vOYeht/57bffwOPx8NtvvzX3UAgEAsEjzu/R5mbEiBEYMWJEg76bmZmJ+Pj4RhuLX42vkydPYsqUKYiLi4NEIkH79u1x2223Yc2aNf7cLcEDZ86cwdKlS302ICsqKjBt2jRIpVK8++67+PzzzxEQEODfQRIIhBZDfZ8pjYnVasWqVauQkJAAiUSCnj17YvPmzU0+Dq1WiyVLluCOO+5ASEgIeDweNm7cWK9tqFQqPPLIIwgPD0dAQABGjhyJY8eO+WfAhEZBp9Nh6dKlDZ4E+834OnToEPr164fjx4/j4Ycfxtq1azFnzhzw+Xz83//9n7926zcefPBB6PV6xMXFNfdQGsyZM2ewbNkynx+Uf//9N6qrq/HSSy9h9uzZeOCBByASifw7SAKB0GKo7zOlMXnhhRfw7LPPchP62NhYzJgxA19++WWTjqO8vBzLly9HXl4eevXqVe/vW61WjB8/Hps2bUJ2djZWrVqF0tJSjBgxAhcuXPDDiNsuP//8M37++ecGffejjz7CuXPnuL91Oh2WLVvWYONL2KBv+cArr7wChUKBv//+G0ql0uGz0tJSf+3WbwgEAggEguYeRpPCnifn8+cOnU4HmUzm5xHdmtTU1LQYj+CtONZbcUzOWK1W0DQNiUTS3EMhALhy5QrefPNNzJs3D2vXrgUAzJkzB8OHD8fTTz+NqVOnNtnzOioqCteuXUO7du1w5MgR9O/fv17f/+abb3Do0CFs2bIFU6ZMAQBMmzYNnTt3xpIlS7Bp06ZGGWdLuM/8DUVRDf5uYzse/Ob5unjxIrp16+b2xR0REeHw94YNGzBq1ChERERALBaja9eueP/9912+Fx8fj7vuugu//fYb+vXrB6lUih49enCW57Zt29CjRw9IJBL07dsXubm5Dt/PzMxEYGAgCgoKMHbsWAQEBCA6OhrLly8HwzBef4+7nC92PDk5ORgwYAAkEgkSExPx2WefuXz/xIkTGD58OKRSKTp06ICXX34ZGzZsqDOPrLS0FOHh4RgxYoTDGPPz8xEQEID77rvP67jtxz916lQAwMiRI8Hj8bzmDY0YMQIzZ84EAPTv3x88Hg+ZmZncZ927d8fRo0cxbNgwyGQyPP/889x4Z8+ejcjISEgkEvTq1Quffvqpw7b//fdf8Hg8vPHGG3j33XeRmJgImUyG22+/HZcuXQLDMHjppZfQoUMHSKVS3H333aisrPTpd7rjf//7H/r27QupVIqQkBBMnz4dly5dcljnwIEDmDp1KmJjYyEWixETE4MnnngCer3eYT32Grp48SLuvPNOBAUF4f777wdgy2/Izs7Gd999h+7du0MsFqNbt27YvXu3y5iuXLmCrKwsREZGcuutX7/eZb3Lly9j0qRJCAgIQEREBJ544gkYjUaffjebA3fmzBnMmDEDwcHBSE9P9/m4ZGdnIzAwEDqdzmXbGRkZaNeuHSwWC7fsxx9/xNChQxEQEICgoCCMHz8ep0+f9vn4XbhwAZMnT0a7du0gkUjQoUMHTJ8+HWq12mEbvpxPb8fj7NmzmDZtGuRyOUJDQ/H444/DYDA4rMueyy+++ALdunWDWCzmzmNubi7GjRsHuVyOwMBAjB49Gn/88YfL/lQqFZ544gnEx8dDLBajQ4cOeOihh1BeXs6tYzQasWTJEiQlJXHX3TPPPONyjn/55Rekp6dDqVQiMDAQXbp04e45ljVr1qBbt26QyWQIDg5Gv379GvzitlqtWLp0KaKjoyGTyTBy5EicOXMG8fHx3HOgvs+UxnqWAcD27dthMpnw2GOPcct4PB7+85//4PLlyzh8+HD9f3QDEYvFaNeuXYO//8033yAyMhL33nsvtyw8PBzTpk3D9u3bfb7f7fF27584cQKZmZlITEyERCJBu3btkJWVhYqKCrfbyM/PR2ZmJpRKJRQKBWbNmuXyTDAajXjiiScQHh6OoKAgTJw4EZcvX3Y7Nl/uH/Z9m5OTgwULFiA8PBxKpRJz584FTdNQqVR46KGHEBwcjODgYDzzzDN1vsMB15wvNn/266+/xiuvvIIOHTpAIpFg9OjRyM/Pd/iufc7Xv//+i/DwcADAsmXLuGu/PvltfvN8xcXF4fDhwzh16hS6d+/udd33338f3bp1w8SJEyEUCvH999/jscceg9Vqxbx58xzWzc/Px4wZMzB37lw88MADeOONNzBhwgR88MEHeP7557mbccWKFZg2bRrOnTsHPv+GjWmxWHDHHXdg0KBBWLVqFXbv3o0lS5bAbDZj+fLl9f6d+fn5mDJlCmbPno2ZM2di/fr1yMzMRN++fdGtWzcAthct+3BauHAhAgIC8PHHH0MsFte5/YiICLz//vuYOnUq1qxZgwULFsBqtSIzMxNBQUF47733fBrnsGHDsGDBAqxevRrPP/88UlJSAID7rzMvvPACunTpgnXr1mH58uVISEhAx44duc8rKiowbtw4TJ8+HQ888AAiIyOh1+sxYsQI5OfnIzs7GwkJCdiyZQsyMzOhUqnw+OOPO+zjiy++AE3TmD9/PiorK7Fq1SpMmzYNo0aNwm+//YZnn30W+fn5WLNmDZ566im3xkldvPLKK1i0aBGmTZuGOXPmoKysDGvWrMGwYcOQm5vLTQ62bNkCnU6H//znPwgNDcVff/2FNWvW4PLly9iyZYvDNs1mM8aOHYv09HS88cYbDh6/nJwcbNu2DY899hiCgoKwevVqTJ48GcXFxQgNDQUAlJSUYNCgQdwLPjw8HD/++CNmz54NjUaD//73vwAAvV6P0aNHo7i4GAsWLEB0dDQ+//xz7N27t17HYOrUqejUqRNeffVV7gHly3G577778O677+KHH37gXrKAzcv5/fffIzMzk/MufP7555g5cybGjh2LlStXQqfT4f3330d6ejpyc3MdElXdHT+apjF27FgYjUbMnz8f7dq1w5UrV7Bz506oVCooFIp6nU9vTJs2DfHx8VixYgX++OMPrF69GlVVVS6Tpr179+Lrr79GdnY2wsLCEB8fj9OnT2Po0KGQy+V45plnIBKJ8OGHH2LEiBH4/fffMXDgQAC2PKChQ4ciLy8PWVlZ6NOnD8rLy7Fjxw5cvnwZYWFhsFqtmDhxInJycvDII48gJSUFJ0+exNtvv43z58/ju+++AwCcPn0ad911F3r27Inly5dDLBYjPz8fBw8e5Mb60UcfYcGCBZgyZQpnTJ44cQJ//vknZsyYUa/rBQAWLlyIVatWYcKECRg7diyOHz+OsWPHOhip9X2mNNazDLC9wAMCAlz2NWDAAO5z+4mGM0ajEdXV1T7tKywszOdxNYTc3Fz06dPH4T0F2H7LunXrcP78efTo0aNB23Z37//yyy8oKCjArFmz0K5dO5w+fRrr1q3D6dOn8ccff7gULU2bNg0JCQlYsWIFjh07ho8//hgRERFYuXIlt86cOXPwv//9DzNmzMCQIUOwd+9ejB8/3mU8vt4/LOyzYNmyZfjjjz+wbt06KJVKHDp0CLGxsXj11Vexa9cuvP766+jevTseeuihBh2n1157DXw+H0899RTUajVWrVqF+++/H3/++afb9cPDw/H+++/jP//5D+655x7OcO7Zs6fvO2X8xM8//8wIBAJGIBAwgwcPZp555hnmp59+YmiadllXp9O5LBs7diyTmJjosCwuLo4BwBw6dIhb9tNPPzEAGKlUyhQVFXHLP/zwQwYAs2/fPm7ZzJkzGQDM/PnzuWVWq5UZP348Q1EUU1ZWxi0HwCxZsoT7e8OGDQwAprCw0GU8+/fv55aVlpYyYrGY+X//7/9xy+bPn8/weDwmNzeXW1ZRUcGEhIS4bNMTGRkZjEwmY86fP8+8/vrrDADmu+++q/N79mzZssXlmHiD/c1///23w/Lhw4czAJgPPvjAYfk777zDAGD+97//cctommYGDx7MBAYGMhqNhmEYhiksLGQAMOHh4YxKpeLWXbhwIQOA6dWrF2MymRx+O0VRjMFg8DreJUuWMPaX9L///ssIBALmlVdecVjv5MmTjFAodFju7hpcsWIFw+PxHK4r9hp67rnnXNYHwFAUxeTn53PLjh8/zgBg1qxZwy2bPXs2ExUVxZSXlzt8f/r06YxCoeDGwh7Pr7/+mlunpqaGSUpK8uk8sscjIyPDYbmvx8VqtTLt27dnJk+e7LDe119/7XDdV1dXM0qlknn44Ycd1rt+/TqjUCgclns6frm5uQwAZsuWLR5/T33OpzvY4zFx4kSH5Y899hgDgDl+/Di3DADD5/OZ06dPO6w7adIkhqIo5uLFi9yyq1evMkFBQcywYcO4ZYsXL2YAMNu2bXMZh9VqZRiGYT7//HOGz+czBw4ccPj8gw8+YAAwBw8eZBiGYd5++20GgMPzyZm7776b6datm9ff7yvXr19nhEIhM2nSJIflS5cuZQAwM2fO5JbV95nCMI3zLBs/frzL+4FhbPeHp/vTHvbZ5su/+vD3338zAJgNGzb4/J2AgAAmKyvLZfkPP/zAAGB2795drzEwjOd7n2HcP+s2b97s8i5jt+E8tnvuuYcJDQ3l/v7nn38YAMxjjz3msN6MGTNc3qO+3j/s+Rk7dix3vzAMwwwePJjh8XjMo48+yi0zm81Mhw4dmOHDh3s5IjaGDx/usN6+ffsYAExKSgpjNBq55f/3f//HAGBOnjzJLZs5cyYTFxfH/V1WVuby++qD38KOt912Gw4fPoyJEyfi+PHjWLVqFcaOHYv27dtjx44dDutKpVLu/9VqNcrLyzF8+HAUFBS4hBy6du2KwYMHc3+zlvKoUaMQGxvrsrygoMBlbNnZ2dz/s94HmqaxZ8+eev/Orl27YujQodzf4eHh6NKli8N+d+/ejcGDB6N3797cspCQEC7c4gtr166FQqHAlClTsGjRIjz44IO4++676z3exkIsFmPWrFkOy3bt2oV27dohIyODWyYSibBgwQJotVr8/vvvDutPnTqV82gAN87ZAw88AKFQ6LCcpmlcuXKlXmPctm0brFYrpk2bhvLycu5fu3bt0KlTJ+zbt49b1/4arKmpQXl5OYYMGQKGYVzC1wDwn//8x+0+x4wZ4+Ah7NmzJ+RyOXc9MAyDrVu3YsKECWAYxmFcY8eOhVqt5qqcdu3ahaioKC4PBABkMhkeeeSReh2HRx99tEHHhcfjYerUqdi1axe0Wi33/a+++grt27fnPAu//PILVCoVMjIyHLYnEAgwcOBAh+Ps6fix18FPP/3kNsxZn3HXhbM3ff78+QBsx9ue4cOHo2vXrtzfFosFP//8MyZNmoTExERueVRUFGbMmIGcnBxoNBoAwNatW9GrVy/cc889LvtnPQtbtmxBSkoKkpOTHX7PqFGjAID7Paw3b/v27bBarW5/k1KpxOXLl/H333/7dAy88euvv8JsNjuE9IAbx+lmaYxnmV6vdxs5YHPynNMFnBk7dix++eUXn/75m5v9Ld5wvvcBx2edwWBAeXk5Bg0aBABuKyydtzF06FBUVFRw1zp73yxYsMBhPdaDz1Kf+4dl9uzZDp64gQMHgmEYzJ49m1smEAjQr18/t+96X5k1a5ZDPhj7Tr+ZbdaF38KOgC1XaNu2baBpGsePH8e3336Lt99+G1OmTME///zDPdgOHjyIJUuW4PDhwy4PXrVa7fCCtjewgBsP7ZiYGLfLq6qqHJbz+XyHEw8AnTt3BoAGVew4jwcAgoODHfZbVFTkYDCyJCUl+byfkJAQrF69GlOnTkVkZCRWr15d77E2Ju3bt3dJXiwqKkKnTp1c3OdsaKCoqMhh+c2ey7q4cOECGIZBp06d3H5un0BZXFyMxYsXY8eOHS77cZ4ACIVCdOjQwe0267oeysrKoFKpsG7dOqxbt87tNthCh6KiIiQlJbmEAbp06eL2e55ISEhw+Ls+x+W+++7DO++8gx07dmDGjBnQarXYtWsX5s6dy42LrchijQZn5HK5w9/ujl9CQgKefPJJvPXWW/jiiy8wdOhQTJw4EQ888AB3/uszbm84f79jx47g8/ku97/zcSsrK4NOp3N7/FNSUmC1WnHp0iV069YNFy9exOTJk72O48KFC8jLy+NyR5xhr4P77rsPH3/8MebMmYPnnnsOo0ePxr333ospU6Zw99qzzz6LPXv2YMCAAUhKSsLtt9+OGTNmIC0tzesY3MHep87Pp5CQEAQHB9d7e840xrNMKpW6zYViw6L2BoY7oqKiEBUVVe/9+oOb/S3ecL6GAaCyshLLli3Dl19+6VL85vysA1yfaew1UFVVBblcjqKiIvD5fIdJJ+D6nKrP/eNp397eEfV9P9jj7Tf6C78aXywURaF///7o378/OnfujFmzZmHLli1YsmQJLl68iNGjRyM5ORlvvfUWYmJiQFEUdu3ahbfffttlpuepgsXTcsaHJLyboSn3+9NPPwGwXRCXL1/2Kb/FX9zMA4HF3+fSarWCx+Phxx9/dLvNwMBAALYZ2W233YbKyko8++yzSE5ORkBAAK5cuYLMzEyXa1AsFrsYmL6Ond3WAw88wBU0OFOvvAEfcD5Xvh4XABg0aBDi4+Px9ddfY8aMGfj++++h1+sdkqPZ3/T555+7TTy292ICno/fm2++iczMTGzfvh0///wzFixYwOVldejQoV7jrg+ehHkb4xr3htVqRY8ePfDWW2+5/Zx9wUilUuzfvx/79u3DDz/8gN27d+Orr77CqFGj8PPPP0MgECAlJQXnzp3Dzp07sXv3bmzduhXvvfceFi9ejGXLlvn1dzSEm32WRUVFYd++fWAYxuH8Xbt2DQAQHR3t9ft6vd6toeGOm0mm9wW2WtIZX3+LN9xdw9OmTcOhQ4fw9NNPo3fv3ggMDITVasUdd9zh1rPaXO9Wb/t2t/xmxtMcv7FJjC97+vXrB+DGhfX999/DaDRix44dDtanryGE+mK1WlFQUMB5uwDg/PnzANCo6rX2xMXFuVROAHC7zBO7d+/Gxx9/jGeeeQZffPEFZs6ciT///NPlxeYNf6u/x8XF4cSJE7BarQ4v17Nnz3KfNyUdO3YEwzBISEhwON/OnDx5EufPn8enn37qkLDpj5ADWw1ksVgwZswYr+vGxcXh1KlTLi8Ye62ZhuDrcWGZNm0a/u///g8ajQZfffUV4uPjuTAFuz3AllBd12+qix49eqBHjx548cUXcejQIaSlpeGDDz7Ayy+/XO9xe+LChQsOHoH8/HxYrdY67//w8HDIZDK3x//s2bPg8/mcwdSxY0ecOnXK6/Y6duyI48ePY/To0XXem3w+H6NHj8bo0aPx1ltv4dVXX8ULL7yAffv2ccecrRi87777QNM07r33XrzyyitYuHBhvSQy2Ps0Pz/f4ThVVFS4eAIa8kxpjGdZ79698fHHHyMvL88hNMwmSNuneLjjq6++ckmb8IS/jYzevXvjwIEDLs/NP//8EzKZ7KaudWeqqqrw66+/YtmyZVi8eDG3/Gb0xOLi4mC1WnHx4kUHr5bzfVKf+6clcLPvU7/lfLGzEmfY+DB7kliL035dtVqNDRs2+GtonC4Mu9+1a9dCJBJh9OjRftnf2LFjcfjwYfzzzz/cssrKSnzxxRc+fV+lUmHOnDkYMGAAXn31VXz88cc4duwYXn311XqNg9V48VeLoDvvvBPXr1/HV199xS0zm81Ys2YNAgMDMXz4cL/s1xP33nsvBAIBli1b5nItMgzDlVa7uwYZhvGLGLBAIMDkyZOxdetWty/nsrIy7v/vvPNOXL16Fd988w23TKfTeQxX+oqvx4Xlvvvug9FoxKeffordu3dj2rRpDp+PHTsWcrkcr776Kkwmk9ff5AmNRgOz2eywrEePHuDz+VxIpr7j9sS7777r8DfbcWPcuHFevycQCHD77bdj+/btDiHKkpISbNq0Cenp6VyIdfLkyVyqhTPs2KdNm4YrV67go48+cllHr9ejpqYGANzKrLDGBXtsnH87RVHo2rUrGIZxe068MXr0aAiFQhe5H/vnJkt9nymN9Sy7++67IRKJHCokGYbBBx98gPbt22PIkCFev99cOV/Xrl3D2bNnHc7JlClTUFJSgm3btnHLysvLsWXLFkyYMMGnqnhfcfesA4B33nmnwdtk7xvn8LHzNutz/7QE2Cr3hr5P/eb5mj9/PnQ6He655x4kJyeDpmkcOnSImzmzs47bb78dFEVhwoQJmDt3LrRaLT766CNERES4dcXeLBKJBLt378bMmTMxcOBA/Pjjj/jhhx/w/PPPe8y9uFmeeeYZ/O9//8Ntt92G+fPnc1ITsbGxqKysrNOCfvzxx1FRUYE9e/ZAIBDgjjvuwJw5c/Dyyy/j7rvv9llVuXfv3hAIBFi5ciXUajXEYjGnr9YYPPLII/jwww+RmZmJo0ePIj4+Ht988w0OHjyId955B0FBQY2yH1/p2LEjXn75ZSxcuBD//vsvJk2ahKCgIBQWFuLbb7/FI488gqeeegrJycno2LEjnnrqKVy5cgVyuRxbt271W7z/tddew759+zBw4EA8/PDD6Nq1KyorK3Hs2DHs2bOHe9mynSEeeughHD16FFFRUfj8889vWszW1+PC0qdPHyQlJeGFF16A0Wh00WOSy+V4//338eCDD6JPnz6YPn06wsPDUVxcjB9++AFpaWluX9z27N27F9nZ2Zg6dSo6d+4Ms9mMzz//nDNWGzJuTxQWFmLixIm44447cPjwYa5E3pf76OWXX+Y0tx577DEIhUJ8+OGHMBqNWLVqFbfe008/jW+++QZTp05FVlYW+vbti8rKSuzYsQMffPABevXqhQcffBBff/01Hn30Uezbtw9paWmwWCw4e/Ysvv76a/z000/o168fli9fjv3792P8+PGIi4tDaWkp3nvvPXTo0IErerj99tvRrl07pKWlITIyEnl5eVi7di3Gjx/vcN/xeDwMHz7cqyp3ZGQkHn/8cbz55pvccTp+/Dh+/PFHhIWFOTyv6vtMaaxnWYcOHfDf//4Xr7/+OkwmE/r374/vvvsOBw4cwBdffFGnwGpj53ytXbsWKpUKV69eBWCL6LA6V/Pnz+dylRYuXIhPP/0UhYWFnKd1ypQpGDRoEGbNmoUzZ84gLCwM7733HiwWi0vIODMz0+X79UEul2PYsGFYtWoVTCYT2rdvj59//hmFhYUN/u29e/dGRkYG3nvvPajVagwZMgS//vqr28iOr/dPS0AqlaJr16746quv0LlzZ4SEhKB79+51SmtxNKhG0gd+/PFHJisri0lOTmYCAwMZiqKYpKQkZv78+UxJSYnDujt27GB69uzJSCQSJj4+nlm5ciWzfv16t9IO48ePd9kXAGbevHkOy1g5g9dff51bNnPmTCYgIIC5ePEic/vttzMymYyJjIxklixZwlgsFpdt+iI14W48zuWsDGMrpR86dCgjFouZDh06MCtWrGBWr17NAGCuX7/u6TAy27dvZwAwb775psNyjUbDxMXFMb169XIr3+GJjz76iElMTGQEAkGdJeLepCY8lbWXlJQws2bNYsLCwhiKopgePXq4lF27OzcMc6Ps11luwNM4nHGWmmDZunUrk56ezgQEBDABAQFMcnIyM2/ePObcuXPcOmfOnGHGjBnDBAYGMmFhYczDDz/MyUTYj5+9htzh7jpkGNt1Yl+ezzC24zRv3jwmJiaGEYlETLt27ZjRo0cz69atc1ivqKiImThxIiOTyZiwsDDm8ccfZ3bv3l0vqQlPEgW+HBeWF154gQHAJCUledzfvn37mLFjxzIKhYKRSCRMx44dmczMTObIkSPcOp6OX0FBAZOVlcV07NiRkUgkTEhICDNy5Ehmz549NzVud8fjzJkzzJQpU5igoCAmODiYyc7OZvR6vcO6ns4lwzDMsWPHmLFjxzKBgYGMTCZjRo4c6SB/w1JRUcFkZ2cz7du3ZyiKYjp06MDMnDnTQWKEpmlm5cqVTLdu3RixWMwEBwczffv2ZZYtW8ao1WqGYRjm119/Ze6++24mOjqaoSiKiY6OZjIyMpjz589z2/nwww+ZYcOGMaGhoYxYLGY6duzIPP3009w2GMYmCQKAmT59utfjxDC28v1FixYx7dq1Y6RSKTNq1CgmLy+PCQ0NdSjzZxjfnymN/SyzWCzMq6++ysTFxTEURTHdunVzkLlpSljZIXf/7N8ZrNSKs7xQZWUlM3v2bCY0NJSRyWTM8OHD3T7vJk+ezEilUqaqqsrreLzd+5cvX2buueceRqlUMgqFgpk6dSpz9epVl3eep224exfq9XpmwYIFTGhoKBMQEMBMmDCBuXTpklspBl/uH0/PfE9j8vZctseT1ITzO4d9Rzk/++2lJhiGYQ4dOsT07duXoSiq3rITPIZpgqy5W4TMzEx88803DmXzzcl///tffPjhh9BqtW2udRGB0NQsXboUy5YtQ1lZmd+FM29Fdu3ahbvuugvHjx9vkGinSqVCcHAwXn75Zbzwwgt+GCGhLiIjI/HQQw/h9ddfb+6hEG4Sv+V8ERxx1mqpqKjA559/jvT0dGJ4EQgEv7Nv3z5Mnz7dJ8PLnbYUm8Nj356F0HScPn0aer0ezz77bHMPhdAINHm1Y1tl8ODBGDFiBFJSUlBSUoJPPvkEGo0GixYtuult+1I2HRISclNNRQkEQsumPt6Sr776Chs3bsSdd96JwMBA5OTkYPPmzbj99tsbpB3mK+RZ5plu3bq5iJASWi7E+Goi7rzzTnzzzTdYt24deDwe+vTpg08++QTDhg276W37Uja9b98+MmMlEAg+0bNnTwiFQqxatQoajYZLwn/55Zf9ul/yLCO0FdpUzldr5dq1azh9+rTXdfr27dso6tQEAoHgL8izjNBWIMYXgUAgEAgEQhNCEu4JBAKBQCAQmpA2l/NltVpx9epVBAUF+b3dDoFAIBAIhMaBYRhUV1cjOjraY3/dlkKbM76uXr3aovpHEQgEAoFAuMGlS5fQoUOH5h7GTdHmjC+21calS5daVB8pAoFAIBDaMhqNBjExMU3eqs4ftDnjiw01yuVyYnwRCAQCgdDCaA0pQy07aEogEAgEAoHQwiDGF4FAIBAIBEITQowvAoFAIBAIhCaEGF8EAoFAIBAITQgxvggEAoFAIBCaEGJ8EQgEAoFAIDQhxPgiEAgEAoFAaEKI8UUgEAgEAoHQhBDji0AgEAgEAqEJIcYXgUAgEAgEQhPS5toLEQgEz6h1NMq1NDQGE+RSEcICKChkVHMPi0AgEFoVxPgiEAgAgKsqPZ7degIHLpRzy4Z1CsNrk3siWiltxpERCARC64KEHQkEAtQ62sXwAoD9F8rx3NYTUOvoZhoZgUAgtD6I8UUgEFCupV0ML5b9F8pRriXGF4FAIDQWJOxIIBCgMZgAADJKgKz0BKTGKGE0WyERCXCsuAo1RlMzj5BAIBBaD8T4IhAIkEtEkFECrM5IxYaDhVi7N5/7LC0pFFP6dGjG0REIBELrgoQdCQQCAiVCLBqfgg0HC3Ewv8Lhs4P5FVi0/RTJ+yIQCIRGghhfBAIBNUYzundQuBheLAdI3heBQCA0GiTsSCAQoNabcF1j8LpOtYHkfREIBEJjQDxfBAIBcokIlMD74yBIImqi0RAIBELrhhhfBAIBgRIhSquNSEsKdfv5sE5hCAskSvcEAoHQGBDji0Bo41xV6fHCtyfRTi5B9sgkFwNsaKcwrJzck7QZIhAIhEaC5HwRCG0YVtn+aFEVenRQYHRyBJZO7AbaZEUNbYFSKkKkXEwMLwKBQGhEiOeLQGjDlGtpHC2qwuqMVPxVWIlpH/6B7f9cxXWNAdUGExgwzT1EAoFAaHUQzxeB0IbRGEzISk/AhoOFyC1WuRVZJc21CQQCoXEhni8CoQ0jl4iQGqPEwfwKzghz1voizbUJBAKhcSHGF4HQhgkLpMDj2f6fNcLcQZprEwgEQuNBjC8CoY0TpbCFE41mq9f1iMgqgUAgNA4k54tAaMOUVhthtjBISwqFWGibi8koAbLSE5Aao4TRbIVEJMCx4irIpURklUAgEBoDYnwRCG0Yld6Eyhoas9ISUKIxYFRyOB4YFIf1OY5J90OTQjG9X0wzjpRAIBBaDyTsSCC0YQIoAYR8HhZszkWZ1ojFd3XFhpxC5Djlfh3Ir8DCb0+SpHsCgUBoBIjni0BowwRQQpRoDEiNVeLtXy4gPSkMB/IrPIYey7RGIrhKIBAINwkxvgiENoxSJkJSRCCyRyYBAExmBjJK4FbvKy0pFPf0bt9cQyUQCIRWAwk7EghtGB1tAQBcqtTh2TuSESQVetT7OphfgaXfnyahRwKBQLhJiOeLQGijqHU0nvnmBI4WVyErPQGhgWLEhsowODEU63MKkT0qySXsuD6nEOVamoQeCQQC4SYgxheB0Ea5rjHgQH45AHDhxSdu64QhiaEew46rM1JRYyR6XwQCgXAzkLAjgdAGUetoXK7Suyz/8PcChASIPYYdNxwshEJKvF4EAoFwMxDji0Bog3hqFaSjLVDpaY9thg7mV4C2eFfCJxAIBIJ3iPFFILRBNAYTTl5RY2hSmMtnpdVGr9+tMZr9NSwCgUBoExDji0Bog8glIvB4wGMjOyItKdThM0UdbYSCJKTNEIFAINwMJOGeQGiDhAVS6B8XgtmfHkFWegKy0hJgNFshFvIRKBYiPSnUReUeANKTQhEoIY8NAoFAuBnIU5RAaIMoZBQoIR862uJQ0QgAGzP7IzMtAQzgkPuVlhSKzLQEEnYkEAiEm4QYXwRCG8VTeFFnsuCpLcddPGK5l1RYsDkXm+YMbOKREggEQuuiWXO+9u/fjwkTJiA6Oho8Hg/fffed1/W3bduG2267DeHh4ZDL5Rg8eDB++umnphksgdCKuKrS40hRlUu+FwCI7Txisz89gse+OIbZnx7B2r350NGWJs35UutoXCzVIre4ChfLtERdn0AgtAqa1fiqqalBr1698O677/q0/v79+3Hbbbdh165dOHr0KEaOHIkJEyYgNzfXzyMlEFoPah2NZ7eewEs7z2BWWoKLAVZabcTQTq5VkAAwrFMYwgKbRufrqkqP7M25mLA2B7+eLcW/5TU4UlSF89eriRFGIBBaNDyGYZjmHgQA8Hg8fPvtt5g0aVK9vtetWzfcd999WLx4sU/razQaKBQKqNVqyOXyBoyUQGjZXCzVYvRbvwMAZJQAWekJXBshsZCPTuGBEAr5eG7rCey/UM59b1inMKyc3BNRSqnfx6jW0cjelIujxVWc2r59/tmwTmF4bXJPRDfBWAgEwq1Ba3p/t+icL6vViurqaoSEhHhcx2g0wmi8oVuk0WiaYmgEwi2LxnCjPZC7hPvvHhuC3rHBWJORinItjWqDCUESEcICqSbr6ci2PsoeleRWbX//hXI8t/UE1mSkkj6TBAKhxdGidb7eeOMNaLVaTJs2zeM6K1asgEKh4P7FxMQ04QgJhFsPeR05W2xOl0JGoWNEIHrHBqNjRGCTGTn2rY/6xAZ7VNvff6Hco1I/gUAg3Mq0WM/Xpk2bsGzZMmzfvh0REREe11u4cCGefPJJ7m+NRkMMMEKbJlBi0/E6VqxyCDlKRAKUqPUIamYdL9agklECyCiB13WrDaTJN4FAaHm0SOPryy+/xJw5c7BlyxaMGTPG67pisRhisbiJRkYg3Pqo9TRmpydinoiPtfvyHcKOQ5PCMLjjjWR7tY5GuZaGxmCCXCpCWID/Q48agwm5l1RYOqErgsRCl7w0iUiAY8VVWJ9TSNT2CQRCi6TFGV+bN29GVlYWvvzyS4wfP765h0MgtCjUOhqXKvU4eUWNI/9WuoT0DuSXY9H2U1ibkYoa2oJnt57AAaeke38nussoAdbnFGJHdhqOFVXhk5n9XIzEtKRQrM/s32SVlwQCgdCYNGvOl1arxT///IN//vkHAFBYWIh//vkHxcXFAGwhw4ceeohbf9OmTXjooYfw5ptvYuDAgbh+/TquX78OtVrdHMMnEFocbEivR3uF2/ZBAHDgQjlUOpOL4QXcSHT3l9SDWkfjWLEKgxJDYDBZcVVtwHv78l2MxIP5FXh3X76HrRAIBMKtTbMaX0eOHEFqaipSU1MBAE8++SRSU1M52Yhr165xhhgArFu3DmazGfPmzUNUVBT37/HHH2+W8RMILQ02pFcXNbTZxfBi8Weie7mWxps/n8Ozd6SgxmhGj/YKHPBiJJKEewKB0BJp1rDjiBEj4E1mbOPGjQ5///bbb/4dEIHQypFLRFifU4iv5g7yul4NbfH6ub8S3TUGE6YPiMXynafxxJjOMJqtzTIOAoFA8CctWmqCQCDUj7BACv3igvFrXimGumktBNjyupQe+j6y+CvRXUYJkBqjxMH8CuTklzfbOAgEAsGfEOOLQGhDKGQUXpvcE6evqDHTTWshVsU+IkiMYU3cYojN9wJsRhiPB0QpJUj3YiSShHsCgdASuWXaCzUVrak9AYHQUEo0Bqh0NBgGYADoaDOUUspBxf6qSt+kLYYulmoxYW0Otjw6CNfURmw4WIhz16vx8cz+ePOncziQ3zytjggEwq1Ba3p/tzipCQKBcHNcVek9SkjYa3hFK6V4fWovVNXQ0BjMkEuFCJZRiJRL/DIujcEEHW1BicZmeOXWisCqamg8eXtnPDMuGdV6E8ICxYiUi0lbIQKB0GIhxheB0IZQ62ivEhL2vRK9GWn+0Pli2x7xeTzkFqu4htrO+l6vTOpBDC8CgdCiITlfBEIbolxL+yQhUZeR5g+dr7BACrelREAitCna2zfUllECZI9KQlZaAi6WaXGhpNpvWmMEAoHgb4jni0BoQ2jqkGZgpRt8MdIa2/ukkFFYOrEb/q3QITVGyXm8ZJTArResKdT2CQQCwR8QzxeB0EZQ62hIRd4bVbPSDb4aaY2NwWTF4QJHUVVnLxiLv9X2CQQCwV8QzxeB0AZg87d6xSiRlhTqYsgAjtINbP6Vp6bW8jr0txqKxmByEYG194I54y8vHIFAIPgT4vkiEFo59vlb63MKMcuLvhdrxLD5V+/O6INohWN1Y3uFBGKBfx4dcokIOtriIAJLVO4JBEJrg3i+CIRWjn3+lo62YMHmXGSlJyArLQFGsxWJYQGIUkgcvEcKGYVlE7uhqFKHH05ec/CUpSWFIiE8EIESYaN7nCQiPtKTQrFufwFWZ6TCCkAs9G7oEZV7AoHQ0iDGF4HQynHO39LRFocw3nePDXFrRJksDNbuy3cJUbJ/v9rIkg9qHY0lO04jMy0BDAo5IzE8SIyhSWEOIqssROWeQCC0RIjxRSC0cuQSkcfcrfU5hR49RzW02W1uGGAzwGpoc6OOs1xLY09eKQ5drHDwzFVqafy/sV0AHlw0x1Y6CcMSCARCS4AYXwRCKycskML6zP5Ys/cC1ucUckZYaowSWx4djECJ+8dADW3xul1dHZ/XF9ZD5+yZA2yJ/9vnpYHP46HaYEKQROTQColAIBBaEsT4IhDaAO/uzfeoGu9JL0tZR0WjopErHuVecrd0tAV8Hg8dIwIbdZ8EAoHQHJBqRwKhlVOupXEgv7zeelkRQWIM7RTmdptDO4UhIkjcqOMMC6QwzMP+SG4XgUBoTRDPF4HQymHDeakxSqzPKUT2qCS3uV/OelkKGYWVk3viua0nsL8Jcq0UMgqvNeH+CAQCobkgxheB0Mphw3lmK+OxWfXqjFTUGF31sqKVUqzJSEW5lm6SXKum3h+BQCA0B8T4IhBaOax2VrRCitd253mVjnCHQta0xk9T749AIBCaGpLzRSC0Yuy1s/g8eJWOqEtJnkAgEAiNA/F8EQitGHvtrI2z+ntdt65m2k2BWkejXEtDYzBBLhUhLIB4wQgEQuuDGF8EQivG3qAKoLzf7jJKUO/tN6axdKVSh/0XyhAhl8BotqJKZ8JfhZUY0TkcUU4yGAQCgdCSIcYXgdCKYdXt12SkgsezJde7Cz2mJYXWaZw5c1Wl5xp2s3jSDKtzW1U6FFfpsNNdH8mwAMgoARQyinjGCARCq4AYXwRCK4ZVt7dYGfySV4LskUkA4GLgzB/VCUqZZ5FTZ6MnUCx0MbyAG5phazJSfTaK1DoaKr3Jax/JFZN6oIa2NJqxRyAQCM0JMb4IhFbOu3vzkTEwFh/+XoCe7ZUY3yOK65soFvJRojEgMkjs0Vhy5+HaNGegi+HFsv9CuYtmmDfKtTTMVsZrMYDZyuCFRjL2CAQCobkh1Y4EQivmusaAA/nlEAv50NEWzNt0DFfVBod1rqoNYDx8X62j3Xq4VHrvyfnV9Uje1xhM0Bm994nUmy11GnsEAoHQUiCeLwKhlaLW0bhcpQcA5F5Scflezk2rh3UKw8PpCW63Ua6l3Ro9YqFt3iajBFyjbnvFfHk9+j4GioWwWL0ba3U18a6PsUcgEAjNDTG+CIRWir03aH1OIVZnpAJwzPcaWkfrHk/yE7mXVBiVHI4ZA+NcFPPTk0IxvV+Mz+OkBHwUlGkxNCkMB/JdDb0xKRGQS7w/qoK8NOUmEAiEWw1ifBEILRhv1X8ag8nB47Vgcy6y0hO4fC+lVISOEYGIlEs8bl9uZ9TYe7nMVgaT+7THi9+dcsnVysmvwPPfnvQ5D0ulpxEeJEH2qCQADA44GYeL7uqKQxcrPFZqkqbbBAKhpUGMLwKhhVKX1INcInLweOUWq7j1xEI+QgMpSITe0z7DAikM6xSGI0VVLn0h12f295gkX5+k+0CxCBkf/Ym5wxPx9B3JeBq2MKOQz0NOfjn0Jgte2nnGrecuLSkUy+/uTpLtCQRCi4IYXwRCC8RTIrx99V9YIIV+ccFYsDkXc4cnYsld3fDSztMOIcK6pBoUMgorJ/dEUaUO7+69gNxiFbJHJSE1RgmpyCbK6invy12jbnew43z7lwt4+5cLDp8N6xSGYZ3CoKMtLp47sZCP3EsqaPQ0gIB6HD0CgUBoXki1I4HQAvGUCA84ep1em9wT/eKCYbIwWLbztENIj133ua0noNZ5rhZkAFitDI4Wq7A6IxW5xVWY/ekR6GgzZJTAYdljXxxD1sa/kVtcBbnUN2+UQkbh1Xt6YGinMIflw9h8NA/b4fF4AIBAku9FIBBaGMTzRSC0QOrqw8hW/0UrpViTkYpraoNLlSOLtxAh62HLGBCLrPQEbDhYyHm/woPEWDahKzYeLHQrjrp4+ymf8r6uqvRY+v1p9IpRInNIPJePFhcqQ5RSCrWOxm0pEbhvQOxNJ/cTCATCrQDxfBEILZC6+jDaV/8pZBT0poZJNbAeNolIgNQYJXLtvF9ZG/9G9w5K5NSR9+UN1rjbk1eKtXvzOe/ZjI//xMJtJ6HW2YzCpRO7YYMbI49N7vfmuSMQCIRbDWJ8EQgtDLWOxrFiWxWjO9xV/8nrCM15kmrQGEyQUQJue48MS+Q8XdMHxOKqSu91u3Xpb/kSPgUAg8laZ3I/gUAgtBSI8UUgtDDKtTRe2nkGs9ISXAwwT9V/bNWiO7xJNcglImSlJ+CdPefRTiHG6JQIztOVGqOsc6x16W/5Gj71dT0CgUBoCZCcLwKhhaExmFyq/8xWBlEKCWizFaXVRlgYxkHzi02+f27rCex3kqbwJrIaFkhhSGIo1u7NxwOD4sAwN6obAyghci6We9TfGuqD/lag2Dfx1IZ67ggEAuFWhBhfBEILw9kQofh8xIdJsXT7KYdqRmcZCTb5vlxLo9pgQpBEhLBAymtCvEJGgeK0wHgQ8IDVGanY9GcRRnYJ53TExEI+ukYrOLkJpUyEDkqp121fVenxzyUVhiaFulRhsuNnjTd7vTFnWYsSjYGIrBIIhBYFMb4IhBZGWCDFVf9t+rMIY7tGYvF2V6V5e80vew9YfQVJg2vXN5gsEAv52PRnER4cFI8ASoC+sUos23Ean8zsXy8NMbWOxuLtp3D/wDg8NjIJVnhve8TqjRVX6rBu/0UAtrCnwWRBfKgMWqOZCK0SCIQWAzG+CIQWBlv998zWE+gfH4Jqg9ljMvqRoiqodCaPLYh8IVAixOjkcEQEiaExmNE1WoGyagNkFB/Zo5Igl4iwbOdpn4w/lnItjeQoOT7OKcC569VYObknnhuXDK3BgkCJEDVGs0tFp4wS4KP9Bbh/UBy++KMIgM0Aq9KZAOjAMECHEJnPv4tAIBCaC2J8EQgtEB1twcH8CjwxpjNKq41u12EFUF/87qTXcGSd+zKa8cwdKTh+qQqhgWKkxigRHiTGyt1n0T8+BP3jQ+rdZkhjMCE1RsmFLdc7yUikJYXilUk9HL5XWm1E9w4KbPqjCBkeGnq/dm9PYoARCIRbHlLtSCC0MK6p9KissUkrmC0MxB76M7KyEA1RtbfHZGWwcncewoMkaCeXgLZYAdjChD3aK6DW178SMVAshNFs5YRb3Ym0Ltp+ymGMKr0J6UlhSI5WeNT8Wkg0vwgEQguAGF8EQgtCraPx2/kymK0MAEAmFiD3kqvml4wSOMhCOFMfbSyrlUHXaAU+zinAL3kliJJLoTPaRFvZHovecFeJSAn4UEhFSI1RevSaHXAaYwAlgNnC1Os7BAKBcCtCjK9bBLWOxsVSLXKLq3CxTEtm7wS3lGtpRASJcbigAqOSwyGjBDhzVe2i+fXIsESUadyHI1l81cbS0WbO4Fm3vwCBEgEktU212ebWngRfPclNqPR0nfIRzmMMoIQIkAhgNFt9/g6BQCDcipCcr1uAqyo9nt16wkHpu755OYS2gcZggtFsxfqcQnz5yCAcK6rCw0MT8dGBAqTGBiMrLQFGsxUJYQGoMZq9biugDo0tFoWUwvVaQ05HW1BQXoMouRRDk8KQe0nFGX+AY8VielIoVtzTw21yf6BYhN2nr2FE5wiv+7b3mokEPMhEQiikRPOLQCC0bIjnq5lhe9s5t1ipb14OoW0gl4ggFvKhoy0o19JY+v0ZGExWjEmJ5LSvxEI+qg1mUEK+R49UWlIoKIFvt39YIAWlncEj4PEwa+NfeOqOLjh7TYMZA+Ow6c8ipMYG45OZ/fDe/X2wac5ArJzsOfk9LJBCakwwSqoNSPcwxvSkUARKbAaiWkdj8Y7TMJgsCJGJPH7Hm1o/gUAg3CoQz1cz40tvO6JfRGAJC6Tw17+VSEsKhdFsgY62YN6mY8hKT0CkXMKtJ6MEuKLSu/VIpSWFYlZaAtR6GkBAnftUyCjEhcqQnhSKnPwK5F5SoUu7IGSs+wNZ6QkQ8niYP6oThAIeqvVmxIbIEBEk9km8lTZbkZmWAMbNGDPTEjjvXbmWxp68UvxzSYWNs/rjhfEp+KdYjQi52EFsdWTncHK/EAiEWx5ifDUzpGcdoT4oZBRGdA5HYlgAxEJb3pWOtjhILsgoAXZkpyFQLMTDnx3hWhCxXrHcSyos2JyL77PTfd5v+2AZXru3JxZ+e5KThwAKXURVV07uiSgfQ+XBMgql1UY8teW4xzFumjMQwI37pFxLI3PD3/gksz92nbzqIqExvHO4z7+JQCAQmgtifDUzzkKSzpD8FYIzUUoprFYGOpPFoa8i23Px9q6RyC2qQvf2CvSJVToYSCwNCc91CJFhbW17ohqjCa9O6gHaYkWN0ey2VZFaR3sVdw0LpFCiEbkYj/a46+04fUAsVu0+Wy9RVwKBQLiVIMZXM3KlSoejRVXcC5R9ebK5O8EyEZfzQiCwqHU0nvv2JB4YFMeFFXOLVXjv/j745EABUmOUWPL9GXxwf188f2cKVuw6iwP5N0Lbzq176oO39kRsxa7WaIJCSmHRd6e4/cooARbd1RV9YpXQ0RbOGLMPZzrjrrfj/gvlSI1xb1ACJFRPIBBaBuTN3kyodTSKKnR4+Yc8rjHxDDeq3aTqkeAMmyeYOSQe8zfnIis9Ac+PS8FrP+bhQH4FMgbGQUdb8OgXRzF3eCKevqMLnkYX6GgLhHweFFKRz6FBX7Gv2M0elYTc4irOMxUWSOHjmf3x5k9nsXDbSe47wzqFYdXknlw407na17m342uTe+K5rSc4qQnnyYpEJMCx4irUGEmontC28ORlrsv7TGg+iPHVTJRraaj0JuhoCxZszsWajFRsdKPaTUIpBGfY/KfcSyqk1oYVx3aL5PKfWNFTHW3B279cwNu/XHD4/q9PDm/U8ThX7Np7pmSUAOsz+2OlXZhQRgkwd3giRnaJQFmNEbTZipfu7gaThfEYwgSAaKUUazJScU1t4FonOU9W0pJCMaVPh0b9fQTCrYpaR6NKZ8IipxZit6VEYNFdXfHCd6eIhNEtCjG+mgmNweSgDK6UiVzawLDsv1COitp2MmQWQ2Dzn24kvgN6+obwKCt66k4F3h9SDM4Vu/YiqFnpCag2mJFbrEL2qCT0iw1GdLAElVrawSADboRDvb0Y2Ot90V1dPbYlWrz9FJmsEFo1ap1t8v5XQQW2H7/qErbvEiXHwm9PIrdYhSdu64TRyREQiwSgTVZcrtJDazQjMkgMgLxTmgtifDUTcokIv54txajkcMwYGAej6cYLiw2n9IsNhkImAiXkw8oA2ZuO3VSDZELrwD7/aUFt2DHArnDD3ig76HS9NDTXyxvOFbv2k4o+scHQGs2clwoAotUS/HDymovhdMBHL69CRqFPrNIhhGkPyfsitGZKVHoYLVYs+/40nritM57e6nofsE3r37+/D2QUH3weDyt35SE5WoHUGCU0BhMoPg+HCyoQIZfAaLaiSmfCX4WVGNE5vNHTEgiuEJHVZkCtoyHk83D2mgb/HdMZm/4sgjLA9qJgwylnrqphZhi88fM5/HjqOpbsOHXTDZIJrQOFjMKr9/TA0E5h0NEWrM8phJQScIKqbCibFT39ZGY/7P7vUKzJSPXLQ9W5TZB9uyEhn4cohYTzUqXGKBEpl3jszehrz0kdbfH6OZFoIbRG1DoalXoTLlXp0TVagVIPLcSMZiseGZaIUo0BgWIR3vz5HO4fFI/YYCki5WJ0jgjENY0Bv+SVIPeSCmIhHwaTBXGhMqj0JvJOaQKI56uJYROTjxZVYXVGKrRGM7pGK2C2WJGWFIr+8SHYeLAQvWODuRdWVloCqe4icFxV6bH0+9PoFaNE5pB4hARQKNcakD0yCYDN28XKN6QlhSJ7ZCeEeKlSvFnsPXGAo+ctOEAEo8nKGVt19WUEfDOc5BKRx4T79TmFRKKF0CoprTaCAaDWm5AaowSPxwPgWnwSUyt0TAn5qNKb0DNGCRnFR0yIDGeuatC9vQIfHShwW+SVnhSKVya5bwtGaDyI8dWEOCcmL9iciw8e6IvUGCUqtTTmpCciIkiMd/ZcwCw7g4s0Eiaw2F9De/JKAQCfzOyHZ7eewKaHB+GuHlEOYqWlGgPaKyWIsFO/b2zsKxH3XyiHjrbgua0nsHZGH4j4fJTqb8zO7UOSnvDFcAoLpLA+sz/W7L3gknC/PrM/aTFEaHVcU+mh0plgZRhIRAKYLFZEKcQYnRyO+wfFYX3ODSMqe1QShiaFAQDMFgYju0Tg1BU19uSV4MnbOsNsZdA1WuE2bzInvwIvbj+FtQ3MmyQVlr5BjK8mxDkxWUdbYLJYYTRbceaaBrHBUlgZBgBAW24YXHW9sMgsv+3grh2V0WxFuZbGjI/+wMrJPREhF0NrsCBQYssD0/jYRuhmYCsRWQFWea3O1+z0BETIxdx6uZdUiFZIGqUg4N29+W4T7vk8HtbWet4IhNaAWkcj50I5ukbLwePzoDWaERMsxRs/n8MTY7pg1e48HKstakmNUcJsZRAoEaJab0ZwgAgMA0QrpHhwUDx0tBVWK8NVJdtXHwO295JIwIdKb6q30VRcqcML206Q3GQfIDlfTYi7VkK5l1RQSEVYn1OIlGg5eDweZJQAMcEyh3U8NUgmjYTbFu6uIdY4L9fSmP3pEUxYcxCzP/0bP50uAQDozQwulmn9nsehkFHoGBGIuNAALNpuE1g9UlyFvKsaDK29ftfnFCJKIUX2yCSXa7o+4q/lWtpBONaeAz7mjREILYWSagO6tg8Cn8cDD0xtZxQe9p4tA22x4GixCqszUpFbXIXZnx7BE1/9A4lQAIlIALOFgZ62QCEToazaACnFh1DAg9FshYwS4N0ZfTAgPgTv/5aPsmojAsQC0GYrtEYzLlfpAAClGgMKy7Q4fVWNvwsrcb6k2uV5cqmiBgudDC+A5CZ7olmNr/3792PChAmIjo4Gj8fDd999V+d3fvvtN/Tp0wdisRhJSUnYuHGj38d5s7DK3+48WLb8FCH6xCpxuUoPhmGwbEJXCHi22Du7zqy0BJeXlb+q1wi3Ls7J7YCrcc4WbbAP4qkfHMboN3/H/M25uKrS+32M9t659TmFCA+S4LFaY4ttBP7Xv5V44c4U/LAgHd88Ohi/PDEMa+tREEB6ohLaCmodDYPJCosVUOlpVFTTEAn4KK60GUYmC4Os9ASHEOIjwxJxrKgSEhEPRpMFCqkIQgEPieGBYBigoEwLpVSEeSM7orzagM8P/4v/jumC9QcLcd+Hf+DgxXKUaYyoNtAoLq9BQZkWL24/hakfHMbvF8pwqVKHI0VVOH/dZoRdrtKhuEp/04U0bYlmDTvW1NSgV69eyMrKwr333lvn+oWFhRg/fjweffRRfPHFF/j1118xZ84cREVFYezYsU0w4vrjrPztHG7R0RZkbfwbn2UNgEpngsnCIDUuGG/+fA6L7uqGl3aeRk5+BScp8NiIJIiFfATLKLdClITWjVjIx9CkUIfZJZvgzgNwrFjV7IK9VXYzXNbYmjs8EQvHJdu0hsxWLrQRESRu0FjcGaH2kFA8obVQrqVRm1ePgxcrcOaqGtmjOkEksEVJgsRC9IkNxtq9+QgLpLByck+0V0px7/uH8MH9fdEhWAraYoFGb4aAx8PBi6UYlBCC4AAKY1IiYbIwCAkUY/nO0yiu0OG7eWlY9WMe+sYGQyIU4uDFcuw8eQ25td415wT9Fff2QK8OSqj1ZEJUH5rV+Bo3bhzGjRvn8/offPABEhIS8OabbwIAUlJSkJOTg7fffvuWNL6cE+zd6S/JKAH+3+1dIBTwEK2UoERjhI62oGNEEFbuzkP/hBA8c0cyAEBntEAk5KOgTItOXQOJ4dWGUOtoaPQmXFXr8djIJFhx4xrS0RZ8+WcxVt7bEyYrg6sqvVfBXn9Wx6p1NGinAhEdbcGHvxegW7QCm/4sQtdoBfrFBkPI54E2W3GhVIvgAKpeibnOFZb2kFA8oTWh1tPQGm3SKuw75Ow1DQDgxfEp4POBAEqAsEAKX8wZhJW78/Do8CSuxVj2qI4YmBAKhVQEK8Pgw98L0LO9EkqZLV+02mBGhFyMc9erseXRwXhl5xncPygOVTVGtFPYinUO5lfgv2M6YfOfRUiNDeaKeiQiAZRSEaqdRMPdQSZEjrSonK/Dhw9jzJgxDsvGjh2Lw4cPe/yO0WiERqNx+NdUuEuwZ/WXNmb2x89PDMUP89Ox68RV3P72Afxw8hosVgY6owWpMUr8UVCJnu2VOHVFjbJqIyp1NNR6E0wWK1Q6MotoK1xV6bHr1HVUG81YvTcfsz89wml4vXd/H3wysx9GpUTAyjBYtP0UVM04Ay3X0jhUUOESIs9KT8CmP4swY2Ccg4bd+DU5mNKAsKhCRuHlSd250DxLelIoXp7UnUxMCK0GKSWE2crAbGW4d0iZ1oj+8SHo1UGJ62oDxEIBVk7uieU7T6NnByWk1I0WY6t2n4dab8aevBII+Tykxioxb9MxmK0MeDxALhVCa7Bg5eSeqNabcf+geLSTS5AcpUC1wQzaYssNu61rBDJq799TV9XoECxFRBAFK8MgSCLymps8lEyIXGhR1Y7Xr19HZGSkw7LIyEhoNBro9XpIpa75IitWrMCyZcuaaogOuMtLYUUxe2cocbxYxbWGkFECDOscjp9Ol2BMciQqdTTmDk+ERMR3UQNPSwpFYngglDIRecm0cljvaeaQeJitDHcduNN9+/HxoVzDbW/4cwaqMZi42blcIsSUvjGIkIvBhy1usuFgIVLtNOzsqU9YVK2jsXznGfSODcYsO2mN3EsqvLTzDN6Y2ovcG4QWT4nGAJPFiutq26SETVt5+5cL+PD3Anz4YF8w4IHPB9rJJcgtVuG5cclgGDikuBwrrsKZq2qMSYlA9sgkrN2XD43eDJPFiiCJEHKJEIESAYQ8Pq6p9QgNpKCnzQgUC8HniZGVngCLFdj0ZxEyBycgLIjCWz+fQ8bAOLSTSyAS8pB3VY1ZaQkAHDtrkAmRe1qU8dUQFi5ciCeffJL7W6PRICYmpkn2bZ+XYi+CFxJA4eP9FzFv1I3WEDY1YiPW5xRibNd2UEpFGNklwqX/HXDjwn6VCOG1eljvacaAWOiMvqm6N3VvR3vkEhF0tAXLdpzGxqwBWLz9FA7mV+C9+/twpe2z0xNvWjS4XEtjT14pp3Xm7nNybxBaOlU1NCq1NKIUUsgovouQMm22SRVdUxuglIqQlZ6AUo0Rp66qHdZlJ0Tv7cvHoyOScFePaChkIlxXG6DWmdA+RIqKahpyKR/RCimEAj6kFCAU8CDjCZDWMRRCAR+9YpSIkFNY8+sFzB/TGTqjzTN27roGC+9MwYpdeQ5hSYVUhPZKKZRSEnJ0pkUZX+3atUNJSYnDspKSEsjlcrdeLwAQi8UQi8VuP/M3YYEUbkuJQPcOCozrFoWXdp7G2r35+HTWAMwdkYRrtbMZGSXA6JQIlNbme83a+Bc2PzIIBpPFY/XIwfwK1NDmpvw5hGaA9Z6KhbbycG+4a7jtrnG1P40SNhdr5pB4LN5+imuoHRMixeUqPWSUADKRwOs2fAmLkmpHQltAYzDhSK3XqleMEqOTI7B0YjfQJitqaDOCZRTKqo3QmyyQiYWc6j2b1zXeTnRZyOPhoSHxEIv46BcfDLGQjxK1HgyA7/65jLnDk1BtMEMhE6GqhkaQRIjTV9SICZFBKaVQWUNjZJcI0GYGj47ohFW78/DI8I5Q60wIDhCjqsaIh4clIkBsC2NGyAWoMVrAB8hEyA0tyvgaPHgwdu3a5bDsl19+weDBg5tpRN5RyCgsuqsr/iiowPLaqkUZJUBEkBiVdhVh7GzF3mORse4PvH9/XwCurSPYNioGk3dPCOHWo77qz6xBlXtJhdhgKYYmhbnVtxraKQzBAa4Nt9kHr1IqQseIQET6UekesIXVHxuZhCCx0KE6SiTgYUxypC18USsk7AlfwqKk2pHQ2lHraARQQm4yteFgId7+5QL3eVpSKF6Z1B1xoTLsP1+GALEAAh4PIYG2xvPzNh1DVnoCd89bGAaF5TqktJNzzxwegKtqPRLCAqA1miAWCsDn2xLxj5yzVUXKxEKYGQZGsxVBAEQCPoxmK44WqxAaKMauk9c443BklwgwDMDjAUaTFZcqdUhpF9QMR+/Wp1mNL61Wi/z8G+GHwsJC/PPPPwgJCUFsbCwWLlyIK1eu4LPPPgMAPProo1i7di2eeeYZZGVlYe/evfj666/xww8/NNdP8Aqbl/L4mE54pja8mJWeACvDQK034cw1DdKSQpEaowTg6rHg829oNjmX96YlhWJyn/ZN/psIDcdedoSlLvVn1pO0PqcQ787og+xRSQAYh2rGoZ3CsGpyT0TKJXhtck8s2X4KXaLknLEeLBMhNkTmd8NLraPxzDcncLS4Chsy+ztoD/WPD0G10YS0jqE4eLHCY1jU18Rc9rgcKapymZiUaAwkuZfQ4qmooSEWCdAnVukymWJbh8koISLkEgzrFI5rGj3iQmV46YczyExLAAM3PRvvcUxViQkNgFgkgM5oBgNAyOehuErP5Yj1bK8Ej2eGycLgWHEVhiaFQSixNeHOSk+A2WLFmatqrkekvXFoy/UiqTGe4DFMHdNQP/Lbb79h5MiRLstnzpyJjRs3IjMzE//++y9+++03h+888cQTOHPmDDp06IBFixYhMzPT531qNBooFAqo1WrI5fJG+BWeuViqxbf/XEFqjBLza2+esd0iUVVjgtnKIHvTMU6fKfeSCrnFVcgtVnEvk7BAMc5c02Dniase83f8rdlEaBzUOhrZm3NdWgMB3s/jNZUel6p0yC/VIkYpQ7tgCQQ8HvS0BTraJp4YKXfUyrpcqXNRmm6KFh/nrmsw9p0DAIDv56ehVGPE7E+PALD1nxTweJCJhcjc8Bc3oXAuJFl+d3d0DA/0aX/XVHoUVeqwZu8Ft+HVltjORK2jodKZUEObUUNboJSKGqyFRmjZnC+pxqnLKvSMUWLpDlvkhCU9KRRLJ3ZHuJ3Wo1pH47rGgLHvHHCJlrDFKJN6RyMpwrsn6tx1De557xBWZ6Ri059F6BWjxNiu7XDv+4fwzaNDoDWaIRHxUamlES6ncE1t5CRk2P0ppCIESYQIEguR4OP97AtN+f72N83q+RoxYgS82X7u1OtHjBiB3NxcP46q8dAYbJ3nBTwe97LpGiWHRCQAwzDcjOazrAF2Xq8bsxUZJcCWuYOxcNtJt9v3t2YTofFw15ORxdN5VOtoLNp+CjMGxuLXvBJkDIzD0h2nHQwN1qhSyG58Z+G3Jz22+PCXsW5Tub6Rw+h8W7PN4UODxFy5vPNMPveSCmaL9yby9sgogdv+jgeaSEy2sWmNxiSh4VisDBQyCtPX2Xq2PjsumevZWqoxYvq6w/jqkcHcNa6QUSgorwFgC/+7K2oZkxxR537bySXoFxfM3aPdoxUwmq3oGxeMfedKkJ4UDgAICaRw/JKtWbe94SUW8nG4oAJnr2nw5tRejXhEWhctKuerpSGXiHBNbYBYyOdm+VlpCThWXIW0jqGca/i382VI9eBaJqrBrYOGJIiXa2kkR8nxSU4h+seH+KRa3xAjrzFgW4ewYfL3f8vHgtGduc9ZAUazxcqFHJ1fDmlJobi7V3S99umpv2NLm5iodTR+O1/m1stdX2OSeM9aPmodjcoaGkazlevZ6g7n5wabC+kpT1juQ9WhQkbhtck98dzWEw6OgPWZ/fHxgQIM7xyBvKsadO+gwMs/5HlMiyHyEt4hxpcfCQukUKIRgbZYcbA22Z7PA85e0yC9YxhnbPWLDcaEnlF4eWeewwU8rFMYXhif4nUfJLG4ZdCQBHHWc7o+pxDPjUvGO3suuPmmo6HRXFWAGoMJuZdUeHF8CjfR6N5ewRUI5F5SIVohgYwSuNUCSksKxay0BAj43is6nffp6SWzPqewRU1MyrU0IoLEdfbGq+tlRrxnrYNyLc1NwL3h/NxgK+zvGxDrYhClJ4Viej/fZJailVKsyUhFuZZGtcGEIIkIYYEU3pzaC5U1NAYkBKO0mvbqxVYTIXCvEOPLjyhkFOJDZbhUW2K/OiMVZdVGzE5PgBWMg2uYfYlkpsXDaLYiMSwAUQpbgjRpo9LyaUg7HNZzylbDeoM1NJqrClAuEeHLv4rxWdZAPP/tKQDAhoP/4os5g/DSztNcwYBSKsLHBwoctIDYh/VXfxXjjXqEKRRSkcdZ9+qMVJ9m+bcKGoOJC816oi5jsjG9Z4TmpUpH41hxFaIVknpp9ilkFJZO7IZntp5w+U5OfgWe//akz9eAQua+EptdRluqAXgOcd7TmxSEeaNFtRdqiQSIhbBYb3SdDw0UY/anR6CnLRiaFMatx17Asz89gi//KkaUQsJd/K9N7olhncIctjusCTSbCI1HQ85jWCAFpVTEVcN6gzWqWCPPHf401sMCKayd0YfTrgOA6QNi8c6ec5iVloCv5g6CjBJALBJg0V1dcfySCrM/PYLHvjiG2Z8ewYlLKiy/u35higCx0K1S/sH8Cmw8WIgAccuZW8olIs7LIaMEeOK2TtiRnYYd2Wn48pFB2PqfIQgOqFt41hfvGeHWRq2jIRUJsD6nEFEKKbJHJrm07fGm2WcwWZvkGogIEjfLs6a10HKeTi0Uttfd4MRQrN2bj/sHxkFHWzB/cy5WZ6TCCqZOIUzWBeycxyGjvItVEm4tPLnyPRkcChmFuFAZzl6v9qpaby/PYJ+vsd9J0sLfxvq7e/ORmRbP/d0vNhi9Y5RY72QgjUoOx9Nju+CF8Skw0JY6j4MntAazx5dMTn4FtAYzIltIQVRYIIW//q3EqORwPDgoHhIR36W7RV2hQ9Z71lpCsW2Vci0N2mLlejDOHZ6IZ+9IBmCbpEuEAihlQkR5uQ680VjXQHM+a1oDxPjyM2yvu/SOthkCO7v1FCtPCg90uanUOhpVOhMWfXeyyeUDCP6BAQAf0pvaB8ugNZrx7NYT+Hhmf/BxziHJPC0pFC85eYwCKAFeurs7amgzJ0fh74RrNvm9V6ySMxIVMhHe+Pmci4G092wZjGYrlk7oht6xwQ3eZ2tTuU9LDMXgxFAculju0s8VqDt0KJeIoNaZWk0otq3gLLys1tPQ6M21uZE27SxWP4vNjZRLPb+6mzL1oL4TSsINiPHlZ9hedwazTY3e3oPhHCtn9Z7suarS42B+Obb/c8VB5wXwv3wAoXFpiMgqYCv9XjujD1b/eh69YpVcXqBCKkJIAIVg2Y2Hqbd9sHIU/oA1hOyFgoUCntf2WBbrzUkMthaVe/ac9Y0LxsCEEETKJQ1KvA8LpFCmNbok2wO2480D8Oa03n74BYT6wBpbWqMJCimFRd+dcphQfTcvjWsp5C438su/ir1KODQkv/Rm8JQbRvAOyfnyM+yNYLEySE8KxfqcQsxKS/Aphq/W0Vi8/RSSo4JcDC8WksfRMlDraBejCLhhQKt13s/hu3vzsfdsGZcX+NgXx3D/x3/i1V15jbaPm4E1hFiPbmpsMPS09wRyHX1z7bGaK7+tMbE/Zz3aK1Cla3jivUJmM8TrCsUSmo+rKj3+35bj+PafK+DxeLXRDMf7VcDjcarxucVVDrmR/xRXYdFdXb0aOyRPuGVAPF9+hr0RLlXWcLpe9uFGAIiQiyGXiFzCjazOk6+VboRbl5vR3/KmZ3XA7rvsPjzl/FTU+E/3yn62zXp0+9QRUlTcZAisNeSc2F8X7Lmqq+mIN48ea9B6ugZqjORZ0Vywk+nptTIQfWKDXcSQZZQAepMZMwbGYdOfRQ6eL1Y1vlpPAwjwui8SDrz1IcaXn1HraBhNFgj4fCzYfMQhxwuwhSHX5xRi05yBiAt1vKFYnae6aCnhlbbMzeQn+fpdVvfKU87PPan+K/1mDSH7vpLBMpHHRuCN5Zlq6S8Z+3MrFvLBMAxKNYYG976US0Rer4EpfTo07g8g+Aw7mWYrdB8d3tFlnXkjOyKAEiJzw98u7YEOF1RgfU4hvs9O92l/JBx4a0OMLz/C5nL0ilFicGKoRz0UwL0Bxeo8sQ24b6YRMaF5uZn8JF+/K5eIHJpZ23MwvwJLd5zGWj/mB0YrpVgyoRsWbrMpY7NGAAPGIWze2J4p++1oDCaukKElvHjsz23uJRXSOoaiXa28AOAoRDs0KcyluMKZQIkQi+7q6vEaWLz9FMkRbSZUOpoTTX7mjs4IDxIDuOGlHBwfguhgKQ4XVCA1Vun2XUGe960HYnz5Cftcjswh8ThcUFFvA4pVyLdPYnZWBa/rYUy4NbiZJNhAiRBDO4V5bMrNfjcskMKQWkkTdxzwUSW9oTj3lbSv6H1sRBIkIgEU0sb3TDW0kOFWwP66YKui5206huxRHbF0YjeYzEytR0+I6xoDtAbPIaerKj0Wbz+Fx8d0Iv1gbzHUOhoCAR9mK4N3Z/RBlEIMIZ+HUcnhmDEwDluPXsLk1PbQ0mauZQ/g+rxfPrEbOXetBGJ8+QnnXA5vBtQyDzcUq/PUx0Pfx9Jqo0OlG+HWZvnd3bFo+ykXI8GTF4iVGHl552nMHBIPK+OoCef8XYWMAlVHOxJ/5ge6y2tjvb1r9+bj1yeHo2NEYKPu012RQVgghay0BOhpC05fVUNntEAhEyHyFuxv6Jy3pjPZcrY6R8pdmqinJYXilUk93G5HraPx7DcncCC/HJP7eg8tkhxR/+MsH2G1MuDzgJhgKf65pEKwjAKtp/HfMZ2xcvdZzE5PwHWNAQI+32vLniodjYTm/nGERoEYX37COZfD2w3ljfbBMrx2b08s/PYk1ucUcnkAAND3JjSSCE0H65k5WlSFucMT8fTYLuDxAANthVLmXiz3cqUOBy6UYWet3tM/l9VYObknnhuXDK3BArlEiOAAyqVII7gO48Kf+YHN0WvR2eCLCZbi06wBKNEYsHjHqRbR39A+b83KMA0KG17XGLjcOkpQv36AhMbFnSf2izkDoTWaERMsQ6RcAoPJAqGAh3ItjXPXqxGlkMJgsoBXGzP3lKJSn8bzhFsbYnz5CZdcjtqQo/MNNaxTGB5O9z6X6RAiw9qMVE5o1VkbrCWEV9oq9p4ZGSVAt2iFi3K58zm8UqXDs9tOICstgWvI/trkni5K8e6MiabW+LGnOXot2k9yZJQAG2YNwB8FFdiTV+JQKcYagYu3n8KbU3s1iwfM3huikIoQIBZCazBz3hE2HGtlmHqFDdU6GperbrR1OnlFjaFJoS6VdEDLkeBoqbD3e941DT6Z2Q/tFGLwwQd4gMFkQXGlDgwYhIsF2Hu2FL07KLEhcwDUOhMCJAL8mlfqsUhlaKcwRNTmiRFaPsT48hPOuRxsyDG3WOXgvYoJ9l35ctH2Uy4PVCK0emtj75nJSk9wKR9njYIl209xTaWLKnQ4mF+B+wfGcd9z5wlxp3jenPIL3not+kvg036SM3d4IkwWK6IVUswYGOfWCJyVluBXyQ1POHs/x3WLwlNf/8PdzzLK1vOyT6wSar2ZW+aLXES5lgaPZ/OYhAVSGJUcgSGJIRjXIwqRcgn33RKNASM7h5PnhB8p19LIu6bBF3MGYeXuPE4y4v/d1gUlGgPiQgO4LicnLqtwV88oaA0WBEgEUOlMWLe/AGtnpAJgHJ71Q72kpxBaJsT48hPOL8EFm3Mxd3gilk3ohmXfn6639+pmdKIIzUdVrbCpjBJgVJdw9I5RejUKGAZQ6W0vV/YhnRrjvvIJcH/um0t+oTl6LdpPckZ2iYBaZ/LY1oj9e+mEbo07iDqw94ZsengQ8q6qsWznjXwue2mIhdtO4pOZ/eolF6ExmMAwDEYnh+PxMZ3xzp7zeGBQHHadvOZQZTo0KRRDk9yL0hIaB43BhFVTemL5ztNIjQ3Gpj+LMGNgHDQGE6IUUoTIRGAAnLqixsNDE1FjtMBgsqCmxoywQDF0tAXZm2zpKZlO6SnWOvTfCC0LonDvR6KVUrw+tRd2Pz4UG2cNwMSe0Vj2/RmP3itvCuStrY9dW0Cto0HXNjpenZEKoYDv0TO04WAhLFYGGoMJYiGfywMbmhTWIMVzhYxCx4hA9I4NRseIwCYxzJvjGnVW8w6QCPze1qi+sN6QzQ8Pwus/nUWEXfsgGSXAmoxUfGp3XeReUuHF8Sle877snxVyiQgCHg+Pj+mMaoMZXaMV+CSn0KUrxoH8Ciz89qRfOx20dRRSEdoppDiYX4E+scHoGq3AhoOF+LOwEl/8UYR950uhN1kQHiQBnwfUGM2QiQV4dusJBEmESEu6IUlkr2yfW1wFEZ+8rlsTxPPlR5wTLz+Z2c+jUnld3qvW0seuLVGupXGooIJ7kT43LrlOo0AuEWH/hTJ8MrMfPjpQgJlp8ZCKXBPy7blVzn1zXaOsp+98iRYagwmS2uPlKWxnMN1cW6P6ojWasD6zP0qrjQ7hZBklwLsz+iBYRuFosQrZo5KQGqOE2cogLkSG57895XZ79s8KtY6GSMCDlWFQrqVhMFlcPKUySoC5wxMxsksEAOB8iRZKmf+brbdFKCEfpRojwgIpBIqF3LkYkBCC2UMTsHZfPpLbKZC96RjmDk/EbSntYLZa0aVdEC6W1dQ203atiJ+VlgC1D8r2hJYDMb78hLsS+Ib2bAOaN5Ga0DA0BhPW5xTiq7mD8Py3p1BV493zo6Mt6BguQbRCivf25eNAfgX+KKjEmoxUvyvFNwbNmuwvo6CUifCfL47if7MH3lIq70ophStqPdS14WTWOJw7PBESER8qHY13Z/TBNbUtad5iZbjQsydqjCZcVelxML8c+86WYP7ozigsr4FYyHd4zrAGnkTEdyn0uFWrP1sqah2NS5U6yKVCbMgcgGrDjT6dPdorMftTW4eTsEAKfWOVePuXCzBZGMQG20R1rQzw8GdH3FbEL9ic67OyPaFlQIwvP+EuR0tchwaTN89Aa+hj19aQS0TQ0RauEs1cR7hLIRVBIaPQs4MCT39zAoDNIJu/ORerM1JhhXedr+amua/RiCAxUqLk+PVsCRaN7+qxuOGVH87gjSaseKQtVpgtDBdODgukMDo5HHd0a4flO89g4bhkVBvM2JNXgq7RCqTGKN3Kj9ijkFKcoGpRpQ65xVWICw3A4YIKDE4M5dbLSk/ANbXeY/UnW+hxq1xDLZlyrU2XL0AshNXK4FDtuZBRAshEAi6cyBZgWQGszynEuzP6gM8DeDybfJC7/M5baZJFaByI8eUn3OW/2EtOOOPLzdXS+9i1NVhPEKu7dOKyysWDxYbGhiSGQq2ncbFMixqj2WE7zhpxQRIRQgOoW/LcN+c1qpBRWFnbX/K/t3VCuFx8S1Q8ao1mBAeI8NPpErw4PgXv/5aPZ8elwGS24mB+BUQCPj46UOBQoZk9KgmjksM5Y8zeYDp3TQPaYkVylBylGiNSY5SYvzkXXz5iS+a/vWsk0pNCkZNfgdQYJQQ8Hld1B9gKOAwmC4Z0DMXtXSNR2QzVn60RNl+zsoaGRCjAl38VY3JqeywanwKLXbK88/1MW6xICJKBxwOW390Ni3ec9lmImdByIcaXn3CX/+JJ5b4hNxcDcD3sCLcmChmFlyd1x8H8cqQlhYLHAx4b2ZHzYHkKjW2aM9BlW/aii/5Qim9MmrOhb7RSijem9sI1jcFjwjrQtBWPcokIGoMJZ66qcUe3driqNuDIv5XoGG47h0azlUvMZsf35V/F+GLOICzf6VgZnZ4Uilfv6YGKGpqTqzGardDRFmRt/Bsfz+yPD3+7iKfGJoOHczCarYhWSrD61wt4cFA8yqoNXE9BHW0BwwACPnmQNAZyiQi/ni21eS7FAkwfEItVP53F/FGdsevUNYeJt/39PLRTmEPP1bVkgt0mIMaXn3CX/8LOeBbd1RVLJ3RDjdFcr5urJfewayvYC2mGBFB46fsz6BGjwJK7uqFca+TyPrLSEhASQOGtn88h1y7Z2mi2IkgiIiKZ9cS5nQsY3DIVj2GBFMqqDXhwUDxqjGbOaBIKeJBRAhhMVpck+ekDYrF852mX35CTX4EXvzuFRXd1xTW1AedLqjEgPgSALew146M/kJWeAFUNjSdv7wwJJQDDAL1ilJBRfMSEyBxyv2SUAIvGd4XeZIGOttjEXgPIy74hSER85F1VY2y3SDAMMLi2z+qMgXFe28stddLvas7JC6HpIMaXn/CU/9IvLhgjOoe7tIWpC3cJ/AARWb2VcFfduudsKfacLcWHvxfggwf6Osx4P5nZD0eLVS7eLxklwCcz+wE8Hgk/+ICndi7e0NFNV/GokFGICZHhYH45YkJkMJqtEPB5oAQ2w4cS8F2KcerSdqMEfIQGiNCrgxLBMhEXZrS/vmSUAFv/MwRVNTRGdYnEySsq/FDbror9nNMX+/aGon5bmdA5G+w3Y3SqdTRe3ZWHZ+5IwfFLVeABiA21VSYqZSKv7eXMFu+FWITWCTG+/Ehj5r8QkdVbG7WOxuLvTqFXjBKZQ+JhNFsRIHa8vZyTqI1mq0f1+r/+rcTzdyZDLBBAb7Z5JZRS930g2zLspORoUZWD91Bh18rIneREaEDT3iuBYiF6xihxpUoPhVQEuUSEt/ecwxO3dcaveaWc94qlrspotZ5G+2AZnt16AsUVOnwysz9e+uEM94yQUQKsz+wPlY6G2WJr6hxppy8GeO6c0BYmdI0dRSjX0kgID8TK3XnoFaPEnd2jQNeeQ7OF8dheLi0plPRrbKMQ48vPNJYLmYis3tqUVBswfWCsgwfrk5n9ANzwMJwvqXbI+xAL+W41mVZnpGLTn0Xo5pQHBLQdr4SvlGtpHC2qcvEeZo9KQnpSKI658SwCTXsc2Rf9jIGxkAoFUEiFEPB52Hu2DFP7xWDd/gKMTo7gvFdA3ZXRAWIRtEYzcmt/32u1L33W8I8PlWHFrjzMGBQHSsCH1mh2Mej6eKisA1r3hM4fUQSVjubu5b1ny/Dh7wV4d0YqhnYKg1pn8qrfRXLu2ibE+GohEJFV/9AYoQe1jobBZHUxlNjq1tTYYGw4WMi9KAHbQzj3korL/2G9M7d3jcTru8+iV+132qJXoj5oDCa3PTMDKCHGpEQi76q6WY+j/Ys+c0g8dCYLfj9fhpR2tj5LlIAPHW3BrNpkeR7O4UB+uU+V0edKtA7eq71ny7h12JD2M+OSUVZNQ8DnORh0rPyBJyHa9TmFrXZC19hRBLWOhsApdKyjLZi3ySYRc9WN1Acbcvzqr2KupyuhbdEg40ulUuGbb77BxYsX8fTTTyMkJATHjh1DZGQk2rdv39hjJICIrPqDxgo92BobuyZ4s0m2UpGA8zDY532YrQzaK6UOuTepMUocyK9AZlpCm/RK1Be5RIR+scFue2aOSg7HU7cnY6EPSvH+wv5Fn3tJhcGJoUhuJweb7m9vZLHJ8plp8TBbGUzqFY1lO894zPuTS4Qec8PYkPbJy2pEyiXIyS9HZJCEk6+4vWskdEazRyHa1RmptsKFVkhVHe2V6mt0lmtpCHg8h1A3cKPAKntUR7w4viuW7HDt6UtyONsu9Ta+Tpw4gTFjxkChUODff//Fww8/jJCQEGzbtg3FxcX47LPP/DHOFkljJnQ2t4Bla6MxQw8agwnVBrPLcvbh++GDfR2W2T+A/zumExbd1ZXzXjwwyNZ6hq4jCbe1eiXqS1gghRrajJW7z7pUjUpEAqga+UVbX+zTBdbnFOL2rpEwmCyc0eVcBcdeG8M6heH1yT3xxtReqKqhoTGYIZcKESyjECmXAACCAyhcUend7lcs5KNPbDCyNx3DV3MHYd3mAnz4QF88f2cKXt2VhxGdw1FDWzzKcfAAvDmtd+MfkGaG7bfqjfpGEbRGE4wmK4IkQofQMUvnSDle/uGMQ1hYKRUhLlRW78IrQuuh3sbXk08+iczMTKxatQpBQUHc8jvvvBMzZsxo1MG1ZPwhC0FEVhuPxgw9yCUirnWMO5Qyzw/z//1RhP/NGYiF205CRgnQIdh2bYQHir3u0zmZv62ikFEQqQ1cSNe5anTrf4Z4/b6/j6N9ugCrxfVZ1kCuawFQ6OANBYD2wVJEySWooS14dstxj8+QSLnEo3F56qoagxJsSvfl1Ub0jQvG0eIqnDykwoyBcVDrTeDxPDcgz8mvgNZgRqS8kQ7ELQLbb9WTgO3Za5p6RxGUUgqXjXo85hQ6BuAxLAzYziVJH2i71PvJ8/fff+PDDz90Wd6+fXtcv369UQbV0vGnLATRgGkcGrOAISyQAm2xup31sqEfd/k7MkqA9+7vA7XO5LIuJeR7zPlJSwrlVPMJgJ42u63cy0pPAMPYKs1yi1UuuU3X1XqI/XwcndMFyrU0fj5zHX1jlS7SAwBQWm1Ev7hgAPDpGdJOLsHQTmEu6zEMwDAMVmek4vM/ijBziK1Bu9nKYMPBQmSlJdTZYLw1eVfZKERFDe1VwPblST3q/XylLVYcLqhAl3ZBDqFjo9mKmBApSR8guKXexpdYLIZGo3FZfv78eYSHhzfKoFo6/paFaMxwZlulLsmG+oQetEYz3vzpLDLTEkAJ+Q4z6rgQGaZ+eNitwOKL41NwsVTL6QGxbWJWZ6SiUkt7rZBS62kAAT6PsTWjkFJIjVFifU4hnritE0Z2iQAACHg8XKrSY066rYH12n35Di/CoUlhGGTXB9EvY3OTLrBufwHWZ/bHu07jsU8huFiq9ekZwrZUck5HGBAf4hBW/KOgEh880JfLEUuNDXboAemO1lLEYx+F+GRmP68Ctou2n3JQm/flWas1mu3Cx475c2zFsydak4FLqB/1Nr4mTpyI5cuX4+uvvwYA8Hg8FBcX49lnn8XkyZMbfYAtEX/KQhCV+5tHraNxrPjm+mzab6u4Uoc9Z8vwz2U1Pp7ZH2/+dJZ7AL93fx+PAotKmQhqvRmHCyqQlhTKtYlZsDkXn2UNwEPr/3Iryrhgcy6+z05v1GPSkgkLpHCpUod3Z/SBRMTnFNzfu78PxEI+jl9W4ci/lS7n+kB+uS0J2s+hn2ilFK875W6FyCivbWTYZ4inasQao8lh+87pCGo9DUNt70jAFvI0Waych2177hVM7dvBrbcWaD1FPGodjWe/OcGFAdmiB0/eqAN2hq2vz1q5xLOIqnMSvjOtxcAl1J96G19vvvkmpkyZgoiICOj1egwfPhzXr1/H4MGD8corr/hjjC0Of8lCEJX7xqFcS+PNn8/hizmD8NLO0w4vn/SkULw0qbvPx7Gihgavtsnm9AGxeP2nsw4veba83znRXkYJsDGzP2QiAdbnFOLdGX0QYif8qdab0NeDDlNreTE2FgoZhbhQGQ4XVDgouLPG6uDEULyz54Lb7x5ogtCPt5e4px6dconIpfenjBJg7vBE3Nm9HRgAR4sqERpAwWRhoDWaIZeKkBAWwHnOrmuMDttkj4WMEuDd+/vgtR/zuB6Q9s3e2f6RreFZcl1jcPht63MKkd4xDAC448l6SnW0BSIBH1aGqdezVizic0as8/264p7ubsPCALmP2zr1Nr4UCgV++eUX5OTk4MSJE9BqtejTpw/GjBnjj/G1SPwlC8EKSjpXdLG6PCR/wDc0BhOmD4jFyt156B0bjFlOnqWXdp7Bm1N7+XQszVYGFsYmHOCu7N+dXpOMEmBNRioCJUJU1eZ7MWCgN5kxOjkcGQPj8MWfRZiZFs814WYh1a3uMVsZFwX33EsqnLmq5l62nvBn6KehE6awQMqhClZGCTjP3iu78rgCg7d+Oe9WhDcskEKJxnGSx1ZbLhqfgmqDGT+eKsHv58sdcpTYe6CuatuWgFpH43KVazWoSGjrqfnB/X0RFkRhxa48hz6qQzuF4cXxKT6FfdU6GpcrdchMSwAD1xSBdgopXrq7OxZvP0Wq1AkONLjUJz09HenpJPThDn/JQmiNJq+6PPahCIJn5BKRgxq1O3w1ZK1WxiFs6IyzlADrzZCIBNDRFhwuqMCL41PwSU4hHk5PxONjOnNhsz8KKh3CGEqpCB0jAjmpAcIN3Cm4s8feCu9NtP0Z+mlo/qdCRqFPrBILt9l6LmalJ+CaWs959rJHJdUpHhsXKnMIK9pXW/5bUcMtc+ddHZMccVO/+1agtNrR88feexdLtVg2oSvCgyi8sivPJex6tKgKKp1vqSPlWhqVOhOe2nLcbYrAvE3H8OXDA0mVOsGFehtfy5cv9/r54sWLGzyY1oQ/ZCGUUgqrfjrnVpcHAF6d1OOmxtxWCAukuJePJ3z1huhos4OYquvnN3JBFo3vCgGfh+Xfn0bGwDjweDYD4au5g/D8t6dw/8A4WLW0Q56O84vx1yeHt7ry/8ZALhGhssZRdoE99mybl+YI/dyMoKd98+/UGKWDNIQvrYE6RgTitXt7YuG3J7nfXq6lcV2jh8TNtWpPa8hFUulNDp5nthPCg4PiERsiQ0m1wW2+W1a6TQDZG+zx0RhMEAv5Ho1YwNYKilSpE5ypt/H17bffOvxtMplQWFgIoVCIjh07EuPLjsa+4WiL1aMuz8H8ilYRKmgKFDKK09PyBPtwravaSSGluJf8moxUDE0Kc8gxAWwv0ROXVHg4PcHmCalVsGc/Y0MjEpGgTZX/NyZhgRT++rfSbYg3NFCMeSM6wso4hnCH+jn0c7OCnva5o2YrA4XE9rgOC6QQWIc+GXuddAiRuST2M2Cgoy0ek+2HtpJcpABK4OB57hNrk/D4OKcAz96RDLPFZmCxuV+jkyMgFglgtjDYe7bEo8Fuf3zkEhF+PVvqsXintRxLQuNTb+MrNzfXZZlGo0FmZibuueeeRhkUwT1ao6uKuj01dXxOuGFM8Xm8Or0hvlQ72ef3Pbv1BD6e2R8AHAww+3BzQbnN45Z7SYVohYTT7JJRAoQFUm6V8u1pDR4Jf6CQURjRORwJYTb5DTbEuz6zP6d+7xwWKq02ukiOqHU01DoTzFYGerMFOtoCpVSEiCBxvY00VtCzoS9m+2srSiFBtcEMGSXAhswBdRrh9teJ8ySwRGPAq7vy3OYppSeF4pVWkmwvowRIjVXiua0n8MaUXgiwa8ekM1oQHCDiculkFB/VBjNW/HgWM4fEY3jncPSJDYZIwHOQjlHKRAi2OzZhgRTOXdO4lYVJTwrFilZyLAmNT6PIO8vlcixbtgwTJkzAgw8+2BibJLiBNNduGGqdTVyRAbB0+ykcsMu9YhjGYfbPGkrADZFL53L/oooaCPg8RMolXH7fku2ncN+AWHz4ez4y0+LxzLgu0BoskEuEUMhEXBsR9hyyFY7ZI5NQWF6DF8en4J095/HfMZ1bffm/v4iq7ZP56qQeqKHNEPB5qLAL47oLCw2ID+FejtdUelyq0oFhGFwsq0GkXAKj2YpqgxlHiqowonN4vdrBaAwmrM8pxNoZqeADjkndSaFYNrGb1xezfe4obbZy+YEWK3NTRp3WYMbes2UuOYVsnpK5FXjQr6n0MJqteHxUEiwMUFhegzhhAJcXKBTwYLEyeHF8Cq6pbZ7nH05eQ26xCssmBqBEY8TjX+ZifWZ/nL6i5rZrMFmRW1wFWccwzqhddFdXLPv+tEPjbIVUhNhgKTqEyJrl9xNufRqtt4ZarYZara57xTaCP4RQSXPt+nO5UoeF206gV2wwcourHPKpFmzOxdzhiXj+zhQAQE2tl0NGCbhEaRklwNoZqbaXqL1AZ62RFq2UIlopxcv39MAL205g+sA4rD9Y6KCofl1jQI3RgnZyscM5nLfpGBfuEAr4eP7bUzhRqxXmXP7v7xBZa8Hey3OxVAuVl7ZPwI3wnFpH47fzZRDwgJgQmYNkBWArakkIC4CMEtSr7RQA8MDDuB5RyLQzcko0Bgh4vDq3weaOni/VcvmBNQaLSyGH/TiXTvBu1LEaYq012V6to5GTX47YECkUUhFe+cHm5TtcUMEJy/5ZWIFRXSLQo4MCZdU0mNqQ9NNjO0NrsECtN+HBwXGoMZqx0821kBgeyLUNW77zDFLsvGNiIR+HCyqw8ZoGb/hYNU1oe9Tb+Fq9erXD3wzD4Nq1a/j8888xbty4RhtYS8ZfQqikuXb9uFKlw7PbTuBgbY6VuxdNt2gFXtmV51Kuv2B0JwDAI8MSsSGn0MUTdaA2zMgKdGoNZiRHK7Ch1vBanZGKTX8WAbAlS18s06Kyxoi4EJnDOXz7lwt4+5cLWJ9pU8Iu19IuLUrEQj5iQ0gT3vrCJkN7g/UWl2tpRASJER4k5qpN7bEvavH1PmPlIj7OKfAo5uuLNp9CRiFERnH5ge2VUo+injaZCO95g63dg16updGlXRBW7j6L2emJOJBfgRmD4vDlX8WYnNoe6UmhMFkY/HNJhSiFFDKRAJU6GjJKgJFdIlFUWQOxkI+RXSK4kLV95wQdbYFUJIBGbwJtYbAnrxR78ko9joU8lwnuqLfx9fbbbzv8zefzER4ejpkzZ2LhwoWNNrCWir+FUElzbd9Q62gUVei4l547GQh3/QAB27l6dHhHyCgBRqdEeBXoLNPaytkrdTSXT5I9Kgmb/izCjIFxLrIg6UmhWHlvT5dzaGVuVFd5qnIk1I/6JENrDCauYMVbUUsN7XtepbNchDP1aTXGekzFQluOGvubnK+TtKRQTO3Tweu27EVBAUcVfQCw1IqMttRnisZggoBvqwy9f2Ac17B++oBYrPrpLJ4amwyd0Yw5nx3Bjuw0lFYbIRbykZWegGqDCZTAZsSO7RaJ3GKVS+cElqGdwvDf2kmaJ0iBDMET9Ta+CgsL/TGOVoN9uMpdW5CKmpt/qJGy5bop19IOISd3HhB3oqgsfxdVYn1mf+iMnr0IMkoAHnjI3pyLzCHxnIHHvsTcGXY5+RV47tuTWJuR6qBurtbRJKTcyDgnQ9uHggGgQ/CNfBy5RASLlfF6vgFH+Qdf0NZRQFGfl/PLd3eHzmTBycsqZI9MAuAacpw/qhMXDnOHsygo66V1niS05JZlcokIZbUaX6xRdfKymmsr9Pv5cnzwQF/oaFt4UU9bUKoxID0pFIFiIQ7kl+PMVTWGdQrHI8MScV2tdwk9AjY9sLYg2UHwD9598oR6ozGYuGTu3OIqzP70CB774hiyNv6N3OKqOuQeCY2Fc8iJ1fuxx503jIVhgHf3XoDUSwPurPQELN1xCgculCP3korr42Y0W5Eao/ToQWFb2gC2l+HFUi3+rajB8ru7Y1gnRzV2ElJuOAoZhWV3d8dXfxUjLSkUO+en43jtPTn70yMY+85+PLXlOK5V6UAJbKrndb1M6+rVZ49aR3u9xgDfXs5XKnXIu6bBkaJKqPU0YkNl4POA8T2i8MnMfnjv/j74ZGY/3NUzGvEhMq/XCisKumBzLlJjg/HlI4PwqRexVnUdOmW3ImGBFCS19y3bUunlH/Ig4Nty7Ng+l4BNiFXA46G9UobgAAoSkQBnrqoxY2AcpCI+RqdEIFIhdXsvPzIsEScuuz5XWMikieANnzxf9957r88b3LZtW4MH0xqQS0Qew1kH8yuwtAka+RJcQ07uEpS95QP1aK/AO3su4GnAY9jKvkEv27olPSkUEpEARrN3D0mN0eSSGyijBFh0V1e8MD4FetpCQsqNQLRSijem9oJab8LCb0+6aIDdNyAWRVU6MAwg4PEgpYRutdoAW5gpIkjs875vVmoCsOUt/n6hDD+cvIZn70jGyt1nce56Nd6Y0gsDEkJgNFlRQ1sQQAnQOSIQ7erwVDmLgqbGKB2qMO2pT1j0VkIhoxBuNGNoUphDL0d7bTR2MkYJ+NCZLDhfUo0JwdE4WlSJh4cm4qMDBXhiTGdUVNOQuTHI2ZSE+z78w2Phw/K7fe8RS2h7+GR8KRQKf4+j1RAWSGGI3UvZmaZo5Etwr7/DVje+cGcKGAACvk3r62hRlUuImDXM9p0r9RjiEfJvVKuxrVvWZ/aHiM/36vGQUQIoZRSe/ea4w4tPR1uwcNtJnxOxCb5zuUrvYgCxk6TnxiXjUqVN9f2xTcfwSWZ/4Cc45G0OTQrFS/V8mbJSE55eznVJTbB5i/Y9K9kw4UdOSfxpSaF4+e7udY7JeVJSl2eupeYstQ+WYcW9PbDw25PQmSyYOzwRAh64XDf2vJRoDIgLDUCP9groTRYs/f4M3p3RB2NSIsHj8RBSq71nn0ZitjJICAtAVQ3ttfChssaI+FrdOQLBGZ+Mrw0bNvh7HK0GhYwCVUeFVUt9oLUk2JDTqz+cQVZaAp4blwyd0YLwIDGWbD+No8VVmDs8EUsmdAVttmLFrjwHg3nTnIEAgM8PF2Fc9yjc1SPKUaBTY3DJrSnX0th7thTnr2vw1Nhktx4UGSXA+pn9cblK3+o8Drcqzvl/LGyLHq3BArGQj2PFVejSLggZ6/7A3OGJeHpsFwCAzmiBlBI4hKB9kZKRS0ReX871HbfOaPHqVV/sg1fdeVLiazVoS4RV91fpTIiSi/H6z+cchGXZydiQjqG4WFYDrdEMHW3BvE3HkJWegMQwM4QCHo4UVeKTmf2wdl8+1u7Nx3/HdMLnh//FM3ckA/As2XFn93ZN/IsJLYlG0/ki3CC4jpdmS36gtSSilVI8Ny4FC7edwNFiFdZkpGLt3gs4aicFMapLBF5zIy1wqKAC6Umh6BcfgpU/5iElWoEIu4bWV9QGCC+rXZLke3dQont7BXS0GY+N7AgrHFvavDg+Be/uu4AZg+K8jp0Y6I0HG2pz9l4E1bbrCZQIcPCiLcl6VloCxMIidItWuFS3sfl3DOBS0XxbSgSWTuwGg8nKGWSBEiF3fTi/nId1CsPD6Qk+jZtFKOB5LRLxxavOTkqWbD+F1NhghAeJMTQp1O1EoDXkLLHFSaevqj0Ky+46dQ2jkiO54gj7kCxtsYJhgPf25eNgfgXCAinc3rUd1u0vgFjI9xhSTksKRQBFXq8EzzTo6vjmm2/w9ddfo7i4GDTtmJB57NixRhlYS0WtoyES8PyuUu4PEdfWhlpHY+G3J3G0tlw8WEbhQH4FskclYcPBQqTGBkNjMLt9eLIK9BFBYryz5wJ+PVvmso6MEmDXgqFYvP0UZ4ApZCK88fM5PDcuGbM/PeLyoFdIRXj5hzw8My7Z7fZY48BkZXCxTEvOayMgl4iw/0KZg/cie1QSJ7hZqjEirzbJetOfRbh/YBw2ekhC/+18GXaduObg0WRzx57ZesLhO7elRODlSd3x4nenGqTLx4YI2TZUOfnl6NHeewqIL0Y7mwdXrqVRYzThpUk9HK7h+oyxJaDW0S6GlTNjkiNRWF7j4K1mk/XZ/E+2XVWpxoDVGak4fUWN+Q2sOiUQGiSy+sILLyAzMxPbt2/HrFmzcPHiRfz999+YN2+eP8bYYriq0uP382X45cx1j33TXm2EXl/+EnFtbbCyH0/c1gkSER8VNbbyczbclJWWwFWnupMFOXNNDSsj97oPK8NgXI8ozKyVmhCLBDiYXwGVzuT2Qf/e/X240nf7WTNbIduaSv5vFcICKUQrpJz3ArDJgRwuqMCo5HCcK9Hgxbu64uWdZ9A1WoEIudhjSDgiSOwSSvYUCvylVnjz9am9oDWY663Lx4YIB8SFYNnEblixKw+jU7yrz/vqVXeWq2mJ2oG+TkDLtTRX6egJPp+H9KQwxIbIADA4UJsXdnvXSK7ZvU0HzIyQQArv7DmPBwfFg1dbdercM7SuqlMCod7G13vvvYd169YhIyMDGzduxDPPPIPExEQsXrwYlZWV/hhji4AVV80cEu+1bxp9k33T/C3i2pqoqi2TZ5WqZ6cnQkYJuOols5VBbIjUrdGTlhSK58Ylo1Rj9Lj9R4YlYkltr0iWz7IGQEYJPIaexUI+UmOUmL851yER25vgKzmvN4dCRqFnBwWe/uYEt8xotuLLv4rxxZxBWL7zNNbn/IuVk3siQi72qvXlLkHdUyhQRgnQJUqOqhoaepOl3h5qNkR4ML8cnx4uREq0Ajym7obwDaGlaQf6MgFljbOKGhqHLpZ7rWIND7Q1TpdRArxc2xtUR1sQIBZALLRtLzVGyYWCu0Yr8HFOAacdF2mXkgDAq0QNgQA0wPgqLi7GkCFDAABSqRTV1dUAgAcffBCDBg3C2rVrG3eELQTWy5IxINajJ2V9TuFN901j9+MOkqh9A7WOBm33ojyYX4GstAQsGp8CS62afJRCgmqD2WMCc6nGyJWk2wt0Gs1WBFBCRMjFLur3ZiuDrPQETv/Hebu5l1ScyOfpq2o8W5u0K+DxPObykPN68ziLo4qFfEwfEIvlO09z5xYALlXqEeOlGbK7BHV3BlljeTKjlVL0jlHi6W9O4NezZVyVnpVh3OajtYVrxJcJaA1t4db5ZGY/rNtfgLUzUsF6tVicq1jdGaGsALLRbEVEkBhlWqODwV1Xw3YCwR31Nr7atWuHyspKxMXFITY2Fn/88Qd69eqFwsJCMEzblRBlm9XKRO4fumlJoVidkQp5PUQave3HEyRR24a9xhLryRDweOjeQYGfTpcgLSkUtNkKHW31KIYK3Mj9koj4+OhAAQDbDFguFeKqSu+y/rHiKgxODMXDnx1xKzFw5qoaE3pFcdfI27/YjLf37u/j9feQ83pzOPczZPN5WGPGvg+n2WL16CUprTa6FFnYG2TsxOv2rpF43U0hR0M8mVrjDZV8d9WT8aEytFdKb+pl35JySOuagKp0Jry4/RS3Tu4lFVJjlcjelFvbM9UxRBhcR24W21P33/IaUEI+5BIR1D42bCcQPFFv42vUqFHYsWMHUlNTMWvWLDzxxBP45ptvcOTIkXqJsbY22Ie7hWE8elJ4AN6c1vum9iOrw51NKilt2GsssarlerOtMTG7XK03edU5yr2kQt+4YBy/rMLJyyo8MCgO63NsRvUnM/u5/Q4r6uhNYkAi4LtcI6255P9WgO2NeKRW061fbDAoga31jHMfTtZrxYBxKJoZ1ikMIzuHY3jncIfm9rmXVEhPCsUxuyraEZ3DG01KxNlwdM4l/PXJ4TdlKLW0HNK6JqA1tNnht9zQWnP1QvrqLYxWSiHg83D+WjU6hEhRRwoZuV8JdeKz8bVz507ceeedWLduHaxW2wtr3rx5CA0NxaFDhzBx4kTMnTvXbwO91ZHUNqvl8XgePSk5+RXQGsyI9J7D7RG1jsaxYvfhLKB1lIY3BHezdnuNpXdnpGJMSgQ6BEtRqjFyyz/LGsDNYJ1DxQGUEAzDYHKf9rimMgAANuQUci9jo9mKM9c0LudCR1ugq03Q9VRZdVfPKLfhSHJe/YdCRmHl5J4oqtRhzd4LWLs3H+sz+7vtw8leH3OHJ+L5O1MAADW0BUqpCFJKAIWMckhQl0tFmN4vBgfyyzlDrjE9IxKnRtj23Oy10RJzSO2V6t1R4xRidp4IBUlECA2g6l1UECmXQGc0Y9VPZ/HsHckez0l6UigCJURmguAdn6+QSZMmITIyEpmZmcjKykLHjh0BANOnT8f06dP9NsCWgFpHY8n207YKxzpCrzfjji7X0nhp5xnSzsIOT7P2Fff24MJD8zbl4uu5g3HysgoMgFHJ4egarQBVK5Y6Kjncredjw8FCnLtejbUZfZCeFOaQ3yUW8j2ql19X670mRevswkgsnrbVlnJ5/I2MEuDdvTcqHk9cVqFHe4XHhPleHZRYsSvPMUeo9nxEuwnz9YsLxhWVHhsOFiIrzbuGl6+eEbWOxpIdp/1WPd0Sc0gpgXd9rSA3ho/9ROjXJ4c7NLWvD2Yrgx9PlWB6/zi35yQtKRSZaQmocXOPEwj2+Gx8FRYWYsOGDfj000/x2muvIT09HXPmzMGUKVMgld56rummpLTaiD1nS3GooAKfZQ3wuu7NuKM1BpPXcJZGTwNoO+0svM3al+44jVfv6YHnvz2J/RfKYTRb8NIPefjg/r54/s4ULNlxmsvnevr2Lnh5Vx73EGUrD9lWLhaGAZwK4Ng8EnfnorKGxgq7fbOwhpRz8jfgODtfNL4rDCbS27GxKdfSXB6XjBKgVwclIoLEKKrUuaw7b2RHfHKgwCV0eOBCOZ7desKtkrzWaOYMudTY4EbxZJZraezJK8WhixV+qZ62D+G5KxSy3oJ5vCo97dA2jCUtKRSz0hIg4PFc8vJYbtpTWOvRrKHNeGrLcbfnZMHmXK5DBoHgCZ+Nr5iYGCxevBiLFy/Gvn37sHHjRvznP//B/PnzMX36dMyePRv9+/f351hvWdgWIDragt/Ol/ktfMTmfjiHs9iHJiUUILe46pZPmG0svM3af8krxcI7U7jwUGVtH7Zjl6qw7kAld37mbTqGz2cPcDhf7AvUXox1bLdIADeOdb/YYEzoGYWXd+a5zSOJUko9aiex1VPOLwcdbcGJSyo8nJ7Q6s9dc6DW3xCEzkpPwMc5BegfH4IB8SEu6w7rHI7XfzrvslxGCdArRolragMKymsc7jUZJcA1tc0YYmUsXtp52iE0lZ4Uipcn+e6hZo0jz+KgN1c9zT5TZJQAa2ek4os/bhQeGEwWlGuNkFECtA/2XAHa1ASKRcj46E/MHZ7IVQvrjBaIhHwcuFCGTmEBeGlSd7zw7cmbOvbOXKnScRXU9s3J3UFyvgh10aDA9MiRIzFy5EisXbsWX375JTZu3IhBgwahe/fuOH78eL239+677+L111/H9evX0atXL6xZswYDBnj2IL3zzjt4//33UVxcjLCwMEyZMgUrVqyARCLx+B1/EmCXBO/P8BGbNGz/0m7L4pysjpcnNHoTEsMDoZBRMF5VAwCnVs2ioy0ocdLyYpPwWSMst1iFSb2jXcKTYYG2PKLnxiWjhjZDLhUhWEZxmj+etJPY6in7pG2AhBj9jcyu3Yv9uR2dHOGQvyOjBDDQrh6lsEAKH8/sjzd/Outyr624tweOFasQF2ozUqYPiMXK3XnoHRuMWU6ekZd2nsEbU3v5dJ6dk+2dudmXPPtMGZgYgk1/FCHD7vpmSU8KxWv39kQHLxIcTUlYIIW0jqFuW0CNTg7H5NT2WPL96Zs+9vaodTRUOhNXQU1yNAk3y01lBQYFBWH06NEoKirC2bNncebMmXpv46uvvsKTTz6JDz74AAMHDsQ777yDsWPH4ty5c4iIcJ3Vbdq0Cc899xzWr1+PIUOG4Pz588jMzASPx8Nbb711Mz+nwQRQQu5GdA4LAkD7YCmi5JKbfqm6e2m3VXFOex0vT7pqCqmIS8aXCAVISwp1W93oXGnI/s2uq6Mt+On0dYfwpIwS4LXJPbHe6dj7avRGe/GMEfwDn8/j7lP766CqxoTn70zBil1ncSC/HFnpCS5VxWxrGeeXPWC714oqdHhp5xlsz05DelIoZ9ztddOWCoDPuVTuJlwsjfGSZwsRVHoT9Car22dJTn4FFn57ss6m3U2FQkZhyYRueHbbCZexpkQrUFylx96zZTd97O1R6Uy4rjE4SJO4C32SCRTBVxpkfOn1emzZsgXr16/HgQMHkJCQgCeffBKZmZn13tZbb72Fhx9+GLNmzQIAfPDBB/jhhx+wfv16PPfccy7rHzp0CGlpaZgxYwYAID4+HhkZGfjzzz8b8lMaBaVMhPmjOgEAZ4Ct3ZvP9fhqDMOLxfmlLREJ2qQ4J6vj5eyNYhmdHA5+3w7I3pyLo0VVeG9GH8wf2YkTWLXHeRbL/m1vlG04+C9Gdonk1nlkWKLH/n++Gr0tTVW8pSPk87gXJntus9IT8OGBi5zQamZaPMKDxBCLHJO6s9IToDWaOcPb2dg3WxnoaAuuVhmQWUeyPeB74U1TeElllADFlbqbbtrdVFxV6XGpSufW65Qao/SLBlcNfaM3JDu5FvJ4eOr2LnhuHA9VOhMigsSN+qwntG7qZXz98ccfWL9+Pb7++mvQNI17770Xe/bswciRIxu0c5qmcfToUSxcuJBbxufzMWbMGBw+fNjtd4YMGYL//e9/+OuvvzBgwAAUFBRg165dePDBB92ubzQaYTTeCCtpNJoGjdUbChmFuBAZ7uoZ3SQ9vuxf2rnFVV7XdfegaUmCip5gdby+fGSQW29ESrQCz397kkua/+yPf/HgoHhIKb6LgCY7m+XBNsv/8q9ifJLZH2euajh1+9cm98Q1tU1UVUYJMDolwkXdnqU1G70tmdAACit25WFAQghiQ2UY2inMrVL5e/f3gUwkQLZd0+R+scEQ8HgOYf71OYWYOzwRI7tEQCSwGXNsIvbnsxuv8MbfXtJyLQ0pJUBFjfcw/q0gHMoW2WQMiOWW2RvDAZQQgPdKw4aEamtoi8MkzdlIHdop7JbxDBJaBt6VHe3o2rUr0tLScOzYMaxYsQLXrl3D//73vwYbXgBQXl4Oi8WCyMhIh+WRkZG4fv262+/MmDEDy5cvR3p6OkQiETp27IgRI0bg+eefd7v+ihUroFAouH8xMTENHq83opRS3Nm9HeJDAxCtkCA+NAB3dm+Hdn7OuapvTshVlR7Zm3MxYW0Ofj1bin/La3CkqArnr1dDXUcO1a0Eq+NVrqU9zoDteybuPVuGeZuO4c/CSiy6qyuGJoVy6+poC776qxgrJ/fE3v83HF/PHQwjbYaAByy5qxsWjU/BhoOF3PpZ6Qleez4Ct8aLiuCIQkZh+d3dMSghFK/tysPMIfFu1xML+Xjqm+MIDRTjrh5R+GRmP7RTSCCXihwqYd+d0QcD4kPwzp7zMFmsSLfzlooENm0udzQkXKiQUegYEYjescHoGBHYqC95NqlfUUf3jVshiZwtsmGPM2sM5xZXYf7mXARIBJyR5I6hDQzVKqUirM8pxKy0BJdtpzm1KCIQfMFnz9eYMWOwefNm9OrVy5/jqZPffvsNr776Kt577z0MHDgQ+fn5ePzxx/HSSy9h0aJFLusvXLgQTz75JPe3RqPxmwHGeqRYz5KtGor2q2epPjkh7KzxaFFVi0/SFwttLzeDyX0TZOekecBmZL39ywV8+HsB12ZEUZskb1+JuOvUdew8cZULMX2WNQAHvz3FyQf0iQ2uU8/tVnhREVyRUbYw/YH8chwuqHQrDZN7SYUu7YIw46M/uGbblJAPg8mCwYmhWLs3H/8d0wnX1Xr8kleC+wfGYfWe88hMS0CJxoAXx6fgndq//aHN1djIJSLsPn0No7pE+k3MtbFgDUXWwEqNDeby1LJHJeHkZTXOXFW7zcdKTwrFigYe+4ggMfrGBbuVlvGlRRGB4IzPxtfq1asbfedhYWEQCAQoKSlxWF5SUoJ27dq5/c6iRYvw4IMPYs6cOQCAHj16oKamBo888gheeOEF8PlOydNiMcRicaOP3Rm1jkZFDQ0GwNLtpxz0gfxp1LA5IUu2n0KXKDmXhxIsEyHWKeTJzhpZCYWDdtVdrNs+75oGNUYzIoLEt9QLwp4rVTos2XEKmWmuidEszknz9tiXiH/32BAHwcVyLY2IILGD2nlptc3L9eVfxdj08CBU1dj0ojxVOzV0dk3wP6XVRi7k7Ekahg1DbzxYiNmfHgEA7JyfjisqPRQSERd2rqimMWNgHCQiAfacLcOhgkpkj+qIUcmReP7bU/ijoNIv2lyNTVgghYggCbRG2qHwgGVop7BbxmBkPf3sOZLa5bymxigxf3Mu1s5IxaY/ipAaG8wde6VUhA7B0gZXbLKFCc9tPdHgFkUEgj3N2gOBoij07dsXv/76KyZNmgQAsFqt+PXXX5Gdne32OzqdzsXAEghsL+DmauzNqqz3ilEit7iqySsPo5VSLJrQDS9sc30w2Bt97KzR3hvU0qQq1DoaxZU6/Hq2DOdLtPgsa4Db2Trbb68+PRPVOhqVOtrFYGO3MX1ALP4prkL7YJlHSRESgri1UTklY7s7j/ZhaIPJimqDCXraAiGfB53JwoWdQwIovPHzOdw/MI7bXudIOa5U6bnt+EObq7FRyCj07KDAPe8dwtzhiXj6ji54Gl2gq/3NOfnlt4zBGCgRcvf7gs25+PDBvtxn7H3LAw+jUiIRKZdwRu+/FTVop7g5KSJSoUxoTJq9AdWTTz6JmTNnol+/fhgwYADeeecd1NTUcNWPDz30ENq3b48VK1YAACZMmIC33noLqampXNhx0aJFmDBhAmeENSX2KuuZQ+KbpfLwSpUOL2w74aLGvd9JjZudNdobFy1NqqJcS8NkYWytYu7vg5d+OOM2vJN3VY1X7umBQxcrfNLjuarSY/H2U3h0eEcXg40LcdT2ATxcUIFBiSE4fVV9Q+Sx9kVVWF5DQhC3MAFOnlJnaRi5RIQQp75/ah2NaxoDfr9QhmiFBIMTbeFuocDWx5WVlGErYGc1UmuhpqTaYObC8m//4lpIMqJzeDOMypUaoxlZ6QngAci7Xo3QgBtRDbGQz4nnevJI32xSPKlQJjQWzW583XfffSgrK8PixYtx/fp19O7dG7t37+aS8IuLix08XS+++CJ4PB5efPFFXLlyBeHh4ZgwYQJeeeWVZhm/vcq6uxCXPf5IwlbraJRpaRfDi+XAhXKUVhuhqM1rGtYpzMG46BMb3KKkKjQGE4IDbInP1QYz9p4t8xjesVoZ3Nm9HQYnhmLR9lMu/R/ZcIFaR2Px9lOYPiAW50uqAcDBYLP3jtAWK6devnznaYcXlU1B+9YIzxDcY6/Jx2IvDfPqpB6IC7vRouuaSo/fzpehR7QCZ69p0Dc2GEI+D7mXVBicaEu8zr2kwqjkcK4CtndsMNc/1Fl77tw1zS0XkrbXzPPErWIwVhtM4IGHCb2i8dLdIdCbLBidHI6UaAXCg8QYUpuT545bSS6DQKi38fXZZ5/hvvvuc8mjomkaX375JR566KF6DyI7O9tjmPG3335z+FsoFGLJkiVYsmRJvffjD+x7o9UnxNVYlGtpGNz0CrSH1b1h88N+t8tzEfJ5Pn33VkEuEUFjMGFwYig3Nm/hnYRahfu1XsIF5VoayVFyhyo2e5kB1juy6eFBMFusmD4gFst3nnYrRrlo+ylScn4L46zJx8Jq8illjmHookoddp64ipd2nqltv/Mv/jMyCetzCnFHt3aQUYL/396dxzdVZv8D/2S7SdM0SWm6QjdooewEqlBaUAEFN1QYRxGVzZ2KDqMCjgKKCo4zjgO4S5H5KeDXwRURBwtKi+yUpeyFShFaSrekadrcLPf3R3svSZOmLbRpm5z368VrpslN++Ta3pz7POc5B+ogCRbf2R+nS00A4BKcN64U31lyp5zxNfP4a0LjOmahShlUHppVdwRtEIO//3QS+rhQDOhux4qtp/HChL54c/NxyCQijOyp8/p62oVMOotW/0XNmDEDEyZMcKs+X11djRkzZlxV8NWVOZd6OHLBgFFJYR5nodp6txC/o7K8hoVS7n251TkpPaahJAY/GxQa7D0gbCqhvaPoVAwuV9dBIhK1Ktj1tlxgrLO65MHNXnvAtW8ca4dWWb8rstxkEXa8eUJ3151ba2ryVZmtWLH1tBCkZa6tX56UScQYFheKX0+V4j8zUqENluOPqlqhVIO34Pylb/I73VI+XzNv+RQ95FIxHhqRgGJDLSQiEaI1CkglYhSUmmAwWxGp7tiNOKzdISz12hwcekWE4M3Nx4VCywO7a72+vrPM4BHS4jpfPI7jIBK5z5b88ccf0Gg0bTKoroRfylMyEgzuocVTNyW51YEZ1cY7YvhaXWPf/hX8xFVTdW3Sk8IaCg9eoVEySNAFY+UUPWQSsdfXSpqZGfM1jZJBbDclOHBtVs9HrZC5LBnzuS8TV+7AxJU7cP9Hu1DH2hGpVqDOaofEw++/M7q77txaWpOvhrV5XJ68/6NdmJaegIgQBWwcsOi7o6gyW8FIxUJuoKecI+DKUn5nwtfMm7MuDw+PSECQTIw9heXoHhqEE8VGlBrrYKi14o+qWmzKL0FxVW2HjdVkqS+garE5YLbYoY/Vol+MRshbPVBU2eQ1obOUyyAEaMXMl16vh0gkgkgkwtixYyGVXnmp3W5HYWEhJkyY0C6D7Mw0Sgav3T0AOwrK8EnuWaFNSeO76raaQXJO8AcARirGiWKjyzIZz9NSCv89+Ar3SrnEY02c9KQwzEhP7HTBFwB0D1WC44DjF882Wc9n2T0DAQBnSk3NVvLXqRhcMsqE5ZbUuFBolDJIJWJU1rCwOziENrxOE8TgXIXZ6/jo7rrza0nidE0Ty/lm1o75Gw7js0eGw+o0E1NsqGs22R7ofMG5c63AbioG7/9SgHnjU1BsrMPGI8Vu14VEXTCUjKRDZsD4lQa5VAypRATW7hBmrZWMBDKJCIvu6I8lG4+6lfuhkhCkM2lx8MWXgjh48CDGjx8PlepKbSSGYZCQkIDJkye3+QA7O4OZxasbj+GJG3phx9f5AOBxSer6hG5t8ofvnOAPAMWGOoSHKCAWAbcPjHYN+owWRDaq18WXxeC/R+aYJBy/aHCpicMnrH+xpwj/uLdji+o2pUc3JV6ZOACLvz/qVs8nIUwJiETIXJfnlmTvqXyGRskgIUyJVdNS8Z+dv2Nc30j886cTHmu16VQM9vxe0aIdlKRr0zZR8Z1vqn6hshbKhlllPgH/0f/s81i41VlnC86d+0cCwJ+GxcJstWPltgK333H+6zc6aGMJHyjmna9CXGgQekeqUWysdSmZ41xEGQC6hwZRz0XS6bQ4+OIT3BMSEnDfffdBofBeM2XdunWYOHEigoODvR7X1ZWZWPx8vBSThvbwelxb3e3yCf78LE2MVoH7Ptwl9JgDrpQ9OHLBAOfKZ41nzQDXgpJdqXigwcyCtTvwwoQUODgOZosdmiCZEPg0DrwA7+UzguVSrMopxJxxyXjn51MYHBeK6Q0BHb9TbdG3+fjHvYNxY+9wJDbsiHP+cGrr5WXSsSJC5BiVrHP7PeLLs8xMT4RKUT+jnZVbiFv6RWJonNZj4VZeZw3O+RpWpy6ZEKGWw8Fd+d321Ejc7uiYmopm1o6nbkzCRzlnMCwuFCEKKYAgl7ZPjceaV1SF6AGei3YT0lFanXA/bdq0Fh33+OOPY/jw4ejZs2erB9WV8MGQr3Y6qhsqbPN3eQCgj9N6rM8zOlmHGU796xrPmikZCR6/oSei1HIsvqs/RJwIdTZ7fYJ5kKzTJdvzGs/eAcDNfSOweGJ/lJlYWGx2tw9MXlPlM8pMLFJi1Kix2ITkXedglF+GLa9h0TNcBSUjwRt3D0QNW18fSRMk69RdAYi75hrMO1c133euUvhQj1DLsXJrAfRxochIChOKfs78dC8+mXYdVmaf9rgc3tlvaDRKBlqlDGUmVkg3aKoIM3+j4csizAYzixf+exj7iyqFWl+VZhZapQxpPcOEG0lPf7tpPcM67Xkngand9g93VLV5X+NzEJw73jfWlne7OhWDl+/oJySY5hVVuVTo5u9SR/asr+5eVlOf3KtRMi5lMZSMBO8+MBQKmRhvbzklBByNPyw6W5V7T7N3OhWD2WOSMX9DfaHZ96YO9fo9PM1C8jseFTKJ1+WWxXf2B0DFFru6PyrMWNCoMLGn33d+RqjSbMXL3xzByq0Fwu9XVm4hro/vhsUT+2Pxd0eRW1COBz7ehZkZiQhmJFh4Rz9wHITgvCtUQ1cyEqgVUvB7SpoqwpzTAUWYnVtD8cHVqmmpqDCzUMtlQpFbT3+7VAKGdDado3hLF8bnIDTVbqat73Y1SgZD47RY8NURIdCSikR47pY+ePE2MRiJGK9+f9RjqyDnshgzMxJRbKjFD0eKhea0eUVVyByT5DJl/+upy7htQFSHXbQaz044HJzb7F3W9Ovw980nhBZDVzMLqVbIUGyog1QibnKn2o6CcpflluZmTkjndKHSjHlfHW5VV4eXv7nSr9X59yvvj0roQiLw2t0DUNvQiiikoUp+pPra2tn4msHMYtF3RzH/1hRYbQ6MStJhaFwosnIL3a4LB4oqkZVb6NOyKo1bQwFXcu0sNodQ5NYTKgFDOhsKvq6Rc7Kqc5sSAOgRGoSodkj0NLN2j8sBmWOScOyiocl8pdfuGYjRyTrsO1eJm/qEo8psFXZqdcYpe77lT0pDw/DS6vp+es5mZiTCZLG59HbkK47zFcZtDg4xmiBYbHYY66xwcBwMZtcLcX39MBlqmylYa2543tPSZ2ecKSSuDGYW58rNzZaCcP7dcJ5xAa78fvGzxY27HCybNKjLBV7AlfzVkyXV+PyR4Zgztn4HdVPXheVT9Kix+G7npqc0CD7XzszaUGq0eH19Z9tlSgJbq+t8EXf80sT3mRkYlxKBhLBgpMaHok+Uul2CFrVC5nE5IDUuFA8Mj0deUSVmrdmHpz4/gJmf7kVeUSXuuz4OtRYblt4zEJ/OuA52OyfUtrLYHE0uL/BT9gazb2sTObf84d/PkQsGWBs1+NXHamGzuy5xr99ThHkT+iKvqBJPr8uDRCzCss3H8acPdmLmp/tw87+24+l1ebjoVK9Io2TQo5sSNof3NiuaIJnHpU/gysyJr88VabkyE+txBsVZ4w9pT824nx3X2+PfS25BOV78+kiX/B3g0xLOV9Zi6ie7ER4iR7Bc2uR1YfWOQmiCfHNTZjCzEMG9nqGZtWPmp3tbNI7OtsuUBDYKvtqIRsmgV4QKQ+JC0StC1a4zRToVg5E93fPLtMGyJi+Ua3efAycCfjtbjjOlJgTLpVDI6u8k5VKx18KQOR1QGNK55Q8/Ln2sFrWsHRlOF2CLzeFWpf/BEfFY0lBhvLnG4c4fkharQ2jE7QlfuLXxxoXG37ezFdEkVxjrrK1elvbUjLvMxHapQqot4ZyWcL6yFmfLzDCzdiGXNHNMElZNS8V7U4cia/p10MeFwtrMzUpbKTOx2HL8EjI9FLHuExUCY621zYouE+IL7bbsGB8fD5mM7jTag0bJgJGKXbaA2xwc5FJJkx8I/WI0WPhNvlD7Ri4TQ8mIkZEUhrzzVdDHar3+TF9P2Tdu+QPUB1pKmQTT0xPBoT6olEvFcDiAUUk65BSUITY0CBP6Rwm5H42/h7PGS0zObVYA96Kzr0zsD42SwdmyGq9jp+WNzkutkCH7RGmTm2M8fUh7asZdZ/W+PN0Vfweci60C9e/RYvOc4qBkJFh8Zz9IRCIcu2hATcMO6fba8VtpZvHhr2cxqLvWrZ7hJWMdNEqZ17/dJXcNoHwv0qm0Ovjatm0bbrrpJo/Pffjhh3j88ccBAPn5+dc2MuJVt2AGy6fosXb3OQDALf0iUVHT9N02H4Q8MCIeHAeUm1iEKKSYnp6ItbvPYXz/SACea/ocKKqEuomCk+2FT4B3JpeKYbba8dyXh4Tcum7BDBipCE/d1AsqhQQvjE9xCY6c2wZ54vwh6dxmpXGXgrzzVS7HeUPLG52XTsXgZLERszISIQZcdjuOSgrDUg+Nrz014/ZVaRlfcs5f3X66DHKpGCKRyG322Hmn9Evf5nusddeWeY8GMwvW5oCZtWP22gOYmZHoklN30VCHdJkEqfGhHv92S6stCFV2vf8exL+1OviaMGEC5syZgzfeeEOY2SorK8OMGTOQm5srBF+BzBe74ILlUqzdfU5I+tXHaj323OTxQUi4Sg5DbX1boaKKWvz1/+oDGREnwri+Ebj/+ji35NqMpDDcnxrbpuNvDt/yxxm/s4nvsQfUfxD894mRmLVmH9Y/NgIXPQRs3jh/SDrf+TeeLRudrMOjGYluxzXWWYtoknoaJYNX7xqA85Vm3DowWtiYwn9Ie2qnZWbtbh0kwkPkGJUU5hK88bry7wCfv1pmYsGBg9XOuTWSd94p7YsSFGUmFnt+rxBmtxv/bY5q+NvkA8euVCyaBK6rmvl6+OGHsWXLFqxduxaFhYWYNWsW+vTpg4MHD7bDELsWX+2CM9XZXBrKTh0ej2PFxiaXU/hWKUzDNH2wXCLM9KzcWoCs3EKsf2wE3tx8oskkYl/W9NEoGcSHKYUClkB9ovP4fpEuj5lZO4oq6nNTRCLAUGt1OQ+tqb/W+M7f+TjnC3hLjyOdk5KRYEV2gcsORt7oZJ3L77nBzOKFDYexv6HIKj/jUmFiseC2vhD9eMLvfgf4GnYGM4u//t8hPDKqvlC2TlVfdDZaG4TiqtpW7Ri9FsY6K0Qi4KmbesEBzm1JcXZDX1vnwJEv+dEVaquRwNTq4GvkyJE4ePAgnnjiCQwdOhQOhwNLlizBCy+84HXmJRA0twuuLYOXxjlRcqnYLeeBX0JM6xmGMBWDUck6FBvqEK0JgkQERGkVQiDT0iRiX17IJCIRXrytL5ZuOiF8UFbWWN0ek0nqf+9MdXa389Da+mstvYDThb7rKjOxHgMvwP333HlzReMZFyUjwY9zRsHm4Pzyd6DMxOLnE6V4YEQ8dCoGnz8yAq9uPIoHG1IXvGnLnDeVXIoBMRrMWrPPYzrAzE/34vvMDCFo9JfzT/zbVSXcnzp1Cvv27UOPHj1w8eJFnDx5Emaz2e/7ODanJbvg2urCwOdE8QFWeIgcw+K0Qs7Doxk9Ea1V4LWNx7Bya4GQNBskk+DR/+zD4zf0xC39IvDa3QPx8rf5yDld1qmSiA1mFs83zDg8fkNPPD+hD4IYCV797ij2N/Rvm56e4LIEpFJIsLuwHMPiXHM/bA4O8yakwMEBDgfXbLXxll7A6ULfNRmb+T12/j33dqyZtaPSzGJIXGibja0z4d/7gaJKvDd1KF7deBR5RVWYf2tKszW12jLnjZHUpw44pxs01hU3OJDA1urga9myZVi0aBEee+wxvPXWWygoKMBDDz2EQYMG4bPPPkNaWlp7jLNLaM1F/VrxRUH5XUhZuYVY+YAeyK3P18ock4S83EphtodPJF8xRY9hcaFCL0g+eJs+MgERarnXn+nLJGI+kNWpGNzQOwJvbT6B6emJQo6N80WYDyxrLHZ01ygw/KZeWLmtwK0o5NNjktE3KoQCpgDXmg0Tgby5gn/v6/cU4faB0dhRUI7MMUk48ocBAITl/MabdEKVMqgUbbeRvqqW7VTXJkLaQqvrfP373//GN998gxUrVkChUGDAgAHYs2cPJk2ahBtvvLEdhth1+PJCzRcFdd6FJIIItw6MxqppqbilX6TbEqKZtePpdXmYlp6AUck64bGVWwuw5rff0U1Zn0juia+TiI11VqF10Fs/nUBOQTlYu+edi3xgGR7CYGCsFrPW7IM+LlSoSbRqWir0caGY+eneLll/ibQtfsOEJ41/z1tzrL/h3/v918fBYK6/cdTHavH2llMY0F2Dp29KxpiUcLz7wFDEaK7sPqy1OrD1RCmKnYoYXwuFTILs46UYRTW8iB9p9e3JkSNHoNO5XoxkMhneeust3HHHHW02sK7I17vgLFaHEGDNzEjEJ7lnha+bai7NByrfzk6HWCRyy1XpLInkfBX/6jqbcHfdI7TpDQtm1g5wItSyNlqeIF615vdco2Tw2t0D8OLXR1xaWGUkheG1u/27dhR/nn4vq0Gwor7QrJ3jsGzyILzz8ykMjtXipdv7oqzafQmS4zicrzRDyUiu6RxdqDRj/7lKHP6jCtPSE+GAa+5mRhPlQQjp7FodfDUOvJzdcMMN1zSYrs7XwYvzMmfjYqLeSizUb50XoVeEyuVxg5mFzebA4jv7o9Zmh7mdCyd6w1fx51u7PDa6J/L/MDS7c9G58bUntDxBgJZvmDCYWby68RiGxIViRqNE7yUbj+Ef9w726w/+GG0QSgy1KDVaMDYlHD11wVj0XX3u1+BYLcQQwc4BPx+/hH4xGqTGhUKjlCEyRA4za0eJsb70y9WcI74P52s/HBdqGurjQoWEe02QDLGhQejRTdnWb5uQdkeNtduYL3fBqeRX/vM1LibamhILAFBcVYtzFWZ8tP2M0JDaYnPAZndc893r1eCr+MsbKvmP7RuB+z7c1WQF69fuGgBDrRX7zlW06n2TwNWSDRN8s+mfj5c2+bw/B18AoAli8Nj/248vn0iDwWxDXlEVlk/Ro8JkgY3j8HHOWTwwPB5rd5/DkFgt/vG/k247i6+m1A7fh9O58DF/XZJLxdh5thwhfSMQFxbYG71I10TBVzvwxS64i1W12HeuUgg0Gs90tabEgsHM4pdTl7HlWIlQtLVxkdVlkwb5/A4zVMlgx5kyrJqWCrPF7rX6vJ3j8NI3+cIHAwCPlbf9/YOStC1fbqLprHQqBv2i1aisseJSdR1mZtR3xZh7cx9YrA6h3qA+LtRrH9XWltpx7sPZVCrBPUO6X9ubI6SDUPDVBfH1xPafqxQCjcYzXc6Byuwbk6CQSZossVBmYhERIncp2uost6AcC74+gpU+LLJqMLNgJCLEaILw3rYCPD8hRXhfni7C/G4sAB4DtJ66YES3YZFbEhgCebcjj0+nOF9hBiMRC31gDbVWyCQiIeVhZnpii/uoNsW5O0gQI0HeiaZn8CnRnnRlrd7tSDoeX4aBD7D0caFIjQvFwjv6YVSSDkpGgswxSVgxRQ99rBY6lRy9woPRK0Ll8eJnrLPCYnNAH6ttsshqTsPF0xeKq2pxvKQai74/ipToEKG8RHoTu53Sk8JcZiD4AG3Wmn146vMDmLVmHy7TLkdyFQJ5t6OzGG0QQhRSocepPlYLdZAUErGovuE9I4FM4v3jpLlZwj8qzMhcewBj3/4Vj/5nHyQiEY5fNGBGeqLb3z4l2pOujma+uiCjh0ADqK939fgNPfHqXf2x8Nt8l7vQm/tG4JWJ/WG1c6hhbahxSqZXK2SoqGFb1YS6vTgvgfaL0aDGUl/4ddvJUmQ2tBFpnO/19JjkZmco1G1Yd4gEjs60A7ijBTNSHLtowPj+kThfUQubncOZUhPiuimxfIreY19MZ95mCS9UmjHvq8PCzuas6dfh7S0n8cy43jhZXI15TjPfCqkEOhVDifakS6NPpC6oqUDDzNphtXNY+G2+S8NfJSPBA8Pjca7CjJXbCtxyoZZNGojSagvimrmY+WKJpczEIlqtcGkYDgAf/noWg7prXZob882QE7opIRKLXHo+OstICkNocOB8SJK2Ra2k6mmVMjw2uheOXzSiR6gSBrMV4SEKRKoVWPFtPvRxoVe12YXf1ehcNqfGYsOfU+NgsdoBuO5gFonqS1kQ0pXRsmMX5G0pZGTPMOQ03D1mjknCqmmp+PyR4Sgx1LoFXkD9cuLi745idJIO3YIZZDSxtOerJRZjnRUapUzIPeNz2cysHbPXHsBFQ51wbJBMgjEpEYjSBiFSrcAb9wx0G39GUhjeuGeg0BCZkKuhUTLoFaHCkLjQJpfv/Z1GySC+mxIikQjRGgWKDbX4f7t+R6XZih0F5cjKLfS4RNjcZpcyEwtDo7I5CpkEl6vr4OA49OimxJubT2Diyh24/6NduOvdHXjx63z8UWFu1/dLSHuima8uyNtSCF+aga+LAwDj+0ciQq1oMp9ry/FSLLitL2I0Crxx90DsOFuOiBA5LDYHFDIJLhnrcFPvcJ984KgVMpitNmGsjXdt8kup/LKPc1AVFxaMf/55CCprWBjrbFArpAgNZijwIqSNRGuDMLp3OAy1LNJ6hiExXIVKc30+ZVO7keO6Kb1udjHUsi4FlC02B6QSEVKi1ci/YMAPR4rdbxoLyny+CYiQtkTBVxfV1FJImYkVtoLzS3f9otXNfj9jrRU9w1WoYe3IPnYJKTFq6GO1qLPakRCmhN1H0/wKmRglRpvwtacLekKYEt21QR4vupFqBQVbhLSTi1W1mLfhMHJOlwk5prf0i2ryeJFIJDTG9sRgZqGQSZB/wYBRSTrkFJRBLhWjssYKrVKGSC83jTkt3EFJSGdEwVcX1lQ9sfRe9dP+/NLdrIyezeZIhChkMJhZLPw2H/cPjxNqffFNcx0cUGyoQ2gwA11w++S7GMwsfjtT7hYsmlk7snILhSKLNawdZTX1d9t04SXEN/gSNzkNs+1m1o5/bTkNq51DRlIYDjTU2ONn3Pmbt4uGWkglInQPdc8pLTOxMLN2lNVYsGhiPyzddBwAIJOIYLbYO8UmIELaAwVffkajZCBrqMXDB0/hKgb5F5puzcPXyykzsUiJVgtBG7982bjo6tVWrG5OmYlFt2AGW45fwqikMGHTgK/HQQhxx5e4aYxPDbhrCIt1TjPuLSnUbKyz4rLJgoykcPzzfycxZ1xvfPRLAZ69pQ9q6uxe26QBgVFnjfgnSrj3MwYzC9bmEGrvvPvAUEjFIkRpgpB5U5J7MmySDkvuqm8QbKyzutT6mpmR6LVitcHctrWz+HpjH20/i2lOibuPje6JT304DkKIu6aq/ZtZO+ZvOIyBPTTo20yh5sZ/q2qFTFiW7BOlxoqfT+FPqXGoqrFAHSRFqdHSZH2/QKqzRvwPzXz5mTITi9/OliOtZxhmZiSi2FALB8fh6XV5ePyGni71cqRiEXILymCsZQEEQ62QodhpN2HjZt3OWlqxujX4emPOeV6PZvRElEaBd34+7bNxEELceauld//1cbhQWYuhcaFNXjM85WgpZGKUGuugkkuRkaSDzcGh2FCLH44U42RJNVbPuA6J4fW9G6ldGPEnFHz5GWOdFVm5hbilXyTSeobBYnOA4zghP+NfW9yDmDsHxQCoL2FxyXjlAuvrfAudisGe3680xl65tQCZY5KQ1tPznS/PUEt5H4S0N77EzXYPS48je4ahzuaAtKHQKp8ryjfCVsgkOFBU6XLNMJhZvLHpOJ4Z1xt2BweD2SrU9eMDrfs+3OV206hVyhCtVlDgRbo0Wnb0M2qFDGbWjpmf7q0vOyGTCLWyPHHuj6ZRMogPUwq1snydb6FRMrixdzieHpMsjJdvY+KNkpG06TgIIe74EjeNawyOTtYhSCaGTsUgLJgRcjTziiqFFl8zP92LvKJKaIKuXDPKTCwSw1VY9uNxlBrrEKyQwNKQMsHjbxonrtwh1PmqY+0UeJEuj4IvP8PfnZpZO0IUUtg5Duv3FGHhHf09FiB97e4BLhey7qFKLJs0COP6RgCozwnzpL3yLaK1QegbFYI37h6ITXMyEKKQwmbnvPZ1bK6tCSGkbfAlbrLn3oBvnhqJ7Lk3YMUUPboFy/HOz6cgEYvw8u39POZ97Sgox8Lvjgp5X3yO6dYTl/Hk5wcQJJNAEySjJHsSECj48jMaJYM3Jw9C1vTrUMs6sPNsOebe3Btvbj6OIXGhWDUtFe9NHYpV01IxJC4Ur2085pYE26ObEovv7I+v9p/HX8f3cQvA2ruvnUbJIF4XjH4xGoQFy2EwWz1Wzk5PCsOM9EQKvgjxIU/V/lm7A1tPXIbdwWFQD02ztbmA+ll6fpbLzNrx09ESdFPKUGqsoyR74vco58sPKRkJ3t1agAdGxCErtxBfPD4CL36dj60nLns8vnESrMHMYvH3R3H/9XFYnn0KqYmheH5CHwBALWuHVsm021KfwcyiymwVmn+HqxgUG+uw5VgJ9HGhLpWz885X4Ys9RfjHvYPbZSyEkJYxWeoLI9da7bhssng9ls/7apxj+u62MxjcXYu0nmFI0FGSPfFvFHz5oTITi5yCMkxPT4CZteNCZZ3X4xsnzjvX+zpZUo05Y3vjrc0nXJp1t0eNreKqWpyrMGPF1tPCRVfJSPDpjOuQOLoXVmw97bKTalSyDn+nizEhHY7fCXnZZPFa0R64smxorLUK/WRzC8phZu3YV1SJ1b8VYlCs1m1ndmFZDeV3Er9BwZcf4uvx5J2vwpiUcHQP9d5up3EOBZ+LkZVbiPWPjcCbm080WWNrRRv1VjOYWfxy6jI2Hr7o8rPMrB3TV+/FKxP74/W7B8DM2mFm7dAEyRARIqfAi5BOgM81ZSRiYYOPt4LOl4x1WPT9UUxPS8SLt/XF0k0nkFNQhoHdNXjn59PIPnHZ487soXNvoL954hco58sP8XehWbmFeHZcbxz5w9CqHAolU7/raGZGIqrrbE3mb2x3yt+4VmUmFhEhco8/y8za8fx/D8PuAPrFaJCa0A3JkSF0ESakk+B3QpZWW3DsosFjjmZGUhiW3jMQGiWDyhoW/WI0+DDnDP70wU4MjtNi1bRUKBnv8wHUToj4C5r58kMqhVSYyi8zsXjth+NYPkUPwDWHIj0pDK/eNcAt3+tAURXiw5QYGhfabA2ttroYGuusYO3Ux42QripGG4TbBkQhrWcYXvvhmEuOpjZIhvgwpdDf0VhncynizP/vqmmpXn8G7XQk/oKCLz9UY7FhenoiOAB1VrtLxfjGCet8dXtemYnFP/93El8+noaLhroWNeRuC5ogGaQS77sW6cJLSOemUTLQKBn8897BLhtntEEyqORXPm7UCinKPCTme1uypJ2OxJ9Q8OWHDLVWIdiK7VafEG9m7R7bftwzpLvL18Y6K+6/Pg5LfjiG58anYNOR4mbzN655vGYWMrFIWB5tz59FCGl/NawdL32bj/3nKoVK90UVZsSGKhGpliM0mIGmxj1lgW/SDbjO0rd3eRtCfI2CLz/EV7nng63W3EmqFTJhOWDO2GQhfwNwvRhmJIUJDbmvxcWqWszbcBgz0hPx9pZT+PyREViy8ShyG/2sxsVgCSGdk8HMYt6Gw9h/rhLLp+ixekehy43f6GQd3po8CHGhQUJ6BI+fpX/5jn5YfGd/1FhsCFHIoFMx9PdP/AoFX37IuQdba+8kdSoGv5fXAACqaqx4YHg81u4+55K/oQmSIUQhbXZJsjkGM4uF3+ZjcKwWSpkE918fJxSDndFoeXTJxmP4572D6QJMSCdXZmKRc7oMmWOSPFa63366DFtPXcbes+VYeEd/LPnhGHKc+kUOjdNiVJIOPbopfT10QnyGgi8/xO88mr/hMLafLhOWIGffmAS5TAxtENPknaRGyaBHaP1S5b6iShy7aKjfYRgXCo2yPi+rssYKs8WOSLX3EhbNKa9hcf/1cVi9oxD6WK0w49bSYrCEkM6HL3XjnFDfWKRaga8OXsTmY5cwMyMR00cmuNxsNbf5hpCujoIvP8X3YCszsaius7Zq6j5KrcDoZJ0wa7Z29zkMidXiH/876TZ7di2FVm0OTrgzvi6hGwZ213g9nnY7EtL58aVuLDYHlIxEyPmy2BxQyCQ4cqFKKJbaVC7quJQIn46ZEF+jOl9+zFMPtpa+btnkQUiND8WcdXmYOjwea5pYPpi/4bBbb8iWcjg47Cgoh5KRYHAPLaKamUmj3Y6EdH582oNSJsHyKXrkFVVi1pp9eOrzA5j56V6Eq+Q+20VNSGdFM1/EI+eZM4vN7tJayBlfaPVqlgPNbH0/uMdG98Sq3LNITeiGUUlhHn8WbTMnpGvgb97+qDTj39mnkVdUhb/cnIyb+tTPZskkIljtnFuyPY92NpNAQMEXaRIfUJ0qNQGAxyWEA0WVqLFc3XKgJqi+QffYvhF45+fTOFBUheVT9HCAGuoS0pXFaINQXWdFXlEV3n1gKBQyMd7cfAJ5RVXY8MRIvPPzSaEWYXvsoiaks6PgizSJLwMxfWQClIzE47bx9KQw/Gloj6v6/iqFFC/f3helxvpii00Vg43rpkR0GzbwJoS0L4OZxR+VtZiZkYhiQy1+OFKMHQXlyByTBAfHYeuJy9h1tsJj4WeLzd7Rwyek3VHwRTzia/XknC7D4FgtXrq9r8dt4zsKyrHw2/yrarBdY7FhQA8NLlezbrNqIpEIx4qNyMotxPeZGW351ggh7Yzv+aqP1QK4Mrulj9WivKG4alPJ9mP6ULI98X8UfBGP+Fo9QH3V6S8eH4HXfjjukrthZu2QScTIOX0Z5TWtz/sy1Fpx2WRBjEaBVdNSsXJbgdusWtb06yj/g5AuxlDLIu98lXAzxeNvrLzRBFGyPfF/FHwRj4xOZR3MrB3FhjqX3A2XnKwkHSYOjmn1z1ArZJCIRTh20YjvD130OKsmFomwsqFILCGka1AyUmTlFuK/T4xEsaFWeFwuFeNAUSW1ESMBj0pNEI/UjbZ6R6kVKDbUYuW2AreLZk5BGRZ9d7TVJSd0KgYODghTyZvcTZnTsJuSENJ1iMUi6OO0sDs4XDLWYUxKODLHJCE8RI4TDS3L0pPCXF6TkRSGpfcMpGR7EhBo5ot45NyiSMlIIBLVV6X2dLcKXAmSWnPh1CgZ2EtNLssSnlBxVUK6FqlYhBnpiSg3WdBDq8SLt/XFou+OYv2eInz+yAj8ffNxt5ZlcaFB1FKIBAya+SIe8bV6bu4bgeVT9Cg1WtolSNIqGcil3n8NqeAiIV1LWDCDL/YUQaWQ4sD5Siz+7ih2FJTjwRHx+Pvm4+gboxHyweRSMXaeLcerG49ddcFmQrqaThF8vfvuu0hISIBCocDw4cOxZ88er8dXVVVh9uzZiI6OhlwuR+/evbFp0yYfjTZwxGiD8No9A7FmRyEAtEuQpFMxKK22uC1B8Ki4KiFdj0bJ4JW7BuB0qQnXJXRDbkMni7F9I5B94jJWbi0Qqt7PWrMPK7cWYMvxUkoxIAGjw5cdv/jiC8ydOxcffPABhg8fjnfeeQfjx4/HyZMnERHhvuWYZVncfPPNiIiIwH//+190794d586dg1ar9f3gA4CpzoacgnIMjgtFjEbRZKLs1QZJGiWDG3uHI1EXDICKqxLiL2K0QbhtQBRONxRpnpmRKNT0awqlGJBA0eHB19tvv41HH30UM2bMAAB88MEH+OGHH5CVlYX58+e7HZ+VlYWKigr89ttvkMnqZ1oSEhJ8OeSAwu96zMotxLsPDEXmTUkA2jZIitYGQclI8MbdA1HD2mBm7dAEyRARIqfAi5AuTKNkEKqs72RxY+9wGGq9B1eUYkACRYcGXyzLYv/+/ViwYIHwmFgsxrhx47Bz506Pr/nuu++QlpaG2bNn49tvv0V4eDgeeOABzJs3DxKJxFdDDxjOux4PX6jC2JQILJ7YH6zVgRrWBnWQDNFqxTUHSRolQ4EWIX5Ip2KQNf06GGqtyDtfRWUmCEEHB19lZWWw2+2IjIx0eTwyMhInTpzw+JqzZ89i69atmDp1KjZt2oSCggI89dRTsFqtWLRokdvxFosFFsuVqW6j0di2b8LP6VQMbu4bgfuuj8PqHYX415bTwnMZSWFYNomWBQkh3r27tQDT0xOQlVuI5Q11+5wDsHTq6UgCTIcvO7aWw+FAREQEPvroI0gkEgwbNgwXLlzAW2+95TH4Wrp0KV555ZUOGKl/0CgZLJ7YHy9sOOx2t5pbUI4Xvz5yVa2FeAYzizITC2OdFeogGXTBNANGiD8pM7HIKSjD4DgtRvTshqMXDZg3IQVAfQFnqViEwrIahCppyZEEjg4NvnQ6HSQSCS5duuTy+KVLlxAVFeXxNdHR0ZDJZC5LjH379kVJSQlYlgXDuH5wL1iwAHPnzhW+NhqNiI2NbcN34f/qrI4m63ttv4r6Xrw/KsxY8NVhlwKro5N1WDZ5EGKokTYhfoHPG+VrfL268ajbDPobVFyVBJgOLTXBMAyGDRuG7Oxs4TGHw4Hs7GykpaV5fE16ejoKCgrgcFypOXXq1ClER0e7BV4AIJfLoVarXf6R1jE22oGkZCTIHJOEVdNS8d7UoWBt9lbX57lQacb8RoEXUB/Mzd9wmOr9EOIn+LzRB0fEY8nGox5n0F/6Jp/+5klA6fA6X3PnzsXHH3+MNWvW4Pjx43jyySdRU1Mj7H58+OGHXRLyn3zySVRUVOCZZ57BqVOn8MMPP+CNN97A7NmzO+ot+D3npHslI8HyKXrkFVUKdXpuXZ6Lp9fl4WJVrZfvcoXBzKKowozcZmbTCCFdH583OrZvBP3NE9Kgw3O+7rvvPly+fBkLFy5ESUkJhgwZgs2bNwtJ+EVFRRCLr8SIsbGx+Omnn/CXv/wFgwYNQvfu3fHMM89g3rx5HfUW/J5zq6GZGYlYvaPQ7e6Vn7FqSf5XmYmF1c55Paa5LemEkK6Bzxs9UVLt9Tiq8UUCSYcHXwCQmZmJzMxMj8/98ssvbo+lpaVh165d7TwqwuNbDc3fcBj6WC1Wbi3weFxL87+MdVaEBntPrlUyVDaEEH9RZ/XemgygGl8ksHT4siPpGmK0QVgxRQ91kPcLZEvuXtUKGWx2rsmWQulJYZCIRVc1TkJI52Osu1LjyxOq8UUCDQVfpMU0SgbdmpnVasndq07FwGK1Y0Z6otvFOD0pDDPSEyn4IsSPqORSZOUWNvk3TzW+SKDpFMuOpOtwzv9qrKX9HTVKBrHdlFj4bT70caGYmZ4Ii80BuVSMvPNV+GJPEf5x7+D2GD4hpAMwEjH0cVrMWZeHmRmJLn/zl4x1NAtAAo6I4zjvmc9+xmg0QqPRwGAwUNmJq1RcVYtfTl1GRIgcFpsDCpkEl4x1uKl3OKJaUZ/rjwozFnx9BDlOgdzohj6R0VTnixC/ceh8JS6bWLfNOvxMd4SKwaDY0A4cIekK/Onzm2a+SKtxADYdLkZOgWvQdEPv8FZ9nx7dlFg5RY8yE4vqOitCFDLoVFThnhB/o5LLMOXj3W6zXnnnqzBnXR6+z8zo6CES4lMUfJFWMZhZzNtw2CXwAtxLTbS0bRA11CbE/+lUDFLjQz3ulG5pugIh/oSCL9IqZSbWZZnQ2fbTZSivYVHD2usDtEbLidQ2iJDA5FyuZruHNAO6ASOBhoIv0iqNWw0B9TW5ZmYkQh+rBWtzYNG3+U22DbqWJtyEkK6LL1dDaQaEUKkJ0krqRqUkGrcbulBV6xZ48aiFCCGBTaNk0CtChSFxoegVoaLAiwQsCr5Iq6gUUmQ41elp3G7IYvNeyZpaiBBCCAl0FHyRVqmx2DDdqVCiPlbrsnVcLvX+K0UtRAghhAQ6yvkirVJRw7oUSlQyrr9CfAuRvKIqIQ/MuRYY7WoihBAS6Cj4Ii1mMLNgbQ6YWbuwZXzVtFSXY7JyC/HuA0OhkImxcluBy9byUQ21wDRKnw6bEEII6VRo2ZG0WJmJxW9ny116s3lulsvhvW0FLsuRAJDTsOPRYK5PujeYWZwpNSGvqBJnLpuExwkhhBB/RjNfpMWMdVZk5RZi+RQ9AGBHQTnW7ynC54+MwJKNR3GgqArLp+jBSCVedzxSLTBCCCGBjGa+SIupFTKYWTvmrMuDPi4Uq6al4uOHU/HW5uO4LrEbvs1Mx5odhTDUet/RaHdwboEXcKUWGM2AEUII8WcUfJEW06kYjE7WCTlfs9bsQ0UNi9/OVqB/jAalRgtyCsqhkEm8fh+7g/NaJZ9qgRFCCPFnFHyRFuNbhIxO1gmPWWwOodaXodYKJSOBTsW41AJzVh+82bz+HKoFRgghxJ9RzhdplcYtQhSMBHKpGCu3FmBmeiJmZiTinZ9PYXp6IjjAJek+IykMb9wzsNlCrFQLjBBCiD+j4Iu0mkZ5pR/b+fIa4fG881VI6xmGlVsLsOtshVALzGJzQC4VI+98FVi7Q1i+3O5h6XF0so5qgRFCCPFrFHyRq3axqhaLvj+Kv9zcG0B9ja+MXvVLks61wJyNS4lAz3AVlk0ehPkbDrsEYKOTdXhz8iDq90YIIcSvUfBFrsrFqlpU1rDYeuIyBvXQYlRSGHIKymG22r2+jl9SbLx8GaKQQadiKPAihBDi9yjhnrSawcxi3obDMNbVJ85/tP0spjX0ezxQVOmh6Gq9xkuKGiWDXhEqDIkLRa8IFQVehBBCAgIFX6TVykws9p+rhEZZP4vlXPsrNS4UC+/oh1FJOpfX0JIiIYQQUo+WHUmrGWpZzMxIhLGWRUZSGHILyl1yvJSMBC/f3hcv39EPZtbmcUnRYGZRZmJhrLNCHSSDLpiWHAkhhAQGCr5IqykZKfSxWmSuzRNaC+U6lZQYGqfFyCQd4sOCPb7+YlUttRYihBASsCj4Iq0mFosA1C8/Tv1kF96cPAjzbk2Bqc4OlUKCUqMF1bUsAPfgi88Xa6q10IopepoBI4QQ4tco+CKtJhWLEKGWA6gPwGat2Sc8p2QkmJmRiDsGRiOvqNJtSbHMxDbbWoiCL0IIIf6Mgi/SamHBDPafqxTKS/CUjATLp+ixekehS40v5yVFYzOtg6i1ECGEEH9HwRdpNY2SQUaSDrHdlHDgSgshvsfjjoJyYQZMH6uFxebAufIaSMQiqJtpHUSthQghhPg7Cr7IVYnWBkHJSPDG3QNRw9pgZu1QyaVYubWgyRmwUck6LJs0kFoLEUIICWhU54tcNY2SQbwuGP1iNEhN6Ibahur2zjNgznJOl2Hxd0fxxj31AZgzqgNGCCEkUNDMF2kz/JKiPlbrsa8jAGw5XooFt/Wl1kKEEEICFgVfpM3oVAxGJ+tgsTm8HmestaJnOLUTIoQQEpho2ZG0GY2SwbLJg6ANoqR6QgghpCkUfJE2YzCzqLPaEa1VYFSjnC4eJdUTQggJdLTsSK6JwcyivIYFB2Dxt/nIaSgzsXyKHhzHubQdoqR6QgghhIIvcg34Ho2DY7XIK6oUdjeaWTvmrMvDzIxEPHVjEhQyCTRBlFRPCCGEALTsSK6Sc49GfazWrayEmbVj5dYCPPDJbmiCZOgVQQn2hBBCCEAzX+QqOfdo9LS70bnCfXkNC1w2ufR4JIQQQgIVBV/kqjj3aJRLXSdQW9LjkRBCCAlUtOxIropzj8a881VITwoTvm6qwv3202WYv+EwDGbWZ+MkhBBCOhsKvshV4QuqAkBWbiFmpCcKAZinHDDe9tNlKDNR8EUIISRwUfBFrgpfUHV0sk7Y3aiPC8XaR4YjROF9NbvaacmSEEIICTSU80WuWow2yGOPxuZmttRBMhjMLMpMLIx1VqiDZJSMTwghJGBQ8EWuiUbpGjQZzCykYhFGJeuE3ZDObu4bAUYiRua6PJfnKRmfEEJIoKBlR9JmLlbVInNtHm5dnoNpIxNckvCB+gBr8cT+WPD1EbfAjJLxCSGEBAqa+SJtwmBmMe+/h5FTUB9U8RXuZ6YnAgDiuikRESJ3qQ/WGJ+MT8uPhBBC/BnNfJE2UVptEQIvoL7CfVZuIfLOVwEAqmqtKKthYaj1PrNFyfiEEEL8Hc18kTZRVesaNDVVaHXtI8O9fp8Qp/phhBBCiD+imS/SJoIZicvXTRVa/e1sOTIa5YLxRifroFPRkiMhhBD/RjNfpE0EM1KkJ4UJwZY+Vous3EJkjkmCPlYLi80BhUyCEyUGPD8+BSLRSbfdjm9OHkT5XoQQQvweBV+kTWiVMjw9JhkAsKOgHDYH57bsqGQkWDUtFSuyT2FwrBbTRybAYnNAGyRDfJgS0VRmghBCSAAQcRzHdfQgfMloNEKj0cBgMECtVnf0cPxKcVUtfjl1GREhcsSFKbH4u6Muy46ZY5KQV1TpsfXQ6GQdVkzR08wXIYQQj/zp85tyvkibidYG4bYBUUgIC4bdzrkFWdTzkRBCCKHgi7QxjZJBrwgVaq12t+csNofX11KZCUIIIYGAgi/SLtQeSkbIpd5/3ajMBCGEkEBAwRdpFzoVg9HJOpfH8s5XubUc4lGZCUIIIYGCgi/SLjRKBssmD3IJwLJyC/H0mGSMahSUUZkJQgghgYR2O5J2ZTCzKDOxqK6zIkQhE2a3Gj9GgRchhBBv/Onzu1PMfL377rtISEiAQqHA8OHDsWfPnha9bv369RCJRLj77rvbd4DkqvEJ+EPiQtErQgWNkvH4GCGEEBIoOjz4+uKLLzB37lwsWrQIBw4cwODBgzF+/HiUlpZ6fd3vv/+O5557DqNGjfLRSAkhhBBCrl2HB19vv/02Hn30UcyYMQP9+vXDBx98AKVSiaysrCZfY7fbMXXqVLzyyivo2bOnD0dLvDGYWZwpNSGvqBJnLptgMFPdLkIIIaSxDm0vxLIs9u/fjwULFgiPicVijBs3Djt37mzyda+++ioiIiIwa9Ys5OTkeP0ZFosFFotF+NpoNF77wImbi1W1mLfhsFu/xmWTByGG2gYRQgghgg4NvsrKymC32xEZGenyeGRkJE6cOOHxNbm5uVi1ahUOHjzYop+xdOlSvPLKK9c6VOKFwcy6BV5AfdX6+RsOY8UUPYD6JHuTxQqtkgFrc8BksUEdJIMumBLuCSGEBI4u1Vi7uroaDz30ED7++GPodLrmXwBgwYIFmDt3rvC10WhEbGxsew0xIJWZWLfAi7fvXCUqzVa8/G0+9p+rxPIpevz9p5MubYZohowQQkgg6dDgS6fTQSKR4NKlSy6PX7p0CVFRUW7HnzlzBr///jvuvPNO4TGHo75ljVQqxcmTJ9GrVy+X18jlcsjl8nYYPeEZvbQFmpmRiJe/OYKcgnJkjknC6h2Fbv0dnWfIaAaMEEKIv+vQhHuGYTBs2DBkZ2cLjzkcDmRnZyMtLc3t+JSUFBw5cgQHDx4U/k2cOBE33XQTDh48SDNaHcRTKyGePlaLnIZgixprE0IIIZ1g2XHu3LmYNm0aUlNTcf311+Odd95BTU0NZsyYAQB4+OGH0b17dyxduhQKhQIDBgxweb1WqwUAt8eJ7/CthLZ7WHoUia78f9ZOjbUJIYSQDg++7rvvPly+fBkLFy5ESUkJhgwZgs2bNwtJ+EVFRRCLO7wiBvGCbyU0f8NhlwDs5r4R6N6Qx6VkJOgR6j2nixprE0IICQTUXoi0mcathFQKKbaeKMXGwxehjwtFjEaBH44Ue1x6HJ2so5wvQgghTfKnz+8On/ki/oNvHcQ7U2rCko3H8O4DQ9EtmMGUj3dheUPZCecALD0pDK/eNYACL0IIIQGBgi/SbvhdkGIRUGe1w8zaMWddHmZmJGJmeiIsNgfkUjHyzlfBWMsCCO7YARNCCCE+QMEXaTdqhQwzMxJxyViHHqFKAICZtWPl1gK3Y+8Z0t3XwyOEEEI6BGWyk3ajUzEY2TMMPcNV+O1sOdKTwjweNypZB52KlhwJIYQEBgq+SLvRKBkwUjFsdg7r9xRh4R39kdEoAMtICsMSyvcihBASQGi3I2lXZ0pNqGFt+N+xSzh20YB+MRroY7Uu+V4nio34572DKQAjhBDSJH/6/KacL9KudCoGlio70nqGYeXWAmw9cdnjcWUmloIvQgghAYGWHUm7MrN2iMUiSMUir8dRdXtCCCGBgoIv0m4MZhYvbDiMBz/Z3Wz1eqpuTwghJFBQ8EXaTZmJRU5Dw+z/HSvBqCZ2O46m3Y6EEEICCAVfpN0YnZYSP9p+FjMyEt0CsNHJOrw5eRDlexFCCAkYlHBP2o260VKiCCLcOjAa052q25dWWzpodIQQQkjHoOCLtBudisHoZB22ny7DzIxEfJJ7lppqE0IICXi07EjajUbJYNnkQRidrIM+Vusx8AKA7Q15YYQQQkggoOCLtKsYbRBWTNFDHeR9NyOVmiCEEBIoKPgi7U6jZNCtmSVFKjVBCCEkUFDwRXyCz//yhEpNEEIICSQUfBGfcM7/ckalJgghhAQa2u1IfIbP/yozsaiusyJEIYNOxVDgRQghJKBQ8EV8SqOkYIsQQkhgo2VHQgghhBAfouCLEEIIIcSHKPgihBBCCPEhCr4IIYQQQnyIgi9CCCGEEB+i4IsQQgghxIco+CKEEEII8SEKvgghhBBCfIiCL0IIIYQQH6LgixBCCCHEhwKuvRDHcQAAo9HYwSMhhBBCSEvxn9v853hXFnDBV3V1NQAgNja2g0dCCCGEkNaqrq6GRqPp6GFcExHnDyFkKzgcDly8eBEhISEQiURt+r2NRiNiY2Nx/vx5qNXqNv3e5Ao6z75D59o36Dz7Bp1n32iv88xxHKqrqxETEwOxuGtnTQXczJdYLEaPHj3a9Weo1Wr6w/YBOs++Q+faN+g8+wadZ99oj/Pc1We8eF07dCSEEEII6WIo+CKEEEII8SEKvtqQXC7HokWLIJfLO3oofo3Os+/QufYNOs++QefZN+g8Ny/gEu4JIYQQQjoSzXwRQgghhPgQBV+EEEIIIT5EwRchhBBCiA9R8EUIIYQQ4kMUfLWRd999FwkJCVAoFBg+fDj27NnT0UPqUpYuXYrrrrsOISEhiIiIwN13342TJ0+6HFNXV4fZs2cjLCwMKpUKkydPxqVLl1yOKSoqwu233w6lUomIiAg8//zzsNlsvnwrXcqyZcsgEonw7LPPCo/ReW47Fy5cwIMPPoiwsDAEBQVh4MCB2Ldvn/A8x3FYuHAhoqOjERQUhHHjxuH06dMu36OiogJTp06FWq2GVqvFrFmzYDKZfP1WOi273Y6XX34ZiYmJCAoKQq9evbBkyRKX/n90nltv+/btuPPOOxETEwORSIRvvvnG5fm2OqeHDx/GqFGjoFAoEBsbi7///e/t/dY6B45cs/Xr13MMw3BZWVnc0aNHuUcffZTTarXcpUuXOnpoXcb48eO51atXc/n5+dzBgwe52267jYuLi+NMJpNwzBNPPMHFxsZy2dnZ3L59+7gRI0ZwI0eOFJ632WzcgAEDuHHjxnF5eXncpk2bOJ1Oxy1YsKAj3lKnt2fPHi4hIYEbNGgQ98wzzwiP03luGxUVFVx8fDw3ffp0bvfu3dzZs2e5n376iSsoKBCOWbZsGafRaLhvvvmGO3ToEDdx4kQuMTGRq62tFY6ZMGECN3jwYG7Xrl1cTk4Ol5SUxE2ZMqUj3lKn9Prrr3NhYWHcxo0bucLCQu7LL7/kVCoV9+9//1s4hs5z623atIn729/+xn311VccAO7rr792eb4tzqnBYOAiIyO5qVOncvn5+dy6deu4oKAg7sMPP/TV2+wwFHy1geuvv56bPXu28LXdbudiYmK4pUuXduCourbS0lIOAPfrr79yHMdxVVVVnEwm47788kvhmOPHj3MAuJ07d3IcV3+xEIvFXElJiXDM+++/z6nVas5isfj2DXRy1dXVXHJyMrdlyxbuhhtuEIIvOs9tZ968eVxGRkaTzzscDi4qKop76623hMeqqqo4uVzOrVu3juM4jjt27BgHgNu7d69wzI8//siJRCLuwoUL7Tf4LuT222/nZs6c6fLYpEmTuKlTp3IcR+e5LTQOvtrqnL733ntcaGioy3Vj3rx5XJ8+fdr5HXU8Wna8RizLYv/+/Rg3bpzwmFgsxrhx47Bz584OHFnXZjAYAADdunUDAOzfvx9Wq9XlPKekpCAuLk44zzt37sTAgQMRGRkpHDN+/HgYjUYcPXrUh6Pv/GbPno3bb7/d5XwCdJ7b0nfffYfU1FTce++9iIiIgF6vx8cffyw8X1hYiJKSEpdzrdFoMHz4cJdzrdVqkZqaKhwzbtw4iMVi7N6923dvphMbOXIksrOzcerUKQDAoUOHkJubi1tvvRUAnef20FbndOfOnRg9ejQYhhGOGT9+PE6ePInKykofvZuOEXCNtdtaWVkZ7Ha7ywcRAERGRuLEiRMdNKquzeFw4Nlnn0V6ejoGDBgAACgpKQHDMNBqtS7HRkZGoqSkRDjG038H/jlSb/369Thw4AD27t3r9hyd57Zz9uxZvP/++5g7dy5efPFF7N27F3PmzAHDMJg2bZpwrjydS+dzHRER4fK8VCpFt27d6Fw3mD9/PoxGI1JSUiCRSGC32/H6669j6tSpAEDnuR201TktKSlBYmKi2/fgnwsNDW2X8XcGFHyRTmf27NnIz89Hbm5uRw/F75w/fx7PPPMMtmzZAoVC0dHD8WsOhwOpqal44403AAB6vR75+fn44IMPMG3atA4enf/4v//7P3z++edYu3Yt+vfvj4MHD+LZZ59FTEwMnWfSadGy4zXS6XSQSCRuu8EuXbqEqKioDhpV15WZmYmNGzdi27Zt6NGjh/B4VFQUWJZFVVWVy/HO5zkqKsrjfwf+OVK/rFhaWoqhQ4dCKpVCKpXi119/xfLlyyGVShEZGUnnuY1ER0ejX79+Lo/17dsXRUVFAK6cK2/XjqioKJSWlro8b7PZUFFRQee6wfPPP4/58+fj/vvvx8CBA/HQQw/hL3/5C5YuXQqAznN7aKtzGsjXEgq+rhHDMBg2bBiys7OFxxwOB7Kzs5GWltaBI+taOI5DZmYmvv76a2zdutVtKnrYsGGQyWQu5/nkyZMoKioSznNaWhqOHDni8ge/ZcsWqNVqtw/BQDV27FgcOXIEBw8eFP6lpqZi6tSpwv+n89w20tPT3cqlnDp1CvHx8QCAxMREREVFuZxro9GI3bt3u5zrqqoq7N+/Xzhm69atcDgcGD58uA/eRednNpshFrt+lEkkEjgcDgB0nttDW53TtLQ0bN++HVarVThmy5Yt6NOnj18vOQKgUhNtYf369ZxcLuc+/fRT7tixY9xjjz3GabVal91gxLsnn3yS02g03C+//MIVFxcL/8xms3DME088wcXFxXFbt27l9u3bx6WlpXFpaWnC83wJhFtuuYU7ePAgt3nzZi48PJxKIDTDebcjx9F5bit79uzhpFIp9/rrr3OnT5/mPv/8c06pVHKfffaZcMyyZcs4rVbLffvtt9zhw4e5u+66y+N2fb1ez+3evZvLzc3lkpOTA7oEQmPTpk3junfvLpSa+OqrrzidTse98MILwjF0nluvurqay8vL4/Ly8jgA3Ntvv83l5eVx586d4ziubc5pVVUVFxkZyT300ENcfn4+t379ek6pVFKpCdJyK1as4OLi4jiGYbjrr7+e27VrV0cPqUsB4PHf6tWrhWNqa2u5p556igsNDeWUSiV3zz33cMXFxS7f5/fff+duvfVWLigoiNPpdNxf//pXzmq1+vjddC2Ngy86z23n+++/5wYMGMDJ5XIuJSWF++ijj1yedzgc3Msvv8xFRkZycrmcGzt2LHfy5EmXY8rLy7kpU6ZwKpWKU6vV3IwZM7jq6mpfvo1OzWg0cs888wwXFxfHKRQKrmfPntzf/vY3l/IFdJ5bb9u2bR6vydOmTeM4ru3O6aFDh7iMjAxOLpdz3bt355YtW+art9ihRBznVAaYEEIIIYS0K8r5IoQQQgjxIQq+CCGEEEJ8iIIvQgghhBAfouCLEEIIIcSHKPgihBBCCPEhCr4IIYQQQnyIgi9CCCGEEB+i4IuQLmr69Om4++67O3oYncZDDz0kNLFuSkJCAt555x3fDKiLmD9/Pp5++umOHgYhAYWCL0I6IZFI5PXf4sWL8e9//xuffvpph4zv448/xuDBg6FSqaDVaqHX64VGxoDvA8NDhw5h06ZNmDNnTqteJxKJ8M0337TPoJxUVFRg6tSpUKvV0Gq1mDVrFkwmk9fX1NXVYfbs2QgLC4NKpcLkyZPdmhAXFRXh9ttvh1KpREREBJ5//nnYbDbh+eLiYjzwwAPo3bs3xGIxnn32Wbef89xzz2HNmjU4e/Zsm7xXQkjzKPgipBMqLi4W/r3zzjtQq9Uujz333HPQaDTQarU+H1tWVhaeffZZzJkzBwcPHsSOHTvwwgsvNBtMtKcVK1bg3nvvhUql6rAxeDN16lQcPXoUW7ZswcaNG7F9+3Y89thjXl/zl7/8Bd9//z2+/PJL/Prrr7h48SImTZokPG+323H77beDZVn89ttvWLNmDT799FMsXLhQOMZisSA8PBwvvfQSBg8e7PHn6HQ6jB8/Hu+//37bvFlCSPM6ur8RIcS71atXcxqNxu3xadOmcXfddZfw9Q033MBlZmZyzzzzDKfVarmIiAjuo48+4kwmEzd9+nROpVJxvXr14jZt2uTyfY4cOcJNmDCBCw4O5iIiIrgHH3yQu3z5cpPjueuuu7jp06c3+fyiRYvc+sFt27aN4ziOKyoq4u69915Oo9FwoaGh3MSJE7nCwkK397R48WJOp9NxISEh3OOPP+7Sp68xm83GaTQabuPGjS6PX7p0ibvjjjs4hULBJSQkcJ999hkXHx/P/etf/+I4juPi4+NdxhgfH9/kz7gWx44d4wBwe/fuFR778ccfOZFIxF24cMHja6qqqjiZTMZ9+eWXwmPHjx/nAHA7d+7kOI7jNm3axInFYq6kpEQ45v333+fUarXH89W4h6ezNWvWcD169Liat0cIuQo080WIH1mzZg10Oh327NmDp59+Gk8++STuvfdejBw5EgcOHMAtt9yChx56CGazGQBQVVWFMWPGQK/XY9++fdi8eTMuXbqEP//5z03+jKioKOzatQvnzp3z+Pxzzz2HP//5z5gwYYIwUzdy5EhYrVaMHz8eISEhyMnJwY4dO6BSqTBhwgSwLCu8Pjs7G8ePH8cvv/yCdevW4auvvsIrr7zS5HgOHz4Mg8GA1NRUl8enT5+O8+fPY9u2bfjvf/+L9957D6WlpcLze/fuBQCsXr0axcXFwtee9O/fHyqVqsl/t956a5Ov3blzJ7Rarcv4xo0bB7FYjN27d3t8zf79+2G1WjFu3DjhsZSUFMTFxWHnzp3C9x04cCAiIyOFY8aPHw+j0YijR482OR5Prr/+evzxxx/4/fffW/U6QsjVkXb0AAghbWfw4MF46aWXAAALFizAsmXLoNPp8OijjwIAFi5ciPfffx+HDx/GiBEjsHLlSuj1epdE9aysLMTGxuLUqVPo3bu3289YtGgRJk2ahISEBPTu3RtpaWm47bbb8Kc//QlisRgqlQpBQUGwWCyIiooSXvfZZ5/B4XDgk08+gUgkAlAf+Gi1Wvzyyy+45ZZbAAAMwyArKwtKpRL9+/fHq6++iueffx5LliyBWOx+v3ju3DlIJBJEREQIj506dQo//vgj9uzZg+uuuw4AsGrVKvTt21c4Jjw8HACg1WpdxunJpk2bYLVam3w+KCioyedKSkpcxgYAUqkU3bp1Q0lJSZOvYRjGbVk5MjJSeE1JSYlL4MU/zz/XGjExMQDqz2VCQkKrXksIaT0KvgjxI4MGDRL+v0QiQVhYGAYOHCg8xn848zNAhw4dwrZt2zzmSp05c8Zj8BUdHY2dO3ciPz8f27dvx2+//YZp06bhk08+webNmz0GSPzPKigoQEhIiMvjdXV1OHPmjPD14MGDoVQqha/T0tJgMplw/vx5xMfHu33f2tpayOVyIaADgOPHj0MqlWLYsGHCYykpKVedI+fp5/oTPnjkZ0QJIe2Lgi9C/IhMJnP5WiQSuTzGBygOhwMAYDKZcOedd+LNN990+17R0dFef9aAAQMwYMAAPPXUU3jiiScwatQo/Prrr7jppps8Hm8ymTBs2DB8/vnnbs/xs1BXQ6fTwWw2g2VZMAxz1d/Hm/79+ze5zAoAo0aNwo8//ujxuaioKJflTgCw2WyoqKhocsYtKioKLMuiqqrKJWC8dOmS8JqoqCjs2bPH5XX8bsjmZvIaq6ioAHBt/x0IIS1HwRchAWzo0KHYsGEDEhISIJVe/eWgX79+AICamhoA9UuHdrvd7Wd98cUXiIiIgFqtbvJ7HTp0CLW1tcJszK5du6BSqRAbG+vx+CFDhgAAjh07Jvz/lJQU2Gw27N+/X1h2PHnyJKqqqlxeK5PJ3MbpybUsO6alpaGqqgr79+8XZuK2bt0Kh8OB4cOHe3zNsGHDIJPJkJ2djcmTJwvjLyoqQlpamvB9X3/9dZSWlgrLmlu2bIFarRb+e7RUfn4+ZDIZ+vfv36rXEUKuDiXcExLAZs+ejYqKCkyZMgV79+7FmTNn8NNPP2HGjBlNBiVPPvkklixZgh07duDcuXPYtWsXHn74YYSHhwuBQUJCAg4fPoyTJ0+irKwMVqsVU6dOhU6nw1133YWcnBwUFhbil19+wZw5c/DHH38I359lWcyaNQvHjh3Dpk2bsGjRImRmZja5nBkeHo6hQ4ciNzdXeKxPnz6YMGECHn/8cezevRv79+/HI4884hYkJSQkIDs7GyUlJaisrGzyPMXHxyMpKanJf927d2/ytX379sWECRPw6KOPYs+ePdixYwcyMzNx//33C7lWFy5cQEpKijCTpdFoMGvWLMydOxfbtm3D/v37MWPGDKSlpWHEiBEAgFtuuQX9+vXDQw89hEOHDuGnn37CSy+9hNmzZ0Mulws//+DBgzh48CBMJhMuX76MgwcP4tixYy5jzMnJwahRo7wGkYSQtkPBFyEBLCYmBjt27IDdbsctt9yCgQMH4tlnn4VWq20y2Bk3bhx27dqFe++9F71798bkyZOhUCiQnZ2NsLAwAMCjjz6KPn36IDU1FeHh4dixYweUSiW2b9+OuLg4TJo0CX379sWsWbNQV1fnMhM2duxYJCcnY/To0bjvvvswceJELF682Ov7eOSRR9yWM1evXo2YmBjccMMNmDRpEh577DG3xPd//vOf2LJlC2JjY6HX66/iDLbM559/jpSUFIwdOxa33XYbMjIy8NFHHwnPW61WnDx50iXn6l//+hfuuOMOTJ48GaNHj0ZUVBS++uor4XmJRIKNGzdCIpEgLS0NDz74IB5++GG8+uqrLj9br9dDr9dj//79WLt2LfR6PW677TaXY9avXy9syiCEtD8Rx3FcRw+CEEKA+vIQVVVVra46X1tbiz59+uCLL74QZt9Iy/z444/461//isOHD1/T0jMhpOVo5osQ0uUFBQXhP//5D8rKyjp6KF1OTU0NVq9eTYEXIT5Ef22EEL9w4403dvQQuqQ//elPHT0EQgIOLTsSQgghhPgQLTsSQgghhPgQBV+EEEIIIT5EwRchhBBCiA9R8EUIIYQQ4kMUfBFCCCGE+BAFX4QQQgghPkTBFyGEEEKID1HwRQghhBDiQxR8EUIIIYT40P8H+/kfKASsNsAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot([x for x in range(len(x_t_list))], x_t_list)\n",
    "plt.xlabel('Time Step (dt = 0.001)')\n",
    "plt.ylabel('x_t Value')\n",
    "plt.title('Sampling x_t from learned reverse process, gt x_0 = 1.0, random init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/rsg/chemistry/johnyang/miniconda3/envs/cellot/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGdCAYAAAA8F1jjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAA9hAAAPYQGoP6dpAABdKUlEQVR4nO3deXxTZd4+/itLkzRtk7RNF6ptaUllX8pigbYoyAiIjqM8fkdgZijgMsoyCo6Ao6w6gPjTGRF1nGGb5xGccRhRUVEElRYRBYpAWWyh0Cq02NIk3bKf3x8lx6ZJSxFKTtvr/Xr1pUlOkjsnpblyL59bJgiCACIiIiIJkge7AURERETNYVAhIiIiyWJQISIiIsliUCEiIiLJYlAhIiIiyWJQISIiIsliUCEiIiLJYlAhIiIiyVIGuwFXy+Px4Ny5c4iIiIBMJgt2c4iIiKgVBEFAdXU1EhISIJc332/S7oPKuXPnkJiYGOxmEBER0c9QWlqKG2+8sdnb231QiYiIANDwQnU6XZBbQ0RERK1htVqRmJgofo43p90HFe9wj06nY1AhIiJqZy43bYOTaYmIiEiyGFSIiIhIshhUiIiISLIYVIiIiEiyGFSIiIhIshhUiIiISLIYVIiIiEiyGFSIiIhIshhUiIiISLLafWVaIvqJpc6BihoHrDYndKEhMIapoNeqgt0sIqKfjUGF6GeSWig4Z67HvC2HkVtYIV43Is2IFRP6IcEQGrR2eV2P8yW194SIrh6DCtHPILVQYKlz+LUHAHYXVmD+lsNYPTH9un9gNw4NYSolDpRUYdm2Y6hzuAFc+/PV+D3RqhSYlpWC4anRUCnliAxTMbQQtVMMKkSXXO7buPd2tyDg+Y+Oo3+iATnDu8Lu8kATosDBkiosevcoXrivf5v0FJjrnKh1uFDvdCM6TAWnW0C1zQmtWgkI8AspXrsLK1BR42iTD+nmzlmgIJdtisbWRzNRXFmLEIX8mp6vxkFNq1Lg5YnpWL+nGK/sKhKPuZpgxJ4aouBhUCGCfw+JVqXAM3f2wsAkA2xON/ShKjyz9ShyiyqwIWcI7s9I9vsgzDRFY2pmCsqrbdf0Q+y8uR5nL9Zh9a5C5JeY8fLEdLy44zvsKaoUj1k7ZXCLj1Ftc/pcbumD13ubpd4BrVoJuUwGpVyG6CYfzufM9Vi49Sh6JOiQnmjAeYsNF7QhSIzSYsF/j/j0bKQnGmB3eVBRa4dSLsPMTQeRnmTA1MwUVNYGDlFXEg4qahzie/fwLam4YLVhWmYKJmckiyFyXV4x5m85jFX39UeNzSU+brhaiVq7C5b6wM8jtd4zos6GQYU6vabDJo2/kS/47xHMHGVCfkmVGAz02hC88MlJn6AAQLw8b2wPWOquvgfDUufAhWo76p1urNlViD1FlZg5yoT1e4r9nvtyIjQh4v+39MErA/Bkk9syTdF4ICsVB85Wod+NetTaXQhTK3G41IzJQ5Pxv1+dAQCkJxpQVeeETuNE/0QDjp+3YsWEfn6BLttkxMsT0zF/y2FcsNpwoyEU35y5iDCVAmFqJQyhIah1uK8oHFgvBTGtSoFxvbtgybYCn3OUaYrGpgeHwlzrwJmKWtQ63GJ4GZhkQE5mCmZvzkedw+3zPFIcUiPqbBhUqNNr/G0cAKZlpfiEgfREg88HrVIhazYo7CmqhEyGqx5qaRwm1k4ZjNxm2uKVX2pGpik6YLtGpBlhDP+pt6TpPA5vb8fZylrIZDIcOFsFAOLtg5MicUNkKNblncYf/3NYfNzsNCMW3tkLC+7oiSXvFfj1Lq3LGYKV20/4tSm3qAIeCOLtT71z1Od+f7qjJ1785LsrCge6S0FsWlYKljUJKcCl9wUnMCApUmxnpikaL09Mx+zN+VApz2L1xHQAEM+FQi5Drd0VlCE1IvpJmwaV5cuX47///S9OnDiB0NBQDB8+HCtXrkT37t3FY2w2G+bOnYu33noLdrsdY8aMwauvvoq4uLi2bBqRyNpkWKRpGLC7PD63V9X6Ht9UVZ0TbrXws9tjqXPgi+9+RM7wrph4cxJiI9SYOcqEt74uQVSYCmunDPaZF7Murxjr8orx8sR0yAEcKDGLAQQAEiO14mN7Q1lz8zga93asmNAPm/adxeDkSPxYbcfEjGRMzUoVnzO3sAJLtx3DXf264GCJGTNHmcTQowlRIEQhw5CuUZiWmeLX3j1Flai2ucRA0Tg0nbfY8MhIE3ok6LAur1icfAs0Hw6M4SqMSDM2G+QAIK+oElMzU8TL3ud+aEQq+tygx4Y9xWIgBBqC2OJf9oZWpfBpQ2NNh9SI6Npr06DyxRdfYMaMGRgyZAhcLheeeuop3H777Th27BjCwsIAAI8//jg++OADvP3229Dr9Zg5cybuvfde7Nmzpy2bRiTSNRoWAfyDiVrpWxfR5Wk5hLjcgs9Qy5WqqnNi2+FzPr0Co3rE4M0HhuLZbQU+H6aNewVmb87Hvx8eCrVSgf1nLoqv5XtzPb793ozMbtGwu9x4dfJAxOk0OFlmRX6J2ee5c4saeg/W5QzBa58XYVJGMtbmnvZ7Tu8wSp3Tja7RWvzroaH4y6ffYV1eMR4akYrsNCNq7G5kpERhz6lKrMsrBgA8M74X/vP74Si5WAedRikGsEBDRI1fW+OgYKl34tSFGr+5Kysm9MPJsuoWz23T93ZPUSUeH30TXvr0O/+en8IKLH6vANOyUpoNP1fzPhNR67RpUNm+fbvP5Q0bNiA2NhYHDhzAiBEjYLFYsHbtWmzatAmjRo0CAKxfvx49e/bEV199haFDh7Zl86iVOvqKB++38d2XuvibBpOmwyoHS6qQbYr2+fD2yjRFo9xqw6Akw89qi6XOgWe2HvH70OyVoMfSZoY0gIYhj/ySKlRUO6AOkWPbkfM+x47uEYs+CTqUWe0Nz1Pf0BOwZtJAzNh00CcI5BZV4BFbNzx6axpWbj+OvADPKcdJPDm2B/YfK8MTb3+LgUkGTM9KxW+HdcXa3NP4y6eFPufklUnpkEGGf+SdxoJ3jog9KMNSozEiLQZuj4D0pEjkl5jFtjR+bY2Dgs3pxr2vfSlebjyn5HI9HE3fW6AheDY3lJdbWIFHbukWMKg0HlIjorZzXeeoWCwWAEBUVBQA4MCBA3A6nRg9erR4TI8ePZCUlIS9e/cGDCp2ux12u128bLVa27jVnVtnWPHg/TY+f8th7C6s8Asm3mEVoOHDc11eMV6ZlA5AJvZAAA0fyLNGpaFrlNYvyJVbbaiqdcBqc0EXqkSkVoU4ncavLReq7QEDUEtDGnuKKvHorSYMSDQgTqfGsx8e9/ng1aoUuD8jye/6TFM0Zo404eFbUvG3L077zFfRaxtW+zQNKV65RRXIqbYhv6RK7PX4ZbUN7397zq/9DcEGGNe3C/YUVTY77BSoB2VPUSWmNRquyTJF48vTvo/vnbuy6r7+OHi2qtm5OtmmaOSXmv2u16oUAV+jl1wu83vMEWlGrJzQ75pMmO7IXwIup7O/fmqd6xZUPB4PHnvsMWRmZqJPnz4AgLKyMqhUKhgMBp9j4+LiUFZWFvBxli9fjiVLlrR1cwnSLCLWVhIMoVh+b1+craxDtd2FX/ZLwLJLwyx1Djdmb87HM3f2wsI7e6He4YYuNAQv/L/+sNY7Yal3QqtSIEylhEEb4ndOSiprseAd316S23rEYPFdveFwCz5/pJvOl/FqOmTRlEohRxe9Bjan2+9DuunkYC/v5flje6J3gh7r9zTMdZmWlYJ4nRqhKjk+mJ2FWrsboSoFIAC7Tpbjb1+cRp3DDbvLIz7Gw7ekoleCHk9uORKwfblFlZialdqq9jTtQfG+9myTEVMyu2L25ny/x99dWIGqWgeWfXDcJ1R6ZZqi8cxdvfGrNb5DypmmaCjlsoBt9qpzuJGeFCkGpqQoLWIj1Ff9u98ZvgS0pLO/fmq96xZUZsyYgaNHjyIvL++qHmfBggWYM2eOeNlqtSIxMfFqm0cBNF0N01hHW/FgqXNg/qXaH8BPkztzGn046UJDUGt3oQ5uCAA0Sjni4iJafNxyq80vpGhVCkzMSMb8JtePSDNiSTOTNwMNWTQWoVEiNSYc31yam9LY5XpjlAoZQkMU+N2wrlh0Vxie/+g4BiQasL5JrZZRPWLw5JgeGNM7HtZ6F8LVCuyccwtKL9YhTq9CjS3whFMvnUaJdx4djhCFvMX2zB/XA7266MTJt0lRoVg7ZTBiItS4/42vmp3YarW5xFA5LStFnMSrVsqRX2rGuap6n/tmpxmx7O4+UCvlyE4zBvxdzzRF42BJlU97d8655ZoWqGusI34JCKSzv366MtclqMycORPbtm3D7t27ceONN4rXx8fHw+FwwGw2+/SqlJeXIz4+PuBjqdVqqNXqtm4ywX81TFMdacVD01BW53CLH05alQIfzs7GE29/e8Xf/qpqHa3u4dhdWIGF7xXg6fE9fZbsAg3zZLJM0QGHYrJM0YgMa/ijbgj1n9zpcLfcG1NV64DN6UZoiAIVNQ2re97cd9YvXE3KSMayD44FHD4KV4XAXFff4vNo1UqcN9dfdgJq6cV6PPrmQQANPU9390+AVqWA3enBK5MGiiuHmgYWnabhz1nj966xD2ZlYcfjI1BrdyFCEwJj+E/DDCsbDf01fm1TL9VXaexa/N5f7kvAeYsNpytqO+xwSGf6EkRXr02DiiAImDVrFt555x18/vnnSElJ8bl90KBBCAkJwc6dOzFhwgQAwMmTJ1FSUoJhw4a1ZdOoFZquhmmqI614aCmUTctKwTNbj/jNvWjNtz+rzeV3XUs9HLmFFZg/toffnIhj5yx49ld98fTWIz5hJcsUjefu6SvOd4mNUPv1DsSEtxzstSolJv1jn3jZO8Ty1emLYhiYlpWCTfvOikMgjZcb/3PvGTwxpjtuMITizQcyYKl3+ixFrnO4kW0y4sMj5/HKrqLLVtH19h55e54Wv+9fvK3pXJYRaUZEhvlOim4syxSNcI0Sbo+AFGOY3/sVplJg2d19UOtwodbhhrXeifxSs9+KI+Da/N5f7kvA6YpaMax1xOGQzvQliK5emwaVGTNmYNOmTXj33XcREREhzjvR6/UIDQ2FXq/H9OnTMWfOHERFRUGn02HWrFkYNmwYV/xIQNPVMI1JccXD1UzMaymUtRQsLvftz/stv7HLzTexudy4s1+Cz9DFhWo7LtbaMC0rBfPG9UCNzY1wjQIXrHas2n4Cz93TF3ptw+tt2jugUsqbnWCaaYqGvMmokrcgW+O5IoOTIjEg0YBN+86K58TmdCPLFI0J6Teg3unGog8LfEKUN1Bs3ncWT43vhbtWNwz7HvnBgmyT0Wcisle2yYgjPzRMum/tXBbvxNY4ncZnUnTjx3xiTHdMeO1LVNQ4xA/+MJUCFTUOVNU54HR7xGXU07JScKikKmDv1bX6vb/cl4DGQ30dcTikM30JoqvXpkHltddeAwDceuutPtevX78eOTk5AICXXnoJcrkcEyZM8Cn4RsHXdDWM17Va8XAtXe3EvJZC2eW09O0vMkzlN2RzufkmhlAV7ugTj4oaB6ptTkRoQmCKCce4l3ObnZ/x+C+6i+9HgiEUqyemi/d3uj1iobOmPRNTM1Nw3mLze7ymq2302hCs3lWISRnJPmHF4RJQ73Rj+YfNLWOWISezK2xOl9h2mQx4dGQ3eCD4tefRkSZ8fablKrzex37qjp64o088wtRKceVO49duqXfC5nTjy9OVmPj3n+a27C6swLwth3FH3y5Y8N+fJv96g5W32B0An9d0LX/vW/p9ywywOqm9DYdc7ktDe/sS1FlJZVVWmw/9XI5Go8GaNWuwZs2atmzKFZPKGxRsTT/0mo7tS8G1mJjXUii7MbLloNPSt784nQZ/vqcvnnrnpyGbluabeP9Ie3tHvPJLqpoNKYB/WGp8/1MXavDbtV8HnGA6e3O+WDq+qcY9P0qFDL0S9Ni07ywmNdmQsXGJ/6Zl+TUhChjDVTDX/dS+Pgl6TN+4P2B7Zm0+iHU5Q9AnQQ+tquU/T2cr63yGR1ZO6AftpV4Sq80JrVqBXScvBJzPkltYgZzhXX2u84am+29OEifkPj2+F2xO9zX/vW/u9625eTFA2w2HXOu/da350tCevgR1VlJalcW9fgKQ0ht0JdoqXDX90JSaazUxr7lQBuCqvv0lRYfh//t/A8Q6KvpQJf7f4EQ8/c6RVv+RvpqucmO4CoOSIwP2TgT69u6lbzQxt6rWKZbkbzoc4w00WpUCayYNxHmL76Tak+etuDm1Ye8fm9ON2Ag1pmWl+AUIb32VVdtPILeoEmunDA4YfLxzXxr3TO0/W4WzF+uwZleRX22bQNVtG7e7MW9PkndC7ugesRiQFBnw/Fytpr9vmhAFth05H7CtQNsMh1zrv3VX8qWhPXwJ6qyktiqLQaUJqb1BrdVew9W1cC0n5jUXyq7221+cTuNX4O1K/khfTVe5XqvC8nv6Yv5/DyPvUsG1aVkpGJ4aDYVchjqHGzNHmXyCQ7bJiJgINd6flYmqOieitSqcvVjnNxyjVSlwY2TD8mGVUo6oMBXOW+ox61KPwEMjUvGLnnEoulADmUyGY+eteOLtbzEoyYBXJqVj5qZ8nwm7jUPQ0XMWrJ0yGK98VuS/4eGUIQhVybEuZwgOllQhRCHD6ks7TDfWXG0WoPkhuMYBpq3nSjT+fbPUOXC41BwwpLTFcEhb/K270i8NUv8S1FlJbVUWg0oTUnuDWqO9hqtr5XpMzGv67S9MrYRKIceFahvqnO6f1Xt1JX+kr7ar/MYoLVZO6IfSi3WIDFPh2W3Hmq0Km55kwBNjuuNijR1KhRxddBqEqZWw1DthvlR6X6tSYMbIbhjbuwsWv3fUZ+jn6fE98fbvh0Ipl+PZbcf8yul7nwd5Z/DQiFTx9qYhSBCAVz8r8lsmnZ4UCY8giCuqEvQaDOkahb99cTrga28638bbjuZ6krwB5nrPlbjewyFt8beOq3k6Bqm9jwwqTUjtDWoNKYer6zHX53pNzPMGi2D1Xl1tV3m4WomoMDVKq+owNSsV/ZMixV4Ub5n7tx4aik+OlePlnd9h0V29kRTdsHno2cpaRIapEKKQY9usLCjkMsggYNF7R8W5No1L45+zNJTXv1wPxx9Gp/kEmcb63qD3ua2l0vupxjA8fEsqXtoR+LEa95KMSDPi0ZEmTNvwjd9x3gATrLkSbTUcEujfYY392v+t42qejkFq7yODShNSe4NaQ6rh6np9oF/Pb6LB7r36uV3lgd6LpvM3cosq8UdAnIuybNsxvHBff9Q63Hj6nSN+Oygvvqs3hqREYeqlCbGJkVqs3H5c7MFoacWOt4dDEID/PjIcNqcb6hDfoZimc0gut1x53tgezQaVVGMYtj46XPzgr3O4MTg50ncZ86XKwADwYFZK0ML9tR4Oae7f4dK7+wSsguz1c/7WcTVPxyC195FBpQmpvUGtIcVwdb0/0K/XxDwp9141p7n3ItD8je+rfqoKCwDmOieefvdowI0Gl247hrv6dUF+qRnpiQYIEMTelcvVivHeHqZWQK1U4N7XvsTMUSafei9N55BcbrmyrJkte0akGdFFr2kyN+LK5gi1Vy39O1z47lE8c2cvnyXaXj/3bx1X83QMUnsfGVSakNob1BpSDFfB+EC/HhPzpNp71ZKW3oum8zcahwNjuAr1LjdyCytgDG8oJBerU6PG5kaERolyqw0JBjXe/fYcXtlVhFcnDwz4OIGolXJkm6IRGqKA0yNAq1L47VLddBfryxbKc3r8/h209O+2M0zkvNy/wz+N73lF56w1uJqnY5DS+8igEoCU3qDWkGK4ao8f6K0hxd6rywn0XjRe9qtVKbEuZwjKLPU4eq6hKqwxXIU3HxiKMnM9nhx7E8b16YJl246hV4Ie6YkGVNU5YNCGIEwVgpLKOgC+4aRpyGgs2xSNC1YbpmalYPzqPAxKjsQ7jw5HmcWO/NIq3JwShelZqVApZbg3/QYseq8AuYUVrSiUF9Ku/t1eD5f7d1jvcLfJOesMIbAzkMr7yKDSDKm8Qa0ltXDVHj/QW0OKvVeX0/S9aG5SarbJiKlZXaFVKbByQj+s3H4cf7qjF0LVcnxTfBGP/+ImXLDaxWXG6/KKMTDJgLVThuBXr+7xCSdNe0d+eo5oLP1VH1RU2xGuCcErk9Lx5H8O49ltxzHn9ptwc0oUwtVKTNvwDSpqHPhFz1i8cF9/1Nhc8AhCs7scZ6cZERuhbnf/bttaa/4d8pyR1MmE1pSPlTCr1Qq9Xg+LxQKdThfs5tAlljoHZm3Ob/YDvT0vmT5nrm+296qLBGvWNH0vZo4yBVyRAzRMkk1PisS43vH4qKAMJ85Z8NT4Xlj47lG/fXy8FVQHJUeif6JBDCcb9xQjt1G9lmGX6rWEq5WosTthc3hQ53RDE6JAuaUeg7pGYdLfv8LKCf0wfeN+ZJmi8cSYHlizqxBL7+7jc07b27kPto7875Dav9Z+fjOoUJvpyB8q3uWeUui9ao3G78XaKYMxfeP+Zo/d/odsWG1OVNtcyC8149uSKr/JtMBPoeaVXUXY8sgwmOuccHkEdIsJx9nKWp/S+FqVHOmJkXilSV2UTFM0Zo40we5sCC/eibzZaUa8cF9/vyJ5QPs798HWkf8dUvvW2s9vDv1Qm5HacNS11N66yxu/F5W1jhaPtTnd0IWGoKLGEXClTeP5LWEqJQYlRSJKq0KNzQ27ywVLvRMXrDYs++C4uPT1vZmZWLn9BPJLzJg5yuRTEr+4ohYZqVE4U1EnPseBs1WwOdw4daHGrwZPezv3wdaR/x1S58CgQm2KHyrSIb4XF2paPC5MrcT+M1VIitbCUu87GbO5+S1ZpmjkZKbgibe/RZ3DjWyTUey58YaV/BJzswXbhqZGixN5vc/x9Fbf2i2dZUuItsB/h9SetTyNnog6HO+E4EBGpBmhUsix7INjiNAofTYmBJovupZXVIn1e4oxLathqXNuUQVe/awI78/Mwtopg2F3elos2LbovQJ4B6G9xzUdbvLW4LHUtdwjREQdC4MKUSfjXc7eNKx45y1YbQ5My0pBVa0TNxg0yDJFi8ekJxoCTsIFGgKHt6otAOQWVaLW4YKAS3v0tHDf3MIK9L1Bf9nn8NbgIaLOg0M/RJ1QS/MW7C4P8kuqsC6vGK9PHoSn7uiJ5R+eQG5RRasrznrVO9yYvTkfrzUqBtfa+zanvdbgIaKfhz0qRJ2UzeWB0+2Bwy3A6fHA5vLAUufAM1uPNlSszUrB33JP4X9e34v+SQb85/fDkBjV8vyQxkXZtCoFYsLVeGXSQNQ53UgwhGLmKBO0KkXA+3aN1mLnnFuQFKVt8Tnaaw0eIvp52KNC1AmVVNZiwTtHfIZYskzRePZXfXG8zArAd2+dV3YVYV1eMd56aCiyTNE+NVUa10txewSsyxmCw9+bMSw1CoveO4rjZdVYOaEfXB4PsroZMb5vF5y31OPJ/xwWh3FGpBlxgyEUeq0KljpHuyuqR0Rth0GFqJMpt9r8QgrQMCH26a1HxMJr3qGYxsuRz5lt+NP4XjhUYsayD44BQDNVbqMxNCUKZyrr8OYDQ7F0W4FfKHrzgaGY/I+v0KuLzmerByluCUFEwcOgQtQJeIukWW1OaEIUzU5WzSuqxLxxPQA0DOMkRoZi3dQh+NFqh7m+4b4fHDmPE+es+Gh2NiADfqiqx+SMZEzPSsXBS3Nbcosq4QGwZvJAv5DifZ5l2wrw30eGQx8a4hc+WPuDiLwYVIg6uHPmeszbcljcI+fVy0xsrbU31D05WW7FP6fdjKffPepXTfaBrFSUWW14ZVehzzLiTFM0Xp6Yjtmb87GnqBJKhbzFUFTndCMpOizg7az9QUQAgwpRh2apc/iEFAAt7kKsVSkQG6HGpgcyoNeGYGGTkAI0LEO+s28CPjxyzq/WiffYaVkpeGVXEarrW16hc85cD50mhEXciKhZXPVD1IFV1Dj8dhv27nLclFalwNopg7Ho3QJM+sc+lFlsAff4AYBYnbrZ2xqCTBf877Sbode2vEJHHxrCIm5E1CL2qBB1YNYANUe8uxyrlXL0StAjPdEAl0dAWkw4yqw2TMxIwtSsFERqG+aF3H9zEtITDXC4PYiN0CBEIUPdpeEhr8YTbu0uD1weATdGhqKqzu63SsgryxQNXWiIWMSNwzxEFAiDClEHpgtQc6TO4cb8LYfxjylD8P99fEIMLoveO+rTSzK6R6y4Yqfp3jzzx/UQw8nApEhoQxTwQMCXpyqxLq8YdQ43skzRWParPpielQoB8JvnkpOZAruzIfCwiBsRNYdBhagD8+7r07Qmyf03J2HVxyewp6gSM0eZAu7B0yNBF3DFzp6iShSWVeM/vx+G5R8e9wsx3sm0eUWVWPhuAQYlRyI9KRLTMlNgd3mgVsqRX2rG7M35WJczBACLuBFR8zhHhagDa25fn+Gp0WIAaW5vneau16oUSIuLwHMfHg84mdZnc8LCCvS70eBzjEwmE/9fKZexiBsRtYg9KkQdXKCaJJb6nyavNrfHTuPrG89BUSvl0KqUmJaZgskZydCEKMT6KXUOd0P5/cwU8b5hKgXyS6r8el7W5QxBycU6FnEjohYxqBB1Ak1rkpy6UCP+f3PLlb3Xa1UKsfqsdz7L4ibzWRoP+dQ53NCqlFiXMwQHS6ogCELA4SO5TIYX7uuPOJ3mWr5UIupgOPRD1Al5564AwJEfLMgOsFw5v9SMLFM0pmWliHNYvP9/uSGfOocL0zZ8g0MlVdColAE3IswtrECNzdUGr46IOhL2qBB1Qt65K4vePYr+NxqQkRIFQIbcop8m3R47Z8HSu/vgvMUmDts03qjQq/GwUJhKieHdolHvcEOrUiCvqBICTogF4Jriah8iupw27VHZvXs37rrrLiQkJEAmk2Hr1q0+t+fk5EAmk/n8jB07ti2bRESXJBhC8ew9fbEu7zSmb9yPnMyuePOBDLw6eSDWThmMXgl6/HCxHm6PIN6n6XwW77BQfkkVpm/cj/v//hUm/X0f1u1pGCLSqhr2FUpPNARsQ2iAnhYiosbaNKjU1taif//+WLNmTbPHjB07FufPnxd/Nm/e3JZNIqJGau0u9E+KxOqJ6XC4PdCHhsBc58CszfkNJfAdLjjdP4WTpvNZGg8LNdZ0KCjQhN3sNCM8HgEHz17EqR9rWJ2WiAJq06GfcePGYdy4cS0eo1arER8f35bNIKJmCIDfipxsUzS2PpqJ4spaJEVp8cGR88g0NSxn9pbfb7y0ufF9m1ao7RqthVIuQ2STUvrZJiNm3GrChNf3os7RUPRtRJoRKyb0474/ROQj6HNUPv/8c8TGxiIyMhKjRo3Cs88+i+ho/4l9Xna7HXa7XbxstVqvRzOJOhxLnQOLA2w6mFtUiSXbCpCeFIkecRE4cd6KqZeWG7/1dQn+MWUI5DiJ3KIKuDwCZo4yiSX2EyO1OPy9GbMurf4BGkLJHX27YEPOEGjVSshlwHfl1Zi28RvxGADYXViB+VsOY/XEdC5XJiJRUFf9jB07Fv/85z+xc+dOrFy5El988QXGjRsHt9vd7H2WL18OvV4v/iQmJl7HFhN1HBU1jmY3FswvMeOOPvFwuD34/S3dEKZS4oGsFGx+cCj+/kURcjK74oPZmbgpNhwJ+oblxYIAXKhu+BKxZtJAcaVPblEFlr1fgP0lVXB7BFjqnXjqnaM+IcXLu+8PEZFXUHtU7r//fvH/+/bti379+qFbt274/PPPcdtttwW8z4IFCzBnzhzxstVqZVgh+hkCbVgI/DRBdnmTyrPZaUbMHGnC/wxOwj/yTuPmlCjc3DUKHxw577ePz8yRJjx8Sype2lEIoKGXJiczBeEaBaouMxeFK4GIqDFJ1VFJTU2F0WhEUZH/MkYvtVoNnU7n80NEVy7QhoUAmq2VkltYgVc+K0KoSo78EjNGdo/FK58VBZxI+8pnRRjZPdbvsS9Y7c0WmPPivj9E1Jikgsr333+PyspKdOnSJdhNIerwGhd9a6y5PX6AhrDi9gAvT0wHgGaP815vDFdh7ZTBeH9WJiLUSsTrNEgwaDC+T+AJ9Nz3h4iaatOhn5qaGp/ekeLiYhw6dAhRUVGIiorCkiVLMGHCBMTHx+PUqVN48sknYTKZMGbMmLZsFhHhp6Jv87cc9ttduSWWeife3HcWf7gtrcXjbE433nxgqN8OzNkmI5b+qjemZnVFjc2NOqcbmhAFyq02jLwphhNpichHmwaV/fv3Y+TIkeJl79ySKVOm4LXXXsPhw4exceNGmM1mJCQk4Pbbb8eyZcugVqvbsllEdEmgDQs9gtDifdRKOfYUVeJPd/QKeLt3ibIxXI1FAVcVVeDprUdxZ98uiNFp8MTb36LO4caINCNuuSnmmr02IuoYZIJwmb9KEme1WqHX62GxWDhfhegasFwq+Lb/bJVPTRRNiAJllnqY6x1wuASM7R2PH8z1kMlk4u7JAMQNDKdlpmD6xv3NPs/aKYOxbk8x0pMixVosI9KMXJ5M1Em09vM76HVUiEha9FoVVk7oh7MX67B6V2GTYnBGPHNXLzz/0XH85dNC8Xrv7skF5yxipdrJGcktPo/d5WnY6PBSjRbgp+XJDCpE5MWgQkR+tCoF1uwq9Bu2OV5mxcVaOx6/vTumZ3dDhEaJcqsN87YcxsY9xVj8yz54aUchtCoFYiNaHsL1rv5pWl6fy5OJqDEGFSLyE6gYnDFcFXBybJYpGm8+MBST//EVah0uJEaGYu2UIThw9qJPuf3GMk3RyC81A/DfP4jLk4moMQYVIvITqBjcygn9/EIKAOQVVWLZtgKsnNAPdqcb/5x2M55+9yjyS8wBlzFnpxkxNbMrZm7K9wksAJcnE5E/BhUi8hOoGFysTt1s3ZS8okrMG9cDoSEKnLPYxONmb87HtKwUTMtMgd3lgVopRxe9BjuOl2NgkgE5mSmYvTkfQENIWTmhH+enEJEPBhUi8uMtBte4vkqNrfk9uACg1u6GUi6Hpf6n3pg6h9tnMi4AvDp5IMb0isf9Q5JQa3dh0wMZiNCEwBiuYkghIj8MKkTkx1sMbt6Ww8i9FFbCNYqW7xMaAmu987Il8tVKOWxON+J0mmvWXiLquBhUiCigBEMonr27D05V1EKrUiBCrcQdfeIwYVAiYnVq1Njc4qqfLQdK4XJ7EKZWIreootlJtNkmI/JLzbhnwA1BeEVE1B5Jaq8fIpIWgzYE4eqGkHKmsg5/GH0TKmvs2P3djwhTK+ARBISrlfjD6JsQrlbAoFHi+DkLpmamINMU7fNYWaZoPHNXL5w8b+WEWSJqNVamJaJmnTPXY95/vhWXKmtVCqzPGQxBAFY32Tk5O82IZ3/VB6WVdVj3ZTF6JejFqrb60BBEaJSwOVxIjApDF0NosF4SEUlEaz+/2aNCRAFZ6hwNc1QahZFpWSk49WOtX0gBGnZWfvqdI0iM1mLWKBOyuhkRG6HGjZGh2H/2Iu5/4yvI5HKGFCK6IpyjQtSJWeocqKhxwGpzQhcaAmPYTytvKmoc4kRar/REAwA0u0w5t6gS31fVY+/pSnG1T3aaEQvv7IX0GyNhDOOQDxFdGQYVok7qnLneZ1UP0FDLZMWEfkgwhAYs+ta03H0glnonBiZFipdzCyuw+P0CpCdF4p97LVj0yz6odbhgrXdBF6pEpFbFFUBE1CwGFaJOSBzWadJjsruwAovePYrn7ukLQ2gI1k4ZLO6cfLCkCpoQBS43rU0TokCcTu1334zkKAxINGD+fw/7leD/8z19kRQd1iavlYjaN85RIeqEAg3rAA2TZSdlJOP0jzV45t2jmL5xPx598yCmbfgG+SVViAlX4YLV5reix3vf5ff2RYJeg+p6F+J0GqiVcjz5n2+RX1KFhKhQbNp3NmAJ/qfeOYJyq63NXi8RtV/sUSHqhAIN6wANk2XPW+rxwZHzfoFiT1ElXv/iFJ4c0wMpMeHidUBDSFmXMwRrdhViwX+PiPdpvGHh4vcK0D/RgF0nfvR73ryiSlTVOjgERER+GFSIOqFAe/kAwOCkSESFN8wZmZyRLA7brMsrBgDcM/BGLNtWgL6JBswb2wMAUO9wIzZCjYXvHvXbcbnxhoXTN+5HzvCuzbbJanNdmxdHRB0KgwpRJxRoLx+tSoEuBg2e3XbMJ3BkmqLx8sR0HP3BgvV7irGnqBKfnvgRL+0oFO+35ZHhfiHFy7thIdDyZFydhn+OiMgf56gQdULevXxGpBnF66ZlpfiFFKBheGf9nmJkmYx+w0FalQJrJg2EtT7wUJJXnd2NdTlD0DVaC63Kf8+gLFM0Irl0mYgC4FcYok4qwRCKVff1x6kLNTDXO5EYFeq307HXnqJKzBrpv9rHO6cl+TIrdrRqBX79xlfITjNi7ZTBmL5xP+ocDbsxe1f9cH4KEQXCoELUidXYXJj0j30AgFcnD2zx2LAAuyd7C8DtPV3Z4kaEF6x2ABBXGm3/Qzaq7S7U2d3Qa0OgDw08Z4aIiEGFqBNrvPpHrWx5JFilkPuFEe+ck3V5xXh5YjoA36q1maZoLPplb9z/xl7xutzCCnxfVS8GJMC30BwRUWMMKkSdWOPVP/ml5hZ7Rb4tNWNqZkrDsSVmTMtKQWJUKC5Y7ahzuDF7cz6mZaVgWmYK7C4P1Eo58kvNcLjcqKhx+Dyeucmclt2FFZi/5TBWT0wXS/gTEQGcTEvUqXlX/wANvSJTM1P8irllmqIxNasrzlttUMpkeHJMd2yblYVvS6rwcUE5yi8VgKtzuPHKriLM23IYaqUcsTo1sroZIZPJsHbKYBjDfwoggXpvdhdW+AUaIiL2qBB1Yt7VP/O3HMbuwgqxV2TGrSYoFTJU21zILzVj5qZ8cfLrzFEm5JdUYU9RJQ6UmLFm0kDMHGkCAJwsq8abDwzF0m0FfmXyvYXfusdHIL/UHLA91c0UoiOizksmXG7jDomzWq3Q6/WwWCzQ6XTBbg5Ru+TdRbna5kSEJgTGcBXOW2wY+9dcv2PX5QzBtA3fiJe1KgUeviUVI7vHQqdR4k9bjwYcPsoyRWPmKBOiwtSY9PevAvae7JxzC7rFhl/bF0dEktTaz2/2qBAR9FqV39wQm8uDLFM08pqEDqVcBq1KgWlZKUhPNIgbD35yrBx39IkPGFKAhsJvC+7oiZUfHcf9Nyf5LYUekWb0GR4iIgI4R4WImhGn0+DP9/RFVqM5K1qVAjdGhmLro5n4tqTKb9NClVIRsKCbl7XehZ0nfsTwVN95MCPSjFg5oR8n0hKRH/aoEFGzkqLDsPyevjDbnKizuxEToca+05XY1symhUveL8DqiemYtfmnOS2NhV+qxaIJUWDnnFt8hpoYUogoEPaoEFGLdKEhWLX9JPafvYhF7x5FrE7T7PBObmEFNCEKvDwx3a9npXHhN31oCLrFhmNAUiS6xYYzpBBRsxhUiKhF3pVBt94Ui9yiyhY3FgQAS70TG/YUY1pWinidt/DbvC2HOReFiK5ImwaV3bt346677kJCQgJkMhm2bt3qc7sgCFi4cCG6dOmC0NBQjB49GoWFhW3ZJCL6GRIMoeJQzuUq2KqVcuQVVWJM7zi8Onkg1k4ZjPSkSPxQVY9eXXSci0JEV6RNg0ptbS369++PNWvWBLz9+eefx8svv4zXX38d+/btQ1hYGMaMGQObzdaWzSKin0GrbhjK8VawDSTbFI0jP1gAAKUX6/HomwcxfeN+fFtqRtdoLVZPTEcXlsknoitw3eqoyGQyvPPOO/jVr34FoKE3JSEhAXPnzsUTTzwBALBYLIiLi8OGDRtw//33t+pxWUeF6Nrz1lWpsTth0KrgcHlgqXfC4fbgUGkVMrvF4IWPTyK3qEK8T7YpGgvu6AkBAkou1iMxUovtBWU4ed6KpXf3YUAhIh+Sr6NSXFyMsrIyjB49WrxOr9cjIyMDe/fubTao2O122O128bLVam3zthJ1JufM9Zi35TAOnK3CyxPT8fzHJ8XJs1qVAmunDMbqnd+hf5IBOZldYXd5YAgNQReDBs9vP4GPjpaLj5WdZsTye/oypBDRzxa0oFJWVgYAiIuL87k+Li5OvC2Q5cuXY8mSJW3aNqLOylLnwLwth5FbWIGZo0xYv6fYJ6SsnpgOjwDcOygRmhAFDpZUYV1eMeocbmSZojEgKRLAT0Elt7ACT71zhJsNEtHP1u5W/SxYsAAWi0X8KS0tDXaTiDqMihoHcgsbhnPSEw0+IeXlienYsKcYk/+xz6fIm3cpcl5RJdITDX6Pyc0GiehqBK1HJT4+HgBQXl6OLl26iNeXl5djwIABzd5PrVZDrVa3dfOIOiVro00BGy9DnpaV4te74i2hDwD/Oz0Dn528AJcn8JQ3bjZIRD9X0HpUUlJSEB8fj507d4rXWa1W7Nu3D8OGDQtWs4g6NZ0mRPx/TUjDKh+tSoFbb4rx613Jv1RCf/rG/Zjw2pfIL6lCSnRYwBL6EY0el4joSrRpUKmpqcGhQ4dw6NAhAA0TaA8dOoSSkhLIZDI89thjePbZZ/Hee+/hyJEj+N3vfoeEhARxZRARXV/GcBVGpBkBNKzMu61HDF6emA5LfUOPiHeeysZGvStee4oqsWxbgU+hN4CbDRLR1WnToLJ//36kp6cjPT0dADBnzhykp6dj4cKFAIAnn3wSs2bNwkMPPYQhQ4agpqYG27dvh0ajactmEVEzvFVoR6QZoZDJ8IfRN2H9nmIADSHllUnp0IQokNtcCf2iSgxMihQvc7NBIrpa162OSlthHRWia89S58B35TWotrswbcM3mDnKhOTIULz37TlMzEjGo28ebPa+//n9MOhDQ+D2CKhzuKDXqmAM46aDRORL8nVUiEi69FoVDNoQXKxzYOYoEwYnRSLeoMEftxxBTmbD0E7jCbV2l0dcrhyuUWLp+8d8isGNSDNixYR+SGA9FSK6QgwqRBRQbIQaMgD/3HsGr+wqwr8fHiZOlB3dIxb3ZyRh/Z5ivLKrSLxPlikaE9JvwIGSKp/H2l1YgflbDmPVff1RY3PBanNCFxrCnhYiuiwGFSJq1pL3j4mTZiPUDat93tx3Fo+Nvgkrt5/wm1CbV1SJhe8VYPXEdMzanC9uZAg0hJVTF2ow6R/7xOvY00JEl8OgQkQBVdQ4xOEbrUqBcLVSrKUyZVgK0pMiMS0zxWfYZ11eMXILKzD3F93x30eG48caO1xuAQcu3Wau962n4u1pYeVaImoOgwoRBVRjd2LmKBPSEw2IClPhe3M99hRVQqtSIF6vRn5Jlc+wT6YpGi9PTMfszfmwu9z49ES5WF7fe5tSJvN7Hm/lWgYVIgqEQYWIAPy0Y7J3/kikVoVj5yx46+sSbH5oKNRKBTY/OBRxOjX2na7EtMwUTM5I9ulNkaMYD41IRZhaiWPnLGJw2VNUCRmAqZkpAZ+blWuJqDkMKkQk7pjs3ecHaJgY+1B2N8QbNFj8XoHYm7L10UxsO3LeZ36Kt8dk/pbDWPzLPrC53JiamQKFXCbOV8krqsS0rNSAq4Ui2ZtCRM1gHRWiTs5S58DMzfk+IcXrrYcy8Mbu0+iVoBeHgF785KRY8K3pnj8JhlAcKqnCsg+OixNps9OMeGZ8L5RbbFAq5YjQKHH4ezOebXQMJ9USdT6t/fxud7snE9G11XjH5KYiNEpMykgW9/W5WOvAgRIzZo4yYV3OEKybMgTDu0Ujv9SMWZvzMe6vudh25Ly4ozIA5BZWYNm2Y4iP1GDW5oO4c3UePmhyjHdSraWOuywTkS8O/RB1ctYW5ofIIffZNdnlEfDyxHS/+imNJ9J6j334llQ43YI4xONwerD5waGY+PevxGOmZaWIj8NJtUQUCIMKUSena2FnY0HWsNmgMVyFlZeGZqptLjw9vpf3CECQwSN4IJPJ8OqkgXh000Hkl5ix6K7eWPJ+gV9BuH9MGYJJl8LKtCaTazmploiaYlAh6uS8OybvLvypZop33kmt3QVjuAqbHhyKpe8XIK/JBNqpmSnYtO8sJmUk4619JXhqfE9snDoEYWolLtbacbKs2ue58ooqIcNJsSfF7vL43B7RQmgios6JQYWok/PumDx/y2HsP1vlM7SzYeoQvHBff6z46DgGJEViapMCb5v2nUWvBD3W7ylGelIknnn3KNKTIrEurxjPjO+F/5ueAUu9E0qFHLmFP+KN3aeRW1SBnMyuAAC18qdpciPSjDCGc9iHiHwxqBAREgyhWD0xHeY6J57eekRciuz2CLghMhSTMpKxad9ZAEB6ogE2pxvDu0Xj9l5xsNQ68cquIkzLbOglmZ6VigETDVi/pxgL3jkiPke2yYhXJqVj5qZ82F0eZJoaJuECDSFl5YR+nJ9CRH64PJmIRKcu1OC2F7+AVtWwr8+mfWfx5JgeeP7jE5iUkewzsRZomHOy7O4+KLlYD12oErM352PD1Jthc7phtbkQoVGi3GrDvC2HUVHjQLYpGv2TIpHZLRpd9KGw1jsQpg6BMZybExJ1Nq39/GaPChGJvCuApmU1zD2ZnJEMARCHdwJuQvhuAfonGXDinBX/Oz0DT2894jOXJcsUjTcfGIrJ//gKuUWV+P2tJiRHh12qmRJ2HV8dEbVHDCpEJPKuABqcFIkBiQZs2FOMiRnJGJgU6bN6p7HcogpMzWpYvbN0W0HAuSzPbz+OVf/TDwdKzDCEhuAHcz3qnW4Yw9iTQkQtY1AhIpF3BZBeG4IXPjmJPUWVmJ6VCk2IosX7RWiUuDf9BgxKisQ/8k5jXV6xuHIoPdGAsb3jEaZW4N/7SzG+UeDJTjNi2d19EKkNYWAhooAYVIhI5F0BVFXrEId53IIAAQJmjjJhYFIklHIZosJUcLo9sNa78M3Zi6i1ufDyzkI8M74Xfj+iGyJCQ7Dq4xM+vTDZaUY8Pb4XvjlThYqahgq0uYUV+NPWI7izXwJuuSmGJfSJyA+DChH5SDCE4rylXryslMsRqlLiUEmVXzXaB7JSkRQZilidBpMyklBZa0eCQYNvS80Bd1detq0AKyf0w/SN+8XH8RZ+m7/lMFZPTGfPChH5YFAhIj+Nq9XqQpVY9fEJv4m0+SVmaELkeO/bc3hyS6NlyGlGzLi1G6Zt3C9uOti4xP68cWq/57O7PCyhT0QBMagQkR+VQo5MUzT2FFVCqZCJIcVbSj9Wp0a9wwO3x4MBSZE4WGIWQ0luYQU8guCzj0/jvX1qbG6/5/MWfmMJfSJqikGFiPyY6x2YmpmCUKUctfaGYGEMV+HNB4Zi6bYCn96VbJMR7zw6HGUWO745exHr8hqWMT8++iasyysWA8yeokrMG9sDIQp5w+7Ll25rXPiNJfSJqCn55Q8hos4mXB2C+VsO48lxPRGmUmDmKBM2P+QfUoCG5clLtx3DN2cv4tuSKrwyKR1alQKWeidentjw/17fV9Vj3F9zkV/SUKp/VI8YTM1Mwbq8YpbQJ6KA2KNCRH6M4SrMG9sD35ZUoe+lJcYutyCGFK1KgYdGpCLLZITLLSBMrYBWpUSIQoZNX5XgoRGpAIBN+85i9cR0AA3zUJKitGJvihxnkJPZFbM252NwciRL6BNRQCyhT0QBFVfU4JmtR8Uqs69OHogn3v4WD41IxW09Y3HBaodMJhNX9KQnGTBrVBriItS4WOuAJkQBjwD89dOT+PTEj+Ljenddnr05H//5/TColQqW0CfqhFr7+c2gQkR+LHUOzP33IfRI0GNwUiT02hCEqhRQyGRY+n4BchsN/zQOHkNTo/DQiG5QKeSosbsQHaaCXC7Dj1Y7vr40f8U7LyU9KRKje8RiQFJkEF8pEQUL9/ohop+tstaB+y/tmDwg0YAXPjmJ9KRI5JdU+c1R8V5++JZU9L1BjzW7Cn2CTLYpGlOzUnDsnEVcouytncLJs0R0OZxMS0R+XB4B6/cU+2xGmJ5o8AspXnuKKnFb9ziszyv2CSkAkFtUifV7zmDOL7rjgtWGh29JFW/j5Fkiuhz2qBCRH49HEHs9vLVQ7C6PTx2VGpsb+lAlXB4BF2sdkMnhF1K8cgsr8Ifb3PjgyHksuqs3/vbFadwYGcp5KUR0WQwqROSnzuEC0BBOvCLUSp86KlqVAi9PTMemfWfRK0GPrG7GFh/TdSn8LHv/GJ65sxfidZo2fQ1E1DEEfehn8eLFkMlkPj89evQIdrOIOjV9aENPh7dirFalQGJUKJY1CimrJ6bjw29/wII7emJc73jIZMC2WVlYO2VwwCEdbz2V3KIKDEwysDeFiFpFEj0qvXv3xqeffipeViol0SyiTssYrkJ2mhH5pWaM6hGDyRnJqHd6MCkjGdOzUhEdroLd6cKM227Ccx8cQ78bDcgyGVFjcyFOp8HbDw/D91X1ePzfh1BR40B2mhEhCjnW5QzBwZIq2J3+ZfSJiAKRRCJQKpWIj48PdjOI6BK9VoXFv+yNFz8+iXlje+LZbQVNVvIY8ew9ffCXHSfxm6HJWJ9XjL98Wtjo9mgs+mVv/OfhYfjrzu8wvv8NmPDal+LS5P8ZeGMwXhYRtUNBH/oBgMLCQiQkJCA1NRWTJ09GSUlJs8fa7XZYrVafHyK69mQA/vCLm/xCCtAwfPP0O0cwc1Qa3vzqLPonRWLtlMF4dfJArMsZgv5JkVjx4QmUVdvxh9tuwsmyn/6d7imqxMJ3j8JS57jOr4iI2qOgF3z76KOPUFNTg+7du+P8+fNYsmQJfvjhBxw9ehQRERF+xy9evBhLlizxu54F34iuLUudAxU1DpyprIXLIyBBHwqZDKhzuBGhUUIua9hl2eH2wFLvQqhKDggy7DpZjm9LzZiUkYywS/NSSi/WISpcjdmb88VNCnfOuQXdYsOD+RKJKIjabWVas9mM5ORkvPjii5g+fbrf7Xa7HXa7XbxstVqRmJjIoEJ0jZ0z12Pef77FgRIzXp6YLtZTARomxq6dMhivflbkNyS05O7eCJE3lNbvagzD8x+fxLyxPbBy+wmkJ0WKy523PjqcVWmJOrF2W5nWYDDgpptuQlFRUcDb1Wo11Gr1dW4VUediqXNg3pbDyC2qxGOj07B531mkJ0VielYqQhQyxESo4fEI+M2wrpialSru93OgpAr7TldiQFIkuhhCoVYqMH9sD6hC5PjN0GQkRmoBAOvyilmVlohaRXJBpaamBqdOncJvf/vbYDeFqNOqqHEgt7ACWpUCv+gVi3436rEur1jsDdGqFHh6fE/0vVEPc50T4/t2wT0DboC5zoEwtRJyuQzfnLmINZ+dwqAkAxbe1RvPbD2KihoHMk3RWJczhFVpiahVgj6Z9oknnsAXX3yBM2fO4Msvv8Q999wDhUKBiRMnBrtpRJ2W1eYEAEzLSoHgkWF9XrG4i7JWpcArk9Lx4ZHzuGv1Hvx27dcY99dcLH6/AEqlHL9Zuw/L3j+GwclR+NdDQ3G8rBpLtx3DX37dH0DDZNo1nwXuMSUiairoPSrff/89Jk6ciMrKSsTExCArKwtfffUVYmJigt00ok5Ld2lYJj3RALlchtxLRd6mZaVgTK94PL/9uBhcvHILK6BWyvHfR4bDanPBUu+ERwDeeWQ4Pio4jxidBsZwldhbU1HjYNE3IrqsoAeVt956K9hNIKImjOEqjEgzwu7yoMbuhFalwOuTB0EVIoNCIcOjI9Mwb1xPlFttmLflMCpqHNCqFLj/5iT86Z0jfhNsF/2yFwDghf/pj5wN3wAAqi/12hARtSToQYWIpEevVWHp3X3wg7keoSoFZo7qhoTIUCx676jPDsrZJiPefngY6p1uVFTb8b25HjmZKZiYkQxNiEKcZLv4vQLMHJWGG6NCxftyMi0RtQaDChEFZKl3wOZ0o4teg7G9uuDZD49hSNcozL29O9weAeFqJWQywOH2QC6TIVavRnJ0GGodLlTbXAhTK3FHn3iMMBlR63AjJlwNh6uhhsqINCMn0xJRqwR9Mi0RSVO4OgSzNudDBsDh8eA3Q5Nx4MxF3Pvql5iy7mt8cOQ8LtY4UGNzQaWQQwYZyqw2uD0CtColdp4oxwufnITV7sKMTQex+P0CqJQK/KJnLFZO6Mf5KUTUKuxRIaKAjOEqDE6ORLW9IYisu7TyxxiuwoapQyCXyeARBGhClFj03lG/eSkL7uiB9BsjsWFvMaZlpeCVXUVY/H4BXrivP+J0miC+MiJqTxhUiCggvVaFFRP6ofRiHVRaOQYkReKB7FREaJTQqpSwuzyot7vh9rgwqGsUjpdV4/6bk5CeaIDd5YGl3onkaC1yhnWF51L969zCiks7LAf3tRFR+8GgQkTNSjCEotbugkIuQ1JkKCI0Srg9EPfrsTndCFUpkJ1mxC/7J8Du8qDW7kK4Wgm3IKDMakOMTgOlQgatSoE6h5urfYjoijCoEFGL9KEhKK6oxfvfnvMd3kkzYtbIbvjiuwsYcVMMiitqIZPJxJU+6UkGTM1MwRu7T2Hu7d0xY2Q3rPr4O672IaIrwqBCRC2yOd14ZVehGFK8hd+GJEchKkyNr05VYtXH34nHZ5uM2PTgUDyw8Rus31OM9KRILP/oBJbe3RuHSsxc7UNEV4RBhYia9f3FOpy31KN/UiRyMlMgl8mQYgzDM1uPQCmX4e+5F/0r1BZVQICAdTlDcP8bX2F6Vipe2VWEC1Y7nrmzF1f7ENEV4fJkIgrIUufA4veOIipMjfySKszbchhdjVo8vfUIDpSYcVvPWL+Q4pVXVIlqmwvTslIQrlbg1ckDEaFRYl/xRVjqHNf5lRBRe8YeFSIK6EK1HT0S9Fj6fgH2FFVi7ZTBOG+2Ia+oEjNHmXDBam/x/pZ6J9ITDai2ufDomwcBANmmaAzpGsVeFSJqNfaoEFFA5ktBwzs3JVanhrm+YcVOeqLhsvdXKxv+vOSXmsXrcosq8cy7R9mrQkStxqBCRAGFqRSwuzzi5RqbWwwfdpcH+aVmZJuMAe+baYpGfqkZsTo11uUV+9zm3TmZiKg1GFSIKKAwlRL60J+WEodrFGI4USsbKtXOHdMdWaZon/tlmqIxNTMFJ85ZsPP4BbHmSmOspUJErcU5KkQUkEEbgjqnG1mmaOQVVeKC1Y4T562YO6Y7jp+zID3JgAc2foN1OUPwiM0FS70TaqUc+aVmvPV1Ce7PSMbszfkBH5u1VIiotdijQkQB6bUqRIaGYNndfZCdZsS8LYfx1B098cYXReh7ox6L7+qNnvERuP+Nr7D3dKU4LHRnvy5YeGcvvLXvbMDeFO6cTERXQiYIghDsRlwNq9UKvV4Pi8UCnY4biBBdayfLrPjoaBnG9omHw+mCQavGOXM9QlUKhKmVsDkbyubrtSENYUUArDYHdKEqLHy3ALmFFeJjjUgzYuWEfuhiCA3iKyIiKWjt5zeHfoioRQatCgfOXMSWA9/j/6bdjAvVNnTRh6LO6cbFWgciNCHootegssYOt1sBdYgcdpcAp8eDp8f3hNMtoO5SkInXabg0mYiuCId+iKhFcToNnrunL7pGh2HC3/ai1u5GvdONGpsLYWolNEo55AAUcjmq7S7UOdzQhCjw7Vkzyiw2/OXT75BsDEP3eB1DChFdMfaoENFlJUWH4YX/1x9VdQ5U17vgEQTE69RweQTUOd2wOdyIClNBoZCh9GI9QhQynK2qxyfHyrHs7j6I02mC/RKIqJ1iUCGiVonTafwCh6XOAaHWAZVCDofbgxC5HF2jtahzuHHPgBtgzEphLwoRXRUGFSL62fRaFYMIEbUpzlEhIiIiyWJQISIiIsliUCEiIiLJYlAhIiIiyWJQISIiIsliUCEiIiLJYlAhIiIiyWJQISIiIsliUCEiIiLJkkRQWbNmDbp27QqNRoOMjAx8/fXXwW4SERERSUDQg8q//vUvzJkzB4sWLcLBgwfRv39/jBkzBhcuXAh204iIiCjIgh5UXnzxRTz44IOYOnUqevXqhddffx1arRbr1q0LdtOIiIgoyIIaVBwOBw4cOIDRo0eL18nlcowePRp79+4NeB+73Q6r1erzQ0RERB1TUINKRUUF3G434uLifK6Pi4tDWVlZwPssX74cer1e/ElMTLweTSUiIqIgCPrQz5VasGABLBaL+FNaWhrsJhEREVEbUQbzyY1GIxQKBcrLy32uLy8vR3x8fMD7qNVqqNXq69E8IiIiCrKg9qioVCoMGjQIO3fuFK/zeDzYuXMnhg0bFsSWERERkRQEtUcFAObMmYMpU6Zg8ODBuPnmm/GXv/wFtbW1mDp1arCbRkREREEW9KDy61//Gj/++CMWLlyIsrIyDBgwANu3b/ebYEtERESdj0wQBCHYjbgaVqsVer0eFosFOp0u2M0hIiKiVmjt53e7W/VDREREnQeDChEREUkWgwoRERFJFoMKERERSRaDChEREUkWgwoRERFJFoMKERERSRaDChEREUkWgwoRERFJFoMKERERSRaDChEREUkWgwoRERFJFoMKERERSRaDChEREUkWgwoRERFJFoMKERERSRaDChEREUkWgwoRERFJFoMKERERSRaDChEREUkWgwoRERFJFoMKERERSRaDChEREUkWgwoRERFJFoMKERERSRaDChEREUkWgwoRERFJFoMKERERSRaDChEREUkWgwoRERFJVlCDSteuXSGTyXx+VqxYEcwmERERkYQog92ApUuX4sEHHxQvR0REBLE1REREJCVBDyoRERGIj48PdjOIiIhIgoI+R2XFihWIjo5Geno6Vq1aBZfLFewmERERkUQEtUdl9uzZGDhwIKKiovDll19iwYIFOH/+PF588cVm72O322G328XLVqv1ejSViIiIgkAmCIJwLR9w/vz5WLlyZYvHHD9+HD169PC7ft26dXj44YdRU1MDtVod8L6LFy/GkiVL/K63WCzQ6XQ/r9FERER0XVmtVuj1+st+fl/zoPLjjz+isrKyxWNSU1OhUqn8ri8oKECfPn1w4sQJdO/ePeB9A/WoJCYmMqgQERG1I60NKtd86CcmJgYxMTE/676HDh2CXC5HbGxss8eo1epme1uIiIioYwnaHJW9e/di3759GDlyJCIiIrB37148/vjj+M1vfoPIyMhgNYuIiIgkJGhBRa1W46233sLixYtht9uRkpKCxx9/HHPmzAlWk4iIiEhighZUBg4ciK+++ipYT09ERETtQNDrqBARERE1h0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgkq82CynPPPYfhw4dDq9XCYDAEPKakpATjx4+HVqtFbGws/vjHP8LlcrVVk4iIiKidUbbVAzscDtx3330YNmwY1q5d63e72+3G+PHjER8fjy+//BLnz5/H7373O4SEhODPf/5zWzWLiIiI2hGZIAhCWz7Bhg0b8Nhjj8FsNvtc/9FHH+HOO+/EuXPnEBcXBwB4/fXXMW/ePPz4449QqVStenyr1Qq9Xg+LxQKdTnetm09ERERtoLWf30Gbo7J371707dtXDCkAMGbMGFitVhQUFDR7P7vdDqvV6vNDREREHVPQgkpZWZlPSAEgXi4rK2v2fsuXL4derxd/EhMT27SdREREFDxXFFTmz58PmUzW4s+JEyfaqq0AgAULFsBisYg/paWlbfp8REREFDxXNJl27ty5yMnJafGY1NTUVj1WfHw8vv76a5/rysvLxduao1aroVarW/UcRERE1L5dUVCJiYlBTEzMNXniYcOG4bnnnsOFCxcQGxsLANixYwd0Oh169ep1TZ6DiIiI2rc2W55cUlKCixcvoqSkBG63G4cOHQIAmEwmhIeH4/bbb0evXr3w29/+Fs8//zzKysrw9NNPY8aMGewxISIiIgBtuDw5JycHGzdu9Lv+s88+w6233goAOHv2LB555BF8/vnnCAsLw5QpU7BixQoola3PT1yeTERE1P609vO7zeuotDUGFSIiovZH8nVUiIiIiC6HQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSrzYLKc889h+HDh0Or1cJgMAQ8RiaT+f289dZbbdUkIiIiameUbfXADocD9913H4YNG4a1a9c2e9z69esxduxY8XJzoYaIiIg6nzYLKkuWLAEAbNiwocXjDAYD4uPj26oZRERE1I4FfY7KjBkzYDQacfPNN2PdunUQBKHF4+12O6xWq88PERERdUxt1qPSGkuXLsWoUaOg1WrxySef4NFHH0VNTQ1mz57d7H2WL18u9tYQERFRxyYTLteF0cj8+fOxcuXKFo85fvw4evToIV7esGEDHnvsMZjN5ss+/sKFC7F+/XqUlpY2e4zdbofdbhcvW61WJCYmwmKxQKfTXf5FEBERUdBZrVbo9frLfn5fUY/K3LlzkZOT0+IxqampV/KQPjIyMrBs2TLY7Xao1eqAx6jV6mZvIyIioo7lioJKTEwMYmJi2qotOHToECIjIxlEiIiICEAbzlEpKSnBxYsXUVJSArfbjUOHDgEATCYTwsPD8f7776O8vBxDhw6FRqPBjh078Oc//xlPPPFEWzWJiIiI2pk2CyoLFy7Exo0bxcvp6ekAgM8++wy33norQkJCsGbNGjz++OMQBAEmkwkvvvgiHnzwwbZqEhEREbUzVzSZVopaOxmHiIiIpKO1n99Br6NCRERE1BwGFSIiIpIsBhUiIiKSLAYVIiIikiwGFSIiIpIsBhUiIiKSLAYVIiIikiwGFSIiIpIsBhUiIiKSLAYVIiIikiwGFSIiIpIsBhUiIiKSLAYVIiIikiwGFSIiIpIsBhUiIiKSLAYVIiIikiwGFSIiIpIsBhUiIiKSLAYVIiIikiwGFSIiIpIsBhUiIiKSLAYVIiIikiwGFSIiIpIsBhUiIiKSLAYVIiIikixlsBtARB2Dpc6BihoHrDYndKEhMIapoNeqgt0sImrnGFSI6KqdM9dj3pbDyC2sEK8bkWbEign9kGAIDWLLiKi949APEV0VS53DL6QAwO7CCszfchiWOkeQWkZEHQGDChFdlYoah19I8dpdWIGKGgYVIvr5GFSI6KpYbc4Wb6++zO1ERC1hUCGiq6LThLR4e8RlbiciakmbBZUzZ85g+vTpSElJQWhoKLp164ZFixbB4fDtBj58+DCys7Oh0WiQmJiI559/vq2aRERtwBiuwog0Y8DbRqQZYQznyh8i+vnaLKicOHECHo8Hf/vb31BQUICXXnoJr7/+Op566inxGKvVittvvx3Jyck4cOAAVq1ahcWLF+ONN95oq2YR0TWm16qwYkI/v7AyIs2IlRP6cYkyEV0VmSAIwvV6slWrVuG1117D6dOnAQCvvfYa/vSnP6GsrAwqVcMfs/nz52Pr1q04ceJEqx7TarVCr9fDYrFAp9O1WduJqGXeOirVNiciNCEwhrOOChE1r7Wf39e1jorFYkFUVJR4ee/evRgxYoQYUgBgzJgxWLlyJaqqqhAZGen3GHa7HXa7XbxstVrbttFE1Cp6LYMJEV17120ybVFREVavXo2HH35YvK6srAxxcXE+x3kvl5WVBXyc5cuXQ6/Xiz+JiYlt12giIiIKqisOKvPnz4dMJmvxp+mwzQ8//ICxY8fivvvuw4MPPnhVDV6wYAEsFov4U1paelWPR0RERNJ1xUM/c+fORU5OTovHpKamiv9/7tw5jBw5EsOHD/ebJBsfH4/y8nKf67yX4+PjAz62Wq2GWq2+0mYTERFRO3TFQSUmJgYxMTGtOvaHH37AyJEjMWjQIKxfvx5yuW8HzrBhw/CnP/0JTqcTISENtRZ27NiB7t27B5yfQkRERJ1Lm81R+eGHH3DrrbciKSkJL7zwAn788UeUlZX5zD2ZNGkSVCoVpk+fjoKCAvzrX//CX//6V8yZM6etmkVERETtSJut+tmxYweKiopQVFSEG2+80ec274povV6PTz75BDNmzMCgQYNgNBqxcOFCPPTQQ23VLCIiImpHrmsdlbbAOipERETtT2s/v7nXDxEREUkWgwoRERFJFoMKERERSdZ1LaHfFrxTbFhKn4iIqP3wfm5fbqpsuw8q1dXVAMBS+kRERO1QdXU19Hp9s7e3+1U/Ho8H586dQ0REBGQyWbCbI1lWqxWJiYkoLS3l6qhW4PlqPZ6rK8Pz1Xo8V1emvZ0vQRBQXV2NhIQEv4KwjbX7HhW5XO5Xp4Wap9Pp2sUvsFTwfLUez9WV4flqPZ6rK9OezldLPSlenExLREREksWgQkRERJLFoNJJqNVqLFq0iDtPtxLPV+vxXF0Znq/W47m6Mh31fLX7ybRERETUcbFHhYiIiCSLQYWIiIgki0GFiIiIJItBhYiIiCSLQaUDeu655zB8+HBotVoYDIaAx5SUlGD8+PHQarWIjY3FH//4R7hcLp9jPv/8cwwcOBBqtRomkwkbNmxo+8ZLQNeuXSGTyXx+VqxY4XPM4cOHkZ2dDY1Gg8TERDz//PNBam3wrVmzBl27doVGo0FGRga+/vrrYDcp6BYvXuz3O9SjRw/xdpvNhhkzZiA6Ohrh4eGYMGECysvLg9ji62v37t246667kJCQAJlMhq1bt/rcLggCFi5ciC5duiA0NBSjR49GYWGhzzEXL17E5MmTodPpYDAYMH36dNTU1FzHV3F9XO5c5eTk+P2ujR071ueY9n6uGFQ6IIfDgfvuuw+PPPJIwNvdbjfGjx8Ph8OBL7/8Ehs3bsSGDRuwcOFC8Zji4mKMHz8eI0eOxKFDh/DYY4/hgQcewMcff3y9XkZQLV26FOfPnxd/Zs2aJd5mtVpx++23Izk5GQcOHMCqVauwePFivPHGG0FscXD861//wpw5c7Bo0SIcPHgQ/fv3x5gxY3DhwoVgNy3oevfu7fM7lJeXJ972+OOP4/3338fbb7+NL774AufOncO9994bxNZeX7W1tejfvz/WrFkT8Pbnn38eL7/8Ml5//XXs27cPYWFhGDNmDGw2m3jM5MmTUVBQgB07dmDbtm3YvXs3Hnrooev1Eq6by50rABg7dqzP79rmzZt9bm/350qgDmv9+vWCXq/3u/7DDz8U5HK5UFZWJl732muvCTqdTrDb7YIgCMKTTz4p9O7d2+d+v/71r4UxY8a0aZulIDk5WXjppZeavf3VV18VIiMjxXMlCIIwb948oXv37tehddJy8803CzNmzBAvu91uISEhQVi+fHkQWxV8ixYtEvr37x/wNrPZLISEhAhvv/22eN3x48cFAMLevXuvUwulA4DwzjvviJc9Ho8QHx8vrFq1SrzObDYLarVa2Lx5syAIgnDs2DEBgPDNN9+Ix3z00UeCTCYTfvjhh+vW9uut6bkSBEGYMmWKcPfddzd7n45wrtij0gnt3bsXffv2RVxcnHjdmDFjYLVaUVBQIB4zevRon/uNGTMGe/fuva5tDZYVK1YgOjoa6enpWLVqlc+w2N69ezFixAioVCrxujFjxuDkyZOoqqoKRnODwuFw4MCBAz6/J3K5HKNHj+40vyctKSwsREJCAlJTUzF58mSUlJQAAA4cOACn0+lz3nr06IGkpCSeNzT05paVlfmcH71ej4yMDPH87N27FwaDAYMHDxaPGT16NORyOfbt23fd2xxsn3/+OWJjY9G9e3c88sgjqKysFG/rCOeq3W9KSFeurKzMJ6QAEC+XlZW1eIzVakV9fT1CQ0OvT2ODYPbs2Rg4cCCioqLw5ZdfYsGCBTh//jxefPFFAA3nJiUlxec+jc9fZGTkdW9zMFRUVMDtdgf8PTlx4kSQWiUNGRkZ2LBhA7p3747z589jyZIlyM7OxtGjR1FWVgaVSuU3fywuLk7899eZec9BoN+rxn+fYmNjfW5XKpWIiorqdOdw7NixuPfee5GSkoJTp07hqaeewrhx47B3714oFIoOca4YVNqJ+fPnY+XKlS0ec/z4cZ8Je/STKzl/c+bMEa/r168fVCoVHn74YSxfvrzDlaamtjFu3Djx//v164eMjAwkJyfj3//+d4cO+XT93X///eL/9+3bF/369UO3bt3w+eef47bbbgtiy64dBpV2Yu7cucjJyWnxmNTU1FY9Vnx8vN/KDO+Kg/j4ePG/TVchlJeXQ6fTtcs/tFdz/jIyMuByuXDmzBl079692XMD/HT+OgOj0QiFQhHwXHSm89AaBoMBN910E4qKivCLX/wCDocDZrPZp1eF562B9xyUl5ejS5cu4vXl5eUYMGCAeEzTCdsulwsXL17s9OcwNTUVRqMRRUVFuO222zrEueIclXYiJiYGPXr0aPGn8ZyJlgwbNgxHjhzx+eXdsWMHdDodevXqJR6zc+dOn/vt2LEDw4YNu3Yv6jq6mvN36NAhyOVysft02LBh2L17N5xOp3jMjh070L17904z7AMAKpUKgwYN8vk98Xg82LlzZ7v9PWkrNTU1OHXqFLp06YJBgwYhJCTE57ydPHkSJSUlPG8AUlJSEB8f73N+rFYr9u3bJ56fYcOGwWw248CBA+Ixu3btgsfjQUZGxnVvs5R8//33qKysFENehzhXwZ7NS9fe2bNnhfz8fGHJkiVCeHi4kJ+fL+Tn5wvV1dWCIAiCy+US+vTpI9x+++3CoUOHhO3btwsxMTHCggULxMc4ffq0oNVqhT/+8Y/C8ePHhTVr1ggKhULYvn17sF7WdfHll18KL730knDo0CHh1KlTwv/93/8JMTExwu9+9zvxGLPZLMTFxQm//e1vhaNHjwpvvfWWoNVqhb/97W9BbHlwvPXWW4JarRY2bNggHDt2THjooYcEg8Hgs6KsM5o7d67w+eefC8XFxcKePXuE0aNHC0ajUbhw4YIgCILw+9//XkhKShJ27dol7N+/Xxg2bJgwbNiwILf6+qmurhb/LgEQXnzxRSE/P184e/asIAiCsGLFCsFgMAjvvvuucPjwYeHuu+8WUlJShPr6evExxo4dK6Snpwv79u0T8vLyhLS0NGHixInBekltpqVzVV1dLTzxxBPC3r17heLiYuHTTz8VBg4cKKSlpQk2m018jPZ+rhhUOqApU6YIAPx+PvvsM/GYM2fOCOPGjRNCQ0MFo9EozJ07V3A6nT6P89lnnwkDBgwQVCqVkJqaKqxfv/76vpAgOHDggJCRkSHo9XpBo9EIPXv2FP785z/7/KMXBEH49ttvhaysLEGtVgs33HCDsGLFiiC1OPhWr14tJCUlCSqVSrj55puFr776KthNCrpf//rXQpcuXQSVSiXccMMNwq9//WuhqKhIvL2+vl549NFHhcjISEGr1Qr33HOPcP78+SC2+Pr67LPPAv6NmjJliiAIDUuUn3nmGSEuLk5Qq9XCbbfdJpw8edLnMSorK4WJEycK4eHhgk6nE6ZOnSp+GetIWjpXdXV1wu233y7ExMQIISEhQnJysvDggw/6fVFo7+dKJgiCcN27cYiIiIhagXNUiIiISLIYVIiIiEiyGFSIiIhIshhUiIiISLIYVIiIiEiyGFSIiIhIshhUiIiISLIYVIiIiEiyGFSIiIhIshhUiIiISLIYVIiIiEiyGFSIiIhIsv5/cikSRLATr7MAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot([x.item() for x in gt_scores], [x.detach().cpu().numpy().item() for x in pred_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
