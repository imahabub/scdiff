{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from absl import logging\n",
    "from absl.flags import FLAGS\n",
    "from cellot import losses\n",
    "from cellot.utils.loaders import load\n",
    "from cellot.models.cellot import compute_loss_f, compute_loss_g, compute_w2_distance\n",
    "from cellot.train.summary import Logger\n",
    "from cellot.data.utils import cast_loader_to_iterator\n",
    "from cellot.models.ae import compute_scgen_shift\n",
    "from tqdm import trange\n",
    "\n",
    "from cellot.models.ae import AutoEncoder\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "logger = logging.getLogger(\"data_logger\")\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "TARGET = 'all' if not DEBUG else 'abexinostat'\n",
    "LATENT_DIM = 50\n",
    "\n",
    "from pathlib import Path\n",
    "outdir_path = '/Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/full_ae'\n",
    "outdir = Path(outdir_path)\n",
    "\n",
    "# %%\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "cachedir = outdir / \"cache\"\n",
    "cachedir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import GPUtil\n",
    "import os\n",
    "\n",
    "def get_free_gpu():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "    # Set environment variables for which GPUs to use.\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    chosen_gpu = ''.join(\n",
    "        [str(x) for x in GPUtil.getAvailable(order='memory')])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = chosen_gpu\n",
    "    print(f\"Using GPUs: {chosen_gpu}\")\n",
    "    return chosen_gpu\n",
    "\n",
    "status = cachedir / \"status\"\n",
    "status.write_text(\"running\")\n",
    "\n",
    "device = f'cuda:{get_free_gpu()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "import omegaconf\n",
    "\n",
    "if DEBUG:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "else:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "\n",
    "yaml_str = f\"\"\"\n",
    "model:\n",
    "   name: scgen\n",
    "   beta: 0.0\n",
    "   dropout: 0.0\n",
    "   hidden_units: [512, 512]\n",
    "   latent_dim: 50\n",
    "\n",
    "optim:\n",
    "   lr: 0.001\n",
    "   optimizer: Adam\n",
    "   weight_decay: 1.0e-05\n",
    "\n",
    "scheduler:\n",
    "   gamma: 0.5\n",
    "   step_size: 100000\n",
    "\n",
    "training:\n",
    "  cache_freq: 10000\n",
    "  eval_freq: 2500\n",
    "  logs_freq: 250\n",
    "  n_iters: {n_iters}\n",
    "\n",
    "data:\n",
    "  type: cell\n",
    "  source: control\n",
    "  condition: drug\n",
    "  path: /Mounts/rbg-storage1/users/johnyang/cellot/datasets/scrna-sciplex3/hvg.h5ad\n",
    "  target: {TARGET}\n",
    "\n",
    "datasplit:\n",
    "    groupby: drug   \n",
    "    name: train_test\n",
    "    test_size: 0.2\n",
    "    random_state: 0\n",
    "\n",
    "dataloader:\n",
    "    batch_size: {batch_size}\n",
    "    shuffle: true\n",
    "\"\"\"\n",
    "\n",
    "config = omegaconf.OmegaConf.create(yaml_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ### Utils\n",
    "\n",
    "# %%\n",
    "def load_lr_scheduler(optim, config):\n",
    "    if \"scheduler\" not in config:\n",
    "        return None\n",
    "\n",
    "    return torch.optim.lr_scheduler.StepLR(optim, **config.scheduler)\n",
    "\n",
    "def check_loss(*args):\n",
    "    for arg in args:\n",
    "        if torch.isnan(arg):\n",
    "            raise ValueError\n",
    "\n",
    "\n",
    "def load_item_from_save(path, key, default):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return default\n",
    "\n",
    "    ckpt = torch.load(path)\n",
    "    if key not in ckpt:\n",
    "        logging.warn(f\"'{key}' not found in ckpt: {str(path)}\")\n",
    "        return default\n",
    "\n",
    "    return ckpt[key]\n",
    "\n",
    "# %%\n",
    "import cellot.models\n",
    "from cellot.data.cell import load_cell_data\n",
    "\n",
    "\n",
    "def load_data(config, **kwargs):\n",
    "    data_type = config.get(\"data.type\", \"cell\")\n",
    "    if data_type in [\"cell\", \"cell-merged\", \"tupro-cohort\"]:\n",
    "        loadfxn = load_cell_data\n",
    "\n",
    "    elif data_type == \"toy\":\n",
    "        loadfxn = load_toy_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return loadfxn(config, **kwargs)\n",
    "\n",
    "\n",
    "def load_model(config, device, restore=None, **kwargs):\n",
    "    # def load_autoencoder_model(config, restore=None, **kwargs):\n",
    "    \n",
    "    def load_optimizer(config, params):\n",
    "        kwargs = dict(config.get(\"optim\", {}))\n",
    "        assert kwargs.pop(\"optimizer\", \"Adam\") == \"Adam\"\n",
    "        optim = torch.optim.Adam(params, **kwargs)\n",
    "        return optim\n",
    "\n",
    "\n",
    "    def load_networks(config, **kwargs):\n",
    "        kwargs = kwargs.copy()\n",
    "        kwargs.update(dict(config.get(\"model\", {})))\n",
    "        name = kwargs.pop(\"name\")\n",
    "\n",
    "        if name == \"scgen\":\n",
    "            model = AutoEncoder\n",
    "\n",
    "        # elif name == \"cae\":\n",
    "        #     model = ConditionalAutoEncoder\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        return model(**kwargs)\n",
    "    \n",
    "    model = load_networks(config, **kwargs)\n",
    "    optim = load_optimizer(config, model.parameters())\n",
    "\n",
    "    if restore is not None and Path(restore).exists():\n",
    "        print('Loading model from checkpoint')\n",
    "        ckpt = torch.load(restore, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optim.load_state_dict(ckpt[\"optim_state\"])\n",
    "        if config.model.name == \"scgen\" and \"code_means\" in ckpt:\n",
    "            model.code_means = ckpt[\"code_means\"]\n",
    "            \n",
    "    # logger.info(f'Model on device {next(model.parameters()).device}')\n",
    "\n",
    "    return model, optim\n",
    "\n",
    "def load(config, device, restore=None, include_model_kwargs=False, **kwargs):\n",
    "\n",
    "    loader, model_kwargs = load_data(config, include_model_kwargs=True, **kwargs)\n",
    "\n",
    "    model, opt = load_model(config, device, restore=restore, **model_kwargs)\n",
    "\n",
    "    # if include_model_kwargs:\n",
    "    #     return model, opt, loader, model_kwargs\n",
    "\n",
    "    return model, opt, loader\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_dict(model, optim, **kwargs):\n",
    "    state = {\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optim.state_dict(),\n",
    "    }\n",
    "\n",
    "    if hasattr(model, \"code_means\"):\n",
    "        state[\"code_means\"] = model.code_means\n",
    "\n",
    "    state.update(kwargs)\n",
    "\n",
    "    return state\n",
    "\n",
    "def evaluate(vinputs):\n",
    "    with torch.no_grad():\n",
    "        loss, comps, _ = model(vinputs)\n",
    "        loss = loss.mean()\n",
    "        comps = {k: v.mean().item() for k, v in comps._asdict().items()}\n",
    "        check_loss(loss)\n",
    "        logger.log(\"eval\", loss=loss.item(), step=step, **comps)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _, loader = load(config, 'cuda', restore=cachedir / \"last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"R^3 diffusion methods.\"\"\"\n",
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "import torch\n",
    "\n",
    "\n",
    "class R3Diffuser:\n",
    "    \"\"\"VP-SDE diffuser class for translations.\"\"\"\n",
    "\n",
    "    def __init__(self, r3_conf):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            min_b: starting value in variance schedule.\n",
    "            max_b: ending value in variance schedule.\n",
    "        \"\"\"\n",
    "        self._r3_conf = r3_conf\n",
    "        self.min_b = r3_conf.min_b\n",
    "        self.max_b = r3_conf.max_b\n",
    "        self.schedule = r3_conf.schedule\n",
    "        self._score_scaling = r3_conf.score_scaling\n",
    "        self.latent_dim = r3_conf.latent_dim\n",
    "\n",
    "    def _scale(self, x):\n",
    "        return x * self._r3_conf.coordinate_scaling\n",
    "\n",
    "    def _unscale(self, x):\n",
    "        return x / self._r3_conf.coordinate_scaling\n",
    "\n",
    "    def b_t(self, t):\n",
    "        if np.any(t < 0) or np.any(t > 1):\n",
    "            raise ValueError(f'Invalid t={t}')\n",
    "        if self.schedule == 'linear': \n",
    "            return self.min_b + t*(self.max_b - self.min_b)\n",
    "        elif self.schedule == 'cosine':\n",
    "            return self.max_b + 0.5*(self.min_b - self.max_b)*(1 + np.cos(t*np.pi))\n",
    "        elif self.schedule == 'exponential':\n",
    "            sigma = t * np.log10(self.max_b) + (1 - t) * np.log10(self.min_b)\n",
    "            return 10 ** sigma\n",
    "        else:\n",
    "            raise ValueError(f'Unknown schedule {self.schedule}')\n",
    "    \n",
    "    def diffusion_coef(self, t):\n",
    "        \"\"\"Time-dependent diffusion coefficient.\"\"\"\n",
    "        return np.sqrt(self.b_t(t))\n",
    "\n",
    "    def drift_coef(self, x, t):\n",
    "        \"\"\"Time-dependent drift coefficient.\"\"\"\n",
    "        return -1/2 * self.b_t(t) * x\n",
    "\n",
    "    def sample_ref(self, n_samples: float=1):\n",
    "        return np.random.normal(size=(n_samples, self.latent_dim))\n",
    "\n",
    "    def marginal_b_t(self, t):\n",
    "        if self.schedule == 'linear':\n",
    "            return t*self.min_b + (1/2)*(t**2)*(self.max_b-self.min_b)\n",
    "        elif self.schedule == 'exponential': \n",
    "            return (self.max_b**t * self.min_b**(1-t) - self.min_b) / (\n",
    "                np.log(self.max_b) - np.log(self.min_b))\n",
    "        else:\n",
    "            raise ValueError(f'Unknown schedule {self.schedule}')\n",
    "\n",
    "    def calc_trans_0(self, score_t, x_t, t, use_torch=True):\n",
    "        beta_t = self.marginal_b_t(t)\n",
    "        beta_t = beta_t[..., None, None]\n",
    "        exp_fn = torch.exp if use_torch else np.exp\n",
    "        cond_var = 1 - exp_fn(-beta_t)\n",
    "        return (score_t * cond_var + x_t) / exp_fn(-1/2*beta_t)\n",
    "\n",
    "    def forward(self, x_t_1: np.ndarray, t: float, num_t: int):\n",
    "        \"\"\"Samples marginal p(x(t) | x(t-1)).\n",
    "\n",
    "        Args:\n",
    "            x_0: [..., n, 3] initial positions in Angstroms.\n",
    "            t: continuous time in [0, 1]. \n",
    "\n",
    "        Returns:\n",
    "            x_t: [..., n, 3] positions at time t in Angstroms.\n",
    "            score_t: [..., n, 3] score at time t in scaled Angstroms.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_t_1 = self._scale(x_t_1)\n",
    "        b_t = torch.tensor(self.marginal_b_t(t) / num_t).to(x_t_1.device)\n",
    "        z_t_1 = torch.tensor(np.random.normal(size=x_t_1.shape)).to(x_t_1.device)\n",
    "        x_t = torch.sqrt(1 - b_t) * x_t_1 + torch.sqrt(b_t) * z_t_1\n",
    "        return x_t\n",
    "    \n",
    "    def distribution(self, x_t, score_t, t, mask, dt):\n",
    "        x_t = self._scale(x_t)\n",
    "        g_t = self.diffusion_coef(t)\n",
    "        f_t = self.drift_coef(x_t, t)\n",
    "        std = g_t * np.sqrt(dt)\n",
    "        mu = x_t - (f_t - g_t**2 * score_t) * dt\n",
    "        if mask is not None:\n",
    "            mu *= mask[..., None]\n",
    "        return mu, std\n",
    "\n",
    "    def forward_marginal(self, x_0: np.ndarray, t: float):\n",
    "        \"\"\"Samples marginal p(x(t) | x(0)).\n",
    "\n",
    "        Args:\n",
    "            x_0: [..., n, 3] initial positions in Angstroms.\n",
    "            t: continuous time in [0, 1]. \n",
    "\n",
    "        Returns:\n",
    "            x_t: [..., n, 3] positions at time t in Angstroms.\n",
    "            score_t: [..., n, 3] score at time t in scaled Angstroms.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_0 = self._scale(x_0)\n",
    "        x_t = np.random.normal(\n",
    "            loc=np.exp(-1/2*self.marginal_b_t(t)) * x_0,\n",
    "            scale=np.sqrt(1 - np.exp(-self.marginal_b_t(t)))\n",
    "        )\n",
    "        score_t = self.score(x_t, x_0, t)\n",
    "        x_t = self._unscale(x_t)\n",
    "        return x_t, score_t\n",
    "\n",
    "    def score_scaling(self, t: float):\n",
    "        if self._score_scaling == 'var':\n",
    "            return 1 / self.conditional_var(t)\n",
    "        elif self._score_scaling == 'std':\n",
    "            return 1 / np.sqrt(self.conditional_var(t))\n",
    "        elif self._score_scaling == 'expected_norm':\n",
    "            return np.sqrt(2) / (gamma(1.5) * np.sqrt(self.conditional_var(t)))\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized scaling {self._score_scaling}')\n",
    "\n",
    "    def reverse(\n",
    "            self,\n",
    "            *,\n",
    "            x_t: np.ndarray,\n",
    "            score_t: np.ndarray,\n",
    "            t: float,\n",
    "            dt: float,\n",
    "            mask: np.ndarray=None,\n",
    "            center: bool=True,\n",
    "            ode: bool=False,\n",
    "            noise_scale: float=1.0,\n",
    "        ):\n",
    "        \"\"\"Simulates the reverse SDE for 1 step\n",
    "\n",
    "        Args:\n",
    "            x_t: [..., 3] current positions at time t in angstroms.\n",
    "            score_t: [..., 3] rotation score at time t.\n",
    "            t: continuous time in [0, 1].\n",
    "            dt: continuous step size in [0, 1].\n",
    "            mask: True indicates which residues to diffuse.\n",
    "\n",
    "        Returns:\n",
    "            [..., 3] positions at next step t-1.\n",
    "        \"\"\"\n",
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        x_t = self._scale(x_t)\n",
    "        g_t = self.diffusion_coef(t)\n",
    "        f_t = self.drift_coef(x_t, t)\n",
    "        if ode:\n",
    "            # Probability flow ODE\n",
    "            perturb = (f_t - (1/2)*(g_t**2) * score_t) * dt\n",
    "        else:\n",
    "            # Usual stochastic dynamics\n",
    "            z = noise_scale * np.random.normal(size=score_t.shape)\n",
    "            perturb = (f_t - g_t**2 * score_t) * dt + g_t * np.sqrt(dt) * z\n",
    "\n",
    "        if mask is not None:\n",
    "            perturb *= mask[..., None]\n",
    "        else:\n",
    "            mask = np.ones(x_t.shape[:-1])\n",
    "        x_t_1 = x_t - perturb\n",
    "        if center:\n",
    "            com = np.sum(x_t_1, axis=-2) / np.sum(mask, axis=-1)[..., None]\n",
    "            x_t_1 -= com[..., None, :]\n",
    "        x_t_1 = self._unscale(x_t_1)\n",
    "        return x_t_1\n",
    "\n",
    "    def conditional_var(self, t, use_torch=False):\n",
    "        \"\"\"Conditional variance of p(xt|x0).\n",
    "\n",
    "        Var[x_t|x_0] = conditional_var(t)*I\n",
    "\n",
    "        \"\"\"\n",
    "        if use_torch:\n",
    "            return 1 - torch.exp(-self.marginal_b_t(t))\n",
    "        return 1 - np.exp(-self.marginal_b_t(t))\n",
    "\n",
    "    def score(self, x_t, x_0, t, use_torch=False, scale=False):\n",
    "        if use_torch:\n",
    "            exp_fn = torch.exp\n",
    "        else:\n",
    "            exp_fn = np.exp\n",
    "        if scale:\n",
    "            x_t = self._scale(x_t)\n",
    "            x_0 = self._scale(x_0)\n",
    "        return -(x_t - exp_fn(-1/2*self.marginal_b_t(t)) * x_0) / self.conditional_var(t, use_torch=use_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "r3_conf = OmegaConf.create({\n",
    "    'min_b': 0.01,\n",
    "    'max_b': 1.0,\n",
    "    'schedule': 'linear',\n",
    "    'score_scaling': 'var',\n",
    "    'coordinate_scaling': 1.0,\n",
    "    'latent_dim': LATENT_DIM,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuser = R3Diffuser(r3_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, Linear\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dim = 64\n",
    "num_layers = 2\n",
    "nhead = 1\n",
    "dim_feedforward = 128\n",
    "dropout = 0.1 if not DEBUG else 0.0\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import functools as fn\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim=64, output_dim=50):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def get_timestep_embedding(timesteps, embedding_dim, max_positions=10000):\n",
    "    # Code from https://github.com/hojonathanho/diffusion/blob/master/diffusion_tf/nn.py\n",
    "    assert len(timesteps.shape) == 1\n",
    "    timesteps = timesteps * max_positions\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(max_positions) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32, device=timesteps.device) * -emb)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = F.pad(emb, (0, 1), mode='constant')\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return emb\n",
    "\n",
    "class ScoreNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScoreNetwork, self).__init__()\n",
    "        \n",
    "        self.latent_dim = LATENT_DIM\n",
    "        self.model_dim = model_dim\n",
    "        self.dropout = dropout\n",
    "        print(f'Dropout is {self.dropout}')\n",
    "        self.embed_code_and_t = nn.Linear(LATENT_DIM + model_dim, model_dim)\n",
    "        # self.trmr_layer = TransformerEncoderLayer(d_model=model_dim, nhead=8, dim_feedforward=2048, dropout=dropout)\n",
    "        self.pred_score = FeedForward(input_dim=model_dim, hidden_dim=64, output_dim=LATENT_DIM)\n",
    "        self.model = nn.ModuleList([self.embed_code_and_t, self.pred_score]) #*[self.trmr_layer for _ in range(num_layers)], self.pred_score])\n",
    "        \n",
    "        self.timestep_embedder = fn.partial(\n",
    "            get_timestep_embedding,\n",
    "            embedding_dim=self.model_dim,\n",
    "            # max_positions=100\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        device = x.device\n",
    "        B, C = x.shape\n",
    "        t_embed = torch.tile(self.timestep_embedder(torch.tensor([t]).to(device)), dims=[B, 1])\n",
    "        \n",
    "        x = torch.cat([x, t_embed], dim=-1).to(device)\n",
    "        \n",
    "        for module in self.model[:-1]:  # iterate over all modules except the last one\n",
    "            x = module(x)\n",
    "        x = self.model[-1](x.squeeze(0))  # pass through the last module (FeedForward)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout is 0.0\n"
     ]
    }
   ],
   "source": [
    "score_network = ScoreNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14770"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in score_network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(score_network.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                         | 0/250000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "STEP = 0\n",
    "ticker = trange(STEP, n_iters, initial=STEP, total=n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator = cast_loader_to_iterator(loader, cycle_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = next(iterator.train).to(device)\n",
    "# inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     ex_code = ae.encode(ex_batch).to(device)[None, 0, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_code = torch.ones((1, 50)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_t = 0.0\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/6.29.23_just_mlp_KD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(dt=0.001):\n",
    "    score_network.eval()\n",
    "    # log_freq = (1 / dt) / 100\n",
    "    ex_code_np = ex_code.detach().cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        x_t, _ = diffuser.forward_marginal(ex_code_np, t=1.0)\n",
    "        \n",
    "        for i, t in enumerate(np.arange(1.0, 0, -dt)):\n",
    "            # if i % log_freq == 0:\n",
    "                # print(x_t)\n",
    "            x_t = torch.tensor(x_t).float().to(device)\n",
    "            pred_score = score_network(x_t, t)\n",
    "            \n",
    "            # pred_scores.append(pred_score)\n",
    "            # gt_scores.append(gt_score)\n",
    "            \n",
    "            # _, gt_score = diffuser.forward_marginal(ex_code_np.detach().cpu().numpy(), t=t)\n",
    "\n",
    "            # print(pred_score, gt_score)\n",
    "            \n",
    "            x_t = diffuser.reverse(x_t=x_t.detach().cpu().numpy(), score_t=pred_score.detach().cpu().numpy(), t=t, dt=dt, center=False)\n",
    "        \n",
    "        x_0 = x_t\n",
    "        writer.add_embedding(x_0, global_step=step, tag='reverse_sampled_x_0')\n",
    "        writer.add_embedding(ex_code_np, global_step=step, tag='gt_x_0')\n",
    "        euclidean_distance = np.linalg.norm(x_0 - ex_code_np)\n",
    "        writer.add_scalar('sampled_gt_dist', euclidean_distance, global_step=step)\n",
    "        \n",
    "        return x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 0, TRAINING loss is 9.324869159776895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                             | 6/250000 [00:26<229:07:28,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "At step 0, sampled x_0 is [[0.50457698 0.48538044]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                                                            | 257/250000 [00:32<1:38:43, 42.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 250, TRAINING loss is 6.1476639802343716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                            | 507/250000 [00:38<1:36:52, 42.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 500, TRAINING loss is 0.02079265143426566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                                                            | 757/250000 [00:44<1:31:15, 45.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 750, TRAINING loss is 2.241371571861477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▋                                                                                                                                                            | 997/250000 [00:49<1:32:38, 44.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 1000, TRAINING loss is 15.04563556874262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▋                                                                                                                                                           | 1007/250000 [00:50<3:55:09, 17.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "At step 1000, sampled x_0 is [[ 0.97205262 -0.20700971]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                                                                                           | 1257/250000 [00:56<1:29:16, 46.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 1250, TRAINING loss is 1.0866335253332533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                                                                           | 1507/250000 [01:01<1:32:06, 44.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 1500, TRAINING loss is 0.17390081892137485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                                                                           | 1757/250000 [01:07<1:28:55, 46.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 1750, TRAINING loss is 6.656662567451059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                                                                                          | 1996/250000 [01:12<1:29:59, 45.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 2000, TRAINING loss is 17.34319175577793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                                          | 2006/250000 [01:13<3:57:24, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "At step 2000, sampled x_0 is [[2.30497772 1.74918294]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▍                                                                                                                                                          | 2256/250000 [01:19<1:34:11, 43.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 2250, TRAINING loss is 8.77884646479557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▌                                                                                                                                                          | 2506/250000 [01:24<1:28:58, 46.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 2500, TRAINING loss is 10.18981573219172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▋                                                                                                                                                          | 2756/250000 [01:30<1:38:49, 41.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 2750, TRAINING loss is 13.105586694677386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▊                                                                                                                                                          | 3000/250000 [01:35<1:28:46, 46.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 3000, TRAINING loss is 13.688282820680453\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "At step 3000, sampled x_0 is [[2.91017683 2.13161999]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██                                                                                                                                                          | 3260/250000 [01:42<1:29:32, 45.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 3250, TRAINING loss is 3.81940954000475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▏                                                                                                                                                         | 3510/250000 [01:48<1:30:24, 45.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 3500, TRAINING loss is 7.921482244864591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▎                                                                                                                                                         | 3759/250000 [01:53<1:32:19, 44.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 3750, TRAINING loss is 5.787498942470435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▍                                                                                                                                                         | 3999/250000 [01:59<1:29:32, 45.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 4000, TRAINING loss is 5.6449901625452625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                                                                         | 4009/250000 [02:00<3:47:13, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 4000, sampled x_0 is [[2.03971689 0.29811255]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▋                                                                                                                                                         | 4259/250000 [02:05<1:28:58, 46.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 4250, TRAINING loss is 1.0772556036346965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▊                                                                                                                                                         | 4509/250000 [02:11<1:38:11, 41.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 4500, TRAINING loss is 3.8746360061818512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▉                                                                                                                                                         | 4759/250000 [02:16<1:29:51, 45.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 4750, TRAINING loss is 1.05925154522212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███                                                                                                                                                         | 4999/250000 [02:22<1:29:54, 45.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 5000, TRAINING loss is 0.5727294711425971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▏                                                                                                                                                        | 5009/250000 [02:23<4:08:32, 16.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 5000, sampled x_0 is [[1.78487565 0.87041888]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▎                                                                                                                                                        | 5256/250000 [02:28<1:41:38, 40.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 5250, TRAINING loss is 0.5777912368214133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▍                                                                                                                                                        | 5506/250000 [02:34<1:29:04, 45.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 5500, TRAINING loss is 0.5764414805145215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▌                                                                                                                                                        | 5758/250000 [02:40<1:38:00, 41.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 5750, TRAINING loss is 9.50781150741704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▋                                                                                                                                                        | 5998/250000 [02:45<1:30:18, 45.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 6000, TRAINING loss is 0.7080804650273878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▋                                                                                                                                                        | 6008/250000 [02:46<4:05:12, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 6000, sampled x_0 is [[1.42509818 1.32593067]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▉                                                                                                                                                        | 6256/250000 [02:52<1:34:48, 42.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 6250, TRAINING loss is 10.579005989053723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████                                                                                                                                                        | 6506/250000 [02:58<1:29:09, 45.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 6500, TRAINING loss is 7.506427249157408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▏                                                                                                                                                       | 6756/250000 [03:03<1:39:42, 40.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 6750, TRAINING loss is 5.789553218572635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▎                                                                                                                                                       | 6996/250000 [03:09<1:31:11, 44.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 7000, TRAINING loss is 2.73979700976106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▎                                                                                                                                                       | 7006/250000 [03:10<4:01:30, 16.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 7000, sampled x_0 is [[ 2.79170252 -0.86201967]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▌                                                                                                                                                       | 7259/250000 [03:16<1:32:11, 43.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 7250, TRAINING loss is 18.625347101106097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▋                                                                                                                                                       | 7509/250000 [03:22<1:31:07, 44.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 7500, TRAINING loss is 1.1608804094261265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▊                                                                                                                                                       | 7759/250000 [03:27<1:31:11, 44.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 7750, TRAINING loss is 5.071276605074123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▉                                                                                                                                                       | 7999/250000 [03:33<1:28:43, 45.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 8000, TRAINING loss is 1.5101869677870186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▉                                                                                                                                                       | 8009/250000 [03:34<4:04:48, 16.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 8000, sampled x_0 is [[0.50486289 0.23619258]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█████▏                                                                                                                                                      | 8259/250000 [03:39<1:29:33, 44.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 8250, TRAINING loss is 3.8234463255332614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█████▎                                                                                                                                                      | 8509/250000 [03:45<1:28:09, 45.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 8500, TRAINING loss is 15.170269159378048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▍                                                                                                                                                      | 8759/250000 [03:51<1:29:57, 44.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 8750, TRAINING loss is 0.5051821831727161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▌                                                                                                                                                      | 8999/250000 [03:56<1:31:17, 44.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 9000, TRAINING loss is 5.553557328124489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▌                                                                                                                                                      | 9009/250000 [03:58<5:02:47, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 9000, sampled x_0 is [[0.52944924 1.92158886]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▊                                                                                                                                                      | 9258/250000 [04:03<1:29:26, 44.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 9250, TRAINING loss is 9.046347258807636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▉                                                                                                                                                      | 9507/250000 [04:09<1:28:56, 45.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 9500, TRAINING loss is 0.09207347133679977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████                                                                                                                                                      | 9755/250000 [04:15<1:34:26, 42.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 9750, TRAINING loss is 9.979439631349612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▏                                                                                                                                                     | 9999/250000 [04:21<1:32:09, 43.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 10000, TRAINING loss is 0.0014040742676070341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▏                                                                                                                                                    | 10009/250000 [04:22<4:47:12, 13.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 10000, sampled x_0 is [[2.15030501 2.02440651]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▎                                                                                                                                                    | 10257/250000 [04:28<1:35:27, 41.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 10250, TRAINING loss is 12.30003128161973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▌                                                                                                                                                    | 10506/250000 [04:34<1:39:15, 40.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 10500, TRAINING loss is 9.328672109795662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▋                                                                                                                                                    | 10759/250000 [04:40<1:34:13, 42.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 10750, TRAINING loss is 2.3355401824614215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▊                                                                                                                                                    | 10998/250000 [04:45<1:39:48, 39.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 11000, TRAINING loss is 2.9447664654908747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▊                                                                                                                                                    | 11008/250000 [04:46<4:08:17, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 11000, sampled x_0 is [[0.38097428 0.33329486]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████▉                                                                                                                                                    | 11258/250000 [04:52<1:26:14, 46.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 11250, TRAINING loss is 0.1079736594416957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▏                                                                                                                                                   | 11508/250000 [04:58<1:30:56, 43.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 11500, TRAINING loss is 2.3658155772007836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▎                                                                                                                                                   | 11758/250000 [05:03<1:26:57, 45.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 11750, TRAINING loss is 19.011533886135247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▍                                                                                                                                                   | 11998/250000 [05:09<1:33:50, 42.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 12000, TRAINING loss is 0.6262749728004585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▍                                                                                                                                                   | 12008/250000 [05:10<4:10:22, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 12000, sampled x_0 is [[2.20124359 3.36103777]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▌                                                                                                                                                   | 12258/250000 [05:16<1:26:23, 45.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 12250, TRAINING loss is 3.1159014708417647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▊                                                                                                                                                   | 12507/250000 [05:21<1:42:12, 38.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 12500, TRAINING loss is 12.527635702841225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▉                                                                                                                                                   | 12758/250000 [05:27<1:28:51, 44.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 12750, TRAINING loss is 11.42494575855887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████                                                                                                                                                   | 12996/250000 [05:33<1:28:46, 44.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 13000, TRAINING loss is 5.1022287164641815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████                                                                                                                                                   | 13005/250000 [05:34<4:04:03, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 13000, sampled x_0 is [[1.71598385 1.20172896]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████▏                                                                                                                                                  | 13258/250000 [05:40<1:44:27, 37.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 13250, TRAINING loss is 12.413939107150709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████▍                                                                                                                                                  | 13510/250000 [05:45<1:26:42, 45.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 13500, TRAINING loss is 7.412854724592135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▌                                                                                                                                                  | 13756/250000 [05:51<1:30:09, 43.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 13750, TRAINING loss is 3.476950701125429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▋                                                                                                                                                  | 13999/250000 [05:57<1:26:08, 45.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 14000, TRAINING loss is 7.019206291732046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▋                                                                                                                                                  | 14008/250000 [05:58<3:58:10, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 14000, sampled x_0 is [[0.21995478 1.1403005 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▊                                                                                                                                                  | 14255/250000 [06:04<1:35:41, 41.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 14250, TRAINING loss is 0.9676532808577497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▉                                                                                                                                                  | 14508/250000 [06:10<1:27:29, 44.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 14500, TRAINING loss is 10.540893354673832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▏                                                                                                                                                 | 14758/250000 [06:15<1:31:05, 43.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 14750, TRAINING loss is 8.328691019146932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▎                                                                                                                                                 | 14996/250000 [06:21<1:33:43, 41.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 15000, TRAINING loss is 2.166146913410283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▎                                                                                                                                                 | 15005/250000 [06:22<4:41:32, 13.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 15000, sampled x_0 is [[ 0.73871988 -1.16585205]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▍                                                                                                                                                 | 15260/250000 [06:28<1:27:48, 44.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 15250, TRAINING loss is 1.6689268653639768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▌                                                                                                                                                 | 15510/250000 [06:33<1:27:38, 44.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 15500, TRAINING loss is 5.506904687891991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▊                                                                                                                                                 | 15760/250000 [06:39<1:26:46, 44.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 15750, TRAINING loss is 2.9631503220155704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▉                                                                                                                                                 | 16000/250000 [06:44<1:23:35, 46.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 16000, TRAINING loss is 4.7128404290041495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▉                                                                                                                                                 | 16010/250000 [06:45<3:49:34, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 16000, sampled x_0 is [[-0.29672258  2.6645309 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████                                                                                                                                                 | 16260/250000 [06:51<1:28:13, 44.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 16250, TRAINING loss is 2.1992920687814843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████▏                                                                                                                                                | 16505/250000 [06:56<1:30:06, 43.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 16500, TRAINING loss is 5.392240354218522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████▍                                                                                                                                                | 16755/250000 [07:02<1:27:21, 44.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 16750, TRAINING loss is 4.532915419607861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████▌                                                                                                                                                | 16999/250000 [07:08<1:34:28, 41.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 17000, TRAINING loss is 5.347214049611058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████▌                                                                                                                                                | 17009/250000 [07:09<4:05:43, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 17000, sampled x_0 is [[1.50453419 0.27193624]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████▋                                                                                                                                                | 17258/250000 [07:15<1:29:31, 43.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 17250, TRAINING loss is 4.767452203842043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████▊                                                                                                                                                | 17508/250000 [07:20<1:27:13, 44.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 17500, TRAINING loss is 7.142459632898744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████████                                                                                                                                                | 17758/250000 [07:26<1:25:50, 45.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 17750, TRAINING loss is 6.67991035811608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████████▏                                                                                                                                               | 17998/250000 [07:31<1:25:53, 45.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18000, TRAINING loss is 7.9472649226736936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████████▏                                                                                                                                               | 18007/250000 [07:33<4:39:19, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18000, sampled x_0 is [[1.62558231 0.40491458]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████████▎                                                                                                                                               | 18257/250000 [07:38<1:30:55, 42.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18250, TRAINING loss is 5.2414167207647075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████████▍                                                                                                                                               | 18507/250000 [07:44<1:24:21, 45.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18500, TRAINING loss is 5.801379016917711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████████▋                                                                                                                                               | 18757/250000 [07:49<1:27:13, 44.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18750, TRAINING loss is 0.0020549465882734597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████████▊                                                                                                                                               | 18997/250000 [07:55<1:23:11, 46.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 19000, TRAINING loss is 0.0036831962771321884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████████▊                                                                                                                                               | 19007/250000 [07:56<3:40:51, 17.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 19000, sampled x_0 is [[ 0.4719806  -1.09905814]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████████▉                                                                                                                                               | 19257/250000 [08:01<1:29:24, 43.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 19250, TRAINING loss is 0.4783058208558614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████                                                                                                                                               | 19507/250000 [08:07<1:25:58, 44.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 19500, TRAINING loss is 8.13173261317133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▏                                                                                                                                              | 19757/250000 [08:13<1:41:34, 37.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 19750, TRAINING loss is 7.905727692381133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▍                                                                                                                                              | 19999/250000 [08:18<1:28:49, 43.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 20000, TRAINING loss is 7.254880880592733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▍                                                                                                                                              | 20009/250000 [08:20<3:53:40, 16.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 20000, sampled x_0 is [[1.10363429 1.68006854]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▌                                                                                                                                              | 20255/250000 [08:26<1:35:27, 40.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 20250, TRAINING loss is 0.026618871071028435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▋                                                                                                                                              | 20509/250000 [08:31<1:25:33, 44.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 20500, TRAINING loss is 1.3055252443997378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▊                                                                                                                                              | 20759/250000 [08:37<1:30:18, 42.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 20750, TRAINING loss is 0.4639230871783372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████████                                                                                                                                              | 20999/250000 [08:43<1:27:41, 43.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 21000, TRAINING loss is 11.088352327867337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████████                                                                                                                                              | 21009/250000 [08:44<3:52:29, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 21000, sampled x_0 is [[1.84197024 1.03539124]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████▏                                                                                                                                             | 21259/250000 [08:49<1:26:45, 43.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 21250, TRAINING loss is 1.8405232935396816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████▎                                                                                                                                             | 21509/250000 [08:55<1:25:37, 44.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 21500, TRAINING loss is 1.2044713018393867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████▍                                                                                                                                             | 21759/250000 [09:01<1:26:13, 44.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 21750, TRAINING loss is 4.385552333783544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████▋                                                                                                                                             | 21999/250000 [09:06<1:28:44, 42.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 22000, TRAINING loss is 13.108566569522953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████▋                                                                                                                                             | 22009/250000 [09:07<3:42:44, 17.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 22000, sampled x_0 is [[0.44475602 2.37586621]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████▊                                                                                                                                             | 22259/250000 [09:13<1:31:12, 41.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 22250, TRAINING loss is 6.4293958723817015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████▉                                                                                                                                             | 22509/250000 [09:18<1:24:39, 44.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 22500, TRAINING loss is 5.756835355609687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████████                                                                                                                                             | 22759/250000 [09:24<1:24:54, 44.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 22750, TRAINING loss is 8.213761608664932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████████▎                                                                                                                                            | 22999/250000 [09:29<1:23:07, 45.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 23000, TRAINING loss is 3.141403271790659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████████▎                                                                                                                                            | 23009/250000 [09:30<3:58:42, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 23000, sampled x_0 is [[1.56386876 0.29169054]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████████▍                                                                                                                                            | 23259/250000 [09:36<1:23:53, 45.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 23250, TRAINING loss is 6.156617936142579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████████▌                                                                                                                                            | 23508/250000 [09:41<1:21:45, 46.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 23500, TRAINING loss is 6.28008009306158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████████▋                                                                                                                                            | 23758/250000 [09:47<1:22:33, 45.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 23750, TRAINING loss is 7.572971861856204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████████▉                                                                                                                                            | 23998/250000 [09:52<1:24:54, 44.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 24000, TRAINING loss is 7.220709119626492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████████▉                                                                                                                                            | 24008/250000 [09:53<3:48:24, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 24000, sampled x_0 is [[1.34134447 0.71320326]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████                                                                                                                                            | 24258/250000 [09:59<1:22:45, 45.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 24250, TRAINING loss is 0.2778397196022383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████▏                                                                                                                                           | 24507/250000 [10:05<1:24:57, 44.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 24500, TRAINING loss is 3.818189480273568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████▎                                                                                                                                           | 24757/250000 [10:10<1:22:13, 45.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 24750, TRAINING loss is 5.158082002617498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████▌                                                                                                                                           | 25000/250000 [10:16<1:23:50, 44.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 25000, TRAINING loss is 4.044835969150512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████▌                                                                                                                                           | 25005/250000 [10:17<4:59:20, 12.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 25000, sampled x_0 is [[ 0.9806472 -0.7380722]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████▋                                                                                                                                           | 25260/250000 [10:23<1:30:11, 41.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 25250, TRAINING loss is 0.783511447807089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████▊                                                                                                                                           | 25510/250000 [10:29<1:24:25, 44.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 25500, TRAINING loss is 0.617945568450811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████▉                                                                                                                                           | 25755/250000 [10:35<1:33:18, 40.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 25750, TRAINING loss is 3.422512115060984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████████                                                                                                                                           | 25998/250000 [10:40<1:23:36, 44.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 26000, TRAINING loss is 2.987848870677944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████████                                                                                                                                           | 26007/250000 [10:41<3:54:50, 15.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 26000, sampled x_0 is [[1.63594625 1.02660243]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████████▎                                                                                                                                          | 26259/250000 [10:47<1:26:22, 43.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 26250, TRAINING loss is 7.791253691014696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████████▍                                                                                                                                          | 26509/250000 [10:53<1:21:36, 45.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 26500, TRAINING loss is 1.6159845824506562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████████▌                                                                                                                                          | 26759/250000 [10:58<1:27:31, 42.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 26750, TRAINING loss is 1.0770056408386641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████████▋                                                                                                                                          | 26999/250000 [11:04<1:29:32, 41.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 27000, TRAINING loss is 3.1498992481531785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████████▋                                                                                                                                          | 27009/250000 [11:05<3:47:28, 16.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 27000, sampled x_0 is [[0.51790275 1.34077471]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████████▉                                                                                                                                          | 27259/250000 [11:11<1:22:43, 44.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 27250, TRAINING loss is 5.316579155611378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████████                                                                                                                                          | 27509/250000 [11:16<1:28:11, 42.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 27500, TRAINING loss is 0.13330792240688905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████████▏                                                                                                                                         | 27758/250000 [11:22<1:23:19, 44.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 27750, TRAINING loss is 3.94604169301692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████████▎                                                                                                                                         | 27998/250000 [11:27<1:23:09, 44.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 28000, TRAINING loss is 1.7137818008251422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████████▎                                                                                                                                         | 28008/250000 [11:29<3:48:57, 16.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 28000, sampled x_0 is [[0.90096033 0.58835345]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████████▌                                                                                                                                         | 28256/250000 [11:35<1:21:48, 45.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 28250, TRAINING loss is 3.8281796227905045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████████▋                                                                                                                                         | 28509/250000 [11:40<1:22:44, 44.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 28500, TRAINING loss is 3.429600202184769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████████▊                                                                                                                                         | 28759/250000 [11:46<1:26:38, 42.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 28750, TRAINING loss is 3.388602243283977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████████▉                                                                                                                                         | 29000/250000 [11:52<1:25:53, 42.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 29000, TRAINING loss is 3.012247807990387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████████▉                                                                                                                                         | 29005/250000 [11:53<5:07:30, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 29000, sampled x_0 is [[2.29613426 1.54068017]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████████▏                                                                                                                                        | 29257/250000 [11:59<1:24:32, 43.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 29250, TRAINING loss is 6.855962052096552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████████▎                                                                                                                                        | 29507/250000 [12:04<1:23:06, 44.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 29500, TRAINING loss is 0.005480696533579516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████████▍                                                                                                                                        | 29757/250000 [12:10<1:21:26, 45.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 29750, TRAINING loss is 8.888920686309868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████████▌                                                                                                                                        | 30000/250000 [12:16<1:19:49, 45.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 30000, TRAINING loss is 1.8132025916534176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████████▌                                                                                                                                        | 30010/250000 [12:17<3:39:01, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 30000, sampled x_0 is [[1.9779059  2.27238595]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████████▊                                                                                                                                        | 30255/250000 [12:22<1:24:28, 43.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 30250, TRAINING loss is 10.024860849612939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████████▉                                                                                                                                        | 30510/250000 [12:28<1:22:16, 44.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 30500, TRAINING loss is 5.937294252404583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████████████                                                                                                                                        | 30756/250000 [12:34<1:24:24, 43.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 30750, TRAINING loss is 1.7176180999220338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████████████▏                                                                                                                                       | 30997/250000 [12:40<1:24:08, 43.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 31000, TRAINING loss is 4.948153714594726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████████████▏                                                                                                                                       | 31007/250000 [12:41<3:54:12, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 31000, sampled x_0 is [[1.96846609 1.25888099]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████████▍                                                                                                                                       | 31257/250000 [12:47<1:20:48, 45.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 31250, TRAINING loss is 6.492722632077393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████████▌                                                                                                                                       | 31509/250000 [12:52<1:24:10, 43.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 31500, TRAINING loss is 2.899387479923295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████████▋                                                                                                                                       | 31759/250000 [12:58<1:24:46, 42.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 31750, TRAINING loss is 1.599161702611347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████████▊                                                                                                                                       | 31999/250000 [13:04<1:23:23, 43.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 32000, TRAINING loss is 6.597160881610128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████████▊                                                                                                                                       | 32009/250000 [13:05<3:31:37, 17.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 32000, sampled x_0 is [[1.8890869  0.81132749]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████████████                                                                                                                                       | 32259/250000 [13:10<1:20:45, 44.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 32250, TRAINING loss is 4.385632778064623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████████████▏                                                                                                                                      | 32508/250000 [13:16<1:18:57, 45.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 32500, TRAINING loss is 4.664518969705096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████████████▎                                                                                                                                      | 32758/250000 [13:22<1:23:50, 43.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 32750, TRAINING loss is 4.407332717590502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████████████▍                                                                                                                                      | 32998/250000 [13:27<1:18:37, 46.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 33000, TRAINING loss is 0.3236294957181125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████████████▍                                                                                                                                      | 33007/250000 [13:28<3:53:02, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 33000, sampled x_0 is [[1.81708687 0.39144021]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████████████▌                                                                                                                                      | 33256/250000 [13:34<1:19:35, 45.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 33250, TRAINING loss is 8.260458415830087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████████████▊                                                                                                                                      | 33506/250000 [13:39<1:17:32, 46.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 33500, TRAINING loss is 2.547425115215615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████▉                                                                                                                                      | 33756/250000 [13:44<1:17:22, 46.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 33750, TRAINING loss is 1.6049765763487467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████                                                                                                                                      | 33996/250000 [13:50<1:18:43, 45.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 34000, TRAINING loss is 6.1078850347717575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████                                                                                                                                      | 34006/250000 [13:51<3:30:58, 17.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 34000, sampled x_0 is [[1.95218465 1.22155027]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████▏                                                                                                                                     | 34256/250000 [13:56<1:19:59, 44.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 34250, TRAINING loss is 5.856669536756392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████▍                                                                                                                                     | 34506/250000 [14:02<1:33:25, 38.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 34500, TRAINING loss is 2.9793465259563474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████▌                                                                                                                                     | 34759/250000 [14:08<1:31:59, 38.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 34750, TRAINING loss is 4.357068043232629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████▋                                                                                                                                     | 34996/250000 [14:14<1:20:14, 44.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 35000, TRAINING loss is 2.031474547632515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████▋                                                                                                                                     | 35005/250000 [14:15<4:14:49, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 35000, sampled x_0 is [[1.50791406 0.15457535]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████▊                                                                                                                                     | 35259/250000 [14:21<1:27:29, 40.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 35250, TRAINING loss is 0.17833863492494773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████████████████                                                                                                                                     | 35505/250000 [14:27<1:28:00, 40.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 35500, TRAINING loss is 0.8210175169008538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████████████████▏                                                                                                                                    | 35760/250000 [14:32<1:18:40, 45.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 35750, TRAINING loss is 5.409074866024499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████████████████▎                                                                                                                                    | 36000/250000 [14:38<1:24:41, 42.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 36000, TRAINING loss is 2.0518412086890425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████████████████▎                                                                                                                                    | 36005/250000 [14:39<4:56:42, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 36000, sampled x_0 is [[0.32509818 2.11236174]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████████▍                                                                                                                                    | 36259/250000 [14:45<1:21:40, 43.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 36250, TRAINING loss is 3.382098547071261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████████▋                                                                                                                                    | 36509/250000 [14:50<1:18:23, 45.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 36500, TRAINING loss is 6.38389037345549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████████▊                                                                                                                                    | 36759/250000 [14:56<1:18:44, 45.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 36750, TRAINING loss is 6.325852968212528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████████▉                                                                                                                                    | 36998/250000 [15:01<1:18:29, 45.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 37000, TRAINING loss is 1.7567731595397564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████████▉                                                                                                                                    | 37008/250000 [15:02<3:33:09, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 37000, sampled x_0 is [[1.15756038 2.43621556]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████████████████                                                                                                                                    | 37258/250000 [15:08<1:22:56, 42.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 37250, TRAINING loss is 5.848208981308054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████████████████▎                                                                                                                                   | 37506/250000 [15:14<1:17:05, 45.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 37500, TRAINING loss is 3.341171794306508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████████████████▍                                                                                                                                   | 37756/250000 [15:19<1:24:24, 41.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 37750, TRAINING loss is 0.6005717270777418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████████████████▌                                                                                                                                   | 37996/250000 [15:24<1:14:45, 47.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 38000, TRAINING loss is 1.765681473170002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████████████████▌                                                                                                                                   | 38006/250000 [15:25<3:26:35, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 38000, sampled x_0 is [[0.99988779 0.99659746]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████████████████▋                                                                                                                                   | 38256/250000 [15:31<1:21:10, 43.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 38250, TRAINING loss is 6.78290552174454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████████████████▊                                                                                                                                   | 38506/250000 [15:37<1:19:58, 44.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 38500, TRAINING loss is 0.0027442602623971883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████████                                                                                                                                   | 38756/250000 [15:43<1:20:31, 43.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 38750, TRAINING loss is 2.4733355653694877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████████▏                                                                                                                                  | 38996/250000 [15:48<1:23:29, 42.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 39000, TRAINING loss is 0.47565798573113494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████████▏                                                                                                                                  | 39005/250000 [15:49<4:02:47, 14.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 39000, sampled x_0 is [[ 0.94681119 -0.0373031 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████████▎                                                                                                                                  | 39258/250000 [15:55<1:18:15, 44.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 39250, TRAINING loss is 1.9470392665114495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████████▍                                                                                                                                  | 39506/250000 [16:01<1:21:52, 42.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 39500, TRAINING loss is 3.4270136383481162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████████▋                                                                                                                                  | 39757/250000 [16:07<1:19:16, 44.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 39750, TRAINING loss is 3.8880629093703525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████████▊                                                                                                                                  | 40000/250000 [16:12<1:17:46, 45.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 40000, TRAINING loss is 0.734436606175618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████████▊                                                                                                                                  | 40009/250000 [16:14<3:52:01, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 40000, sampled x_0 is [[0.40046161 1.26993676]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████████▉                                                                                                                                  | 40258/250000 [16:19<1:27:27, 39.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 40250, TRAINING loss is 4.802429642230888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████████████                                                                                                                                  | 40508/250000 [16:25<1:17:52, 44.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 40500, TRAINING loss is 3.4920321281059046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████████████▎                                                                                                                                 | 40758/250000 [16:31<1:18:40, 44.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 40750, TRAINING loss is 2.2003836441365383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████████████▍                                                                                                                                 | 40998/250000 [16:36<1:16:35, 45.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 41000, TRAINING loss is 1.6679307355490596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████████████▍                                                                                                                                 | 41007/250000 [16:37<3:50:30, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 41000, sampled x_0 is [[0.17860719 1.790713  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████████████████▌                                                                                                                                 | 41256/250000 [16:43<1:23:22, 41.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 41250, TRAINING loss is 1.926788971792689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████████████████▋                                                                                                                                 | 41506/250000 [16:48<1:18:49, 44.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 41500, TRAINING loss is 0.5196226919705167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████████████████▉                                                                                                                                 | 41756/250000 [16:54<1:17:08, 44.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 41750, TRAINING loss is 1.4708803859283028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████████████                                                                                                                                 | 41996/250000 [16:59<1:16:19, 45.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 42000, TRAINING loss is 1.2841713267600183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████████████                                                                                                                                 | 42006/250000 [17:01<3:42:51, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 42000, sampled x_0 is [[0.41881687 1.60707867]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████████████▏                                                                                                                                | 42256/250000 [17:06<1:17:48, 44.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 42250, TRAINING loss is 3.3946011219404593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████████████▎                                                                                                                                | 42506/250000 [17:12<1:15:28, 45.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 42500, TRAINING loss is 0.09633431215090299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████████████▌                                                                                                                                | 42760/250000 [17:17<1:24:10, 41.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 42750, TRAINING loss is 6.591003611008677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████████████▋                                                                                                                                | 43000/250000 [17:23<1:21:01, 42.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 43000, TRAINING loss is 1.9115274860731255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████████████▋                                                                                                                                | 43005/250000 [17:24<4:50:14, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 43000, sampled x_0 is [[1.07188677 1.42100823]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████████████▊                                                                                                                                | 43257/250000 [17:30<1:24:06, 40.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 43250, TRAINING loss is 1.014088644938189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████████████▉                                                                                                                                | 43509/250000 [17:36<1:20:54, 42.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 43500, TRAINING loss is 1.582126178748387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████▏                                                                                                                               | 43755/250000 [17:42<1:22:30, 41.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 43750, TRAINING loss is 0.013299596955141275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████▎                                                                                                                               | 44000/250000 [17:47<1:16:31, 44.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 44000, TRAINING loss is 2.8920470970901366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████▎                                                                                                                               | 44010/250000 [17:49<3:25:42, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 44000, sampled x_0 is [[1.33520671 1.47027294]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████▍                                                                                                                               | 44255/250000 [17:54<1:16:35, 44.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 44250, TRAINING loss is 1.525943505421758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████▌                                                                                                                               | 44509/250000 [18:00<1:18:28, 43.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 44500, TRAINING loss is 3.7635777250630262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████▊                                                                                                                               | 44759/250000 [18:06<1:18:44, 43.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 44750, TRAINING loss is 3.1513531332785862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████▉                                                                                                                               | 44999/250000 [18:11<1:19:01, 43.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 45000, TRAINING loss is 4.8098354100802645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████▉                                                                                                                               | 45009/250000 [18:12<3:44:13, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 45000, sampled x_0 is [[1.52313222 1.60397804]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████████████                                                                                                                               | 45259/250000 [18:18<1:15:04, 45.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 45250, TRAINING loss is 2.246781522001835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████████████▏                                                                                                                              | 45509/250000 [18:23<1:15:06, 45.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 45500, TRAINING loss is 0.21205710944275563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████████████▎                                                                                                                              | 45754/250000 [18:29<1:21:18, 41.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 45750, TRAINING loss is 2.436457098233204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████████████▌                                                                                                                              | 45998/250000 [18:34<1:12:31, 46.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 46000, TRAINING loss is 0.5184594805987941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████████████▌                                                                                                                              | 46008/250000 [18:35<3:24:51, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 46000, sampled x_0 is [[1.58046904 2.06482079]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████████████████▋                                                                                                                              | 46258/250000 [18:41<1:15:27, 45.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 46250, TRAINING loss is 2.319965347311393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████████████████▊                                                                                                                              | 46508/250000 [18:47<1:16:18, 44.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 46500, TRAINING loss is 2.442594008615215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████████████████▉                                                                                                                              | 46758/250000 [18:52<1:15:16, 45.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 46750, TRAINING loss is 0.14521703710486075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████████▏                                                                                                                             | 46998/250000 [18:58<1:16:08, 44.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 47000, TRAINING loss is 4.650907867598299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████████▏                                                                                                                             | 47008/250000 [18:59<3:48:16, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 47000, sampled x_0 is [[1.8823613 0.7719062]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████████▎                                                                                                                             | 47257/250000 [19:04<1:13:33, 45.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 47250, TRAINING loss is 4.406650246929409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████████▍                                                                                                                             | 47507/250000 [19:10<1:22:11, 41.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 47500, TRAINING loss is 0.888973183200514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████████▌                                                                                                                             | 47757/250000 [19:16<1:15:52, 44.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 47750, TRAINING loss is 0.02064560892221759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████████▊                                                                                                                             | 48000/250000 [19:21<1:14:58, 44.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 48000, TRAINING loss is 3.7246328117738567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████████▊                                                                                                                             | 48005/250000 [19:22<4:23:00, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 48000, sampled x_0 is [[ 0.94409158 -1.10489639]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████████▉                                                                                                                             | 48260/250000 [19:28<1:15:17, 44.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 48250, TRAINING loss is 7.413920814038808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████████████                                                                                                                             | 48510/250000 [19:34<1:13:54, 45.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 48500, TRAINING loss is 5.702024017950189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████▏                                                                                                                            | 48760/250000 [19:39<1:13:30, 45.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 48750, TRAINING loss is 2.979469306622644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████▍                                                                                                                            | 49000/250000 [19:45<1:18:53, 42.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 49000, TRAINING loss is 3.3301491957149962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████▍                                                                                                                            | 49010/250000 [19:46<3:23:16, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 49000, sampled x_0 is [[0.51513315 1.18130712]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████▌                                                                                                                            | 49260/250000 [19:51<1:16:48, 43.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 49250, TRAINING loss is 2.0068538009385026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████▋                                                                                                                            | 49510/250000 [19:57<1:14:02, 45.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 49500, TRAINING loss is 4.601941479528953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████▊                                                                                                                            | 49755/250000 [20:02<1:21:22, 41.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 49750, TRAINING loss is 3.341092396754314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████                                                                                                                            | 50000/250000 [20:08<1:16:11, 43.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 50000, TRAINING loss is 2.5180298494253526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████                                                                                                                            | 50010/250000 [20:09<3:33:57, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 50000, sampled x_0 is [[1.35072486 0.71341004]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▏                                                                                                                           | 50260/250000 [20:14<1:15:00, 44.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 50250, TRAINING loss is 2.289624764387556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▎                                                                                                                           | 50505/250000 [20:20<1:17:40, 42.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 50500, TRAINING loss is 1.353561519876569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▍                                                                                                                           | 50760/250000 [20:26<1:14:13, 44.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 50750, TRAINING loss is 8.481081838437756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▌                                                                                                                           | 51000/250000 [20:31<1:12:32, 45.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 51000, TRAINING loss is 2.8240677630691877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▋                                                                                                                           | 51010/250000 [20:32<3:17:16, 16.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 51000, sampled x_0 is [[0.58430468 2.22721202]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████████████████▊                                                                                                                           | 51260/250000 [20:38<1:14:16, 44.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 51250, TRAINING loss is 0.2756631946874314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████████████████▉                                                                                                                           | 51505/250000 [20:44<1:13:20, 45.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 51500, TRAINING loss is 3.6348712737702744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████████                                                                                                                           | 51760/250000 [20:49<1:15:15, 43.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 51750, TRAINING loss is 2.6614196515551773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████████▏                                                                                                                          | 51999/250000 [20:55<1:12:31, 45.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 52000, TRAINING loss is 3.0587295116322606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████████▏                                                                                                                          | 52004/250000 [20:56<4:10:16, 13.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 52000, sampled x_0 is [[0.86800714 0.62239685]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████████▍                                                                                                                          | 52259/250000 [21:02<1:20:35, 40.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 52250, TRAINING loss is 3.6023346297265153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████████▌                                                                                                                          | 52509/250000 [21:07<1:11:24, 46.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 52500, TRAINING loss is 4.106117575480525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████████▋                                                                                                                          | 52759/250000 [21:13<1:12:02, 45.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 52750, TRAINING loss is 0.24997501170797037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████████▊                                                                                                                          | 52999/250000 [21:18<1:12:59, 44.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 53000, TRAINING loss is 3.196265317822175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████████▊                                                                                                                          | 53009/250000 [21:19<3:16:46, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 53000, sampled x_0 is [[ 0.57275718 -0.18029878]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████████████████████                                                                                                                          | 53259/250000 [21:25<1:10:48, 46.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 53250, TRAINING loss is 3.484267094686035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████████████████████▏                                                                                                                         | 53509/250000 [21:30<1:10:47, 46.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 53500, TRAINING loss is 1.789548056387399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████████████▎                                                                                                                         | 53758/250000 [21:36<1:11:51, 45.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 53750, TRAINING loss is 2.5656655065728233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████████████▍                                                                                                                         | 53998/250000 [21:41<1:12:01, 45.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 54000, TRAINING loss is 0.2884894575074528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████████████▍                                                                                                                         | 54008/250000 [21:43<4:19:34, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 54000, sampled x_0 is [[1.0917525  1.87443372]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████████████▋                                                                                                                         | 54257/250000 [21:48<1:10:03, 46.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 54250, TRAINING loss is 2.1463366438631013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████████████▊                                                                                                                         | 54507/250000 [21:54<1:11:59, 45.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 54500, TRAINING loss is 1.3310648365878655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████████████▉                                                                                                                         | 54757/250000 [22:00<1:09:12, 47.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 54750, TRAINING loss is 0.7361484931229677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████████                                                                                                                         | 54997/250000 [22:05<1:13:01, 44.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 55000, TRAINING loss is 5.008113300475773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████████                                                                                                                         | 55007/250000 [22:06<3:26:10, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 55000, sampled x_0 is [[1.44156778 1.08405696]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████████▎                                                                                                                        | 55257/250000 [22:11<1:09:25, 46.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 55250, TRAINING loss is 2.8961693952079175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████████▍                                                                                                                        | 55507/250000 [22:17<1:10:30, 45.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 55500, TRAINING loss is 5.4330296580811135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████████▌                                                                                                                        | 55757/250000 [22:23<1:13:06, 44.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 55750, TRAINING loss is 6.0483144366406245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████████▋                                                                                                                        | 55997/250000 [22:28<1:13:19, 44.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 56000, TRAINING loss is 1.517919518918878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████████▋                                                                                                                        | 56006/250000 [22:29<3:37:35, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 56000, sampled x_0 is [[0.86717154 1.07335785]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████████████████▉                                                                                                                        | 56258/250000 [22:35<1:10:55, 45.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 56250, TRAINING loss is 2.77285736516897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████████████                                                                                                                        | 56508/250000 [22:40<1:11:58, 44.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 56500, TRAINING loss is 9.43455056147997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████████████▏                                                                                                                       | 56758/250000 [22:46<1:18:04, 41.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 56750, TRAINING loss is 2.9572014649935197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████████████▎                                                                                                                       | 56998/250000 [22:52<1:11:59, 44.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 57000, TRAINING loss is 0.061075997167824234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████████████▎                                                                                                                       | 57008/250000 [22:53<3:32:53, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 57000, sampled x_0 is [[1.07499615 1.89371149]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████████████▍                                                                                                                       | 57258/250000 [22:58<1:09:44, 46.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 57250, TRAINING loss is 4.608586923838633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████████████▋                                                                                                                       | 57508/250000 [23:04<1:13:55, 43.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 57500, TRAINING loss is 1.0362396874082238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████████████▊                                                                                                                       | 57758/250000 [23:10<1:13:34, 43.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 57750, TRAINING loss is 2.2396231997542024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████████████▉                                                                                                                       | 57999/250000 [23:15<1:15:27, 42.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 58000, TRAINING loss is 2.5706221682429877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████████████▉                                                                                                                       | 58009/250000 [23:17<3:21:58, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 58000, sampled x_0 is [[2.10107763 2.07352915]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████████████████████                                                                                                                       | 58259/250000 [23:22<1:19:36, 40.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 58250, TRAINING loss is 5.385482521696145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████████████████████▎                                                                                                                      | 58504/250000 [23:28<1:24:12, 37.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 58500, TRAINING loss is 1.7291296865722015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████████████████████▍                                                                                                                      | 58758/250000 [23:34<1:19:50, 39.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 58750, TRAINING loss is 3.139189728070638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████████████████████▌                                                                                                                      | 58998/250000 [23:40<1:17:32, 41.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 59000, TRAINING loss is 2.147369628082418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████████████████████▌                                                                                                                      | 59007/250000 [23:41<4:13:16, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 59000, sampled x_0 is [[1.35377839 1.81783644]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████████████████████▋                                                                                                                      | 59257/250000 [23:47<1:16:42, 41.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 59250, TRAINING loss is 2.814013604841933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████████████████████▉                                                                                                                      | 59506/250000 [23:52<1:23:23, 38.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 59500, TRAINING loss is 2.0416742989118557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████████████████                                                                                                                      | 59755/250000 [23:58<1:13:53, 42.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 59750, TRAINING loss is 3.1314390560702967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████████████████▏                                                                                                                     | 60005/250000 [24:05<4:47:32, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 60000, sampled x_0 is [[1.21247855 1.62803592]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████████████████▎                                                                                                                     | 60260/250000 [24:10<1:10:47, 44.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 60250, TRAINING loss is 1.9035477009690833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████████████████▌                                                                                                                     | 60510/250000 [24:16<1:10:15, 44.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 60500, TRAINING loss is 0.37017358476833495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████████████████▋                                                                                                                     | 60760/250000 [24:22<1:07:39, 46.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 60750, TRAINING loss is 2.0074662938962256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████████████████████████████▍                                                                                             | 98996/250000 [39:29<1:00:58, 41.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 99000, TRAINING loss is 1.230239250176456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████████████████████████████▍                                                                                             | 99006/250000 [39:31<2:44:59, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 99000, sampled x_0 is [[0.96796684 0.42286449]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████████████▎                                                                                              | 99260/250000 [39:36<57:01, 44.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 99250, TRAINING loss is 1.8050118870590999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████████████▍                                                                                              | 99510/250000 [39:42<56:42, 44.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 99500, TRAINING loss is 2.3043822376653074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████████████▋                                                                                              | 99759/250000 [39:48<57:04, 43.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 99750, TRAINING loss is 1.7186174238201872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████████████▊                                                                                              | 99999/250000 [39:53<55:33, 45.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 100000, TRAINING loss is 0.3340905510368608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████████████████████████████▌                                                                                            | 100009/250000 [39:54<2:48:05, 14.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 100000, sampled x_0 is [[0.7286717  1.51906913]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████████████▌                                                                                             | 100256/250000 [40:00<55:33, 44.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 100250, TRAINING loss is 0.02392853758022688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████████████▋                                                                                             | 100506/250000 [40:05<54:10, 45.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 100500, TRAINING loss is 1.2826042691834008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████████████▊                                                                                             | 100756/250000 [40:11<54:25, 45.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 100750, TRAINING loss is 1.9408549697588457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████████████████                                                                                             | 100996/250000 [40:16<54:16, 45.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 101000, TRAINING loss is 0.24998223128474056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████████████▏                                                                                           | 101006/250000 [40:18<2:40:47, 15.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 101000, sampled x_0 is [[0.56657951 0.64741136]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████████████████████████████████▏                                                                                            | 101256/250000 [40:23<55:18, 44.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 101250, TRAINING loss is 1.419070639467777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████████████████████████████████▎                                                                                            | 101506/250000 [40:29<56:14, 44.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 101500, TRAINING loss is 2.4109240061418755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████████████████████████████████▍                                                                                            | 101759/250000 [40:35<55:50, 44.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 101750, TRAINING loss is 1.6412747442011684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████████████████████████████████▋                                                                                            | 101999/250000 [40:40<54:50, 44.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 102000, TRAINING loss is 0.9209945770060045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████████████████████████████▊                                                                                           | 102008/250000 [40:41<2:57:58, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 102000, sampled x_0 is [[0.91879822 1.16965807]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████████████████████████████████▊                                                                                            | 102256/250000 [40:47<54:34, 45.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 102250, TRAINING loss is 2.670710651225791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████████████████████████████████▊                                                                                         | 106999/250000 [42:38<56:41, 42.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 107000, TRAINING loss is 1.922336144617669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████████████████████▉                                                                                        | 107009/250000 [42:39<2:39:00, 14.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 107000, sampled x_0 is [[1.13721726 1.23142414]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████████████████████████████████▉                                                                                         | 107259/250000 [42:45<52:58, 44.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 107250, TRAINING loss is 0.4438050070338043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████████████████████████████████████                                                                                         | 107509/250000 [42:51<55:10, 43.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 107500, TRAINING loss is 0.5822386607853934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████████████████████████████████████▏                                                                                        | 107759/250000 [42:56<53:48, 44.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 107750, TRAINING loss is 0.7450454565228436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████████████████████████████████████▍                                                                                        | 107999/250000 [43:02<52:48, 44.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 108000, TRAINING loss is 1.8482470863481453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████████████████████████████████▌                                                                                       | 108009/250000 [43:03<3:00:00, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 108000, sampled x_0 is [[0.14946072 0.33661538]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████████████████████████████████████▌                                                                                        | 108258/250000 [43:09<51:16, 46.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 108250, TRAINING loss is 2.270380775419099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████████████████████████████████████▋                                                                                        | 108509/250000 [43:15<51:09, 46.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 108500, TRAINING loss is 1.256835754040459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████████████████████████████████████▊                                                                                        | 108759/250000 [43:20<53:19, 44.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 108750, TRAINING loss is 0.8474587783346168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████████████████████                                                                                        | 108999/250000 [43:26<57:26, 40.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 109000, TRAINING loss is 1.4193725099323127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████████████████████████████████████▏                                                                                      | 109009/250000 [43:27<2:38:52, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 109000, sampled x_0 is [[1.15862321 1.29751302]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████████████████████▏                                                                                       | 109258/250000 [43:33<54:34, 42.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 109250, TRAINING loss is 2.231695723879157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████████████████████▎                                                                                       | 109508/250000 [43:38<51:29, 45.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 109500, TRAINING loss is 1.1514972677551856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████████████████████▍                                                                                       | 109758/250000 [43:44<52:57, 44.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 109750, TRAINING loss is 1.100096377456754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████████████████████▋                                                                                       | 109998/250000 [43:49<51:35, 45.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 110000, TRAINING loss is 0.6209004943328298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████████████████████████████████████▊                                                                                      | 110007/250000 [43:51<2:45:53, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 110000, sampled x_0 is [[1.17932364 1.00236266]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████████████████████▊                                                                                       | 110257/250000 [43:56<50:36, 46.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 110250, TRAINING loss is 4.369968732476152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████████████████████▉                                                                                       | 110507/250000 [44:02<56:35, 41.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 110500, TRAINING loss is 2.967342091390991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████████████████████████████████                                                                                       | 110757/250000 [44:07<49:57, 46.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 110750, TRAINING loss is 0.13038299259031955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████████████████████████████████▎                                                                                      | 110997/250000 [44:13<54:09, 42.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 111000, TRAINING loss is 3.9801487913383524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████████████████████▍                                                                                     | 111007/250000 [44:14<2:38:37, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 111000, sampled x_0 is [[0.56913937 1.83485368]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████████████████████████████████████▍                                                                                      | 111256/250000 [44:20<56:09, 41.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 111250, TRAINING loss is 1.2499932334788437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████████████████████████████████████▌                                                                                      | 111506/250000 [44:25<52:07, 44.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 111500, TRAINING loss is 0.48430388193075263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████████████████████████████████████▋                                                                                      | 111658/250000 [44:29<52:22, 44.02it/s]"
     ]
    }
   ],
   "source": [
    "eval_freq=1000\n",
    "for step in ticker:\n",
    "\n",
    "    score_network.train()\n",
    "    \n",
    "    # if DEBUG:\n",
    "    #     inputs = ex_batch\n",
    "    # else:\n",
    "    #     raise NotImplementedError\n",
    "    #     inputs = next(iterator.train)\n",
    "    #     # inputs = inputs.to(device)\n",
    "        \n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    # '''\n",
    "    # Get encoded representation\n",
    "    # '''\n",
    "    \n",
    "    # code = ae.encode(inputs)\n",
    "    \n",
    "    t = rng.uniform(min_t, 1.0)\n",
    "    x_t, gt_score_t = diffuser.forward_marginal(ex_code.detach().cpu().numpy(), t=t)\n",
    "    \n",
    "    score_scaling = torch.tensor(diffuser.score_scaling(t)).to(device)\n",
    "    gt_score_t = torch.tensor(gt_score_t).to(device)\n",
    "    \n",
    "    pred_score_t = score_network(torch.tensor(x_t).float().to(device), t)\n",
    "\n",
    "    score_mse = (gt_score_t - pred_score_t)**2\n",
    "    score_loss = torch.sum(\n",
    "        score_mse / score_scaling[None, None]**2,\n",
    "        dim=(-1, -2)\n",
    "    ) #/ (loss_mask.sum(dim=-1) + 1e-10)    \n",
    "    \n",
    "    # comps = {k: v.mean().item() for k, v in comps._asdict().items()}\n",
    "    score_loss.backward()\n",
    "    optimizer.step()\n",
    "    # check_loss(score_)\n",
    "\n",
    "    if step % config.training.logs_freq == 0:\n",
    "        # log to logger object\n",
    "        # logger.log(\"train\", loss=loss.item(), step=step, **comps)\n",
    "        writer.add_scalar('Training loss', score_loss.item(), global_step=step)\n",
    "        print(f'At step {step}, TRAINING loss is {score_loss.item()}')\n",
    "        \n",
    "    if step % eval_freq == 0:\n",
    "        sampled_x_0 = eval(dt=0.01)\n",
    "        print(f'At step {step}, sampled x_0 is {sampled_x_0[:, :2]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(score_network, '6.29.23.1D_mlp_score_network.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/rsg/chemistry/johnyang/miniconda3/envs/cellot/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sampling x_t from learned reverse process, gt x_0 = 1.0, random init')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAHHCAYAAACBYj2uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAA9hAAAPYQGoP6dpAADkUklEQVR4nOzdd3hTZfsH8G/2aJqkmxbaUgh7Ftlt2UNEEEQQ6mgpKK8yHD8VcbBUEJwvw4FaUF9ARaaKqAgKxYmUDUKh0EILpSNJ04yTcX5/lBySZnTQCffnurzet6cnJ09O2+Tmee7nvnksy7IghBBCCCH1gt/QAyCEEEIIuZ1Q8EUIIYQQUo8o+CKEEEIIqUcUfBFCCCGE1CMKvgghhBBC6hEFX4QQQggh9YiCL0IIIYSQekTBFyGEEEJIPaLgixBCCCGkHlHw5QePx8PChQu5r9etWwcej4cLFy402Jgawq5du9C9e3dIpVLweDxotdqGHpJPCxcuBI/Ha+hh1LlffvkFPB4Pv/zyS0MPhRBCfKr4OdrQBg0ahEGDBtXosampqWjZsmWtjKPOg69jx47hvvvuQ2xsLKRSKZo3b47hw4dj5cqVdf3UxIuTJ09i4cKFVQ4gi4qKMGnSJMhkMqxevRqff/45AgIC6naQhJAmo7rvKbXJ4XBg+fLliIuLg1QqRdeuXbFx48Z6H4fBYMCCBQtw5513Ijg4GDweD+vWravWNbRaLR599FGEhYUhICAAgwcPxqFDh+pmwKRWGI1GLFy4sEb/CK7T4Ou3335Dz549ceTIETzyyCNYtWoVpk+fDj6fj//+9791+dR14qGHHoLJZEJsbGxDD6XGTp48iUWLFlX5jfLvv/9GaWkpXnnlFUybNg0PPvggRCJR3Q6SENJkVPc9pTa9+OKLmDt3LvcP+piYGCQnJ+OLL76o13EUFhZi8eLFOHXqFLp161btxzscDowePRobNmzArFmzsHz5chQUFGDQoEE4e/ZsHYz49vXjjz/ixx9/rNFjP/roI/z777/c10ajEYsWLapR8CWs0Qiq6LXXXoNKpcLff/8NtVrt9r2CgoK6fOo6IRAIIBAIGnoY9cr5c6r48/PGaDRCLpfX8Ygap7KysiYzI9gYx9oYx1SRw+EAwzCQSqUNPRQC4PLly3jrrbcwc+ZMrFq1CgAwffp0DBw4EM8++ywmTpxYb+/XkZGRyM/PR7NmzXDw4EH06tWrWo//+uuv8dtvv2HTpk247777AACTJk1C27ZtsWDBAmzYsKFWxtkU/s7qmlgsrvFja3PioU5nvs6dO4dOnTp5/eAODw93+3rt2rUYMmQIwsPDIZFI0LFjR7z//vsej2vZsiXuvvtu/PLLL+jZsydkMhm6dOnCRZ5btmxBly5dIJVKcccddyAzM9Pt8ampqVAoFDh//jxGjhyJgIAAREVFYfHixWBZ1u/r8Zbz5RxPRkYGevfuDalUilatWuGzzz7zePzRo0cxcOBAyGQytGjRAq+++irWrl1baR5ZQUEBwsLCMGjQILcxZmVlISAgAPfff7/fcbuOf+LEiQCAwYMHg8fj+c0bGjRoEFJSUgAAvXr1Ao/HQ2pqKve9zp07459//sGAAQMgl8vxwgsvcOOdNm0aIiIiIJVK0a1bN3z66adu175w4QJ4PB7efPNNrF69Gq1atYJcLseIESOQm5sLlmXxyiuvoEWLFpDJZLjnnntQXFxcpdfpzf/+9z/ccccdkMlkCA4OxuTJk5Gbm+t2zv79+zFx4kTExMRAIpEgOjoaTz31FEwmk9t5zt+hc+fO4a677kJgYCAeeOABAOX5DbNmzcK2bdvQuXNnSCQSdOrUCbt27fIY0+XLl5GWloaIiAjuvPT0dI/zLl26hHHjxiEgIADh4eF46qmnYLFYqvS6nTlwJ0+eRHJyMoKCgpCYmFjl+zJr1iwoFAoYjUaPa0+ZMgXNmjWD3W7njn3//fdISkpCQEAAAgMDMXr0aJw4caLK9+/s2bOYMGECmjVrBqlUihYtWmDy5MnQ6XRu16jKz9Pf/Th9+jQmTZoEpVKJkJAQPPHEEzCbzW7nOn+W69evR6dOnSCRSLifY2ZmJkaNGgWlUgmFQoGhQ4fijz/+8Hg+rVaLp556Ci1btoREIkGLFi3w8MMPo7CwkDvHYrFgwYIF0Gg03O/dc8895/Ez/umnn5CYmAi1Wg2FQoF27dpxf3NOK1euRKdOnSCXyxEUFISePXvW+IPb4XBg4cKFiIqKglwux+DBg3Hy5Em0bNmSex+o7ntKbb2XAcD27dthtVrx+OOPc8d4PB4ee+wxXLp0Cb///nv1X3QNSSQSNGvWrMaP//rrrxEREYF7772XOxYWFoZJkyZh+/btVf57d+Xvb//o0aNITU1Fq1atIJVK0axZM6SlpaGoqMjrNbKyspCamgq1Wg2VSoWpU6d6vCdYLBY89dRTCAsLQ2BgIMaOHYtLly55HVtV/n6cn7cZGRmYM2cOwsLCoFarMWPGDDAMA61Wi4cffhhBQUEICgrCc889V+lnOOCZ8+XMn/3qq6/w2muvoUWLFpBKpRg6dCiysrLcHuua83XhwgWEhYUBABYtWsT97lc1v61OZ75iY2Px+++/4/jx4+jcubPfc99//3106tQJY8eOhVAoxDfffIPHH38cDocDM2fOdDs3KysLycnJmDFjBh588EG8+eabGDNmDD744AO88MIL3B/j0qVLMWnSJPz777/g82/EmXa7HXfeeSf69u2L5cuXY9euXViwYAFsNhsWL15c7deZlZWF++67D9OmTUNKSgrS09ORmpqKO+64A506dQJQ/kHrfHOaN28eAgIC8PHHH0MikVR6/fDwcLz//vuYOHEiVq5ciTlz5sDhcCA1NRWBgYF47733qjTOAQMGYM6cOVixYgVeeOEFdOjQAQC4/63oxRdfRLt27bBmzRosXrwYcXFxaN26Nff9oqIijBo1CpMnT8aDDz6IiIgImEwmDBo0CFlZWZg1axbi4uKwadMmpKamQqvV4oknnnB7jvXr14NhGMyePRvFxcVYvnw5Jk2ahCFDhuCXX37B3LlzkZWVhZUrV+KZZ57xGpxU5rXXXsPLL7+MSZMmYfr06bh27RpWrlyJAQMGIDMzk/vHwaZNm2A0GvHYY48hJCQEf/31F1auXIlLly5h06ZNbte02WwYOXIkEhMT8eabb7rN+GVkZGDLli14/PHHERgYiBUrVmDChAnIyclBSEgIAODq1avo27cv9wEfFhaG77//HtOmTYNer8eTTz4JADCZTBg6dChycnIwZ84cREVF4fPPP8eePXuqdQ8mTpyINm3aYMmSJdwbVFXuy/3334/Vq1fju+++4z5kgfJZzm+++Qapqanc7MLnn3+OlJQUjBw5EsuWLYPRaMT777+PxMREZGZmuiWqert/DMNg5MiRsFgsmD17Npo1a4bLly/j22+/hVarhUqlqtbP059JkyahZcuWWLp0Kf744w+sWLECJSUlHv9o2rNnD7766ivMmjULoaGhaNmyJU6cOIGkpCQolUo899xzEIlE+PDDDzFo0CD8+uuv6NOnD4DyPKCkpCScOnUKaWlp6NGjBwoLC7Fjxw5cunQJoaGhcDgcGDt2LDIyMvDoo4+iQ4cOOHbsGN555x2cOXMG27ZtAwCcOHECd999N7p27YrFixdDIpEgKysLBw4c4Mb60UcfYc6cObjvvvu4YPLo0aP4888/kZycXK3fFwCYN28eli9fjjFjxmDkyJE4cuQIRo4c6RakVvc9pbbey4DyD/CAgACP5+rduzf3fdd/aFRksVhQWlpapecKDQ2t8rhqIjMzEz169HD7nALKX8uaNWtw5swZdOnSpUbX9va3/9NPP+H8+fOYOnUqmjVrhhMnTmDNmjU4ceIE/vjjD49NS5MmTUJcXByWLl2KQ4cO4eOPP0Z4eDiWLVvGnTN9+nT873//Q3JyMvr37489e/Zg9OjRHuOp6t+Pk/O9YNGiRfjjjz+wZs0aqNVq/Pbbb4iJicGSJUuwc+dOvPHGG+jcuTMefvjhGt2n119/HXw+H8888wx0Oh2WL1+OBx54AH/++afX88PCwvD+++/jsccew/jx47nAuWvXrlV7QrYO/fjjj6xAIGAFAgHbr18/9rnnnmN/+OEHlmEYj3ONRqPHsZEjR7KtWrVyOxYbG8sCYH/77Tfu2A8//MACYGUyGXvx4kXu+IcffsgCYPfu3csdS0lJYQGws2fP5o45HA529OjRrFgsZq9du8YdB8AuWLCA+3rt2rUsADY7O9tjPPv27eOOFRQUsBKJhP2///s/7tjs2bNZHo/HZmZmcseKiorY4OBgj2v6MmXKFFYul7Nnzpxh33jjDRYAu23btkof52rTpk0e98Qf52v++++/3Y4PHDiQBcB+8MEHbsffffddFgD7v//9jzvGMAzbr18/VqFQsHq9nmVZls3OzmYBsGFhYaxWq+XOnTdvHguA7datG2u1Wt1eu1gsZs1ms9/xLliwgHX9tb5w4QIrEAjY1157ze28Y8eOsUKh0O24t9/BpUuXsjwez+33yvk79Pzzz3ucD4AVi8VsVlYWd+zIkSMsAHblypXcsWnTprGRkZFsYWGh2+MnT57MqlQqbizO+/nVV19x55SVlbEajaZKP0fn/ZgyZYrb8areF4fDwTZv3pydMGGC23lfffWV2+99aWkpq1ar2UceecTtvCtXrrAqlcrtuK/7l5mZyQJgN23a5PP1VOfn6Y3zfowdO9bt+OOPP84CYI8cOcIdA8Dy+Xz2xIkTbueOGzeOFYvF7Llz57hjeXl5bGBgIDtgwADu2Pz581kA7JYtWzzG4XA4WJZl2c8//5zl8/ns/v373b7/wQcfsADYAwcOsCzLsu+88w4LwO39qaJ77rmH7dSpk9/XX1VXrlxhhUIhO27cOLfjCxcuZAGwKSkp3LHqvqewbO28l40ePdrj84Fly/8+fP19unK+t1Xlv+r4+++/WQDs2rVrq/yYgIAANi0tzeP4d999xwJgd+3aVa0xsKzvv32W9f5et3HjRo/PMuc1Ko5t/PjxbEhICPf14cOHWQDs448/7nZecnKyx+doVf9+nD+fkSNHcn8vLMuy/fr1Y3k8Hvuf//yHO2az2dgWLVqwAwcO9HNHyg0cONDtvL1797IA2A4dOrAWi4U7/t///pcFwB47dow7lpKSwsbGxnJfX7t2zeP1VVWdLjsOHz4cv//+O8aOHYsjR45g+fLlGDlyJJo3b44dO3a4nSuTybj/r9PpUFhYiIEDB+L8+fMeSw4dO3ZEv379uK+dkfKQIUMQExPjcfz8+fMeY5s1axb3/52zDwzDYPfu3dV+nR07dkRSUhL3dVhYGNq1a+f2vLt27UK/fv3QvXt37lhwcDC33FIVq1atgkqlwn333YeXX34ZDz30EO65555qj7e2SCQSTJ061e3Yzp070axZM0yZMoU7JhKJMGfOHBgMBvz6669u50+cOJGb0QBu/MwefPBBCIVCt+MMw+Dy5cvVGuOWLVvgcDgwadIkFBYWcv81a9YMbdq0wd69e7lzXX8Hy8rKUFhYiP79+4NlWY/lawB47LHHvD7nsGHD3GYIu3btCqVSyf0+sCyLzZs3Y8yYMWBZ1m1cI0eOhE6n43Y57dy5E5GRkVweCADI5XI8+uij1boP//nPf2p0X3g8HiZOnIidO3fCYDBwj//yyy/RvHlzbmbhp59+glarxZQpU9yuJxAI0KdPH7f77Ov+OX8PfvjhB6/LnNUZd2UqzqbPnj0bQPn9djVw4EB07NiR+9put+PHH3/EuHHj0KpVK+54ZGQkkpOTkZGRAb1eDwDYvHkzunXrhvHjx3s8v3NmYdOmTejQoQPat2/v9nqGDBkCANzrcc7mbd++HQ6Hw+trUqvVuHTpEv7+++8q3QN/fv75Z9hsNrclPeDGfbpZtfFeZjKZvK4cOHPyKqYLVDRy5Ej89NNPVfqvrt3sa/Gn4t8+4P5eZzabUVhYiL59+wKA1x2WFa+RlJSEoqIi7nfd+XczZ84ct/OcM/hO1fn7cZo2bZrbTFyfPn3AsiymTZvGHRMIBOjZs6fXz/qqmjp1qls+mPMz/Wau6U+dLjsC5blCW7ZsAcMwOHLkCLZu3Yp33nkH9913Hw4fPsy9sR04cAALFizA77//7vHGq9Pp3D6gXQMs4MabdnR0tNfjJSUlbsf5fL7bDx4A2rZtCwA12rFTcTwAEBQU5Pa8Fy9edAsYnTQaTZWfJzg4GCtWrMDEiRMRERGBFStWVHustal58+YeyYsXL15EmzZtPKbPnUsDFy9edDt+sz/Lypw9exYsy6JNmzZev++aQJmTk4P58+djx44dHs9T8R8AQqEQLVq08HrNyn4frl27Bq1WizVr1mDNmjVer+Hc6HDx4kVoNBqPZYB27dp5fZwvcXFxbl9X577cf//9ePfdd7Fjxw4kJyfDYDBg586dmDFjBjcu544sZ9BQkVKpdPva2/2Li4vD008/jbfffhvr169HUlISxo4diwcffJD7+Vdn3P5UfHzr1q3B5/M9/v4r3rdr167BaDR6vf8dOnSAw+FAbm4uOnXqhHPnzmHChAl+x3H27FmcOnWKyx2pyPl7cP/99+Pjjz/G9OnT8fzzz2Po0KG49957cd9993F/a3PnzsXu3bvRu3dvaDQajBgxAsnJyUhISPA7Bm+cf6cV35+Cg4MRFBRU7etVVBvvZTKZzGsulHNZ1DXA8CYyMhKRkZHVft66cLOvxZ+Kv8MAUFxcjEWLFuGLL77w2PxW8b0O8HxPc/4OlJSUQKlU4uLFi+Dz+W7/6AQ836eq8/fj67n9fUZU9/PBlb/XWBfqPPhyEovF6NWrF3r16oW2bdti6tSp2LRpExYsWIBz585h6NChaN++Pd5++21ER0dDLBZj586deOeddzz+pedrB4uv42wVkvBuRn0+7w8//ACg/Bfi0qVLVcpvqSs384bgVNc/S4fDAR6Ph++//97rNRUKBYDyf5ENHz4cxcXFmDt3Ltq3b4+AgABcvnwZqampHr+DEonEI8Cs6tid13rwwQe5DQ0VVTlvoIoq/qyqel8AoG/fvmjZsiW++uorJCcn45tvvoHJZHJLjna+ps8//9xr4rHrLCbg+/699dZbSE1Nxfbt2/Hjjz9izpw5XF5WixYtqjXu6vBVmLc2fsf9cTgc6NKlC95++22v33d+wMhkMuzbtw979+7Fd999h127duHLL7/EkCFD8OOPP0IgEKBDhw74999/8e2332LXrl3YvHkz3nvvPcyfPx+LFi2q09dREzf7XhYZGYm9e/eCZVm3n19+fj4AICoqyu/jTSaT10DDm5tJpq8K527Jiqr6Wvzx9js8adIk/Pbbb3j22WfRvXt3KBQKOBwO3HnnnV5nVhvqs9Xfc3s7fjPjqe/XWG/Bl6uePXsCuPGL9c0338BisWDHjh1u0WdVlxCqy+Fw4Pz589xsFwCcOXMGAGqtem1FsbGxHjsnAHg95suuXbvw8ccf47nnnsP69euRkpKCP//80+ODzZ+6rv4eGxuLo0ePwuFwuH24nj59mvt+fWrdujVYlkVcXJzbz7uiY8eO4cyZM/j000/dEjbrYsnBuRvIbrdj2LBhfs+NjY3F8ePHPT5gXGvN1ERV74vTpEmT8N///hd6vR5ffvklWrZsyS1TOK8HlCdUV/aaKtOlSxd06dIFL730En777TckJCTggw8+wKuvvlrtcfty9uxZtxmBrKwsOByOSv/+w8LCIJfLvd7/06dPg8/ncwFT69atcfz4cb/Xa926NY4cOYKhQ4dW+rfJ5/MxdOhQDB06FG+//TaWLFmCF198EXv37uXuuXPH4P333w+GYXDvvffitddew7x586pVIsP5d5qVleV2n4qKijxmAmrynlIb72Xdu3fHxx9/jFOnTrktDTsTpF1TPLz58ssvPdImfKnrIKN79+7Yv3+/x/vmn3/+CblcflO/6xWVlJTg559/xqJFizB//nzu+M3UE4uNjYXD4cC5c+fcZrUq/p1U5++nKbiZz9M6zfly/qukIuf6sPOH5Iw4Xc/V6XRYu3ZtnY3NWRfG+byrVq2CSCTC0KFD6+T5Ro4cid9//x2HDx/mjhUXF2P9+vVVerxWq8X06dPRu3dvLFmyBB9//DEOHTqEJUuWVGsczhovddUi6K677sKVK1fw5ZdfcsdsNhtWrlwJhUKBgQMH1snz+nLvvfdCIBBg0aJFHr+LLMtyW6u9/Q6yLFsnxYAFAgEmTJiAzZs3e/1wvnbtGvf/77rrLuTl5eHrr7/mjhmNRp/LlVVV1fvidP/998NiseDTTz/Frl27MGnSJLfvjxw5EkqlEkuWLIHVavX7mnzR6/Ww2Wxux7p06QI+n88tyVR33L6sXr3a7Wtnx41Ro0b5fZxAIMCIESOwfft2tyXKq1evYsOGDUhMTOSWWCdMmMClWlTkHPukSZNw+fJlfPTRRx7nmEwmlJWVAYDXMivO4MJ5byq+drFYjI4dO4JlWa8/E3+GDh0KoVDoUe7H9X3TqbrvKbX1XnbPPfdAJBK57ZBkWRYffPABmjdvjv79+/t9fEPlfOXn5+P06dNuP5P77rsPV69exZYtW7hjhYWF2LRpE8aMGVOlXfFV5e29DgDefffdGl/T+XdTcfm44jWr8/fTFDh3udfk87ROZ75mz54No9GI8ePHo3379mAYBr/99hv3L2fnvzpGjBgBsViMMWPGYMaMGTAYDPjoo48QHh7udSr2ZkmlUuzatQspKSno06cPvv/+e3z33Xd44YUXfOZe3KznnnsO//vf/zB8+HDMnj2bKzURExOD4uLiSiPoJ554AkVFRdi9ezcEAgHuvPNOTJ8+Ha+++iruueeeKldV7t69OwQCAZYtWwadTgeJRMLVV6sNjz76KD788EOkpqbin3/+QcuWLfH111/jwIEDePfddxEYGFgrz1NVrVu3xquvvop58+bhwoULGDduHAIDA5GdnY2tW7fi0UcfxTPPPIP27dujdevWeOaZZ3D58mUolUps3ry5ztb7X3/9dezduxd9+vTBI488go4dO6K4uBiHDh3C7t27uQ9bZ2eIhx9+GP/88w8iIyPx+eef33Qx26reF6cePXpAo9HgxRdfhMVi8ajHpFQq8f777+Ohhx5Cjx49MHnyZISFhSEnJwffffcdEhISvH5wu9qzZw9mzZqFiRMnom3btrDZbPj888+5YLUm4/YlOzsbY8eOxZ133onff/+d2yJflb+jV199lau59fjjj0MoFOLDDz+ExWLB8uXLufOeffZZfP3115g4cSLS0tJwxx13oLi4GDt27MAHH3yAbt264aGHHsJXX32F//znP9i7dy8SEhJgt9tx+vRpfPXVV/jhhx/Qs2dPLF68GPv27cPo0aMRGxuLgoICvPfee2jRogW36WHEiBFo1qwZEhISEBERgVOnTmHVqlUYPXq0298dj8fDwIED/VbljoiIwBNPPIG33nqLu09HjhzB999/j9DQULf3q+q+p9TWe1mLFi3w5JNP4o033oDVakWvXr2wbds27N+/H+vXr6+0wGpt53ytWrUKWq0WeXl5AMpXdJx1rmbPns3lKs2bNw+ffvopsrOzuZnW++67D3379sXUqVNx8uRJhIaG4r333oPdbvdYMk5NTfV4fHUolUoMGDAAy5cvh9VqRfPmzfHjjz8iOzu7xq+9e/fumDJlCt577z3odDr0798fP//8s9eVnar+/TQFMpkMHTt2xJdffom2bdsiODgYnTt3rrS0FoC6LTXx/fffs2lpaWz79u1ZhULBisViVqPRsLNnz2avXr3qdu6OHTvYrl27slKplG3ZsiW7bNkyNj093Wtph9GjR3s8FwB25syZbsec5QzeeOMN7lhKSgobEBDAnjt3jh0xYgQrl8vZiIgIdsGCBazdbve4ZlVKTXgbT8XtrCxbvpU+KSmJlUgkbIsWLdilS5eyK1asYAGwV65c8XUb2e3bt7MA2LfeesvtuF6vZ2NjY9lu3bp5Ld/hy0cffcS2atWKFQgElW4R91dqwte29qtXr7JTp05lQ0NDWbFYzHbp0sVj27W3nw3L3tj2W7HcgK9xVFSx1ITT5s2b2cTERDYgIIANCAhg27dvz86cOZP9999/uXNOnjzJDhs2jFUoFGxoaCj7yCOPcGUiXMfv/B3yxtvvIcuW/564bs9n2fL7NHPmTDY6OpoViURss2bN2KFDh7Jr1qxxO+/ixYvs2LFjWblczoaGhrJPPPEEu2vXrmqVmvBVoqAq98XpxRdfZAGwGo3G5/Pt3buXHTlyJKtSqVipVMq2bt2aTU1NZQ8ePMid4+v+nT9/nk1LS2Nbt27NSqVSNjg4mB08eDC7e/fumxq3t/tx8uRJ9r777mMDAwPZoKAgdtasWazJZHI719fPkmVZ9tChQ+zIkSNZhULByuVydvDgwW7lb5yKiorYWbNmsc2bN2fFYjHbokULNiUlxa3ECMMw7LJly9hOnTqxEomEDQoKYu+44w520aJFrE6nY1mWZX/++Wf2nnvuYaOiolixWMxGRUWxU6ZMYc+cOcNd58MPP2QHDBjAhoSEsBKJhG3dujX77LPPctdg2fKSIADYyZMn+71PLFu+ff/ll19mmzVrxspkMnbIkCHsqVOn2JCQELdt/ixb9feU2n4vs9vt7JIlS9jY2FhWLBaznTp1citzU5+cZYe8/ef6meEstVKxvFBxcTE7bdo0NiQkhJXL5ezAgQO9vt9NmDCBlclkbElJid/x+Pvbv3TpEjt+/HhWrVazKpWKnThxIpuXl+fxmefrGt4+C00mEztnzhw2JCSEDQgIYMeMGcPm5uZ6LcVQlb8fX+/5vsbk733Zla9SExU/c5yfURXf+11LTbAsy/7222/sHXfcwYrF4mqVneCxbD1kzDUiqamp+Prrr922zTekJ598Eh9++CEMBsNt17qIkPq2cOFCLFq0CNeuXavzwpmN0c6dO3H33XfjyJEjNSraqdVqERQUhFdffRUvvvhiHYyQVCYiIgIPP/ww3njjjYYeCrkJdZrzRdxVrNVSVFSEzz//HImJiRR4EULq3N69ezF58uQqBV7eaks5c3hc27OQ+nPixAmYTCbMnTu3oYdCblKD7Ha8XfXr1w+DBg1Chw4dcPXqVXzyySfQ6/V4+eWXb/raVdk2HRwcfFNNRQkhTVt1Zku+/PJLrFu3DnfddRcUCgUyMjKwceNGjBgxoka1w6qK3st869Spk0cRUtI0UfBVj+666y58/fXXWLNmDXg8Hnr06IFPPvkEAwYMuOlrV2Xb9N69e+lfrISQKunatSuEQiGWL18OvV7PJeG/+uqrdfq89F5Gbge3Xc7XrSo/Px8nTpzwe84dd9xRK9WpCSGkrtB7GbkdUPBFCCGEEFKPKOGeEEIIIaQe3ZY5Xw6HA3l5eQgMDKzzdjuEEEIIqR0sy6K0tBRRUVE+++s2Bbdl8JWXl9ek+kcRQggh5Ibc3Fy0aNGioYdRY7dl8OVstZGbm9uk+kgRQgghtzO9Xo/o6Oh6b1VX227L4Mu51KhUKin4IoQQQpqYpp4y1HQXTAkhhBBCmiAKvgghhBBC6hEFX4QQQggh9YiCL0IIIYSQekTBFyGEEEJIPaLgixBCCCGkHlHwRQghhBBSjyj4IoQQQgipRxR8EUIIIYTUIwq+CCGEEELq0W3ZXuhWoTMyKDQw0JutUMpECA0QQyUXN/SwCCGEEOIHBV9NkM7IoMRoxcvbjmF/VhF3fECbULw+oSui1LIGHB0hhBBC/GnQZcelS5eiV69eCAwMRHh4OMaNG4d///230sdt2rQJ7du3h1QqRZcuXbBz5856GG3jkKc1YefxK1j87Ql0iwnCJyk98d4DPZCe2gtdo9VYsP04dEamoYdJCCGEEB8aNPj69ddfMXPmTPzxxx/46aefYLVaMWLECJSVlfl8zG+//YYpU6Zg2rRpyMzMxLhx4zBu3DgcP368HkfeMHRGBnM3H0WUSobkPrHIzCnBtE8P4vH1h5C27m9k5pTg/t4xKCqj4IsQQghprHgsy7INPQina9euITw8HL/++isGDBjg9Zz7778fZWVl+Pbbb7ljffv2Rffu3fHBBx9U6Xn0ej1UKhV0Oh2USmWtjL0+nCswYMyqDGz+T3+8uvMkDrgsOTolaEKwcEwntIkIbIAREkIIIXWnqX5+V9Socr50Oh0AIDg42Oc5v//+O55++mm3YyNHjsS2bdt8PsZiscBisXBf6/X6mxtoNdRmUrzebEVaYhwcLOs18AKAA1lFsDsaTTxNCCGEkAoaTfDlcDjw5JNPIiEhAZ07d/Z53pUrVxAREeF2LCIiAleuXPH5mKVLl2LRokW1NtaqulRsxLwtR2stKV4pFSE+Wl3psqKRsVf72oQQQgipH42mztfMmTNx/PhxfPHFF7V+7Xnz5kGn03H/5ebm1vpzVHS5xIi5FQIvANh3thDPbz5ao6T4UEX5jJmtkpktlUxU7WsTQgghpH40ipmvWbNm4dtvv8W+ffvQokULv+c2a9YMV69edTt29epVNGvWzOdjJBIJJBJJrYy1KnRGBheLjMjM0WLWEA3io9Ww2ByQigQ4lFOC9IxsFBqYai8/quRitAiS4Zuj+UjQhHhdekxqE8oFaYQQQghpfBo0+GJZFrNnz8bWrVvxyy+/IC4urtLH9OvXDz///DOefPJJ7thPP/2Efv361eFIq6fQwKDUYsPq5B7I15ncvhelkmJ1cg+UWaw1unYzpRSn8/WYntgKo7tEIkIp5QK7qzoTBrQJcwvqqBArIYQQ0rg0aPA1c+ZMbNiwAdu3b0dgYCCXt6VSqSCTledEPfzww2jevDmWLl0KAHjiiScwcOBAvPXWWxg9ejS++OILHDx4EGvWrGmw11GRzsSguVqKUrMN3x3Ld5uhStCEYNZgDdSymgdAjw5oBZYFdh7LR4bLtZPahCKpTRj3dZ7WhLmbj2L/2ULuGBViJYQQQhpWg5aa4PF4Xo+vXbsWqampAIBBgwahZcuWWLduHff9TZs24aWXXsKFCxfQpk0bLF++HHfddVeVn7cut6rmaU24UFiGEIUYi7/1XQ7itXGd0TJUUe3rnysw4JujeTh4oRiHcrRIS4xzW9a8qjfjrs7lS7CzNma6BV5OA9qEYuWUeJoBI4QQ0qRQqYlaUJW475dffvE4NnHiREycOLEORnRznEVQu0WrMbJThN9yEDXdkag3W9GluQpr9p3HiinxWHsgG6v2ZHHfT9CEoF+rENgdrNfACyhP+q9JzhkhhBBCbl6j2e14Kyg0MNh/thBf/JUDM+Pwe25Ngy+5WACLzYG0xDisPZDtEeAdyCrCy9uPQ2fyv5uy1FyznDNCCCGE3BwKvmqR3myFXCzA6xO6Qiz0f2trUg5CZ2RwKEcLlay83pevmbX9Zwshl/if1Ayo5PuEEEIIqRv0CVyLlFIRNyPVq2UwkjSh2J/lufSX1CYU4YHVL31RaGDwyrcn8cWjfWG22iEXCzxyvpylLMR8vs9yFAmaEIgFFHcTQgghDYGCr1oUqhCjf6sQrNqThcwcLVYlxwNg3QqtJrUJxfIJXWuUb6U3W2Fk7Ehb9zc+n9bHZ87Xiinx0JoYTE0oL91Rcbfl1IS468uSATV+rYQQQgipGQq+apFKLuaWG42MHbM2ZCItMQ6pCXGw2ByQCPmICZYjsoZlHpTS8qXKQgODfJ0Jaw9key3kWlRqRnSQDA9+8hfSEuOQ5vL8mblazNmYiW9mJdba6yaEEEJI1VHwVcuCXGa0jIzdbVYKAH5+emCNrx2qEGNAm1DsO1sIgIfMHK3X2a8l4zvj0MUSxMeoPZ4fKC81EaoQUwFWQgghpAFQ8FXL3AMkdwNusvWPSi7G6xO64vnNR2G22n3ueIxQSjF7YyZWTIkH4Lns+Mo9nVHG2KkAKyGEENIAGrTIakOp6yJteVoTnt981C0AG9AmFMsmdK3xkqOTzshAa7TCaLUjT2vCtE8Pepzz3gM98Pj6QwhViLFsQleEKyUwmO1QSIUo0JvRMkSOhd+cpAKshBBCmhQqskp8ChAL8Oo9nWFzsDDZ7DAydqhlIsjFgpu6rmu7IGeelzcSIZ8reZFeYWYsQROCl+/uSAVYCSGEkAZCwVctu1RsxMIdxzG5T6zHkuDNLOs5q+c7g6b0jGx8OaOv13OPXdbh5dEdfBZhvVxi8lumggqwEkIIIXWHgq9adLnEiLlbjiI+Jshr4HPwYgl+PXMNPWODYLDYqpXk7qye72Rk7Pj5VAGSNCFupSzkYgG6tVAjPFCCeVuPe72WgMfzW6ZCWYMCsIQQQgipGgq+aonOyOBikREHsoqQlhDnFtTIxQLMGNgKd3WOxMELxcgpNsJic6DEaMVf2cUY1Das0lwwvZfZqDX7zmN1cg+M6hKJCKUUFpsD0UFyfPDLWaQktPJ6HblYgGCFGMt2nfY6K8YD8Nak7tV+/YQQQgipGgq+akmhgYHWVB4gWWw3+jqGKsT4OKUXzl7Ro9BgwbfH8j1ysOJCAyAXC/zOgDlrfFXEgsXOY/nIuH7NT6f2xoxBGpSabR7nysUCrJgSD4PF5rM1UUZWEQxmGyKabh4jIYQQ0qhR8FVL9GYrJNcLrDr/Vy4WID21F5btOo3n7+yA13ed8jrbBABLxnXxG3x5K2GRlhiHTzJuLG/KxQKEB0pQbGTw+/kiJGhCkJmj5XK7ggPEePvHfzGlTyx3vre8rzIL5XwRQgghdYUa/NUSpVSEzFwtEjQhOHZZhyRNCNIS42Cw2JCZowWfB5+zTQeyilDGeM5UuXLW+BrQJpQ7VrG5dlpiHBwsC53JivSMbExPbIVPUnriZJ4OmblaCAU87M8q4nZDrpgSj8ycEkz79CAeX38Iaev+RmZOCZQy2ulICCGE1BWa+aolUhEfp/J0mJ7YCnIxH33iggEAPPC4IMwfI2Ov9Dmi1DKsnBKPQgODUrMVVod7ibb4aDWKyhhIhHwYGTuOXNLizBU95gxti7d+OI2OkeVriZm5WrzkZzfk/O3HqdYXIYQQUkco+KoFOiODBdtPYEqfWFwrNWPHkTwcytFi04x+0Jqs6BETBAGf5/caqus7DCtr+aOS3/j6XIHB7RoWmwM8Ho+bgeveQo0h7cO55PrU6422nWUqXth63OfSY1EZ1foihBBC6gIFX7WgoNSC3acL8Nv5InyW1ptLfneAxcGLxegbF4KMrEIkaUKxP8uzuGlSm1CEB0rciqg6udYGqxiYKaRCtzwwiZCPo5e0OJ2nw9SEOAQrxCg130iudwZlB7KKcOl6rS9fJSfGxzevy1tGCCGE3LYo56sWOHc5Ghk7Ckot3PGSMitYFpAIBViz7zymJrZEkibE7bFJ13stAvAIvIDyivMLth/HpWIj/m/TEWw9fBnFZQz+vVKKC4UGvDKuM5cHdjxPh36tgjEtqRU2/HkRAj4POtON5Pn0jGxMTYjDkPZhCFNIfPaGPJBVhIU7TkBnZGrvJhFCCCEEAM181YoAl7ZBzp2OAGBzsOjSXAU+H4iPUWPWhkykJcYhNSEOFpsDEiEfV/Vm8OFZRNVVu0ilW9V811mqoe3DsGR8F1hsDjhYFou/OYF/ru9wLLPY3cZjZOx4fvNRfJzSC6fydOjXKsTtWq723wJthipbwiWEEEIaAgVftSBALOTKOgDglhcP5ZQgPlqNfJ0ZUxPiAHgu701NiIPWxMDup725s4ejt1mqn09fA2M/hlXXE/Gd1e5X7clCj5ggt6VGAJjcOwZv/HAamTlapKf08vu6mnKbocqWcAkhhJCGQsFXLVDLRXhiaBvYHSw+2n8eKQkt4QDLJbYX6C2YvbF81ivNZdYrM1eLORsz8c2sRL/Xt9gciI9WVzpLVbEK/qGcEpy8nv8FlC8n9ogJQnpGNtIS46CQ+v/xB/oo7NrYOftg/nOxhGtA7txM8OuZa7irczOaASOEENJgKPiqBSq5GM3VMjy/+Sj2ZxXhj/PFXKDlcJQn5MfHeA+eBrQJRahCzP3/fV6WHtUyEZdX5kup2epRBT89IxsrpsRjw58XER8ThEcSWyFQKuSOjegYgURNCLdBwNe4mppCA4N/Lpb43EzQr1UIBV+EEEIaDCXc1xKz1cEt+RkZO1btycK0Tw9iykd/oJlSitlD2iChYrJ9m1Asm9CVKx9RsYgqUB4ExYbIofbT7FouFiBILoaQz0OSy+ONjB1zNmaiY5QK/VuFIEotg0wswNoD2egYpcK7u88gNSHOY1yJmhAsGe+/4n5jpjdb/W4meHn7cdpMQAghpMHQzFct8db4GigPgGZuOIQdsxKwdFwX2BwsTDY7jIwdapkIcpdk/YpFVAOlIoQqbiSJe5ulcrYwemnbcfyTUz7b42BZLugwMnYczdXiwd4xKLXYYGTsbs2/XWfpXJdDGbsDTZVCIqzSMm1TDS4JIYQ0bRR81RJfja+B8gCIz+NBKOTjxUqSwF2LqLpqHiTH6/d2xbytx9we//LdHbF6TxZXP2yOS24ZAMQEyxEeKEGp2YbcYiMs14MqZ/Nv5yxdRcPah1f3FjQaYkHlE7pNeTMBIYSQpo2Cr1oiFfH95k8FSIR4ZtMRr3W8nt98tErtfAKlQrx6T2eUMeUzWM6q+PO2HAPgvVG2RMCHwWLD3C1H8dSwtlzdL9cSFN6fq2km2wOA1sQgXCnxe05Tfn2EEEKaNgq+aoHOyGDBjhNITYgDC/cG2s78KYPZ5rOO174qLIP5Kp0wZ2gbAPBZrX7pvV0QGyzHgawizL2zvK5YgibEowSFq6acbA8ACokI3xzNQ5ImhMvDc5XUxF8fIYSQpo2Cr1pQaGCw+1QBfjtX5DN/yldOGACEKsQQ8IHT+XrozTYoZUIEycWIUEoBXC+d8PVRj9ZE+84W4rFBrQHAZ4J5eKAEuuvPna8zI1Ilw6zBGny0/7xbCQqnAS6bAJqqUIUYJy7rkJIQBwc8g+GlTXgzASGEkKaPgq9a4Ays/OVP+coJC1WIsX56X7y47bjXGbOYkABc0Zu99oR0PmeiJsRngrnF5kB4YPkSnJDPw8wNhzBjYCs8Oawt+DzgpdEd4WBZFJcxCAuUIFIpbfKBiUouxqJ7OmPB9uOIjwnigmG1TITYEDmaB8kbeoiEEEJuYxR81QJ/yfYAuF2L3up4LZvQFYu/PeEWeMnFAnSPCUJuiQkmqx2XSkw+ry3g8ZB6fQbLW86XUiqEWMjnlhrjY9R456ezeOens27XGdAmtEp5Z01FlFqGNyd287lzlBBCCGkoVOerFjiT7b1x5k/5quPVTCn1CLxWTIlHZk4JHvj4T7+BFwAYreX9GqPUMu5x0z49iMfXH0Laur9x5mopig0MpibE4VxBKZ4d2R5JGvcxJN0CS43eqORitA5XoHtMEFqHK26510cIIaRpopmvm1SVZHvnh763Ol5FZRa361XM3bLYHDiZr/eZHK+WiTC5dwx0JsZrzter353Cphn9kLL2L3yc0gurfj6DbjFqpCa0hMXmgEomQnSQDJHU75AQQgipFxR83aSqJNu7cp190V8PwFxVzN2SCPlcmyDAPbhL0ISgRZAM/VuFwMg4vAZnRsaOn05dxf+NaIcVP59BxyiV27Lk7+eLsC5fjzcndrulZoZ0RgZFZQxsDhYOloXRYoNKLkZoAC09EkIIaVgUfN2kqiTbu6pYMuKTlJ5u9cGcxU+dnHlac7w05i4otUAlE+FaqcVv78c1+85j68z+CAuUeO11ODUhDkVlt07F9zytCfO3H8fk3jEes4EVi9oSQggh9Y2Cr5tUlWR7J52R8ajVNXfzUayf3hevfHsCh3K0CA+UuCXOswDujW+OBTtOuAVNriUhAqX+G28bGTtYFj57HQLAwjGdqvOyGy3nPe4Wrfb6eqtT1JYQQgipC5Rwf5Ocuxi9qVistNDAeBRaLTQweODjPzAjqTV2zklCTlEZ0lN6IjOnBLM3ZkLA4+FaqRmjOjfDJyk98d4DPfBJSk+M6hLJXUMk4HHFU71JahMKsPC6LAmUH7c72Oq+9EbJeY/jo9U+X6+zqC0hhBDSEGjm6yY5dzE+v/moWxkJb8VK/TXfVgeI8eq3J/DEsHZYvusUDmQVYdYQDfJ1Jnx3LN9nJfqVU+JRVMZwxVMB9yArSROKhWM6QWfyH2wYGXu1Xndj5bzHFZdvK6LejoQQQhoKBV+1wNsuRm81pbwtUcrFAryX3AN8HtA+SgW92cq1xImPVgPwPWPlnMFRSIR4OP0vzBjYCnPvbA+gPJgS8nnIyCqEzeGASuZ9ic25xCkXC5CZUwKlTNSkk9Kd9/hW7l1JCCGkaaPgq5ao5JUHLBULrTpreoUrJcjXmREfreYaXwMAY3eArWQ1sNRsRaRahh4+iqcmakIwpXcMpEK+R5FXX/0gm3JSeqhCjKQ2obd070pCCCFNG+V81aOKhVadNb1s1/OtnLsYgfLAqEWQrEozOBFKKZaM7+JR6NVZZyziesugikVeffWDdCal64xNMy9q5mANTubpMDUhziMP7lboXUkIIaRp47FsZXMrtx69Xg+VSgWdTgelUlnvz68zMig0MLDY7LhrRQa+eKQvMs4Vol+rEPx+vgiZOSXo1TIYEYESsEClOV/OQOKq3oySMqa8ObdUiKCAG825Kz53qdkKqUiAO/+73+c4f356IFqHK2r1tde1cwUGjFmVgbTEOPSMCYJKLoJQwEOJ0QqbnUXr0ADEhgY09DAJIYTUQEN/ftcWWnZsAM4lysycEgCAUMBDekY2RnSMwKnrMzahARIkf/wH3n+gB2Z7S6T3MoMToZR6BFu+nhsAMnNKvPaDPJRTgvSM7CaZlK43W33WXAOAbY/3Rywo+CKEENJwKPhqQM7k8IysQtwRE4S0dX9j3dReMDJ2WK9Xxnew5UVDF47tBKuNRanZCqVUBIVEcNMtgVQyEVZMiceGPy8CKE/wN1vt6N86BCM6RiBQ0vR+PSpuavAILsUC6Iy3TkFZQgghTU/T+3S9hTgT8NfsO49VyfHYfDAXYqEAb/90Bv83vB3SEuPw+R8XkNwnFgt3nPDoG/n6vV3RIlhe4+cPkAix4c+LSO4T65F0n6gJwZJ7u97U62sIrpsabsUNBYQQQpq+Bk2437dvH8aMGYOoqCjweDxs27at0sesX78e3bp1g1wuR2RkJNLS0lBU5L0UQ2PnTILvGRuEWRsyMWOQBou+OYGOUSrweEC/ViHoGKXymhSfkVWEeVuP3VRSvMFs83v9F2/y+g3BdWPBrbqhgBBCSNPWoMFXWVkZunXrhtWrV1fp/AMHDuDhhx/GtGnTcOLECWzatAl//fUXHnnkkToeae3SGRmcv2bAmaulKLVY8dLoDtjyeH+IBHwcyCpCfLQaP526CiGf57dS+/6brNSuN1vr9PoNxVl37e4ukVTlnhBCSKPToMuOo0aNwqhRo6p8/u+//46WLVtizpw5AIC4uDjMmDEDy5Ytq6sh1ro8rQmvfXcSjwxojbd+OM0VVAWALx7pC6C85MSHv57H0PYRKCrzHyDcTFK8UipCvs5cZ9dvSCq5GOcLy/ye01RfGyGEkKatSdX56tevH3Jzc7Fz506wLIurV6/i66+/xl133eX3cRaLBXq93u2/hqAzMpi//ThmDGyNNyoEXgAQIBUAKK/ObmTs2H3qKtSyqjfurq5QhbhOr9/QqtP0nBBCCKkvTSr4SkhIwPr163H//fdDLBajWbNmUKlUlS5bLl26FCqVivsvOjq6nkbsrtDAoH2kEqVmG7ccJhcLMGuIBp+k9IREKECiJgSZuVoMaR8GHg+IVEk9iqc63WyldpVcjNgQeZ1dv6FVp+k5IYQQUl8aTZFVHo+HrVu3Yty4cT7POXnyJIYNG4annnoKI0eORH5+Pp599ln06tULn3zyic/HWSwWWCwW7mu9Xo/o6Oh6L9KWmVOC4jIGFpsDj68/5LYb70BWEUIVYqyf3hf/3f0vnhjWDou/PYF/r5Ti45ReeOuHf7E/y7Nx982WmwCAS8VGzNt6DPu9NAavjes3pHytCb+cuYbwQAlXx+yq3ozBbcPQrIm/NkIIud3cKkVWm1Tw9dBDD8FsNmPTpk3csYyMDCQlJSEvLw+RkZFVeq6G+uGdKzDg36ulkAj5mPbpQcwaokFmTolbUnioQoz01F54Y9eNZUnXWlUAEBMsR3igpFZrVemMDLRGK8oYG8oYO9QyUa0/R31xVvE3WKxQycR4edtxj8CVSk0QQkjTc6sEX02qzpfRaIRQ6D5kgaA8T6qRxJB+hSrEuKoX4bfzRUjQhCA+Wu1Rib3QwOBaqcUtH6xixfafnx5Y60FRGWPHS9uPe8x+NbUgJU9rwtzNR7H/bCEX3GbmaDFriMativ+vZ67hrs7NmmRwSQghpGlr0Jwvg8GAw4cP4/DhwwCA7OxsHD58GDk5OQCAefPm4eGHH+bOHzNmDLZs2YL3338f58+fx4EDBzBnzhz07t0bUVFRDfESqsWZY+VsIeSLxebwe53a3qWnMzJcwOKqqdXDqvg64qPVyMzRYsWUeJzM0yEzVwuJkA+z1Y7YEDl0JtrtSAghpP41aPB18OBBxMfHIz4+HgDw9NNPIz4+HvPnzwcA5Ofnc4EYAKSmpuLtt9/GqlWr0LlzZ0ycOBHt2rXDli1bGmT8NdE8SI5FYzvji79yoPKx01Ai9P9jqe1deoUGxiPwcmpK9bAqvg7G7kBaYhw2/5OLOUPb4rRLAKY1WnFJa8KlYmMDjpgQQsjtqEGXHQcNGuR3uXDdunUex2bPno3Zs2fX4ajqXotgOV4b3wVGiw3DOoSjfaTSbUmMZVkkakKQ4aVAaF3s0tNXMpPWVOphVXwdYQoJesYEYUTHCLy7+4zPNko326aJEEIIqY4mlfN1q3DmJV0oLMO6tN6Yv/24W0AwtH0YXhvfBS9vO459XnYg1naeklws8Pv9plIPq2JdL7GQj2CFGKUV2ihVbLadW2KESMhHhFLaQCMnhBByO6Hgq54585JO5eux8ZG+WLD9uEcLnJ9PXwOfdxJvTOwGg9mGUrMVgVIRQhXiWg+8dEYGh3K0SNCEeG3F05TqYUlFfLcZw3ydGdHB5bldzs0NvpptJ10PbJvS5gJCCCFNU5MqsnorKDQw+OdiCdJTe6Gg1OJ1aREAfjpVAIPZhtbhCnSPCULrcEWd7MwrNDB45duTmJoQh4QKxVYTNCFYfE/nJrEjUGdksGTnKbx8dyeuaKyQz0ORwQKJkM9tYvDVbHt/E9tcQAghpOmima96pjdbkZYYh1KzrdLddvWRa6U3W2Fk7JizMRNpiXFIS4iDxeaARMhHZq4WehMDIKDOx3GzCg0M4sIUWLbrFLrHBGFqQhyCA8QwW+34M1eL/q1DIBcLMKhtmEd5Dyfn5oKmEGwSQghpuij4qmdKqQjx0WroTNZ639XoazyAZy0xp/Hdm9f5GGqD3nxjaXHP6WsAynPZvni0L84XlOK++Ob4JKVnowh4CSGE3N5o2bGeOfOnnDNLFZf6nJLqKdfqVul/KBcLPOqjGRk70tb9jaeGt8NfF4rx3l7vM16umsrmAkIIIU0XBV/1TCUXo0WQDJm5Wpy8Xmy1YgCWqAnB0vFd6mX5SyUX4/UJXT0CsLraWVkXdEYGdgfrtW5aoYFBbokJIQoJ9mcV4dhlHZJu0UbihBBCmgZadmwAzZRS/JuvR3KfWGz48yLiY4K4XCuVTITYYHm91p2KUsuwcko8Cg1Mne6srCvOACtSJfVaH81stQMonx3r1kKNPnHBcABuSfdJTSjYJIQQ0rRR8NUAVHIxFt3TGUu+O4kH+sQiXCmBwWxHM6UQKrkILYLqv+Cna9ChN1sBnufxxkpvtkLI5yFt3d/4OKUXePjXrZG2SiaC2WpHWmIcPs44j8wcrcfmgoJSS6X1zgghhJDaQMFXA4lSy/D8qA6Yt+WoWxPthmpm7dqQuqHHUl0KiRA/ny5Au2aBSP7oD6QlxiE1oSUXWAn4PBSUWtCvVQhX68sVj8fDZa0JRWW005EQQkjdo+CrgeiMDOZtPeYWeAE3mlmvnBJfb4GAs/DrPxdLMGuIxq3V0a9nruGuzs0adVAiFvC5/DnAs33QkvFdEBssR06xEaEKMT5O6YW3fjjtdl6CJgTj45vGzk5CCCFNGwVfDaQqzazrK+BxFn71Vvk9QROC/q1CuPP0ZiuUMhFCAxpPTpjWxPjMnwuUCqE3MejcIghljA3pqb2wbNdpjyKrB7KKsHDHCayqx6CXEELI7YmCrwbSmJpZOwu/VgxepCIBjl3W4orejJe2HXfLo2pMS5IKiQhTPvrTrV+jRMjH7+eLkJ6RjW9mJQIoLyNxVW/x2kYJKK9yT0VWCSGE1DUKvhpIxSbQFdVnvSmlVISeMUHoHq32mPlaMr4zVu052yiWR30JVYjRMzYI6RnZbgFYj5ggNL9bxpWPMDSSrgKEEEJubxR8NRBncdN9XpYe67veVKhCjDLG5nU5LkIpxT85Wjw1vA0GtwsHUF68VCTgY//Za40iSV0lF2PZhK64WGzEyj1nPRpmD2wbBpW8fIavMXQVIIQQcnujIqsNpDEVN1XJxRAJ+F6X42wOFquTe6B3y2As23UaY1cdwOQ1f2DC+7/hnwsl9TbGyvD5PKzec9Zvw2ylVNQougoQQgi5vdHMVwNqTMVNTYzN6/FIlRTHL+vw3bF8z8AmqxALGkGSep7WhAuFZR5Lo07ODQyhCjH+zddjemIrjO4SiQilFBabAwFiISQiHoLkYpwvLINSxjSqDQWEEEJuLRR8NTCVvHF8yKtk3sfA2ByIUEobbZK6s0zGlN4xfs8rNVvROlyBxfd0Rk6xETuP5SMjqwhysQArpsRjzZ5st9fYmDYUEEIIubXQsiMBcCMHTS4WYNYQDT5J6Yn3HugBm4P1aFhdUUMmqTtLdlQ1l0suFmDVniyuBVFaYhzWHsj2CC73uSxXEkIIIbWJZr4IAN9J65+k9GzUSeo6U3lw5Mzl8jZD57qBodDAYH9WIeRiAdIS4zCyUwT3Wp3HXIvMao3WRjEzSQgh5NZBwRfhyMUCrN6T5RbAZOZqEaWSVimwaQhycfmvcHpGNlZMiQfgv2G23mzllhrXHshGx0jl9esIvBaZdT6elh8JIYTUFlp2JBznrJCr9IxsRKpkmDVY47FLsGJg0xD4fB4SNCEwMnbM2ZiJ+Jggbsl0/fQ+eOWeToh0CZyUUpHbUqNzVs/X8uN+Wn4khBBSy2jmi3C8Vd03MnbM3HAIMwa2witjO8Nss8PI2KGSiRAeKGnwJTkhn3e9p2P5jJdz1ipBE4KpCXFwsO7nhyrE6H+9wTZwY7kyPlrtNuPlqr7bPRFCCLm1UfBFOL6q7hsZO9756Szu7hKFjlGqSq+jMzL11gcyJECMpTtPubVFkgj5yMzV4su/cvDmxG5u56vkYoiFfMjFAswY2ApD24fj3vjmyC4sA+A97+tQTgnKLFT5nhBCSO2g4ItwvFXddwYj/VuFQGdicO6awW8wdanYiHlbjrrV3KrLsg0quRgLxnTCvK3H3Gau/BWrDQ4QY3VyD0hFfCz9/jQyc7T4LK03QhVifJzSC2/9cNqjufh9PVrU+tgJIYTcnngsy7KVn3Zr0ev1UKlU0Ol0UCqVDT2cRiVPa8Lzm49i39lCtyT0qtTAulxixHObj/pMzK+LPpB5WhPmbz+O9pFKbrZKLRMhNkSO5kFyr4+5qjfj51NX3QrHPjW8DUZ0iMCrO0/V6/gJIYRU3a3y+U0zX8SNa9V9B8ti8TcncOB6MVLX5biLRWUQ8HmIUEoBlC81XiwyIjNHi1lDNB7LdukZ2bWeN+UssLr/bCF2nypw+56/YMlgtnkUjmVZoMRo9fpana+hMfSxJIQQ0vRR8EV8stod2O9SBd5fGYaCUgtKLTav5yVoQrBiSnyt5005C6x64y9JXm+2wmJzuAVZ4YES5JaYfL7WBE0Ixsc3r9XxE0IIuT1RqQniJk9rwqyNmRj69q+4UGQEUF6GYcOfF93KOKSn9kK3aDUWbD8OnZGB1mRFlErmtVzDgawirD2Q7bOFUU15253pylflfaVUBLmoPMg6mafD8TwdzNbyRH1fJScOZBVh4Y4TVHKCEELITaOZL8JxXcYDwNXA6hkThO7Raq+zQVMT4lBcxkAhEYBleX6X7awO/22Kqksh8f/rG+Dj+6EKMa4ZLFiz7xyS+8Si2GABY3cgM1eLfi5lKCpq6D6WhBBCbg0080U4FZfxnDWwVHKRz9mgDX9eBHiARCBAvq582W51cg9EqaTceQIeD4maENgcLDJzSnDumqFWZpDEAr5H4VenBE0IxALvv94quRhBchE6Rqmw4c+L6BClxO/ni3AyTwcBj+f3ORuyjyUhhJBbA818EY5zGc85c9UzJghjukbCZme97gAEgI5RKszfdhxPDm8LAJgxsBWkIj63kzA6SIZPUnvhlW9O1Hr5Ca2JcSuw6uSckSvv+xjg9bFGxo74aDWEfB4K9BauPZED/jf/NmQfS0IIIbcGmvkiHKVUxCWcZ+aUIHXd3xj/3m8oNdt8PiY+Wo39WUUoKLUgM1eL4R0isGpveX/IUIUYn0/r7RF4AeUJ8XNvsm2PQiLyaCn0SUpPxMcEYc7GTARIfAdKSqkINgeLoR3CwePxuPZEFqsdSW1CvT4mqYH7WBJCCLk10MwX4YQqxHj57o5uS4xGxg6j1e7zMYy9PI9LLOAjPSMbozo14x775n3dYLI6PAIvp/1nC1FQaqlxDlWoQoyesUFec7Qqa/gdqhDDYpMhX2cGACRqQpCRVYST+Xo8Pqg1RAIeOkapbtQOk4sQRLlehBBCagEFX4SjkovRI0aNV7496VarK0whQZImxCOIkosFiLleyDQzV4v4GDVKLTdmyVoEy1Bk8D+zpTPVPIdKJRfj9QlduaKwTv6q27s+9oreDB6PBz6A1IQ4iIV8DGgbhqlr//ZZ6f61cV0aRcJ9fbZwIoQQUrso+CJuzFa7R50ruViAT1J6AuBhf9aNIGfR2E44eqk8Kd+ZMyUVCrjvW6wOyMSCik/hRl7J9yvjWhS21GxFoFSEUEXVAhEjYwfLsrADmLMxEyunxKNAb8Hk3jF444fTXjcYvLz9OFY1cKX7PK3JbVcqULctnAghhNQuyvkibtQyscfORiNjx7RPD2JUl2bY9WQStj3eHz8/PRDdWqjxynenMDUhDvExaszZmIkSo4XLmSpjypcr/e1IDBDffPyvkovROlyB7jFBaB2uqHJgpJSKIODxEK6UwMjcWFqNj1b73GDgLDfRUCqWA3Had7YQz99kDh0hhJD6QcEXccPYHV4DDyNjxwtbj0PA43FBjs5k5RLV42OCsHJKPBg7i5fv7ogkTShkYj72/luAWYM1HgFYgiYEs4e0gVpe+e5BnZHBuQJDrZapAMrzvuwsi59PFSBJEwKLrbzWV2UastxEVar6E0IIadxo2ZG4MVh872wEgLLr39cZGUjF5bG7kbG75UY5S1UoJEIcu6RD1+ZqjO4SibSEOFhs5ZXkC/RmRKtllc5S1eUSm0ouRosgGWZvzMSKKfGQiQRIz8jGlzP6+n1cQ5abqGlVf0IIIY0HzXwRN8oKgYVcLMCsIRqulINULOCSvVnW+5KikbEjM6cEAvCw+J7OWP/nReRd31UIADKRAAPahqF5sNzvWOpjia2ZUoqeseWlKcxWO+6ICeJmwrypbBdlXav486mI6pARQkjjRzNfxE2oQowBbUKx72yhzybTA9qEYs7QNjhwrhCzBmsAAJk5Wq6lEAA0D5JCIOCh1GzFMyPagQVgZGxQy8RVToivaePs6nDdMemcAdvw50WkJMTBAffirVXZRXmzKtvF6PrzqaihA0NCCCFVw2NZ1n9J71uQXq+HSqWCTqeDUqls6OE0OnlaE57ffBRdo9XIzCnxmgO2YXofzPkiE+mpvZB11YDuMeVNtvdfL666fnpfLNt1yqNWVrRahugQ71XnKzp4oRj3ffC7z+9ve7w/uscE1fh1unIGPWUWK1QyMawOB1gWYMFCxOfDbHOg9HpAFCQXI0Iprfyi1XSp2Ih5W4767QSQrzXhYrERK/ecdfu5JLUJxfIJXRFJux0JIbewW+Xzm2a+iAdn+YZ8ndlnk+nM3BKsSu6B93/JwtPD2+Hl7ce5YGDZhK5YtusUkvvEesyaJWpCsOTeroipwpIjYysv4OqrUbdSVntLbCq599m4nKIyzNt6zC3QSdSEYMn4LoipYhBZFZdLjJi75Sgyc7RuNdakIgF+PXMNd3VuBgB4bvNRnMrX4837umHR2E6wWB0oY+wIkAjA5/vvS0kIIaRxoOCLeKWSi3G+sMzr9+RiAQa0CcfyXafQLSYIBaUWt+AkXClBxyiVW8kK1wDq7NVSWKx2hAdKfC7hFRoY/Ha+CEPah/kM4qb0jK7TYqNX9WbM23rMa0B0IKsQUpEA4bUwA6YzMrhYZERmjhark3sgX2dy+z7LstAarbA5WPxzsQSrk3tAIuJjwY4THrNfy6jWFyGENHoUfBGffCV3pyXGQW+2Yn9WEVIT4jyq1BvM5U2rXYu0+sod87VrUW+2Ij0jG1882hfLdnkWPD2Uo0Wu1oTVe7LcCr/WZrHRkjIGmTlar2NP0ISgbyvvSfnVVWhgoDNbPZqSuz5XqzAFxAIe0hLjkK8zeZwDlNcge37zUaxs4CKwhBBC/GvQ3Y779u3DmDFjEBUVBR6Ph23btlX6GIvFghdffBGxsbGQSCRo2bIl0tPT636wtyFncndF8dFqLuBylo5wpZAKYLm+ZAiUB2sVC7cC/nctKqUiGBk7Cg0MDmQVue26/PChO7BjViJW7znrFnhVds3q0putPsd+IKsI83ecqJXnMVisiA6SY3C7cK4pecXnWrnnLOQSIeKj1YhQSj3uyXsP9EB6ai90jVajqIxqfRFCSGPWoMFXWVkZunXrhtWrV1f5MZMmTcLPP/+MTz75BP/++y82btyIdu3a1eEob1/OnYDOAMz5Ya+QCLmASyLkIzNX61ZyokBvQZBL8VR/FeN9FQZ1Bn4Wm52bOcvMKcHsjZkQ8Hm4qjf7bNhdG8VGdUYGAWJhvVS7V8vEMFis4PHg87kOZBVBzC+/5xabw+2eTPv0IB5ffwhp6/5GZk4JbrsdNIQQ0sQ06LLjqFGjMGrUqCqfv2vXLvz66684f/48goODAQAtW7aso9ER4EbyfVEZAxbAwu3HER+t5gKuzFwtzhWUYv7dnfDKtyeQkVWEuZuPYstj/ZGoCUFGVpHbLJg33gqDOgO/glILN/uUmaPFyinxWHcgG1P6xFb7mtVRaGBwRW+u9LyKz+MtB815PddjZpsDJWUM9GYblDIhzIwDfJ7/+6Q1MWgRJMNlrdnvjNzCHScavP8kIYQQ35pUzteOHTvQs2dPLF++HJ9//jkCAgIwduxYvPLKK5DJfOf4WCwWWCwW7mu9Xl8fw71lOD/EZ23MxP6sInSLCcLJPB2mJsRhw58X8eSwtli26xS6xwRh6vUq9gaLDakJcWABj2XJinwVBo1Sy8DY7OjXyqVxt0jA5ZrV5JpVpTdbMXfzUXw+rY/P3ZbpGdluz5OnNWH+9uNoH6lEfLQaBaUWsGEBWLTjJLc8GqoQ44tH+2HBjuPc0mF6ai8YrXYEyvz/OSplIgRKRSgxWtGvVYjPnaj7a6kGGiGEkLrRpIKv8+fPIyMjA1KpFFu3bkVhYSEef/xxFBUVYe3atT4ft3TpUixatKgeR3rrcS146gyENvx5ER2jVODzeNhz+hr2nL7Gnf/eAz3wzKYjSEuMQ1igBEmaEK/LhJUVBtUaGQh4PG6m54HrM17OmTdvy3S1UWxUKRVdf80FSE/phZV7z3ok3Ken9uKeR2dkMH/7cUzuHcMl5z85rA0+//0CMlzGuGxCVy7wAsrz4RwsC4mQj/1nC5GkCcU/OSUewV6RwQKpUIAXtx7DU8PboNRU3gjcV2BYZqE2Q4QQ0lg1qfZCDocDPB4P69evR+/evXHXXXfh7bffxqeffgqTyeTzcfPmzYNOp+P+y83NrcdR3xpcewo6m2k7C6iWmj37QUqEfK7n4+Q1fyAlIc6jFVFlFePztCYYGQeMVjuXeyUVCQAAX/yVgwVjOnm0AUrShODVcZ1vetbHmXNmZBxYvfes1+W91XtvBGOFBgbtI5XY8OdFxMcEYV1qL4zs1Mwt8ALKy3C4Xis+Wg0TY0eB3oyjl7SYnhSH9JSeHrlcNgeLhTtOoH2kEqVmO4xWu9+8L6WMZr0IIaSxalIzX5GRkWjevDlUKhV3rEOHDmBZFpcuXUKbNm28Pk4ikUAikdTXMG8JOiODojIGNgfLzcy4cm2m/UlKT4/Hu85MOYO1tMQ4pF1fLowJlvut8+Xs69gtWo2YIBlCFBLIxQKEKcpn0XrGBaOkzIJRXSKR6tKw+6rejCt6M1Qy0U0FYM6cswuFZXh391mv57gu7+nNVvSKDUb3aDXWHsgGAK7VkiuD2e72tcXmgFwkQDOVDI8ktUJusRE7juR5BHuRSikm9ymfVXPm3L00uoPvnZjbj1PJCUIIaaSaVPCVkJCATZs2wWAwQKFQAADOnDkDPp+PFi1aNPDobh15WhPe/OE0/jNQg1e+PYH9WUWYNUSDIe3DuNkum4NFlEoGi80OiZCPpDahbn0YnUuTPAAZ1wOwVXuyuNmuytrgOJc5/7lYgq9m9AUPPMwY2ApGxorHB2ugkonw2s5TXpcdEzQhWDKuy00HHgFiAcSV5Ks5E+5VMhGkQgFe3XkSB7KKuCDTVahCDLXcPRdNIuTDaLXjmU1HMGNgKwzv0AwLvznpUdQ1LFCCt376F73jghETIsfGv3IwslMEXth63Ou4aqv3JSGEkNrXoMGXwWBAVtaNpZvs7GwcPnwYwcHBiImJwbx583D58mV89tlnAIDk5GS88sormDp1KhYtWoTCwkI8++yzSEtL85twT6pOZ2Tw2ncn8cyIdnjJpWXQF3/lYP30vlj87QkusHp91ykuaXzFlHiwLMstsxkZO778KwfLJnSF2VreFzFQKqpyU23nMqez1peDZTG8QwRe23kKmTlafDWjn9+yDGWM51JodeRpTZi7+ShS+7f0e54z4T5AIoSJuVHpn7E7cCJP75aXtvy+rig1W5GkCeUS8DNztejXKgRGxo53fjqL9s2UXou6fj8nEQ/1bQmpiI+lO8tbN10rtcCfm93xSQghpG40aPB18OBBDB48mPv66aefBgCkpKRg3bp1yM/PR05ODvd9hUKBn376CbNnz0bPnj0REhKCSZMm4dVXX633sd+qCg0M7u3RAnk6s1twM7l3DBZ/W97OZtYQjdtyl+uy4uODNJCKBFDJfAdaVWkJ5Fpdn8/jASzAsjfqYBm85Jm5MjJ2v9/3x7nkuf9sIbpFq6uU2G8w29yKm4YpJEjPyMbq5B64p1sUOkYpIeDzsef0Vcwc3BoOsDiQVYT0jGyM7BjBleWIVEm9VvR3AG6V7Y9e0uGztD5+X8fN7vgkhBBSNxo0+Bo0aBBY1ndJyHXr1nkca9++PX766ac6HNXtTW+2IlwpQW6x+wYGZ7sguViAQW3DPMocOJcVV+3Jws9PD0TrcIXX6ztnlFyXKL21BHImvO87W4igABFyi00otZQHXHKxAAFSgd/XobqJptvednYC7gVQK24WKDGW58c5iYV89G0VDD4PiA6W4+glHVqFKtC+mRJpnx7EjIGtMPfO9uDzALlYiBfu6oClO0+DsTk8Ai+5WAA+j8dVtgfKg+HDuSV1uuOTEEJI3WhSOV+k7imlIhSUWjwS7F2rqlfs5ViRr+Wuq3oz5n59xKPkxD4vPQlVcjGWjO+CeVuPwWZnoZKJIOTzuDGcuVLqkWfmlNQmFOGBNd9g4VzydJZxEPJ4eGZEOzw/io8SI4PQADGaq2XcWHVGBozNgUM5N4KhfJ0ZTw5ri+OXdfjuWD7SEuIQIBWg+Ho7ok5RKizbdRq9Wgbj4IViHMrRIi0xzi2Ac0pLjENxGeNWrDY+Wo3ZGzO9BoYJmhAsvufmd3wSQgipGxR8ETehCjHMVjsOnCt0m1WRCPlcra2nhrX1e40AieevVZ7WhAuFZZW2BHIGDHlaExZ+cwLdotUQC3kQ8IU4na/Hy6M7YsOfF/FQ35aYNVgDsKzbNZPahGK5n/IVVaGUinw2A0/QhOC1Csn8hQYGv50v4grPAoCQz0OhgeFmqx7oE4sCvQUqmcitYv/zo9pzuylX7cnyukPSmXjvGhBbbA4YGTsW7TiB9x/sAblYCBNjh5GxQyEVwuHwXy2fEEJIw6Hgi7hRycUotdhwvkLLIGdi+Ko9WZh7J9/ncleCJgRigfusmTOHKrlPjN/nds6YueZc7T5VAAA4V1CKxwZpIODxcFlnwscZ55F5fbbItdREQakFcrH/JcnKhCrEWDS2E9a55LW5FjM9d80Aq93BlcrQm61uhWfjY4IQFijBtVILN1slFQnw3NdHsGlGP+4+zhqiQYHePWneW/FYZ/J+lErKfU8i5CNUIcYnqb1QZLBg6ffueWJJ15dFoyrZVUoIIaT+UfBFPLQIkmPeqA5Y8M0JrmWQzcFyQVW+zszN8FRc7pqaEAediQEQwB0vNDD452IJnrvTfwN0Z4K4a86VXCyASMDDU8PaYfmuU0hJiOPyzwB4bbHTu2XwTdf46tpChWe/PsqNwdssmDNXTSkVuW06iI9WI19nRmywHHm68v6QLMuifbNAPJz+F96e1B2A9zpgFXPM5GIBWgTJ8H9fHcHq5B7ls30oD9JWJcfj4IViLgnf1f6zhZi7+Sj1eCSEkEaIgi/iFWNnPVoGpaf2AlC+pDbbpWiqc9YpM1eLORsz8c2sRLdr6c1WpCXG4VSevkpthlxzrpxBz4e/nkdaYhzUcpHHZoCKbrbEgs7I4FLJjefw1cTamav2+oSu3G5FZ3AmFwvwwQM9EKmSIlETAgGPh9SE8us4Nw5YbA6czHcvR+EaxM0cpEGoQoJ/LhYjPkaNmRsOuSXqC/h8RCjtPktuUI9HQghpnCj4Il7pvQQwzoTyzFwt4mPUXmedvO2yU0pF6BkTBBbArCFtIBHy0f56sVaLzYEgucgtgd1ZZqJi0ON8vv6t3VsKVXSzJRYKDYzb164zbRXtO1uIUrOVayLuWvfsit6Mz36/gNSEONhZlguqQhViJGlCIBHyve6mNDJ2ZOaU4L4eLWB3sHjrpzNYP70vXvn2BN756Sze+ak8R+yLR/q6JeF7Q7W+CCGk8aHgi3il9BLAuOY1eVt29NWrMVQhRhljw7u7zyC1XxyeHtEOS3eecgtoXHOUnGUmvAU96RnZuKd7FDfTVFGiJgQK6c39WuvNVrfcq8oCHJ3J5tY+KThAjLd//BepCXHYffoafjtfjM/SenPlOJz3schgwR0xarfHuuauBclFOF9Yhsm9Y7Bs1yluCdh5TqBMWGkxWar1RQghjQ8FX8Qr1zpbTkbGjuc3H8Wq5B4Ikovw8uiOYAEYGRvUMrHPoqoquRginRkdo1S4pDXiw/3nvOYouZabeH1CV5zK13tcy8jYkVdidptpckrQhCA1IQ5llpurbq+UitxmpCqW3fA4XyZ063W5bmov7M8qwpQ+sdyYfzlzza3X5fObjyI9tRdiguVYuTfLIxB17thUShkuCHVdAgbKe2oW6M0+Nz8kUa0vQghplCj4Il45A6DnNx/lAjC5WIBVyT2wek8W1x4HuJF47i+3yMTYuARzXzlKruUmotQyn0FUGWPDM5uO+Mw52zDdf+X3yoQqxOgZG8TNSIUFSnzmqg3vEA6FWMjNxIUqxFypDdegreLyYvls1mlux2bFWS/njs1QhRgXisq8jnPu5qPY8EhftAwN4K7rVBslNwghhNQNCr6IT1FqGVZOiUehgUGp2YoguRgvbTvuFngB3oukVqSSiXFF778XIeCeo6SUibwWUpUI+W4zTRXd7FKba+DpukzIAm5LnQPahGLR2E6Yv/0EUhPiIBby8eSwthDweADcy0a4JtKnJcQhQimt0o5NlVyMFkHey0UUGhgkf/QHtj3WH6/e0xlGqx1Gix0qmQgRSgkFXoQQ0khR8EX8cgYAAHCuwID9WYVuNa8sNgekIgEO5ZSgqMz3zrpQhRhX9SKYrP57LjoDpzytCfO3H0dK/5ZwsKzbrE5BqcVndfvaaqtTMfBUykR4a1J3GMw2tybhBaUW7D5dgN/OF2HllHgYzDbIxAIkaEK4oE0i5KOjywYDuVgA8/X74OteugahzZRSjyVgp46RSgReb6XEljEQCfhwsCzOXTNAJRd77ZtJCCGkYVHwRapMb7b6rfw+Pr65z8eq5GLEhshxIKuw0nITrkVWfztX5LYsp5aJoAlXYGDbMLclUefjvSX815Rr4OkUoXQ/50yBAcCNRt5akxWMzXF9Q0I2nt98FB+n9MJbP5x2K0Ox+bH+fu/lffHNoTMy0JusMNrs5TNsO0549MRcPqEryhg75m8/jsm9YzxKYnjrm0kIIaRh8Vh/na1vUXq9HiqVCjqdDkqlsvIHEADlM19bD19GZk6JzwTvyop65hSV4bLWhFV7s7zmKEWqZThXYMDQt3/1eQ1n426dkeFmppwzUfU9y3MyT4e7VmQAAN57oAeXe3YyT4eOUSqM6BiBN3addgs2Zw3RYETHCK7vo7dG2p+n9YJKLsGSnSeR3CcWG/686DZ7ppaJEBsih0IixKyNmegWrfb5cxnQJpRbEnbeM/312TyaGSOENCW3yuc3zXyRKgtViNH/emscbyor6qkzMnhx23H8c7HEb5K5txpjrpxLct5mpupbgFjo1vLHGXgl94nF2gPZiI9We8zyxUerUWxg0KWFCi9sPe5xzUcHtILVwWLBjuOIjwniZrMq7nYc0CYUL9/dEfvPFiK1f0uvPxe5WICu0Wpc0ZtRWMZg4fbjbuOhmTFCCKl/FHyRKlPJxRBXUnbBX1FP17ZB/pLMvdUYc9VQtau8zRqJBDy3lj8n83R4sG8sNvxR3uMxQOz5J+asbO+tvRAAJGpCIRHxcSCrCGkJcX4LvGpN5febsXvWInNd1gTgdWasKpslCCGE1C4Kvki1BFXyAe0vMKrqjJa3GmNOtZVQX115WhOXh+a09N4u+PnkVTzQNxaju0QiSiXD2G6R0JZZMaRDBCKUUsgl5bN5ron1YYESPLPpCL6c0dfrc9kcLKzm8hwyb0GVqwCxAHKxANFBco/vpSXGcY2+7+zUzG8QR22ICCGk/vifxiCkAmdg5E1lgVFVZ7ScpR4qPk9tJ9RXlesGAFfhgRLsPl2AmRsOIU9nhp1lYWIcWLnnLF7YehzTPj2IH09exZD2YVid3ANRKikAwO5gcUdMEH4+VYAkjWerJIVECIXUd1DlKkAsxMt3d4TBYkVihWv1ig1Gcp9YZOaUoLiM8XGF66/RRG2ICCGkvtRo5kur1eLrr7/GuXPn8OyzzyI4OBiHDh1CREQEmjf3veONNH0quRivjuuMF7Yec6t5lagJwavjOvsNjKozoxUgFuCVezqjjLHByJTXrgoPbJjaVa7Lpa6cs1KuNcc+SenpllOVnpGNr2b0RanZxiXXO5cDN/55ESkJcXDAvUCqTCTANYMZi8Z0hIAHn62UBrQJhVouQo8YNfK1Zo/+kuGBEry68yQOZBXh+VHt/b5GZ74dIYSQulft4Ovo0aMYNmwYVCoVLly4gEceeQTBwcHYsmULcnJy8Nlnn9XFOEkjoTMyWPztSY8+g5m5Wrzy7Um8ObGb70KrXqrmA+4zWjojA63Rit/OFSJcKeVqX50tMGBQ2zCo/E8E1Qlvy6W+ZqUq9oE0MnawLM9td6drwdUAsQDz7+4IlgUXZDpYBwQ8oGfLYLzy3UmvrZQSNSF45Xqwe76wDEar3a3qf3CA2K0+mt3B+mxDlKAJgYDPu5lbRAghpBqqHXw9/fTTSE1NxfLlyxEYGMgdv+uuu5CcnFyrgyONT6GBwe5TBdh9qsDn9/3NTlUsXupaIiJPa8KBrELEBMtQsf4Jy7LILTFCLhbU++yXt+XStMQ4bqnPdVbKWx9IFqxH0OOcLVu1Jws75ySiY5SK+975awYYLA7IxXbsOX0Nf5wv9tpKyXi9qbZSKkJxGeMxAycSlI8lVCGGRCjA1IQ4j4KvarkICokQQgq+CCGk3lQ7+Pr777/x4Ycfehxv3rw5rly5UiuDIo1XVZPm/fFWIsKZVzX3znZuS3ROCZoQzBqsgc5orffgy9tyaXy0GmbG4TErlZmr9QjIjBb/Vf2dBVqdQgLEWLrzFB4Z0Ir7vrdk+UFtw7jx/XWhGAmaEK5XZIBYCKPVDrlYgE+n9gZYFlv+ycWcoW3dCr4C5bNor9/btXo3hRBCSI1VO/iSSCTQ6/Uex8+cOYOwsLBaGRRpvOqqDIQzr2r+mI5Y+v1pj5ki59evjO1co+vfDOdy6YLtx9EuUon4aDXkYiFKjIxHg2+5SIBhHSLA4sZrEAr8zyqpZO73TCUXY9E9nVFQ6r8XpvNxKrkYg9qGoXVYAOwOFqv2ZiE+Wo3MXC0WjukIqUiA13aexJPD2mLZLs97m5FVhBe2HqNyE4QQUk+qvdtx7NixWLx4MazW8hkOHo+HnJwczJ07FxMmTKj1AZLG5WZ2O/rjnFFjrA6veUlAeQBmsvmfRaorUWoZFozphCM5JZj26UEYGZtbg+9pnx7E4+sPIXXd30j+6A/ExwRh1xNJ2PZ4f4QFSpDk454ltQlFeKDE6/NFqqRVflykWobYkAC8dz237NhlHU7n6dEjNghGqw17Tl9DoYHxeW+d5SYIIYTUvWoHX2+99RYMBgPCw8NhMpkwcOBAaDQaBAYG4rXXXquLMZJGpK7KQDhn1Mqu5zH5UnGJrr7ojAzmbT3G7WTMzNXiqt6MBC+lIoyMHUdztYhUSdE9JgixIQFY5uOeLfdzzyKU0mo9zmC2cePj8YBpSXGw2OwwMeWbAMyVNDWvypIxIYSQm1ftZUeVSoWffvoJGRkZOHr0KAwGA3r06IFhw4bVxfhII+Qvab6mQhViDOsQDoXE/7KlWtYw1e0rlpv44q8cbHikL+JCAwDAo09lxUC0pvesOo/TmcpnruRiARJah+Lh9L+w5bH+cFaR8LYZwFVDdQ4ghJDbTY0r3CcmJiIxMbE2x0KakLroq/h/w9vhZL4OSW1CvdbV8rVEVx8qbjSY3DsG7/z0L+7vGYNFYzvBYnWgjLFDJubj7NVSr3WzanrPqvK4PK0JZquDqyGmM1lhZOywsyx+OVOAJE0oMnO1PstNNFTnAEIIuR1VO/havHix3+/Pnz+/xoMht68rejMKSi0IDpCU90pkWbdipUltQvHKPf6LuNalihsNesYEoXu0Gh9lnPfYlTk1IQ5FZfXXrse5U7RbtBovje6AtQeykZYQBwAoLmOwZt95rEqOx4Y/LmLq9eOuY26ozgGEEHK7qnbwtXXrVrevrVYrsrOzIRQK0bp1awq+SJW4NqkODhDjUokJwQFivPnjv1y5hFSXulZX9WbYHP77HNalUIXYbUZOJRfhzR//9bkrc+GYTvU2NueS6D8XS/DljL54Yetx9GoZjCRNCKx2FkbGjlkbyou6Cnk8PDOiHZ4fxUOJ0YrwQAkilVIKvAghpB5VO/jKzMz0OKbX65Gamorx48fXyqDIrS1Pa8Jr353EvT1aIFwpgcFcnmQvFPC44MVbXatdTyTV6zgrmjlYw1WNdx1rRQeyimB3VCwTW3ecS6JGxo5LJSbIxQJ0a6FGn7hgZBeWcUuNFe/pgDahVF6CEEIaQK001lYqlVi0aBFefvnl2rgcuYXpjAxe++4k5gxti/QD2Riz8gAuFhuRmauF3tQ4dzoC5bNLaev+RnxMED5J6cntIPSlPsfquiQqEwmQlhiHjzPOY9qnB3HNYMGCuztxDbzlYgFmDdFgw/Q+eGJoGxSWMdAZqcQEIYTUp1oJvgBAp9NBp9PV1uXILarQwODeHi2w+NsT3MyRRMhHeka2R7HRiir7fl3Sm61uNb0MFv+BYn2O1Vl7LVQhRmywHAmty2e6jIwd7/x0FuPeO4BuMUFYl9oLWx/vj9N5Ovx9sRgiIR9lFhtOXynFmSulFIQRQkg9qfay44oVK9y+ZlkW+fn5+PzzzzFq1KhaGxi5NenNVoQrJW5Ldpm5WsTHqLH71FUkaULcEu2dGno3nuvsklwsAMuySNKEYn+W567M+h6rs/ZaTrERr3x3Ev8ZqHH7vjNonDVEg5N/6PBQ35aQivhu1e7lYgFevrsjesSoYWTsUMpECA2o/R2thBBCahB8vfPOO25f8/l8hIWFISUlBfPmzau1gZFbk1Iq8mibk56RjRVT4rHhz4tISYiDA41vN55zdungxRKsmBKPr//Jxf+NbAcAbgFYQ401Si2D3mTFH+eL8exI73/W8dFqAEC+zsT1zpSLBZgxsBVGdYrEK9+ewLwtx7jzB7QJxesTuiJKLauPl0AIIbcNHsuy9ZcZ3Ejo9XqoVCrodDoolcqGHs5tRWdkcKnEhNErM9yOy8XluUo9Y4LQTCUFUD5jo5LdfAHX2pKnNeHXM9fw08krSO4Tiw1/XkTHKBXio9Ww2BxQyUSIDZajRbC8Qcb3V3Yx9p29hhEdI7z2cHzvgR6QCPng8XhIW/c3VxOsQG/2aGTuREn5hJDG5Fb5/K5xkVVCakIlF6PUYkOiJgQZLh/2zqWxRE0I3prUHRFKaQOO0rsotQw9Y4NwWWvC2gPZOJBVhD2nr7mdk9QmFKsaKFhRSoWIj1aj2MB4reelkolgsNigkgohFwuwcko8Nv55Ef8ZpMELW497vaaz5yMFX4QQUnuqFHzde++9Vb7gli1bajwYcntoESTHa+O7YPE3J9Dh+syRzcEiOkgGAZ+HPK0JBoutUeYcGSw29IgJ8loKAwD2N2CwEhQgxmWtCQdzSnAyT4f4mCCkudRKM1vtiA6SQWeyYsWUeMjFAkzuEwudyX9PR+r5SAghtatKwZdKparrcZDbTGxIABaM7YwXtxzlcr5e23nKI9erseUcqWQiWKz+y0w0VLASoZRCa2Qwe2MmVkyJx9oD2W5B4pD2YZh7Z3sYGTvWHsjGMyPa4aP95/HU8Lbcsq9zCVUqEuBQTgnSM7Kp5yMhhNSyKgVfa9euretxkNuMzsjgxa3HsD+rCLOGaLhlPFf7zhbi+c1HG1XOUYBECDtr9ntOQwYrzZRS3BEbhDkbyyvau858FZRaUGaxgccrLxD7/Cg+OkapcCpPj09SemLV3iy3YC1BE4L01F7U85EQQmoZ5XyRBuFsiSMXCzCobZjPZbzGlnNkMNvw+/kinw2qkxq4JIZKLsayCV3x/OajbvfUuQvTyNhxRW+BXCyAibEjPlqNY5d1+OZIntdWSXweD6umxPt8Ptc2UVSeghBCqqZGwdfXX3+Nr776Cjk5OWAY98KMhw4dqpWBkVub3mzldts1pZwjvdmKL/7KwfrpffHKtyfcNg0kakIatPm3U5RahpVT4lFoYFBqtiJQemPHqM7I4KpehLTEONgcDlhsDnRprsK7u896vZa/HLY8rQlzNx/l+l0CjXOpmBBCGptqV7hfsWIFpk6dioiICGRmZqJ3794ICQnB+fPnqcgqqTKltDwAWHsgu9JzG1POkVIqwuTeMVi26xS6X2819N4DPfBJSk90jwnCq9+dbBSV4lVyMVqHK9A9JgitwxVc8KSSixEbIke/ViH47VwR1HIRLLbq57DpjIxH4AXcWCpuDPeAEEIaq2rPfL333ntYs2YNpkyZgnXr1uG5555Dq1atMH/+fBQXF9fFGMktKFQhRv9WIVi1JwvxMUE+l/EaurJ9Ra7jrlhmwqkxLZN60zxIjnydGV/8lYP7ejRHZZX+vAW/zmVjbxrbUjEhhDQ21Z75ysnJQf/+/QEAMpkMpaWlAICHHnoIGzdurN3RkVuWSi6GWFj+6/fFXzl4dmR7JGlC3c5JagSV7SsymG0Q8Hl+z2lMy6S+BAeUtyS6ojcjUCpE4vXG2xX5ymHTV/Iam8I9IISQhlLtma9mzZqhuLgYsbGxiImJwR9//IFu3bohOzsbt2GxfHITguRiyMUCvD6hK1b8fAbdYtRITWjJVYuPDpIhshHlDl0uMeK5LUcxLbGV3/Ma0zKpLwESIdYeyMYDfWIxa0Mm0lN7YfRlPcKVEq7UxBWdCf1ahXgNfpWVvMamcA8IIaShVDv4GjJkCHbs2IH4+HhMnToVTz31FL7++mscPHiwWsVYCQlViPHy3R19VotvTK1tdEYGF4uMyMzRNqqm2jVlMNtwIKsIaQlxMDJ2FBos+O5YntsGgiRNCPq3DvX6eImQ79GlwKmp3ANCCGkoVV52/Pbbb+FwOLBmzRq8+OKLAICZM2ciPT0dHTp0wOLFi/H+++9X68n37duHMWPGICoqCjweD9u2bavyYw8cOAChUIju3btX6zlJ46GSi9EjRu011wu4kTvUGBQaGJRabFgxJR7r/7yIlISWSKiwVNcYl0l9cS4bZuZq8dLoDvgkI9sjkNqfVYT52497JM9fLjFiwY7jSE2I87gHiZoQLBnfpUncA0IIaShVnvkaN24cIiIikJqairS0NLRu3RoAMHnyZEyePLlGT15WVoZu3bohLS2tWrNmWq0WDz/8MIYOHYqrV6/W6LlJ41Bmsfn9fmPJHdKbrYhUSbmG1X+cL3YrYqqSiRDTyJZJ/XEuG6ZnZOPLGX3xwtbjPqvcF5XdSJ7XGRnkFBvx8+lrOHJJV15TbFR7GMx2KKRCFOjNsNr9754khJDbXZWDr+zsbKxduxaffvopXn/9dSQmJmL69Om47777IJPV7ANn1KhRNSpP8Z///AfJyckQCATVmi0jjUue1lRpmYPGkjuklIpQYmS4WTpnI3BXPz01oCGGViNS0Y1lw0slJq7mWsWWRAmaEIyPb859fUVvhtXOcrl66RU6EyRoQrB4bOd6fS2EENLUVHnZMTo6GvPnz8e5c+ewe/dutGzZEo899hgiIyPxn//8B3///XddjpOzdu1anD9/HgsWLKjyYywWC/R6vdt/pGHpjAzmbz+OAInvnXaNKXcoVCGudIdfZbN4jYXOyGDBjhPcsqFYwOdqrnmrcr9wxwnojAx0RgaXSkwICrhRoy0zR4tZQzRcvbNpia3w14ViqvNFCCF+VLvUBAAMHjwYn376KfLz8/HGG2/g2LFj6Nu3L7p161bb43Nz9uxZPP/88/jf//4HobDqewWWLl0KlUrF/RcdHV2HoyRVUWhg0D5SiXd3n2kSuUMquRjNK1lSbCyzdJUpNDDYfaoAczZmIj4mCGGBEvRvVV5nTS4WuAVT6am90C1ajaIyhsu/sztY9GsVgswcLVZMiUdmTglmb8zEyXw9WJZFeKAEV/RmCsAIIcSHm+rtGBgYiKFDh+LixYs4ffo0Tp48WVvj8mC325GcnIxFixahbdu21XrsvHnz8PTTT3Nf6/V6CsAamN5sRXy0Gqv2ZOFoE8kdaqaUYkCbUOzzUly0Mc3SVcY5g+dcOk3PyEZ6Sq9Klx71ZiuO5+kwokMEzDyH2+zX6uQeyNeZAAAWmwOXtWYcytFiUNuwJpMHRwgh9aVGwZfJZMKmTZuQnp6O/fv3Iy4uDk8//TRSU1NreXg3lJaW4uDBg8jMzMSsWbMAAA6HAyzLQigU4scff8SQIUO8PlYikUAikdTZ2Ej1KaUi5OvM/nOH7mlcuUMqeXlh0uc3H3ULwAY0oV2OgGeNLiNjh9Fqr3Tpcf7dHcGywOFcLWJDA7jg+anhbSAV8fHdsXyPn2FcaADkYkGN7g017SaE3KqqFXz98ccfSE9Px1dffQWGYXDvvfdi9+7dGDx4cF2Nj6NUKnHs2DG3Y++99x727NmDr7/+GnFxcXU+BlJ7QhVirsHzhj8vIj4miNs56Nxlt3TnKbw1sVuj+sD117S6qQhViD1m8A7llKDf9bZJ3uw/WwixkI/eLYMx/bOD+OLRvjAxdgDA4Hbh3C5QV86vl4yr/vIxNe0mhNzKqhx8dezYEf/++y/i4+OxdOlSJCcnQ6VS3dSTGwwGZGXdeLPPzs7G4cOHERwcjJiYGMybNw+XL1/GZ599Bj6fj86d3WdCwsPDIZVKPY6Txs/Z4JnHA7pHq70udU1NiHMrc9BYqORNK9iqyNsMXnpGtkd7p4qsdgcEfB6MjB1p6/7GZ2l9uO/5qtV2IKsIZUz1NiI4N2N0i1YjtX9Lt4B8wfbjeLORBeSEEFJdVQ6+hg0bho0bN9ZqUv3BgwfdZs2ceVkpKSlYt24d8vPzkZOTU2vPRxqX5kFyGCw2rNp70uesycIxnRpiaLc8bzN4jkrag9kcLMquz3YVGhj8ePIKkjQhMFrsfh9nZPx/v6KiMgaTe8c0qYCcEEKqo8rB14oVK2r9yQcNGuS3H+S6dev8Pn7hwoVYuHBh7Q6K1CuW9T9rYndQv9C6UnEGT2dkfG4oGN4hHAazDYdySpCgKd8ZuWbfeayYEg+pSOD/eWTV2wVqc7A+c88ACsgJIU1fjUpNEFJbjJUsSVV31oTUnJGx4/HBGq9tkxaN7QTG5kB6RjamXi8NYmTsmLMxEyVGC5LaeF+yTGoTivDA6m12cThYCsgJIbe0myo1QcjNUsn8Lx9Vd9aE1IzOyOC5zUdxKl/vUfbDxNhQarHhrwvFuCMmCHM2Zrq1VuKBh3mj2gM47ZEgX5NdoBSQE0JudRR8kQblbeedU1OqndXUFRoY/HOxBCumxHuU/VgyvjMilFLweMDjg1tj1d4sLhdLLhZg4ZiOiAmRY/HYTnCwgNlmh5GxQy0TQS72vyTpDQXkhJBbXbWXHT/77DNYLBaP4wzD4LPPPquVQZHbh3Pn3YAKy1ZNrXZWU6c3W33W+YpQSgEAnaNUmPbpQcTHBOGTlJ748KE7sH1mAqKD5Xj1u5M4V1iG+TuOY/SKDEz84HcMf2cfZm/MRJ7WVK2xOANybyggJ4TcCnisv4x3LwQCAfLz8xEeHu52vKioCOHh4bDbG/+SgF6vh0qlgk6ng1KpbOjhENwoqNlUa2c1decKDLhQVIZpnx70+N77D/bAiTw94qPVbt+fNUSDKJUU3x3LR3xMEDJzSrzmag1oE4qVU+I9fp6+iqjma024WGzEyj1n3a6X1CYUyyd0pYr5hNzGbpXP72ovO7IsCx6P53H80qVLN133i9y+mnrtrKYuVCHGhaIyj+NysQAtgmT4v6+O4MsZfd2+Fx+tBlCeBJ+WEOezQOu+s4UoNLiXh3AtoioXC5CWGIf+rUIQohDj1W9P4p8crVtemUTIR0GppUbLmIQQ0thUOfiKj48Hj8cDj8fD0KFD3Rpb2+12ZGdn484776yTQRJC6pZKLkaLIM8ZpbTEOBy7pEN8jBr7zlxDkiYU+7PK8/MstvLem3KxACKB/wyG0uv9JIHyGS/XwMu1n+QnKT2x//psV3pGNtIS4xAfrYbF5kCEUgqt0UpBOiGkyaty8DVu3DgAwOHDhzFy5EgoFArue2KxGC1btsSECRNqfYCEkPrhrXF4fLQaczcfxYZH+qKkzIIeMUFwoLwUhFQkAB/AiinxEPA9Z8NdBbr0kyw0MNyuyIp5Zq4Bnbcm30nXcwGpxRAhpCmrcvC1YMECAEDLli1x//33QyqV+j1/48aNGDt2LAICAm5uhISQeuGt7ZDVzmJy7xgczinBjiN5OOSyHNgiSIbiMgtW7slCfEwQEjQhyLz+fedslVQkwFW92S1JXm+2IlQh5oIo1+BKIiyfQfPX85NaDBFCmrpqJ9xXlVKpxOHDh9GqVau6uPxNuVUS9gipC85E+DKLFRKRAJdKyncrVkzGX5faC6GBEty9MgNysQCrk3tAKuJj1d4sj0R519mq7GsGMHYWi789gRkDWuPh9L+4c2cN0SAzpwSPJLaCjfWsdO9sMdQqNACtwm7MvhNCbg+3yud3nVW4r6OYjhBSx1RyMRRSIQKlIq6avHM50JXRakduibH8/zN2HLmkxeoKgRcA7D9biOc3H4XOyAAAJCIBFn97AgeyihAU4F6zKz0jG9MS4xCsEPtsMbT2QDZVuSeENGnUXogQ4ianqAxPf3UY5wvLkFtiQrhSwi0HupII+RC7JNp3baFGho+2QM4djwCgN1lxIKsIcrEAfPCQoAmBXCzArCEavJfcAy2CZBDy+dRiiBByy6LgixDCuao3Y97WYziQVQSLzQEhn4efTxWgQG/26PmYmavF1evH5WIB5JU02HbueNSbbVxCfanFiumJrfBJSk+czNPBzrJ45ZuTKDR4FnJ2RS2GCCFNGQVfhBBOSRnDzThJhHxk5mpx9JIWzVQyzKrQdDs9IxuacAVmD2mDl0Z3gL2SVAPnjsdAqZBLqJeLhbhWasbH+88juU8spCIB9mcVwVbJzBa1GCKENGXU25EQwtGbbzS1zszV4mSeDsl9YvH5HxfQLVqNuXe2BwCYGDvUchGaXW89pJaL8O3RfCRoQrwuFyZdbwukMzLQmazo16o8iHt39xk8NbwtckpMWHsgGw/0iQUAHMop8XktajFECGnq6mzmKzY2FiIR/euUkKZEKb3x77Ev/srB3Ds7YOOfF9ExSoXOUSpcKjGh1GxDlEqKds2UXGcCE2NHekY2pibEeSxPJmhCsGhsJ6jkYhQaGMzacAhiAR89YoKw5/Q1XCoxIT5ajQNZRVxumTPxPqnCtZKo5ych5BZQ7ZmvvXv3YvDgwV6/9+GHH2LGjBkAgOPHj9/cyAgh9S4oQIxETQgO5WixbEJXvLHrFDpEqbi6XRIhH7+fL8K6fL1brS2lVAQjY8ecjZkebYEyc7Xc9fVmKwoNDMxWO9cqSCzgc7spM3O1XL0wHngY1SUSqRVaDBFCSFNX7eDrzjvvxJw5c7BkyRJuZquwsBBTp05FRkYGF3wRQpqeCKUUS8d3wSWtCQ4W2H36Gnafvub1XNd+jaEKMVcdv2JboITWIQiQlL/VKK7/L2N3cDlgmblabhkyPSMbK6bEY3QXMz7OOF+tRt2EENJUVHvZce/evdi6dSt69eqFkydP4rvvvkPnzp2h1+tx+PDhOhgiIaQ+KWUivLf3HHQmq9/zXPs1OqvjD+8QjhVT4pGZU4Jpnx7E4+sPYcpHf+LZTUeQpzVBLOAjQRMCHo8HPr98STI9IxtKqQhJmhBu9qxtRKDPUhOuZSsIIaQpqnbw1b9/fxw+fBidO3dGjx49MH78eDz11FP45ZdfEBsbWxdjJITUo0IDg/1ZhZBWUjrCtV8jAESpZXh1fBd86qU46r7rhVZLjBZMTYgDy7LI15kxNSEOfVsFo7jMgscHazCkfRjSEuNgs/vf7ega+BFCSFNTo4T7M2fO4ODBg2jRogWEQiH+/fdfGI3G2h4bIaQB6M1WyMUChCrK87+88bXjUGtksN/PjJVUJMScjZlQyUQQ8nmYszETD/SJxcf7z2PB9hN4aXRHHMkpQRlTvuvSWXz1k5SeeO+BHkhP7YVZQzRQUqkJQkgTVu3g6/XXX0e/fv0wfPhwHD9+HH/99RcyMzPRtWtX/P7773UxRkJIPVJKRUhLjMO7u88g1cvuxURNCJaM7+KRc6UzMlwfSF8EfB56xgbhlzPXcFVvRnyMGgBw6kopPnzoDry8/Tj2ZxUhM1eLIe3DPJYw09b9jcM5JW6V9QkhpKmpdmPtyMhIpKenY9SoUdwxq9WKF154AStWrIDF0vh3I90qjTkJqQs6I4MTeXokf/wn5GKBW/K8c/fivfHNPRpbnysw4EJRmUcDbie5WIDv5yQhX2/Gmn3n8FDflpCK+Fy1eqlIgAc+/pM794tH+2LZrtOUdE8I4dwqn9/V3u147NgxhIaGuh0TiUR44403cPfdd9fawAghDUMlF0Mi5HsEXlKRAIdySpCekY1h7cM9Hqc3W7lSEd4Cppfv7oiXth3HPzklSEuMAw/lQVaQXAyrw4HcYpPbc/KASpPuKfgihDRF1Q6+KgZergYOHHhTgyGENA6BMiFWTInH2gPZWLUnizueoAnBiinxXnOulFIRVyoCcA+cEjQhiI9RY96WYwDgds1ZQzRIbB0KuUjg9pzvPdDD7xgp6Z4Q0lRReyFCiBudkUFxmRVrvexaPJBVBB6AtyZ193hcqEKMnrFBXgutFpRaYLTYPB4DlNf2uqtLJMq0NrfndFa796XibktCCGkqKPgihLgpNDAwMnafS34ZWUUwmG2IqJBu4az19fzmo24zWwOutwRy5nZVZGTsuKIrX3J0fU5/S5jU35EQ0pRR8EUIcaM3W2G2eg+UnHwt+UWpZVg5JR6FBgalZisCpSKEKsr7P+qMDJLahGL/2UKPx23+5xKmJsS5HfO1hDmA+jsSQpo4Cr4IIW6UUhGKyxi/Cff+lvyczba9mTlYAwfLeuSDPdSvJVQV8sgq9opUyUQIkou5YI4QQpqqapeauBXcKltVCakLOiODH09eRYsgGVbtzfIIlGYPaYMOzQKrHQCdKzBgzKoMr6Ur0jOy8f2cJLy8/Tj2eZkZo9IShBDg1vn8ppkvQogblVyM/q1D8Pzmo14T7vk8HlZdXw6sDr3ZCiNjd8sHc6UzMVzOmGsARsuMhJBbDQVfhBAPZqvDZ5ug/TWssaWsZHdigETkN2eMEEJuFRR8EUI86CupoVWTGltSER+JmhBkVLJ70V/OGCGE3Aoo+CKEeKhslqq6Nbau6s1YsP04UhPiwMJ996KvXpE3S2dkUGhgoDdboZSJEBpAQR0hpHGg4IsQ4iFUIcaANqE+k9+rWmNLZ2SgNVpRYrRi9+lr+O18sUcB1sxcLRi7o1bHn6c1Ye7mo25lLQa0CcXrE7oiSi2r1ecihJDqouCLEOLBtWBqTZPfLxUb8fu5QrQIlnMFVn0l3HvrFenkawZLZ2RQVMbA5mDhYFkYLTao5GIoJEKPwAso7wf5/OajtGuSENLgKPgihHh1M8nvl0uMmLvlKObe2R7Ldp1GWkJcjeqGeZvBGt4hHC/f3RHLdp3GIwNaY9XPZ9A+SoX4aDWu6C2IDZZ7LeQKUENuQkjjQMEXIcSnmiS/64wMLhYZubyuA1lF6B0XjE9SemLV3iyPRt3pqb28LmPqjAzmbj6Kfy6WYNYQDRe0RQfJsfibE3hiWDv8d/e/mNwn1q0BODXkJoQ0dv471xJCSDUVGhhoTeUBjtFSvtwo5PPwXoWCrUB5YLZ6r/e6X4UGBv9cLMGKKfHIzCnBtE8P4vH1h1BQakaXaDX4PKB9lMqjATg15CaENHYUfBFCapXebOUCILGQD7lYgAFtwyqtG+btOmmJcR7BlcXmwOB24biiNyM+Wu0R0DkbcntDDbmrR2dkcK7AgMycEpy7ZoDO6PlzIoRUHy07EkJqlVIqws+nCzCqcwSCA0RYNKYTCvQWv4/xthSolIoQH632SNCXigQAAB6PB8bmuUuSGnLXDtoxSkjdoeCLEFKrpCI+sgtK8dzI9riiN6NTcxXydSa/j/G2FBiqEONCUZlHon5MsBxFBgtYlkV00I0gwPU8FsCisZ1htTtQarZBKRMiSC5GhFJa2y/3luTMt6Mdo4TUDVp2JITUGp2RwWWtCbOGtMEVvRlgedCbrX6XApN8LAWq5GJEB8s8cr4uFRsRKBVBwONBJhYgQRMCuVjAnTd7YyYAYMGO4xj13/2Y9OHvuPPd/Xh20xHkaf0HgaRcoYGpdMcoIaTmKPgihNQardGK//58Fvl6C6QiAewsC7lYgPSMbExNiPMIwBI0IVg8tpPPWRSVTOyR82W02rH336uwsyyulVowNSEOC8d0xLrr53nLEwNuzNo485Yon8m3umgvRQi5gZYdCSG1poyx4UBWER7oEwuhQIzfzxfhrs7NEB+jxpyNmR7V7a/qzRDweD6vZzDbPIIoiZCP1XvP4csZfQEAMzccwmdpffDc5mOQiwUY1DbMayFXoDwAKypjUMbYKZ/Jj9puL0UIcdegM1/79u3DmDFjEBUVBR6Ph23btvk9f8uWLRg+fDjCwsKgVCrRr18//PDDD/UzWEJIpcquV7KXCPkoKbMiPSMbDpbFrMEaxMeUJ887lw/TD2SjVZgCKrnvD3JvMzCZuVrEx6jx86kClFls+L/hbZGvM3FLj7rrZS5CFWJ8ktIT38xOwMZH+uLb2Yn4JKUnWJb1m89EM2A32kt5QztGCbl5DTrzVVZWhm7duiEtLQ333ntvpefv27cPw4cPx5IlS6BWq7F27VqMGTMGf/75J+Lj4+thxIQQf9Sy8kDq2GUd+sQFw8jYkbr2b6Sn9sLdXaLcZr0KSi1oGSz3m7jtnIEJVYixbEJXhCslMFrsuDe+OZZ8dwo9ooMQHxOEy1oTt9yYlhCHUIUY66f3xeJvT3g08X7p7o5UAb8SKrkYS8d3wb6sQoQHSriOBFf1ZgxuG3bb3x9CblaDBl+jRo3CqFGjqnz+u+++6/b1kiVLsH37dnzzzTcUfBHSCIQHSjCsQzi6tVBDLRMhUROCjKwiTF7zB9IS4xCulAAAZCIBhrQPr3T3YahCjLu7NMPsoW2xbNcpdLzeRkhrsuLpEW0hFPCgM9mQmatF/9YhWLUnC/ExQViVHO8ReAFARlYR8kr8J91TPhOQrzXhktaE747mIcPlHia1CcXAtmHVupav3pyE3M6adM6Xw+FAaWkpgoOD/Z5nsVhgsdyoM6TX6+t6aITcllRyMRaN7YTnNh/Fv1dK8XFKL/DwL/ZnFXJ5WM56W1Up+6CSi/H8XR0wf/txJFdoIwSUz2S9fHdHfPFXDga2KQ8K0jOycVeXSI/ACygvRxF2PQD05XbPZ9IZGfxy5hq+PZqHA1lFHqU+LhaVQcDnVfrz0xkZaI1WvLTtmFuBXcqtI6SJB19vvvkmDAYDJk2a5Pe8pUuXYtGiRfU0KkJub2argwt8kj8qn/FKTWjJLTdqwhSIrMYHr8FsQ0cvbYSA8pmsQzla/N+IdmDs5QVXjYwdOqP77JUzgBjRMQLHL+mQoAnxGpxRPlN5mYnwQAkOZBUhVCHGxym98NYPp92C3qTrAbSvACpfa4LWZMVr3510mzkDqFYYIUATDr42bNiARYsWYfv27QgPD/d77rx58/D0009zX+v1ekRHR9f1EAm5LbkmyRsZu8fOw22P90csAqpxPRt6xARh1Z4syMUCzBjYCoPbhXPXl1xvYfTN0XwMaR+GjlEqtyR+1wAiPlqNV7475bUCfoImBIvv6XzbBwR6sxUWm6O8REhqLyzbddojUN3vJ4ByzpzFhQQgw8vMmVQkwKGcEhSVUW4duX01yeDriy++wPTp07Fp0yYMGzas0vMlEgkkEv9LDYSQ2lHbZQqUUiHMVjvkYgFWJ/eAVMR3CwjkYgHWpvbCF3/lYP30vli26xRGdIxAoiYEh3K0SE/thXd3n0G3mCAEiIUwMnavZS8yc7XQmxigGoHhrUgpFaG4jEFaYhxKr5f6qE4AVWhgEKmUgs/ncTtQKy4XJ2hCML578/p+aYQ0Gk2uyOrGjRsxdepUbNy4EaNHj27o4RBCKqjtMgVBAWKEBIiRlhiHfJ0Jq/Zmuc3EpCXGweZgMbl3DJbtOoXkPrF4/5csvHx3J7w8ugPKLDYk94nFyTwdRMIbNcVEAh7CAiVoESRDgESIwe3CaSYG5T+/glIL+rUKgc5kdese4CwTkrbub2TmlID18ni92QqVXISA6wGbt+XiA1lFWPjNCSrrQW5bDTrzZTAYkJV1419D2dnZOHz4MIKDgxETE4N58+bh8uXL+OyzzwCULzWmpKTgv//9L/r06YMrV64AAGQyGVQqVYO8BkKIO5VcjNcndMXzm49iX4UipjVpbB2hlEJrZNCvVQjMVrvHB3l8tBq/ny9Cv1bl1fOdH/Z/XyjBuqm9YbU78NH+83iob0sEiAUY1iEcD/SJ9ZhBAyrPZbodlFlsaBUqB8DjZrx8BlA7TmBVhaVHpVQEo9UGxu5Av1YhSM/IxlPD27gtFYsEfOw/e42WHsltq0GDr4MHD2Lw4MHc1868rJSUFKxbtw75+fnIycnhvr9mzRrYbDbMnDkTM2fO5I47zyeENA5RahlWTolHoYFBqdmKQKkIoYqalxgQCfgQ8Hiw2Bwe37PYHEjPyEZi61DER6u55a1CA4PiMgZBASJ0jFLhWqkZkSoJ/m94W2TmavHdsfxq5TLdDnRGBheKjJj+2UGsn94bIQo5RAK+z44B+73URQtViHEizwzmet6Yt6ViAEjShGJst6g6f02ENEYNGnwNGjQILOtt4rpcxYDql19+qdsBEUJqjUpee/WcQgLEuKo3QyL0zJSQCPkwMnYYrXZux6NTUIAIJWVW9IgJQqhCjKKy8mTyCKXU625HoO4LrTbmuleFBgZakxVGxo7iMisEPL7f9k+AZ100lVyMEIUY3xzNx12dmyHrmsF7oJtViAVeZs4IuR00yYR7QsjtRSUXIyZYjn1nrnmUicjM1SJBE4JDOSUY1j7C7XF2ByAW8iBmy4M2Z+shAD6TyNMzsuus0Gqe1tSoe0rqzVYuwOXxeFxQ60/FDRQ6IwOHg8XJPB3u6hzpN9D1NnNGyO2gySXcE0JuT82D5BjQJgyzh7RBgiaEO56ekY3ZQ9rgdL4eCqmA+16oQgypiI8QhQR2loXRUl6WQiLkQy4qXw6LUrkXCo1SSbE6uQeUstovtKozMpj7dePuKamUirhg1my1Qy4R4OglLZI03jdQJHnZQHFFb0ZOiQnJfWJxRW/yulTsijoKkNsRzXwRQpqM5sFyiIR8vHpPZxitdhgZO1RSESKUErw1sRuyrhkwNSEOAJCWEIdDF0vQKlSB388XYXiHCGScK0SUSgpNeADsDmD3qatcyyKz1Y6WoQEIkokQKKn9t8YrejP2ZzXunpJSER+n8nSYmhAHmUgAoDwg7TO4NURCHjpG/X97dx7eVJ39D/ydfWmapE26QldSaYGCYS8tIFhZxJ1xRkBlU1FBRceNEVcGl3FcRnB3CvgbwPk6biMgDgIKreyUpSyF0toC3eiSpGmWm+X+/khzaZqkBexKz+t5eB6be5Pc3DLkzPmczzkqDI8PQ1iICKFSEVgWOGew4lS1GWqZCCqZCAaLA0I+D4+sz8fn80aCZVsPrnr7RAHSO1HwRQjpMcoNVrzwXQFSY5TccqHT5UaIRIA+YXKoZWLc88+9mJeVhBi1DI+sz0fObE8PsOlD++BkuQnD4sOgCZFi+abjQUcWLb8tvV2v22hhcK6bz5Q0Whi8uukEnp6Shr81tewor7diYKwKs1ftRc6cESi5YEaiVo5qk83TQLdF248fHs2C080i/6wB+ng1fj51AbEqKdf8tuUSb2GFqddPFCC9EwVfhJAewWhh8MJ3BbhrZHzAgOn1OwZDIRViaLxnx2NmPy1Xs3TXyHgs23Acd49OwNrdv2HxDf1bHVm09LuCdi0Er26wt3lOV2eAaswMkiIU3ABzAY+HIfEq1Dc6cE9GAuwOJ4bEqfHrGc/9allELxcL4GaBXcW1ON6UPVu3pxQjE8LxlxvTPMX1LX5nr96e3uXZPkK6AtV8EUJ6hBozg9QYZdCAack3R9Fgc2BOZhIydRoopJ5ls4Nl9chI1mDbyQtYtC4fqbEqWBgX9HHqNgvB24vB6uBqqQIJVDvV2Uw2B/Rxamw7eQErtxVhzup9uO39XyEU8DChfyRcLHDeYEOUUhqwiH5eVhLMdidyckswc1QC1u0pxYBYFcJDxHj5v8cCB7nfFnSLWjdCOhsFX4SQHsEbHLQWMNVbHHh0fT708WGQigTI0nmafHrbJXhnTfJ56NRC8BCxADm5JZjbFBg2l6nT4JVbBnZ5BkghEfrdEwvjwvbCC+DxgBCJEEarA4zLzZ0nFwvw+A0p+O+iTNw4KAYCPo8b3+RdZnSDxc422noQ0tvQsiMhpEdQSkWoMNpaPSdELOACLO+sx2Ubjvm1S8gtqsHIxPBWX6s9lwFDxELo49UBZ0pWmWxt9tLqDGIBH6oAuzxzckswLiUCLjcLqUgApVTIjR36cJangerJChMStQr8eqYGY3Va7Cyq4ZYYP5g1tNX37epaN0K6AmW+CCE9glYhhrqNFhAhYiE3V7LGzGDWZ7sxNzMJ8eEyn3YJn+woRqhUiKwgy4BXMoOyNWq5CI9MTIG+qR7NOyMxJ68EyREKqORdv+PPYGUC3hML44KADyikArAsC7lYgCqTDS/dPADVJk8wnKCRI0QswCc7ijE3KxFjm71GoMa4zXV1rRshXYEyX4SQHkElFyNBI0eWToPcAMtY41K0UMtFPnMla8wM5q/ZjxvSIrH89kFY+m0BdpyugYVxYe7qffh83ki89sNJv6anVzKDsq1rj1PLcNPgWJ+sV3WDHYnh8i5fcgQAhUSEP32yC5/NHgEeCn3aYpypNiNeEwK5WACzzYkYlQzRKikcLjcKzhsBAEI+D8Pi1Vi0zpPdm9P0OSNCJRir0wRcemzvIJeQnoLHtjbf5yplMpmgUqlgNBqhVCq7+nIIIZfhXJ0FS745GjBgimnqEu8d4dNyrmSgxwG02wzKYLwtMtL7qnB9aiSkYgF4LA82p6dXmVomQmSopEuDMKOFwSPr87G/tN6n879EyEddI4PMZA3Om2xosDnx9H8O48NZwyAR8VFjZsAHwMJTA7Zy22mfQCs7LRJLpw3A8o3H0b9Zi5AwuQjx4XL0CZN32WcmPc/V8v1NwVcP/uUR0lsFC65+z2t11KxFo4XBovX5OFBaj/dnDoVczIebhV+PrLFNAWRXjhkqN1i5rKFX88D2dFUDNh6tQFSoBIP6qtBo88zTDJUKsWLbadwzOhEVRiuilNKL2T2TDZn9NBDw+fj1TA36x3j+zbUwLshEAmgVYgrAyCW7Wr6/admRENLjtNfQ7s6YtVhjZrDzdA0WTdShwuhptBpw0HTTmKEVXThomgdganoMZo9J9Fka9YoMlWBMPw1CxEK4WE8BfkhTS48BsSp8llsccDfqm38YjIRwOeI1Ifjb5pM+y8ZjU7R47fZ09A2nAIz0HhR8EUJ6lPbKVBktjF/gBVyctdheQZCpaTefPk7NPRasXUZXjhkyWhg8HeB+AJ6AdMUMPQBgxdYizBwdj1NVDZg8IAqMi0WDzQl9nNqniWpz/aNDcbLChO8Pl/vV6+08XYMl3xxt16a2hHR3FHwRQnqM9sxUeTNSgbRnEKRs2s3XVl8xr0tpvdARS6WXcj8AYGdRDeZkJuLjX4qh7xuGSJUEKpkIRmvr150coQja72vn6RpUN9gp+CK9BgVfhJAeob0zVaY2gpz26j+lVYgxLkXbZssFr7ZaL3TUUuml3A9vgbB3duODaw/g/Zl61FsYRCuDv7fF7gp6zKut4I2Qqwn1+SKE9AiXmpm5VMo2gpz26j+lkovx+vTBqG6wo8pkg8HCYGyKNuC5bY0ZaisA/T2jei7lfnjP8Xbr18er8dR/jmBQHzXC5KKgfdOkYgHkEkGrry8Xt36ckKsJBV+EkB6hvTNV3oxUIO3dfypELEBmsgaZyRoMTwjHw9f1CzhmaOEEXauv094BaHNSEb/NprPee+YdIaSPD0POnBFY9v0x3JOzF09OTvVpZut9bpRCjBCxMOhsy0ydp4ifkN6C/rYTQnqE9s5UeTNSwVortFf9kbfHV2qMElMGRMNkc+C+z/f7jRnKP2vAvNX78P2irKDv3VFLpUYLg1c3ncCTk1P9Gqxm6TR49fZ07pqa37OV24qgj1NztVwzP93d1GD14m5JXYQCcokQuUVVWNQUXDbfcJCp0+CRiSlQd4Mu/4R0Fgq+CCE9gjfrsiPIbrwryVTFqmVYMUPfas+w31PcbrQweOG7Atw1Mh6r8kq4BqPe+ZOBtBZAtbU0FyK5sn/SaxsZ3D60L97begpD4tVc8KSSiRAqFcLhurhZoOU9c7gvtooM9Lm+fXgMnG4WL35/DO/PHIpbh8TimSmpnvPtLsjEAoTLRVRsT3oVCr4IIT1CR2WqWusZ9nuL22vMDFJjlFiVV4K8olrMGpVwxbMOjRYGLjeLTJ0G+WUGny70UpEAlUYrJIIrqyRxulnuGredvOBzLFOnwUs3D/R5rPk9O1NtbvPzmGwOWBgXnvrPYXw2ewTe3HwSB5p9hhqzHVaHG1HKru3yT0hnoeCLENJjXEqm6kq1zHApJMLfvbvSZHP49L/yLi9m6jQ+S29ysQDzspIwJlkDo5XBmQtmvwxbjZnB2Xor7stKhlTEx+e7foM+To24cBnMNheGxKnB413ZZ3e72aC9x/KKauFyBx+EcjkZybtGxuPNH08iv8yA92bosSqvxCdT1t4Nbgnprij4IoT0KO3V3b65QBmudfeN+t19wJRSESqMNu7n/LMGHC83Ym5mEgBPYCMXCy4pEDFaGQj5PBw+Z8CpShMWZ/fHKxuO+QRNWToNlt+ejgRNyGV9fgvjbON48FYRl5qRHJeihT5OjZzcEqyYocf6PaXQx4dxdW9SkQAHy+rx4ncF+PudQygDRq5qFHwRQno1o4XBM/854lNkDgCGNvpOXUpxu1YhRpXp4jJiTm4J3puhx7pmgUd4iBhv/6/QL/PUMsMmFwuxrfACMpI1SO+j8gu8ACC3qBbPfXMUb/3xWkQppW1en5dK1nqgo5K1XgzfVkbSG6CdqmzAezP0CJUIcdeoBL+AM1OnwdzMJNQ2dk2Xf0I6C7WaIIT0apUmG3YW1UAuFmDRRB3+OXs4Ppg1FHFtzBq8lN2VKrkYCRo5137B26JhQKyKGzckEwmCdn5v3j6Cz+fheLkRAj4PkUpJ0GXC3KJa1DdeXsuJ9mi7oZKL0S9SgWvjw9AvUuEXPMWqZUjUyvHVgbNQykRcjVlzeUW1WJVX0uoyJyFXA8p8EUJ6LaOFwbl6K+RiAVbO1CMn92ImZtFEHbJ0GhwMUNxeZbJd8u5KhUSIhRN0cMNTV+XdEehtsdDWkp83wybk8zBzVAJkIgHMttY7xptsrb9mS53VdsPhYvGHYXFwBagx89a96ePUMFgcAeveCLlaUPBFCOm1vFmlB8YlY1Vuic/Q5+/yz+P/zR+JCqMNK7cX+SyPjU3RYvw1EVC1nhwD4MmszVuzz6+vV0G5EbuLazFlUHSrz/e2j9CEiPHaphN4cnJ/CPmtV9YrpZf/T3tHbmbwMtudiFRKUNsiM6dViPHZ7BF468eTVIBPegUKvgghvZbJ5kD+WQNuSIvCJzuKsWiiDsPjw6CSixAmF2NvSS3+e7jcL0uz83QNnvnqCFa2sePRm1lr2f9KLhbg/ZlDcaHBBomA77f70StTp4G4qX2ESi7Gy7cOwumqBsSGyZCl0/gEi15ZOg3CQtoOmIwWBrWNDJxuFixY8FjADcBid0IlF3dI1kkpFaG6wQ5ns2VFrUKM9fePxkvfH0N+mQGLJup8soy/nLqAGwdFUwaMXFUo+CKE9FpKqQhf7C3DhGsiuEL4a+PU+Pv/CvHs1DRoFJKAAQ7gCcDa2vEYbNzPgvGedhFON4vSWgu3+zG/zIAF45NxfWokpCIB7E43qhvsYFxuRIZKEKuWocHmwLxV+7B63ki8+F2Bz/V5dzu2VWxfbrBi+cbjuH9cP6zceoorfm8eAHZE1kmrEMPmcCHvTA0ydRoUVjZg/f2jUd1gD9p+IlOnQUayhoIvclWh4IsQ0mtpFWL8eVJ/qOQivP3TKYxIDMfqvBIUVjbAYnfC7nT71CI1b4mQk1vS5o7HegsTsK/XhP6ReGPzSczPSoaLZfHo+nwsGJ+Ml24eiPpGOxpsTrz2w0mf52SnReKlWwbiYGk94jVy/OnjXXhj+mA8MzUVZpsLCqkAjXYX1G3sTPR23X/s+hS889MpzBqVgNUBit8vp5/ZpVLJxWiwO3Gi3Ij7spIRo5LgQoMdRqsD87KSsCqvJGD2a1dxLcKoCz65ilDwRQjptVRyMYbGq8E4WeSXGfDs1FR8sqMYXzwwGgIeD1bGFTQb894MPZStBDpGCwPG6ebaSwC+Mw3zywyQiwTIPVMDfbwaDheLfb/VAQA2Hq3wa8J618h4lNZasGzjCe6a5q/Z73NNy29LbzNAqTEzGNRHhUa7EzNHJUB6Cbst2zPo6Rsmxws3D8SB3+oQGSqBweqARMjneoBR9ov0BhR8EUJ6NQvjgtnuxAPjklFtsuOBcclosDlhc7gQIhFgxbaigC0ReADe+uO1QV+3usGOX4troY9X49H1+T4F9zaHGw+M82S9vAGHXCyAtamZacv382aFZo1K4NpVBBrMbbIyAFpvsGqyOZCl00LA52HF9iLcPTqh1fOvdFh3axI0IXC7WRTXNHLXro9Tc58z0P1+/ruCNmvsCOkpKPgihPRqcrEA9RZPQGK2OXF9WiTO1Vvx/LcF+Nf8UVwX+kBLj432wC0dyg1WlNVZmmW9fDM5/12Yiey0KPx0ogrD4sPw7FdH8MGsYbA7Awc63hFF85pqw4IN5r792j5tfl6FRIhaMwOpSID8MgOWTE1r9fxL6Wd2JawOT6Dp7fo/ZWC0zyimli6lxo6QnoKCL0JIr2W0MDhYZgDLsggRK+BiWdQ2MOgbJkONmcFvtRZu/M9XB876zFKcOigaogAtH4wWBs98dQRzM5OCZql4PMBodYDHAx6e0A8lNY1wuNxBh27bnW4ACFg/5nWpzVDFAj5CpAKYbU4sGJ8MAQ9Bd05e6mteiUbGhfyzBpypbsCzU9PgdrNoazRlR2ThCOkK1OGeENJr1ZgZLNtwHDEqGRQSIXg8HsIVYhw9Z0SmTgORgId5WUn46sBZLM7uj5y8Ety8Ig8zPt2Nae/lYsk3R1Fa2+j3mgdK66FViJGl03BZqvlr9uPhtQcxf81+mO1OKGVCDIpVYf6a/bgmKhT7fqtDtcmGWrMdY3Uan9f0BmU5uSWYm5mEzBbHx15GM1SDlYFMJECoVIgJ/SPx3rbTeP6mgchq8ZpZOg2W3TaowzJNapkIObkleOg6HQ6V1eO9racQ08bOyo7KwhHS2SjzRQjptUw2ByyMCwvXHcQ3D48By7JgnG78deMJrJypR5XRhoxkDfRx6kuepWiyeXbuffhzEZ6/aSCWbTjm1w5CJODD6fL0urIwLtQ2MhgaF4a+4VKwAOLC5XDjYu1X/lkDl51qmUlTy0ToF6m45FmOCokIm49V4PrUKLjdLPpFhuKNzSdwbXwY5raoIVu24Tje6qAh15GhEgxLCENdIwONQoLkyFDkl9X/7sweIT0BBV+EkF5L2ZRJsTAubD5WiezUKJTVWwAAPPAg4PMgFvChlAnbnKXoDX6UUhE3tzFYUONwuWG2uRGplAAAYlRSFJw3otJkxX8Pl3MjjbwBllwkwI2DovH6Dyex43QNVxc1LkWLN6cPBgCcrDDBZPNk1MLk4qDBmFjAw8HSekzoHwkr4+bqrLadvBDw/I6qs1LJxfjb9MEoq7OgtpGBPk6NR9bnB9wZmqnT4JVbOy4LR0hno+CLENJreQdK7zhdg49/KcbE/lFQSUWYl5WEz3KLkVdUi5w5I+B0C1p9neazFLUKMX6rbcTQ+LBWg5o+ahmqG2wYq9OAcboRrZKBZVkuS9ay8FwuFuCHR8fC6WZ9xv8YrQ4s+c9Rn2AlS6fBq7enI17ju/OxymTDi98fw8xRCSg4b0T/aCVqmurJgunIOiu5WACXm4VEyIfd6f7dOzkJ6Smo5osQ0mt5B0qPS9HCwrgwd/VeRIRKkJF8cenrYFl9m7MSmx9XycWIC5dBLgoesOXklmBUUjgStSF4eIIORqsDQj6PK6wPxMK4UG9h0C9SgWvjw9AvUgGb040l3xwNuBz6l2+Oospk83m8rpHBtpMX8Oj6fFSYbFDJhG02Ze3IOqtKkw2/FteiymSDSnYxC9myRm7ltiKESKjei1w9KPNFCOnVWg6UFvJ5PrsOv9hbhj8O63vJsxSNFgYGiwMulvU718vS1M+rf1QojBYHLA4XHG43HK7Ws1AtA6G6RuaSl0ONFgZGi4N7/3e2nMb/21WK9Q+M7pLdjt65lzm5JXh/5lCEy0XI0mm4JdfmbT2qTDaq9yJXFQq+CCG9nkruO0TazZq5/75rZDze3lKIl28ddEmzFGvMDMx2Fw62Ujw+NkULTdPgapVcDKOFQWmdBVUmGzJ1GuQ3BSDeId9CAR9mmwMCPnC6qgFmuxPaEDEXTAXTfDm0xswgROqbjasxM5jxyW58NnsEeCjEzqIa7ti4y9hBeSW8cy+9Gx4WTeyHZbcOQlWDHSu2nfZZdh2bosX4ayKgknfIpRDS6Sj4IoSQFprXgnkL0nOLav1mKVab7HC7fTNcJpsDNocr6FihTJ0GL98y0CeoUcnFkDbYEKOS4dGJOrhZ4NOdxdyQ78LKBnw2ewSe/7aAGwX0/SOZfsFUS82XQ002B+oaGb8sV42ZwcxPd+P5aWl4/qYBsDBOrp6sIwvcTTaHT9+yv20+BcbJ4ug5A/TxYVzNl7eh7YvfFeDvHbTzsrN5s6ONjBONjGceZ2So5Kr4bOTSUPBFCCEteGvBnv3qCFeHVWNmfGYpen378Bifn+ViASRCfqvF44FEhUrx5uZCzBwVj5zcEgxrGvKdX2bAFw+MxhubfQdtm20uWBjnJS+HKqUi3P/5fqy9b7Rf+4uh8WqM0WmRoOm8gnalVOQXoF7bV41BfVRYt6cUgKezv83hwph+GkwaEIW6xp7f4b7CYEVpnQUrtp32+X16e7XFttHrjFwdKPgihJAAvLVgFcaLReveMUPNlwPtDhfOXDBD2xTouNwst3yYV1Trt2txbIoW92cl+b2fSi7Gy7cOwm81jThQZsAzU9Pw7k+nsWiiDg02p9/ypUIqwCPrDwYMprJ0Gvy1xXKoViHGgBglZn222y+D12h3tVl43960CjGGJ4T5BKhRSine/N9JzByV4Ddc29v0tSczWhj8fOoCNhwp536fzUdXnagwodHupCxYL0DBFyGEBOH9AhyXosX+0nq8P3MoLjTYEKuWYdmGY9wSoPec56al4Wy9FTEqGRZN0AHwXXIcq9P6LTk2F6uWodJoxYLxydyQbX2cGkarf21XtcmO1OjQIMGUEyEtdls2z+Y1z+B1dG1XMM2vxxtkff9IJgbEqgIO184tqsUL3x3r0cO1a8yeDRD5ZQYsmqjD8PgwxKil+OuG4z6B5rgULV5vyoIZLQxqzAxMNgeUMhG0IR27HHylesp1dhc8lm1lS04H27FjB958800cOHAAFRUV+Oabb3Dbbbe1+pyff/4ZTzzxBI4dO4a4uDgsXboUc+bMuaz3NZlMUKlUMBqNUCqVV/4BCCG9QrnBiryiGvQNk6GkphEbj1YELKT/5+zhAIBH1udjwfhkTOgfCcBTVC7k85BbVINbhsQiOUIR9L3OVJvRyDgh4PEwbUUuPpg1FBIh32/JU6sQB816Berx5eX9kmzeK6wrvySbX4/TzcJodQRc3vXa+sR49IsMfv+6s8Nn62F3uGGyO7FuTylmjUrA6rwSLohvngUT8HhI0MqxfMMJpMYqud2fYXIR4sPl6BPWfXYfnK+zYMfpC+irliNKLfX0orM6oJKJEBYSvOHvlbhavr+7NPPV2NiIIUOGYN68ebjjjjvaPL+kpATTpk3Dgw8+iLVr12Lr1q247777EBMTg8mTJ3fCFRNCeqNYtQwjEsPw3LcFmJeZFLS9A+AZBaSPV+OdLafxzpbTPsfGpmgxd0xiq++lVYhhqXfC4XYjU6fhCs5b7pysMTOY9dlurJw5FEunDfB0t5cKg37ZtcxMJGlDukVmovlO0zPVZlQ32Fs9vycP11bLxGgUOPHRjjOYOSoBUpEAB5qyYKMSwtEnXIY9xZ7fsUouwvINxzFrdCIqjFbuNawON3acuoBxKRHoE971Adj5OgvO1luQf7Yeo/tpsPTbgktq+NvbdWnwNXXqVEydOvWSz//oo4+QlJSEt956CwCQlpaG3NxcvPPOOxR8EUI6lIVxIa+oFrNGJQQ9J/+sAScrTJib6anpavkl9Nrt6W0GPCq5GLYqMwR8YG5mEuRiPk6UGwO+Zmp0KGLVMsS38SVcbrDihe8KkBrjyaBUGG2o7oYZFK1CjCpT1zV97WiMy9PF37u0em9GIlbO1GPt7lJMHRiFKpMNW05UYUCsCpMHRiE9Tg2piO+Xac3UaZAUoYBCKuzSAPp8nQU2pxtrdv2GJVPTWm3423z+KelhNV+7du1Cdna2z2OTJ0/G4sWLW32e3W6H3X7x/02ZTKaOuDxCyFWssakGS9pG5/pNj47F8o3HfdolqGUiJGguPdBRy0WwOlxYt6cUiyboMGNUAtbtKfV5TZVMhFCpEK6mxqzBam6MFgYvfFeAu0bGByxif/2OwejbDTIogCfwTNDIu6Tpa2cw2524YLZz7UuWTEnDG5tPYFhiOHg8Hj7dWcxtNhgYq8SE/pF+u1yBiwH4q7e1Hcx3lPJ6T+BlcTjxh2FxATeFeLVs+Et6WPBVWVmJqKgon8eioqJgMplgtVohkwXeovvaa6/h5Zdf7oxLJIRcpby7AVmWDd6J3WhFiFiAv9855HfVVUWGSpBfZsDMUQmotzi4HYHe95II+dhVXIuc3BJ8cf8olBuseOarI9h52rdJ6uvTB8PKuJAao/QL3rzLmS99fwxvdaP+WX3C5Hj9jsFY8s1Rv8/TFRsD2pNcLIBY4JljKRcLwOfzsLOoFo9lXwOnm/XZbPB49jUAPIFW81qw5r87i8PZxjt2DKOFgcHqmeLQaHMhUinxaegbSFvHe5seFXxdqSVLluCJJ57gfjaZTIiLi+vCKyKE9DSRoRJkp0UiTC7C/KxkLBTxsXJ7kW8ndp0WGf20iFBKf1eQoJKLEaOWYtZne/D5vFHcvMOA58rEfoEXAOw4XYNnvzqCxdkpGJEQjmvj1H6Zr0ydBnMzk1Dbzfpn9Q2XY2WzkU/dYWPA72W0MDhYagALFknaELw/cyjMdk9A4nSzcNpd0MepkZNbgkUTdVDLRag1M5CLBXhvhj5g7zO5qGu+witNNjjdLCx2F4QCHrfLtjVtzUftbXrU3YiOjkZVVZXPY1VVVVAqlUGzXgAgkUggkUg6+vIIIVcxlVyMF24agNPVZhw9b8T+3+r8lll2FtXg+e8K2qUdQrRSij9P6o9DZ4OPKRqXogXjcvsEXi17kcnEAshEQvx103GuxUHzDEql0YpETfdYdmyu+eglg8WB8wYrTlWbe2w3+EqTDcs2Hsf7M4ciKlSK3SW1SO+rglwsQKhECKvDBaebxXsz9FiVV4L0PirEhckxLysJ6/aUBu191tnLxkYLA6PVCbebhVDg2cF7Q1oUKk22S274SwB+26d0HxkZGdi6davPY1u2bEFGRkYXXREhpLcwWhg8920BACC9jyrglwwA7Dxdw80t/D1UcjGGxqvx140nMDczCZk6jc/xTJ0Gr9w6iMueAOCyJMfLjXCyLP7+v0KUG6xwsyzyywx4b4Ye+WX1mL9mPx5eexDzVu/DxqMVEPB4v/t6O0KFwYoTFQ34y7dHceN7ubjzo1244Z0dWLQ+H+UGa9sv0E2cr7eg1sxwcywNVgeiVTKwLLB0Whp4PKD4ghlxYTJu2VHI52F7YRXGJGta7X225JujMFp+/9+3S1VjZhAiFnCBV8E5IyQiPr46cBbP3zQQWS3+ngaaf0q6OPNlNptRVHQxii8pKcGhQ4cQHh6O+Ph4LFmyBOfPn8fnn38OAHjwwQexcuVKPP3005g3bx62bduG//u//8PGjRu76iMQQnqJGjODnadrMCwhDOl9VEHPk4sFcLMszlSbf3fDSQvjanVMkcnKQNls99+8rCSsyiuBPj4Mq/JKUFjZgGilDLWNdu5YoOLtF/7b/ZqXGi0Mfi68gC0nKnv0rEejhcHZOgvUTZkfC+NCpckGhUSI7YXVmJQWBRfLIkEjB4/H42q8ACC/1IBhCeEYnhDGZby8mc1RCeGIUkvhYllUGG0oN9pgYZxQy8Ud2uDUZHNAIRXiWLkRBeeMmDk6Hh9sO40/T07FWz+exNzMJK7hr1IqhFIqRBy1mfDTpcHX/v37MWHCBO5nb13W7NmzsXr1alRUVKCsrIw7npSUhI0bN+Lxxx/HP/7xD/Tt2xefffYZtZkghHQ4k80BuViAoXFhiFBKAo4aMloYRCqleOV7/+73r1/B3D6lVBS02DontwS3X9sn4BDw+VnJnmL8B0ajwmiFWi7ijgXizdZ1p0CmusGOGJU04HJbd61VC6TGzEAiEsDpcnPLxxIhH2EhInz8SzEmDYjG2/8rxD2jE+Fye2q83p85FPWNdvxlWhouNNggF3u+qr3HTFYGcRo53th8AgvG6/DWjyfb5e/bpVBIhLA7XEjQyHH/uGR8uuMMUmNVKK+zYvEN/eFys2iwORAmb/8Gq1eTLg2+rrvuOrTWYH/16tUBn5Ofn9+BV0UIIf6UUhEWjE+GSMjDiXIjcmYPxyc7i3FtnBortp3GgFgVJg2IwrIWgRdwsfh9xWVml7QKMXLmjMCKbaf9go+cOSO4IvTmQ8DlYgEXsDU07TATCdquMOluzUsNVgdUchH+/r/CoK0WXrp5YFdc2mUx2RwQCnioMzu4Xm35Zw2YNCAK+ng1nG4W205ewO7iOnw+byQWjE+GQsJHlFKJVzcex+Ls/vCuCi8Ynwy5mI9EjRqvbDiGxdnXBGxFcaV/34Jp3sZELRMhv9yEBI0cpbWNeLRpV6aFccFid0Eq4qN/VGi3D4q7Wo8quCeEkK6iVYhxQ1oUlm86gRGJ4fgm/zyGxIf5FEPr49R+gZfXjivMLr2/rShg8MHn8bByhh6A7xDweVlJkAoF0MepYbI5cKzchOHxYYhUtr7pqDs1L600WLnl20CbBLyZP5e7y6bjXTK5WIAqkx1Otxvrm9p9DI8Pg1jIx9zMJJia5nZaGBd+PnUB09KjwQOwfOMJ7CyqxUMTdODzeMjUaXB9ahSOlxuhlIkxIFYFs92/t1bzTOmpajPCQ37fMmS5wYoXvi1AaqwSGYnhYFkWEaGebJbTzeJCg51bCi+50IjRyeEUeF0CCr4IIeQSqORinDNYkVdUi3mZSXj3p9OYm5UMAFwt1d2jg3e/By4/u1RjZrCzqCbgsUBLhTKxAGOSNeA3JboiFBLk5JZg8oIobD1RjbE6TcDgcGw3al5qtDD4rc4CpVQIs83J7f5rmfl7b4YeNoerC6/Un9HCwGjxzKi0Ol0Q8HnIL61HgjYEbjcPM5otoS7OTkHBOQMeahrADoBbSm6wObnfk8PJwuZwYsHYfuDxgNQYJUxWB4bHh4EPnk+w5XR72li88v2xoIO6L/fzvPBtAWaNToDJyiBeI0dZvRUL1x0MOLv06Hkjun843D30qN2OhBDSlSxNXe6bL+/p49TIK6qFViFGQnjrhcWXm10ytRGseYO5coMVi9bn49tD5yHg81BhtCFSKYFYyIc+Xo2tJ6pRcM6A2QF2TV7q2KPOUmNmECIRYMuJKkSGSoNuEliVV4KwbnLNgGdnZmFVAypMNrzw3wJMey8X5+uteGvLKcQoPYXxj67Phz4+DP+cPRxpMUo8PSUNpyobuN+JhXHB5nD5BJVyiQD7y+ohFfNhblpGDpWKoJKLwILldrfmnzWgr1qGZd8f89uJ612G9O6KNFoYnKk2I7+sHmcumP12SxotDIovmFFhsiE9TgWFhI9r49Uw2ZzYVVzLzS69ZWUeblmZh7s+2Y0/fLQLB0rroaGWEpeEMl+EEHKJvF3uJUI+HhiXDLeb5QKxVXNG4nAbPbkuN7ukbCNYC5WKuPFBQ+LUuD41CrWNdgj5PGw9UY1r+6oxN/Nin6iWXe4vd+xRZzDZHLA53Pj4l2LckBYddGRNXlEtmKbRSl3NaGHw86kLEAt4+Db/PBf82J1u3D06AW/+eBKLJl7j1yxXLhZgwfhkvHjTQCzbeBw7T9egkXFCLvFtWHq83Igb02NgsTthsbugCRWAZfmoa2S43+1XB86Cnx7T6rJ3baOn3cXPhRcQqZTA7nTDZHXiQoMdYXIRbA4XVDIx3tx8Eg9c1w82xoUJ/SNhc7hQ3+iE1eFCTm4J3mta7m45b/LFmwd2myC+u6PgixBCLlFkqARjU7TIP2tAdmoUfjpZhYxkDRaMTwafByzbeCLoF9Mrtw667C+m5jsZW/IGc7WNDO4aGY91e0qR1U+LMLkYx84bceScAdlpUfjjx7swLysJQh4Pj0xMgVDAQ73FAR6Phz5qWbcKvABPwCkUOGFhXCirs7R6bqO99ZE1weZdtrcaM4MYpRSRSin+/OUR7vEQsRDXp0Xi3Z9O45popd+yr4Vx4Z0tp1Fwzoi/3zkEZpsTDpcbTLOdkdsLq3H/2GSYLA7sLqnFdddEYsvxSoxM1IDH43E9wOZlJvn1Pmu5U5YPoLTWgg1Hy7mWFitn6vH+tjPYWVTLLYUuvqE/Ptx+Gg9PTIHLzUIhEcFkdUAhFbTa+sTl7h7BcE9AwRchhFwilVyMN6YPxovfFWBcSgRyckswaUAUbkiLQoXR1mZPLuDy+h0138m4I8icw6oGO9fby8WyEPCBaJUMC8YlQ8jnYWh84BYT41K0WNEUKHYnWoUYJyrtyNJpIBK03vy1tWXc1uZdtncLBpPNszOzeU2fViFGgkaGMxcaAQCf7CjGezP0cMM3MB+bosUrtw5ClFKKKKUnYPzf8SosaqoF+/iXYgzuo0aUUopPdhQjOy0KB38zYFxKJKobLg7pfnZqGqpNNu51vYFVTu7FerkfF4/Fiu2nucDrw1lD8dnOYi4gzNJpAQBOF4s7hsWBB8DKuMDjuSGXCFBtsnNd7Fv+ncrSaXBPGzWP5CIKvggh5DLEqmX4+51DcM5ghYVxYd7qfVgzbyR3PNgcxtuv7XPF77eilTmHbjfLbQLYVVyLrH5aLFx3EO/P1OPTHScxJzMJLHy/8LN0Grzajeq8mlPJxUgMl+OlWwZhX0ntJS3jtsxwKSTCVuddtlcLBi+lVASLwwkB37NcKBcLsGbuCDTaL9ZuBQvMdREKxDQLBlVyMbJ0Wpytt2BaegzmZSaBcbkhF/MxNF6NOav24p9zRuBEhQl91DIYrJ7+cxa7E/lnDcjUaZBfZsD7TYFX8/ovp4vlAq/3Zw5FpFLKBV6e3aWeAMzm8AzL3nKiCpMGRMPtZuFiWfynqYv9sg2+dWXUxf7yUfBFCCGXSSUXw2BxcIFBg82Jo+eNGKvTBtyd+Ht3E3rnHAZiYTxLb4zLjZzcEk9tEOOCmwV+OnkBvxbXBczEdZd6qUCi1TIYLQzG6rQYnazB8k0nkBqj5JbPwuQixIfLoZKLA2a41t03yi/w8rrSlh+t0SrEKCi3IVQqRKZOg3EpEeDzeCg32riAKK+o1i8wH5ui5dqFNBejlkEuFiAqVIpGxrME62JZLL89Hc99cxQzPtmNBeOTMTwhDCw8kw0UEiFyckvw0axhiFCK4XbDr/6rsWnDyLyspKbmrQLu+j+fNwIseGiweWrOzDYXPv6lGNmpURAL+cgvq8e9GYl496dCvy72MrGAq4ckl4aCL0IIuQJquQiPTEyBRMiHQiIAjwc8PKEf3GD96r0WNmsn0N5UMk8QEaGQeEbXGK3I0mlgd3qCq2CZuOzUyA67pvbQPOB86eaBWPL1Eb/2Ca/dkY5nvz7qF2gZrJe2S7Q9r1WrEGPzsUosvl6HUJkYTpen6UJrBerLWqkDDBZwv/XHa1HfyMBkc8LhdiM+TAZBPy0qTTZkJIdDoxDBYHGAz/NvQ6GUeb7yhyeEQSERQiry7NhdPXcEpEIhbE4XlFIRnG43lFIhLIwLs1ftxb8XjEaiJgQsWIxNiQAAnK2zQiLk47eaRoxL0XbLLGp3RsEXIYRcAe/y2FOT+4MHYERCOOav2R8wyzRv9T58vyirQ76gvEX5YiEfmToNnv7PEay9bzRqzPZWn9edmqq2xmhhsOSbo35ZnP2l9dy8zZa8GZ1g2vuzGy0Mjpwz4uhZA6alx6LWbAePx0P+WQP08eqAy43VTTsML5enNsx3ea+qwY5nvjqCLxdkwOpw4dOdxXhqUn+8N0OPdXtKAQCTBkTBbHNg2qBohIiFcLpYSOV8LJ2WBj6PB6vDhZ9OVuHmwbHY/5sBwxPCufquP328G6vmjsDJigYMappramFckIoESIsORWw327TRE1CfL0IIuUIysQCHyoz424+F4PN5XJZp/pr9eHjtQcxfsx8rtxXBwrg6bHyPtyi/vpHB3Mwk9I8OxazPdiNUKsTYFG3A51xJ24uuEijA8tYsBWqy6um3JkdWi35mXh3x2WvMDF787zHcNSoBdocLMrEACokAObklmJuZBH3Tpgfv34ucvJJ26wRvtDCQiQSoMTMorbPA6WYxJE4NuVjItaHIL6tHnZmBxe7GM1NT4XB7Cugb7U7o49RgWcBkc+LjX4pR18ggIlSKeosNy24dhCydBjVmBn/6eDdK6yxosDnBON2IUEiQpJFT4HWFKPNFCCFXqMbMIFIpwbaTF3D36MRWz+3ITFOsWoYGmwO3f/Arl2GpMNrw/LQBWLbBf8i3d6dkTxCo0ey8rCRUGK1I0IT4tVO4JioUyzYeD7rR4K8dsNHAaGW4gvpVc0ZAJhaAB2BYfFjgrJfJDgGv9Z2cl6rGzMDpZjFWp/Vko4Se3lwGqwMDYlVcb7colRR/3XgcS6amwcq4oJaJYLQ6IZYLYLZdbCNhtju5DvY3pEXir7cNgtXhRoPNgRCJEEqJEHGay9u1S/xR8EUIIVfIZHNwtVUHy9q3werlMFoYHCwzcBkWL29g8tB1OkhFAqhkvjslewKlVOQXYMWFy1FtsmF/aR3+OXs4Vm4v4j73949kcoOqAy0BW5nWe4NdCbnY81VqYVyQSwTYdrIakwdEYdFEHVa2GIo+VqfBookpULVTgbrJ5oBIwPPUG7KAsKk9R7nRiuHxYbg2To11e0oxLT2G2xwi4PHgZlmoZSK43SwEfB7XRmJ/aT3Xwf6dLad93qu7tifpiSj4IoSQK6SUilDX6BnNEqywemwnZJpqzAyWbTju9/4WxoX8snr8YWhfJGp7ZrZCqxAjZ84IrGgWxHwwaygAgGWBD7b7Dh432zxLkcE2GoxrKhhvT3w+jwu8q012HDlrgL5vGCKUYtyYHos5LWq9Epp2arYHpVSEeguD+Wv2Y8UMPcrrrYjXyCEW8KGSi/D3/xVi/DVabjSRQipAvYXBnFX7sHruCFgdbuQV1eB0ZQOev2kg/rb5BOZmJgHw/Xvc0zKm3R0FX4QQcoUUUiGqTTbui7flEpNaJkK/SEWH9z9qvuwVKNtjsFx+g9fu5P1tFwMsuViAyFAJjFYH0vuo8O5Pp7nM2PD4MKjbKGJXStv/a48HcAHLM195Njz8bfMJDI5Tc8OnrYwLarkIwxPC2r3NRWldIyyMC4+sz8f7M4dCKRNhZ1ENpg6MRmFlA5bdOgiVTQ1Yq012qGQi1JgZ/PHj3fjX/FH4ZEcxVs7U472fCjFzVAKiVRIsvXEAwPNMEQhr2s1JgVf7oeCLEEKuUKPdiWiVjOtGntes8/dYnRbLbhvUKY0nmy97Bcr23JQe0+HX0FFqzAzXO81baO9mWdQ1MggPEUMuFuC9GXqsyisB4Knr8u7SaylLp0FYOw9+LqttRH5ZPf53rJKbm3m23oJnb0wD43SjweaEWiZClNZ/l2J7UMnF6NPUpNXCuLBw3UF8OGsoTlaYMC4lAm9MH4xGxolfz3ga1np3RXrv0bbCaujj1Vi0zhO4A0BprZXL0t04KJqCrg5AwRchhFwho9XBFSc/MyUVgOcLUMjnIbeo5opGCl2J5steLWXqNBDw26e4uyt4C+7lYgE+mDkUcjEfAh4wMjEMZrsL87KSsCqvhOvyv2hdPpd5SotVcXViarkIcWpZuwZAVSYbXvr+GGZnJGL+2GSf2jPAs+T8t+mDfTrYd4RopZSbAWphXHho7UGsnKmH280iUilBo+3iQOxVeSW4N2cv/jl7BJZtPN5subzEr48aLTN2HAq+CCHkCimlIm44csviZAC4eXBsp1yHkM8LWKeTqdNgbmZSjw6+vAX3783QI1IpQcF5I1xuFnYXi70ldcjsp+GCBsblRo2ZwX1r9nmCiw3H/IKhN1rMdvw9w7frGxkM7qvGZzuLcaDMELCXV1s9x9pDyxmgFsaFRevykTNnBBptLggFPL9l6ZLaRjw1uT8Ypxs8HvDqbelgXG402p1+I6xI+6PgixBCrpC3wemOAI0+O7OXliZEjNc2neCWvZrXe/17bxn+fueQTrmOjqBViPH8TQOwbk8p/nxDfyRHKGC0OmCwOPDJjmKM6efpZSYXC9A3zBNU3arvg5c3HPPLBO5sMdux3GDFM/854jMS6nKGb5tsTmTptHj3J0/gHWjJt71rvIIJNgO03GjDj8cqudFXLa/RO+KIAq3ORcEXIYRcoZYZB6/OXrJRycV4+dZBePYr/xE8PX3pSCUXY2i8GucNVpjtTrCsJ8MlEfJhYTwNTQFP768T5SaM1Wmhj1MHDISAi7MdAfgFXt7jz3x15JICEqVUCIOl9ea5xjZGHbWnQCOJbE43jp4zYG5WIgDWp+fb2KaB2D3570dPRcEXIYT8DsEyDp39hdZdrqMjWBgX9HFqCPg8SEV8hEhl+PFYFTJ1GjhdbmTqNNDHqVFQbsTDE/rBwvh3vm+uweaAm2UDDkEHPBmy6gZ7m/cuLEQMh7v1AeWdsezYmiilFC/ePBAvf38MQ+LDuLYXKpkI8WEyxIVTh/quQMEXIYT8TsGGIPfW62hvSqkIFUYbcotqcMvgWOwuqcXxciPmZibB5nBx9W6DYlWYv2Y//r1gdKuvFyIRBh2+7W1bwbjcyC+rb7UOLEophcXubHWzQ4i4679m4zUhePWOwdxA7j5SIcJCxJ2yE5cE1vV/KwghhJBWaBViVDeI8MmOYkweGI2/bjzBDY2eNSoBX+wpw0MT+qHKZIeFcYFlETQgmpgaAamQz2WktAox3pg+GJFKCSx2FyJCJXjxuwK/5dtgdWAhEiEemZgCwH+zwyMTU9rsO9ZZAg3kJl2Hgi9CCCHdmkouRl+1DMPiw1Baa/HZuSfg8fD01P5wuQCVzLMEWGG0Bdz9OXVQFJ6anIq/fHMUS28agKmDorA4uz9eaSrOXzRRh/yyer+gbUeLQn2vcoMVL3xXgFmjEjAtPcZvp2NiO3ayJ1cXCr4IIYR0a0YLg90lddz8QsC3oezi7BSU1pix+Ib+yNJpIOTz8EiLbv9ykQB9wmR44bsCnKxsgFjAx1OTUvH8fwu4YOtSCvW9wZTRwuCZr45g5+ka/HqmFvOykrjMkkwkwMTUSMo0kaAo+CKEENKt1Zg93ey98wu9bRO8ru2rxvWpkXj9hxN4cnIqTpSb/IaML5qog1jEx8EyA75ckIHSWguiVFLkFdVydV5t1Wc12C7WiVU32LGzaYdroMkCW58Yjyhle3x6cjWi4IsQQki3ZrI5YHe6ufmF783Qww2Wy1iFhYjRYHPih4Iq/HKqBgvGJ+PFpiHRqU1d7iNCJTBYHFgwPhl8Pg8uloXB4uBGFlUYrVC0MfcxVOqp3zpXZ0FZnaXVc5sHaoS0RMEXIYSQbk0pFaGu0dObK9gA8fMGB3f8nS2n8f92lSJnzggcO28EADTaXQgLEWFC/0iYrA7knzVg6sBoLBifDKmIj41HKxCllCJLp8HBpm713tFEUpEAVUYrlFIhztdb8MzXRzCvqaYsGG+gRkgg/K6+AEIIIaQ1nt2OdmTqNAAuLvPNX7MfD689CJPNCYnQ9+vsnowENNqd2HC0AvPX7IeFccLpYsHjATKxADm5JRCL+LghLQortxchr6gWAh4P87OS8c/Zw5FfVs+9/rzV+7DpaCWsDhdKay3ILzOAz/N0hw9kbCdONyA9E2W+CCGEdGsquRjXXROBJK1nSHnz3YhjU7QIkQiw4/QFn/YSE/pH4o3NJ5FfZsCiiTpEhEpgsTvhcPEhFfGhj1dj3qp9+OieYVzdl0DAw4HSehw9Z/AZ1SQVCXCwrB7nDVY02J14b4YeFxrsePi6fnCzrF+LiYUTdJ17g0iPQ8EXIYSQbi9GLYNcLMCrt6WjkXHCwrigkokQ2VTL5W26ClwMzvLLDHhvhh6r8kqQk1uCLx4YDZYFthdWY9EEHVZuL0KDzQm5WICPZg2DViHBtX3VGNRHxT3Hu/zo6bDPR4xKind/OoWHr9Ph3py9fsuf+WcNmLd6H75flEVtJkhQFHwRQgjpEVrr4P/AuH74ZMcZLmNlc7gxLysJq/JKuGBs3up9WP/AaBw9a8TgPmpMS4+BUirCgvHJiAgV4+g5A1JjlFzGzFuIDwBONwuFRAibw4mZoxJgtDoC7nL0ooJ70hqq+SKEENKjqeRiJITLccOAaK5IXiERQh+n9muYWllvw9Kb0rB2TynKjTa43SxuSItCncWBC2Y7RAI+8opqsThbB5mIj59OVKGg3IhkbQjMdgdEAj5W5ZVAwOe1ek1UcE9aQ5kvQgghPV6MWoYbB0Vzg8VDJJ7xQXKxAAvGJ2PSgEjIRCI89+1R5DfbzVhjtiNCKYHZ7sS4ayJQY7ZDqxAjOy0af914HDNHJaDObEeN2Y6zdRak91WjsLIBCeFyZOk0yA0wwmgcFdyTNvBYlmW7+iI6m8lkgkqlgtFohFJJXfAIIeRqdKrKhPP1NsjFfEQopD7d7Jv79wOjIRMLcKHBDh6PB5ZlEamU4MdjVcgvq8czU1LxxuaTuH9sMgR8HhinG2v3lGLmqASfZU0AyNJp8OodgxEfLu/Mj9prXC3f35T5IoQQclVSycTY/1s9AEAhEQUMvABwARUAHCyrx9SB0WiwOaGPUyMntwR8Hg+FlQ0IEQvRYHciUinBtpMXsLu4LmDBvZVxdtpnJD0TBV+EEEKuSmabk5uvaLIFD4hyi2owuK8K+WcNOF5uxFidFkIBD043i/dnDoWFceGN6YPBuNw4WFaPrH6e/l7BCu7HpUR0zAciVw0quCeEEHJVMtkcYFxuTwG+VBD0vE92FCNWLUNObglmjkqAQiJEblEN4sJkqDBaIRbwEamUYFdxLY6XG6GUt15Mr2xjTBEhFHwRQgi5KimlIkQoJJAI+bjQYEdWU4f8lobGq6GUijA8IQyPrs+Hi2Vx9JwBAA9RSil+PlWNRpuLC87MNkfQ18rSaRAWQsX2pHUUfBFCCLkqaRViyMUC1JrtCJUI8NItA/2CpiydBstvT0esWobXpw/G8IQwzFu9D09PSUOlyQrG5cYnO4qhlIu4uZL7S+uw7LZBAV/r1dvTuaVOQoKh3Y49eLcEIYSQ1h0srYNIIMDfNp/AicoGvDF9MCKVEphtLiikAjTaXUiLDuWatxotDGrMDKyMAyKhAA02J/7w0S7kzBmOnNwSrrWEViHmXqvR7oJaJkJYiJgCrw52tXx/U/DVg395hBBCWnem2ozSOgvmrd4X9JytT4xHv0iF3+NGC4PzBiuWbzqBwsoGrL1vNJZtOObT28ub7YrXhHTI9RNfV8v3N1UFEkIIuWppFWL8VtvY6jnBRgGp5GKcuWDG3EzPmKJZn+3GG9MH45mpqWi0u6CUiSAX8SnwIpeNar4IIYRctVRyMfqGyVo9p7VRQCqZGI+uz4c+PgxvTB8Mu9ONapMduUU1+MOHv8Llbu8rJr0BZb4IIYRc1aKVUoxL0WLH6Rq/Y22NAtIqxBiWEBawn9dYGiNErlC3yHy9//77SExMhFQqxahRo7B3795Wz3/33XfRv39/yGQyxMXF4fHHH4fNZuukqyWEENKTqORivD59MMalaH0eH5eixRvTB3PF9sEsnKBDZoudjZk6DRZO0LX7tZLeocszX//+97/xxBNP4KOPPsKoUaPw7rvvYvLkySgsLERkZKTf+evWrcOzzz6LnJwcjBkzBqdOncKcOXPA4/Hw9ttvd8EnIIQQ0t3FqmVYMUPPDd4OlYqgVYjbDLxqzAzmrd4XcIzQvNX78P2irDZfg5CWujz4evvtt3H//fdj7ty5AICPPvoIGzduRE5ODp599lm/83/99VdkZmZi5syZAIDExETMmDEDe/bs6dTrJoQQ0rOo5G0HWy2ZbI6gY4SA4MX6hLSmS5cdGYbBgQMHkJ2dzT3G5/ORnZ2NXbt2BXzOmDFjcODAAW5psri4GJs2bcKNN94Y9H3sdjtMJpPPH0IIIaQtylaK8YHWi/UJCaZLg6+amhq4XC5ERUX5PB4VFYXKysqAz5k5cyZeeeUVZGVlQSQSoV+/frjuuuvwl7/8Jej7vPbaa1CpVNyfuLi4dv0chBBCrk5ahdivVsyrrWJ9QoLpFgX3l+Pnn3/Gq6++ig8++AAHDx7E119/jY0bN2LZsmVBn7NkyRIYjUbuz9mzZzvxigkhhPRUv7dYn5BAurTmS6vVQiAQoKqqyufxqqoqREdHB3zO888/j3vuuQf33XcfACA9PR2NjY144IEH8Nxzz4HP948nJRIJJBJJ+38AQgghV70rLdYnJJguzXyJxWIMGzYMW7du5R5zu93YunUrMjIyAj7HYrH4BVgCgQAA0AsnJRFCCOkEKrkY/SIVuDY+DP0iFRR4kd+ly3c7PvHEE5g9ezaGDx+OkSNH4t1330VjYyO3+/Hee+9Fnz598NprrwEAbr75Zrz99tvQ6/UYNWoUioqK8Pzzz+Pmm2/mgjBCCCGEkO6qy4OvP/3pT7hw4QJeeOEFVFZW4tprr8XmzZu5IvyysjKfTNfSpUvB4/GwdOlSnD9/HhEREbj55puxfPnyrvoIhBBCCCGXjMf2wrW6q2UqOiGEENKbXC3f3z1utyMhhBBCSE9GwRchhBBCSCei4IsQQgghpBNR8EUIIYQQ0oko+CKEEEII6UQUfBFCCCGEdCIKvgghhBBCOlGXN1ntCt7WZiaTqYuvhBBCCCGXyvu93dNblPbK4KuhoQEAEBcX18VXQgghhJDL1dDQAJVK1dWXccV6ZYd7t9uN8vJyhIaGgsfjtdvrmkwmxMXF4ezZsz268253R/e589C97hx0nzsH3efO0ZH3mWVZNDQ0IDY21mf0YE/TKzNffD4fffv27bDXVyqV9D/sTkD3ufPQve4cdJ87B93nztFR97knZ7y8em7YSAghhBDSA1HwRQghhBDSiSj4akcSiQQvvvgiJBJJV1/KVY3uc+ehe9056D53DrrPnYPuc9t6ZcE9IYQQQkhXocwXIYQQQkgnouCLEEIIIaQTUfBFCCGEENKJKPgihBBCCOlEFHy1o/fffx+JiYmQSqUYNWoU9u7d29WX1GO89tprGDFiBEJDQxEZGYnbbrsNhYWFPufYbDYsXLgQGo0GCoUC06dPR1VVlc85ZWVlmDZtGuRyOSIjI/HUU0/B6XR25kfpUV5//XXweDwsXryYe4zuc/s5f/487r77bmg0GshkMqSnp2P//v3ccZZl8cILLyAmJgYymQzZ2dk4ffq0z2vU1dVh1qxZUCqVUKvVmD9/Psxmc2d/lG7L5XLh+eefR1JSEmQyGfr164dly5b5zP6j+3z5duzYgZtvvhmxsbHg8Xj49ttvfY631z09cuQIxo4dC6lUiri4OPztb3/r6I/WPbCkXXzxxResWCxmc3Jy2GPHjrH3338/q1ar2aqqqq6+tB5h8uTJ7KpVq9iCggL20KFD7I033sjGx8ezZrOZO+fBBx9k4+Li2K1bt7L79+9nR48ezY4ZM4Y77nQ62UGDBrHZ2dlsfn4+u2nTJlar1bJLlizpio/U7e3du5dNTExkBw8ezD722GPc43Sf20ddXR2bkJDAzpkzh92zZw9bXFzM/vjjj2xRURF3zuuvv86qVCr222+/ZQ8fPszecsstbFJSEmu1WrlzpkyZwg4ZMoTdvXs3u3PnTlan07EzZszoio/ULS1fvpzVaDTshg0b2JKSEvbLL79kFQoF+49//IM7h+7z5du0aRP73HPPsV9//TULgP3mm298jrfHPTUajWxUVBQ7a9YstqCggF2/fj0rk8nYjz/+uLM+Zpeh4KudjBw5kl24cCH3s8vlYmNjY9nXXnutC6+q56qurmYBsL/88gvLsixrMBhYkUjEfvnll9w5J06cYAGwu3btYlnW848Fn89nKysruXM+/PBDVqlUsna7vXM/QDfX0NDApqSksFu2bGHHjx/PBV90n9vPM888w2ZlZQU97na72ejoaPbNN9/kHjMYDKxEImHXr1/PsizLHj9+nAXA7tu3jzvnhx9+YHk8Hnv+/PmOu/geZNq0aey8efN8HrvjjjvYWbNmsSxL97k9tAy+2uuefvDBB2xYWJjPvxvPPPMM279//w7+RF2Plh3bAcMwOHDgALKzs7nH+Hw+srOzsWvXri68sp7LaDQCAMLDwwEABw4cgMPh8LnHqampiI+P5+7xrl27kJ6ejqioKO6cyZMnw2Qy4dixY5149d3fwoULMW3aNJ/7CdB9bk///e9/MXz4cNx5552IjIyEXq/Hp59+yh0vKSlBZWWlz71WqVQYNWqUz71Wq9UYPnw4d052djb4fD727NnTeR+mGxszZgy2bt2KU6dOAQAOHz6M3NxcTJ06FQDd547QXvd0165dGDduHMRiMXfO5MmTUVhYiPr6+k76NF2jVw7Wbm81NTVwuVw+X0YAEBUVhZMnT3bRVfVcbrcbixcvRmZmJgYNGgQAqKyshFgshlqt9jk3KioKlZWV3DmBfgfeY8Tjiy++wMGDB7Fv3z6/Y3Sf209xcTE+/PBDPPHEE/jLX/6Cffv24dFHH4VYLMbs2bO5exXoXja/15GRkT7HhUIhwsPD6V43efbZZ2EymZCamgqBQACXy4Xly5dj1qxZAED3uQO01z2trKxEUlKS32t4j4WFhXXI9XcHFHyRbmfhwoUoKChAbm5uV1/KVefs2bN47LHHsGXLFkil0q6+nKua2+3G8OHD8eqrrwIA9Ho9CgoK8NFHH2H27NldfHVXj//7v//D2rVrsW7dOgwcOBCHDh3C4sWLERsbS/eZdFu07NgOtFotBAKB346wqqoqREdHd9FV9UyLFi3Chg0bsH37dvTt25d7PDo6GgzDwGAw+Jzf/B5HR0cH/B14jxHPsmJ1dTWGDh0KoVAIoVCIX375Be+99x6EQiGioqLoPreTmJgYDBgwwOextLQ0lJWVAbh4r1r7dyM6OhrV1dU+x51OJ+rq6uheN3nqqafw7LPP4q677kJ6ejruuecePP7443jttdcA0H3uCO11T3vzvyUUfLUDsViMYcOGYevWrdxjbrcbW7duRUZGRhdeWc/BsiwWLVqEb775Btu2bfNLRQ8bNgwikcjnHhcWFqKsrIy7xxkZGTh69KjP/+C3bNkCpVLp9yXYW11//fU4evQoDh06xP0ZPnw4Zs2axf033ef2kZmZ6dcu5dSpU0hISAAAJCUlITo62udem0wm7Nmzx+deGwwGHDhwgDtn27ZtcLvdGDVqVCd8iu7PYrGAz/f9KhMIBHC73QDoPneE9rqnGRkZ2LFjBxwOB3fOli1b0L9//6t6yREAtZpoL1988QUrkUjY1atXs8ePH2cfeOABVq1W++wII8E99NBDrEqlYn/++We2oqKC+2OxWLhzHnzwQTY+Pp7dtm0bu3//fjYjI4PNyMjgjntbIEyaNIk9dOgQu3nzZjYiIoJaILSh+W5HlqX73F727t3LCoVCdvny5ezp06fZtWvXsnK5nP3Xv/7FnfP666+zarWa/e6779gjR46wt956a8Dt+nq9nt2zZw+bm5vLpqSk9OoWCC3Nnj2b7dOnD9dq4uuvv2a1Wi379NNPc+fQfb58DQ0NbH5+Ppufn88CYN9++202Pz+fLS0tZVm2fe6pwWBgo6Ki2HvuuYctKChgv/jiC1Yul1OrCXJ5VqxYwcbHx7NisZgdOXIku3v37q6+pB4DQMA/q1at4s6xWq3sww8/zIaFhbFyuZy9/fbb2YqKCp/X+e2339ipU6eyMpmM1Wq17J///GfW4XB08qfpWVoGX3Sf28/333/PDho0iJVIJGxqair7ySef+Bx3u93s888/z0ZFRbESiYS9/vrr2cLCQp9zamtr2RkzZrAKhYJVKpXs3Llz2YaGhs78GN2ayWRiH3vsMTY+Pp6VSqVscnIy+9xzz/m0L6D7fPm2b98e8N/k2bNnsyzbfvf08OHDbFZWFiuRSNg+ffqwr7/+emd9xC7FY9lmbYAJIYQQQkiHopovQgghhJBORMEXIYQQQkgnouCLEEIIIaQTUfBFCCGEENKJKPgihBBCCOlEFHwRQgghhHQiCr4IIYQQQjoRBV+E9FBz5szBbbfd1tWX0W3cc8893BDrYBITE/Huu+92zgX1EM8++yweeeSRrr4MQnoVCr4I6YZ4PF6rf1566SX84x//wOrVq7vk+j799FMMGTIECoUCarUaer2eG2QMdH5gePjwYWzatAmPPvroZT2Px+Ph22+/7ZiLaqaurg6zZs2CUqmEWq3G/PnzYTabW32OzWbDwoULodFooFAoMH36dL8hxGVlZZg2bRrkcjkiIyPx1FNPwel0cscrKiowc+ZMXHPNNeDz+Vi8eLHf+zz55JNYs2YNiouL2+WzEkLaRsEXId1QRUUF9+fdd9+FUqn0eezJJ5+ESqWCWq3u9GvLycnB4sWL8eijj+LQoUPIy8vD008/3WYw0ZFWrFiBO++8EwqFosuuoTWzZs3CsWPHsGXLFmzYsAE7duzAAw880OpzHn/8cXz//ff48ssv8csvv6C8vBx33HEHd9zlcmHatGlgGAa//vor1qxZg9WrV+OFF17gzrHb7YiIiMDSpUsxZMiQgO+j1WoxefJkfPjhh+3zYQkhbevq+UaEkNatWrWKValUfo/Pnj2bvfXWW7mfx48fzy5atIh97LHHWLVazUZGRrKffPIJazab2Tlz5rAKhYLt168fu2nTJp/XOXr0KDtlyhQ2JCSEjYyMZO+++272woULQa/n1ltvZefMmRP0+Isvvug3D2779u0sy7JsWVkZe+edd7IqlYoNCwtjb7nlFrakpMTvM7300kusVqtlQ0ND2QULFvjM6WvJ6XSyKpWK3bBhg8/jVVVV7E033cRKpVI2MTGR/de//sUmJCSw77zzDsuyLJuQkOBzjQkJCUHf4/c4fvw4C4Ddt28f99gPP/zA8ng89vz58wGfYzAYWJFIxH755ZfcYydOnGABsLt27WJZlmU3bdrE8vl8trKykjvnww8/ZJVKZcD71XKGZ3Nr1qxh+/bteyUfjxByBSjzRchVZM2aNdBqtdi7dy8eeeQRPPTQQ7jzzjsxZswYHDx4EJMmTcI999wDi8UCADAYDJg4cSL0ej3279+PzZs3o6qqCn/84x+Dvkd0dDR2796N0tLSgMeffPJJ/PGPf8SUKVO4TN2YMWPgcDgwefJkhIaGYufOncjLy4NCocCUKVPAMAz3/K1bt+LEiRP4+eefsX79enz99dd4+eWXg17PkSNHYDQaMXz4cJ/H58yZg7Nnz2L79u34z3/+gw8++ADV1dXc8X379gEAVq1ahYqKCu7nQAYOHAiFQhH0z9SpU4M+d9euXVCr1T7Xl52dDT6fjz179gR8zoEDB+BwOJCdnc09lpqaivj4eOzatYt73fT0dERFRXHnTJ48GSaTCceOHQt6PYGMHDkS586dw2+//XZZzyOEXBlhV18AIaT9DBkyBEuXLgUALFmyBK+//jq0Wi3uv/9+AMALL7yADz/8EEeOHMHo0aOxcuVK6PV6n0L1nJwcxMXF4dSpU7jmmmv83uPFF1/EHXfcgcTERFxzzTXIyMjAjTfeiD/84Q/g8/lQKBSQyWSw2+2Ijo7mnvevf/0Lbrcbn332GXg8HgBP4KNWq/Hzzz9j0qRJAACxWIycnBzI5XIMHDgQr7zyCp566iksW7YMfL7//18sLS2FQCBAZGQk99ipU6fwww8/YO/evRgxYgQA4J///CfS0tK4cyIiIgAAarXa5zoD2bRpExwOR9DjMpks6LHKykqfawMAoVCI8PBwVFZWBn2OWCz2W1aOiorinlNZWekTeHmPe49djtjYWACee5mYmHhZzyWEXD4Kvgi5igwePJj7b4FAAI1Gg/T0dO4x75ezNwN0+PBhbN++PWCt1JkzZwIGXzExMdi1axcKCgqwY8cO/Prrr5g9ezY+++wzbN68OWCA5H2voqIihIaG+jxus9lw5swZ7uchQ4ZALpdzP2dkZMBsNuPs2bNISEjwe12r1QqJRMIFdABw4sQJCIVCDBs2jHssNTX1imvkAr3v1cQbPHozooSQjkXBFyFXEZFI5PMzj8fzecwboLjdbgCA2WzGzTffjDfeeMPvtWJiYlp9r0GDBmHQoEF4+OGH8eCDD2Ls2LH45ZdfMGHChIDnm81mDBs2DGvXrvU75s1CXQmtVguLxQKGYSAWi6/4dVozcODAoMusADB27Fj88MMPAY9FR0f7LHcCgNPpRF1dXdCMW3R0NBiGgcFg8AkYq6qquOdER0dj7969Ps/z7oZsK5PXUl1dHYDf93sghFw6Cr4I6cWGDh2Kr776ComJiRAKr/yfgwEDBgAAGhsbAXiWDl0ul997/fvf/0ZkZCSUSmXQ1zp8+DCsViuXjdm9ezcUCgXi4uICnn/ttdcCAI4fP879d2pqKpxOJw4cOMAtOxYWFsJgMPg8VyQS+V1nIL9n2TEjIwMGgwEHDhzgMnHbtm2D2+3GqFGjAj5n2LBhEIlE2Lp1K6ZPn85df1lZGTIyMrjXXb58Oaqrq7llzS1btkCpVHK/j0tVUFAAkUiEgQMHXtbzCCFXhgruCenFFi5ciLq6OsyYMQP79u3DmTNn8OOPP2Lu3LlBg5KHHnoIy5YtQ15eHkpLS7F7927ce++9iIiI4AKDxMREHDlyBIWFhaipqYHD4cCsWbOg1Wpx6623YufOnSgpKcHPP/+MRx99FOfOneNen2EYzJ8/H8ePH8emTZvw4osvYtGiRUGXMyMiIjB06FDk5uZyj/Xv3x9TpkzBggULsGfPHhw4cAD33XefX5CUmJiIrVu3orKyEvX19UHvU0JCAnQ6XdA/ffr0CfrctLQ0TJkyBffffz/27t2LvLw8LFq0CHfddRdXa3X+/HmkpqZymSyVSoX58+fjiSeewPbt23HgwAHMnTsXGRkZGD16NABg0qRJGDBgAO655x4cPnwYP/74I5YuXYqFCxdCIpFw73/o0CEcOnQIZrMZFy5cwKFDh3D8+HGfa9y5cyfGjh3bahBJCGk/FHwR0ovFxsYiLy8PLpcLkyZNQnp6OhYvXgy1Wh002MnOzsbu3btx55134pprrsH06dMhlUqxdetWaDQaAMD999+P/v37Y/jw4YiIiEBeXh7kcjl27NiB+Ph43HHHHUhLS8P8+fNhs9l8MmHXX389UlJSMG7cOPzpT3/CLbfcgpdeeqnVz3Hffff5LWeuWrUKsbGxGD9+PO644w488MADfoXvb731FrZs2YK4uDjo9foruIOXZu3atUhNTcX111+PG2+8EVlZWfjkk0+44w6HA4WFhT41V++88w5uuukmTJ8+HePGjUN0dDS+/vpr7rhAIMCGDRsgEAiQkZGBu+++G/feey9eeeUVn/fW6/XQ6/U4cOAA1q1bB71ejxtvvNHnnC+++ILblEEI6Xg8lmXZrr4IQggBPO0hDAbDZXedt1qt6N+/P/79739z2TdyaX744Qf8+c9/xpEjR37X0jMh5NJR5osQ0uPJZDJ8/vnnqKmp6epL6XEaGxuxatUqCrwI6UT0vzZCyFXhuuuu6+pL6JH+8Ic/dPUlENLr0LIjIYQQQkgnomVHQgghhJBORMEXIYQQQkgnouCLEEIIIaQTUfBFCCGEENKJKPgihBBCCOlEFHwRQgghhHQiCr4IIYQQQjoRBV+EEEIIIZ2Igi9CCCGEkE70/wGAoSxUoya59gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot([x for x in range(len(x_t_list))], x_t_list)\n",
    "plt.xlabel('Time Step (dt = 0.001)')\n",
    "plt.ylabel('x_t Value')\n",
    "plt.title('Sampling x_t from learned reverse process, gt x_0 = 1.0, random init')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
