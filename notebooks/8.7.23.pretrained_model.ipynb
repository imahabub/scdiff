{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/rsg/chemistry/johnyang/miniconda3/envs/pcvr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.functional import pad\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from functools import reduce\n",
    "import math\n",
    "from einops import rearrange, repeat\n",
    "from perceiver_pytorch import PerceiverIO\n",
    "from torch import nn, einsum\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import h5py as h5\n",
    "from functools import partial\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "VOCAB_SIZE = 60873\n",
    "\n",
    "MAX_LEN = 18976\n",
    "\n",
    "DEFAULT_ENCODING = \"utf-8\"\n",
    "\n",
    "DEFAULT_BINS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_vocab(path):\n",
    "    with open(path, \"r\", encoding=DEFAULT_ENCODING) as inf:\n",
    "        return {gene: i for i, gene in enumerate(json.load(inf))}\n",
    "\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn, context_dim=None):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.norm_context = nn.LayerNorm(context_dim) if exists(context_dim) else None\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if exists(self.norm_context):\n",
    "            context = kwargs[\"context\"]\n",
    "            normed_context = self.norm_context(context)\n",
    "            kwargs.update(context=normed_context)\n",
    "\n",
    "        return self.fn(x, **kwargs)\n",
    "\n",
    "\n",
    "class GEGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gates = x.chunk(2, dim=-1)\n",
    "        return x * F.gelu(gates)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, mult=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim * mult * 2), GEGLU(), nn.Linear(dim * mult, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, query_dim, context_dim=None, heads=8, dim_head=64):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        context_dim = default(context_dim, query_dim)\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "\n",
    "        self.to_q = nn.Linear(query_dim, inner_dim, bias=False)\n",
    "        self.to_kv = nn.Linear(context_dim, inner_dim * 2, bias=False)\n",
    "        self.to_out = nn.Linear(inner_dim, query_dim)\n",
    "\n",
    "    def forward(self, x, context=None, mask=None):\n",
    "        h = self.heads\n",
    "\n",
    "        q = self.to_q(x)\n",
    "        context = default(context, x)\n",
    "        k, v = self.to_kv(context).chunk(2, dim=-1)\n",
    "\n",
    "        q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> (b h) n d\", h=h), (q, k, v))\n",
    "\n",
    "        sim = einsum(\"b i d, b j d -> b i j\", q, k) * self.scale\n",
    "\n",
    "        if exists(mask):\n",
    "            mask = rearrange(mask, \"b ... -> b (...)\")\n",
    "            max_neg_value = -torch.finfo(sim.dtype).max\n",
    "            mask = repeat(mask, \"b j -> (b h) () j\", h=h)\n",
    "            sim.masked_fill_(~mask, max_neg_value)\n",
    "\n",
    "        # attention, what we cannot get enough of\n",
    "        attn = sim.softmax(dim=-1)\n",
    "\n",
    "        out = einsum(\"b i j, b j d -> b i d\", attn, v)\n",
    "        out = rearrange(out, \"(b h) n d -> b n (h d)\", h=h)\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "# Main classes #####################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "class Encoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mask_prob,\n",
    "        mask_ignore_token_ids,\n",
    "        mask_token_id,\n",
    "        emb_dim,\n",
    "        logits_dim,\n",
    "        depth,\n",
    "        num_latents,\n",
    "        latent_dim,\n",
    "        cross_heads,\n",
    "        latent_heads,\n",
    "        cross_dim_head,\n",
    "        latent_dim_head,\n",
    "        weight_tie_layers,\n",
    "        seq_dropout_prob,\n",
    "        nbins: int = DEFAULT_BINS,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.mask_ignore_token_ids = set(mask_ignore_token_ids)\n",
    "        self.mask_prob = mask_prob\n",
    "        # TODO: clean up later\n",
    "        self.mask_token_id = mask_token_id\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.model = PerceiverIO(\n",
    "            dim=emb_dim,  # dimension of sequence to be encoded\n",
    "            queries_dim=emb_dim,  # dimension of decoder queries\n",
    "            logits_dim=logits_dim,  # dimension of final logits\n",
    "            depth=depth,  # depth of net\n",
    "            num_latents=num_latents,  # number of latents, or induced set points, or centroids. different papers giving it different names\n",
    "            latent_dim=latent_dim,  # latent dimension\n",
    "            cross_heads=cross_heads,  # number of heads for cross attention. paper said 1\n",
    "            latent_heads=latent_heads,  # number of heads for latent self attention, 8\n",
    "            cross_dim_head=cross_dim_head,  # number of dimensions per cross attention head\n",
    "            latent_dim_head=latent_dim_head,  # number of dimensions per latent self attention head\n",
    "            weight_tie_layers=weight_tie_layers,  # whether to weight tie layers (optional, as indicated in the diagram)\n",
    "            seq_dropout_prob=seq_dropout_prob,  # fraction of the tokens from the input sequence to dropout (structured dropout, for saving compute and regularizing effects)\n",
    "        )\n",
    "\n",
    "        self.seq_dropout_prob = seq_dropout_prob\n",
    "\n",
    "        self.queries = torch.randn(MAX_LEN, self.emb_dim)  # latent_dim\n",
    "        self.emb = nn.Embedding(VOCAB_SIZE + nbins + 2, self.emb_dim)\n",
    "        self.pos_emb = nn.Embedding(MAX_LEN, self.emb_dim)  # +1 for exp\n",
    "\n",
    "    def forward(self, gid, bin_t, pad_mask):\n",
    "        x = self.emb(gid)\n",
    "        x += self.emb(bin_t)\n",
    "\n",
    "        # n, device = x.shape[1], x.device\n",
    "        # pos_emb = self.pos_emb(torch.arange(n, device=device))\n",
    "        # pos_emb = rearrange(pos_emb, \"n d -> () n d\")\n",
    "        # x = x + pos_emb\n",
    "\n",
    "        z = self.model(x, pad_mask)\n",
    "        return x, z\n",
    "\n",
    "\n",
    "class Decoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, emb_dim, logits_dim, latent_dim, cross_heads, cross_dim_head, decoder_ff\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder_cross_attn = PreNorm(\n",
    "            emb_dim,\n",
    "            Attention(emb_dim, latent_dim, heads=cross_heads, dim_head=cross_dim_head),\n",
    "            context_dim=latent_dim,\n",
    "        )\n",
    "        self.decoder_ff = PreNorm(emb_dim, FeedForward(emb_dim)) if decoder_ff else None\n",
    "        self.to_logits = (\n",
    "            nn.Linear(emb_dim, logits_dim) if exists(logits_dim) else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        latents = self.decoder_cross_attn(x, context=z)\n",
    "        latents = latents + self.decoder_ff(latents)\n",
    "        return self.to_logits(latents)\n",
    "\n",
    "\n",
    "class CellGP(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr=1e-4,\n",
    "        mask_prob=0.15,\n",
    "        mask_ignore_token_ids=[0],\n",
    "        mask_token_id=1,\n",
    "        pad_token_id=0,\n",
    "        emb_dim=256,\n",
    "        logits_dim_enc=None,\n",
    "        logits_dim_dec=1,\n",
    "        depth=6,\n",
    "        num_latents=256,\n",
    "        latent_dim=256,\n",
    "        cross_heads=1,\n",
    "        latent_heads=8,\n",
    "        cross_dim_head=64,\n",
    "        latent_dim_head=64,\n",
    "        weight_tie_layers=False,\n",
    "        seq_dropout_prob=0.1,\n",
    "        nbins: int = DEFAULT_BINS,\n",
    "        tokenizer=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "        assert tokenizer is not None\n",
    "\n",
    "        self.mask_prob = mask_prob\n",
    "        self.mask_token_id = mask_token_id\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            mask_prob,\n",
    "            mask_ignore_token_ids,\n",
    "            mask_token_id,\n",
    "            emb_dim,\n",
    "            logits_dim_enc,\n",
    "            depth,\n",
    "            num_latents,\n",
    "            latent_dim,\n",
    "            cross_heads,\n",
    "            latent_heads,\n",
    "            cross_dim_head,\n",
    "            latent_dim_head,\n",
    "            weight_tie_layers,\n",
    "            seq_dropout_prob,\n",
    "            nbins=nbins,\n",
    "        )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            emb_dim,\n",
    "            logits_dim=logits_dim_dec,\n",
    "            latent_dim=latent_dim,\n",
    "            cross_heads=cross_heads,\n",
    "            cross_dim_head=cross_dim_head,\n",
    "            decoder_ff=True,\n",
    "        )\n",
    "\n",
    "        # self.decoder = MLPDecoder(\n",
    "        #    emb_dim,\n",
    "        # )\n",
    "\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad_()\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.mask_ignore_token_ids = set(mask_ignore_token_ids)\n",
    "\n",
    "    def forward(self, gid, bin_t, pad_mask):\n",
    "        x_emb, z = self.encoder(gid, bin_t, pad_mask)\n",
    "        bin_hat = self.decoder(x_emb, z)\n",
    "        return bin_hat\n",
    "\n",
    "    def _mask_with_tokens(self, t, token_ids):\n",
    "        init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "        mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "        return mask\n",
    "\n",
    "    def _prob_mask_like(self, t, prob):\n",
    "        return torch.zeros_like(t).float().uniform_(0, 1) < prob\n",
    "\n",
    "    def _get_mask_subset_with_prob(self, t, mask, prob):\n",
    "        batch, seq_len, device = *mask.shape, mask.device\n",
    "        max_masked = math.ceil(prob * seq_len)\n",
    "\n",
    "        num_tokens = mask.sum(dim=-1, keepdim=True)\n",
    "        mask_excess = mask.cumsum(dim=-1) > (num_tokens * prob).ceil()\n",
    "        mask_excess = mask_excess[:, :max_masked]\n",
    "\n",
    "        rand = torch.rand((batch, seq_len), device=device).masked_fill(~mask, -1e9)\n",
    "        _, sampled_indices = rand.topk(max_masked, dim=-1)\n",
    "        sampled_indices = (sampled_indices + 1).masked_fill_(mask_excess, 0)\n",
    "\n",
    "        new_mask = torch.zeros((batch, seq_len + 1), device=device)\n",
    "        new_mask.scatter_(-1, sampled_indices, 1)\n",
    "        return new_mask[:, 1:].bool()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._shared_eval_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._shared_eval_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss, sync_dist=True)\n",
    "\n",
    "    def _shared_eval_step(self, batch, batch_idx):\n",
    "        gid_orig, bin_orig, mask_zero_batch = batch\n",
    "        no_mask = self._mask_with_tokens(gid_orig, self.mask_ignore_token_ids) #True cannot be masked, False can be masked.\n",
    "        pad_mask = ~no_mask #False cannot be masked, True can be masked.\n",
    "        gid_max = gid_orig.max()\n",
    "        \n",
    "        # if masked training\n",
    "        if self.mask_prob > 0:\n",
    "            no_zero_mask = no_mask | mask_zero_batch #True cannot be masked, False can be masked.\n",
    "            true_can_mask = ~no_zero_mask #False cannot be masked, True can be masked.\n",
    "            \n",
    "            mask = self._get_mask_subset_with_prob(gid_orig, true_can_mask, self.mask_prob)\n",
    "            gid_t = gid_orig.masked_fill(mask, self.mask_token_id)\n",
    "            bin_t = bin_orig.masked_fill(mask, self.mask_token_id)\n",
    "\n",
    "        bin_hat = self(gid_t, bin_t, pad_mask)\n",
    "\n",
    "        bin_hat_batch = torch.cat(\n",
    "            [bin_hat[i, mask[i, :]] for i in range(bin_hat.shape[0])]\n",
    "        )\n",
    "        bin_orig_batch = torch.cat(\n",
    "            [bin_orig[i, mask[i, :]] - gid_max - 1 for i in range(bin_orig.shape[0])],\n",
    "        )\n",
    "        loss = self.criterion(bin_hat_batch, bin_orig_batch)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def fixed_bin_collate(batch, vocab, genes, bins):\n",
    "    \"\"\"\n",
    "    Collate function for dataloader providing binning on a per cell basis\n",
    "    \"\"\"\n",
    "    assert bins > 0\n",
    "    bins = (\n",
    "        bins - 2\n",
    "    )  # searchsorted produces an extra bin on the left or right, and zero genes should get bin 0\n",
    "    extra_tokens = 2\n",
    "\n",
    "    # this array allows us to remap vocab integers to integers between 0-1\n",
    "    index = torch.full((max(vocab.values()) + 1,), -1, dtype=torch.int64)\n",
    "    index[genes] = torch.arange(0, len(genes), dtype=torch.int64)\n",
    "\n",
    "    gid_batch = torch.zeros((len(batch), len(genes)), dtype=torch.int64)\n",
    "    bins_batch = torch.full(\n",
    "        (len(batch), len(genes)), len(genes) + extra_tokens, dtype=torch.int64\n",
    "    )\n",
    "    mask_zero_batch = torch.zeros((len(batch), len(genes)), dtype=torch.bool)\n",
    "\n",
    "    # import ipdb\n",
    "    # ipdb.set_trace()\n",
    "    \n",
    "    for i, (gid, exp, med) in enumerate(batch):\n",
    "        if len(gid) == 0:\n",
    "            continue\n",
    "        try:\n",
    "            gid_t = torch.tensor(gid, dtype=torch.int64)\n",
    "            gid_batch[i] = index[genes] + extra_tokens\n",
    "            exp_t = torch.tensor(exp)\n",
    "            \n",
    "            genes_in_gid = set([x.item() for x in gid_t[index[gid_t] != -1]])\n",
    "            genes_not_in_gid = list(set(genes).difference(genes_in_gid))\n",
    "            mask_zero_batch[i, index[genes_not_in_gid]] = True\n",
    "            \n",
    "            exp_t = exp_t[index[gid_t] != -1]\n",
    "            exp_t = torch.log1p(exp_t * med / exp_t.sum())\n",
    "            bin_e = torch.linspace(exp_t.min(), exp_t.max(), bins)\n",
    "            bins_batch[i, index[gid_t[index[gid_t] != -1]]] = (\n",
    "                torch.searchsorted(bin_e, exp_t, side=\"right\")\n",
    "                + len(genes)\n",
    "                + extra_tokens\n",
    "                + 1\n",
    "            )\n",
    "        except:\n",
    "            continue\n",
    "    return gid_batch, bins_batch, mask_zero_batch\n",
    "\n",
    "\n",
    "class SCDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.hf = h5.File(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf[\"gid\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.hf[\"gid\"][idx], self.hf[\"exp\"][idx], self.hf[\"med\"][idx]\n",
    "\n",
    "\n",
    "class DM(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        vocab,\n",
    "        subset_genes,\n",
    "        nbins,\n",
    "        train_percentage=0.85,\n",
    "        val_percentage=0.10,\n",
    "        test_percentage=0.05,\n",
    "        batch_size=16,\n",
    "        num_workers=16,\n",
    "        timeout=5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "\n",
    "        self.nbins = nbins\n",
    "        self.vocab = vocab\n",
    "        self.collate_fn = partial(\n",
    "            fixed_bin_collate,\n",
    "            vocab=self.vocab,\n",
    "            genes=subset_genes,\n",
    "            bins=self.nbins,\n",
    "        )\n",
    "        self.train_percentage = train_percentage\n",
    "        self.val_percentage = val_percentage\n",
    "        self.test_percentage = test_percentage\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.timeout = timeout\n",
    "\n",
    "    def setup(self, stage: str = \"default\"):\n",
    "        self.dset = SCDataset(self.path)\n",
    "        \n",
    "        val_size = int(self.val_percentage * len(self.dset))\n",
    "        test_size = int(self.test_percentage * len(self.dset))\n",
    "        train_size = len(self.dset) - val_size - test_size\n",
    "        \n",
    "        self.dset_train, self.dset_val, self.dset_test = random_split(\n",
    "            self.dset,\n",
    "            [ train_size, val_size, test_size ],\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dset_train,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            timeout=self.timeout,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns a DataLoader that loads the validation dataset.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.dset_val,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            timeout=self.timeout,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns a DataLoader that loads the holdout (test) dataset.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.dset_test,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            timeout=self.timeout,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )\n",
    "\n",
    "    def teardown(self, stage: str):\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_collate():\n",
    "    vocab = {v: k for k, v in enumerate(\"abcdefghij\")}\n",
    "    genes = [1, 2, 3]\n",
    "    bins = 3\n",
    "    print(vocab)\n",
    "   \n",
    "   \n",
    "    gid = [2, 3, 4, 5]\n",
    "    exp = [2, 1, 9, 1]\n",
    "    med = 5\n",
    "    batch = [[gid, exp, med]]\n",
    "    print(fixed_bin_collate(batch, vocab, genes, bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9}\n",
      "(tensor([[2, 3, 4]]), tensor([[5, 7, 7]]), tensor([[ True, False, False]]))\n"
     ]
    }
   ],
   "source": [
    "test_collate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = read_vocab(\"../vocab_ccle.json\")\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "BINS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ccle_vocab_genes.json\", \"r\") as inf:\n",
    "    ccle_vocab_genes = sorted(json.load(inf))\n",
    "MAX_LEN = len(ccle_vocab_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = '/storage/ujp/processed_raw.h5'\n",
    "subset_path = '/Mounts/rbg-storage1/users/johnyang/cellot/datasets/process_raw_10k_subset.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_file_path = \"/storage/ujp/processed_raw.h5\"\n",
    "\n",
    "# # Path to the new HDF5 file\n",
    "# subset_file_path = subset_path\n",
    "\n",
    "# # Number of cells to include in the subset\n",
    "# num_cells = 10000\n",
    "\n",
    "# # Open the original HDF5 file\n",
    "# with h5.File(original_file_path, 'r') as original_file:\n",
    "#     # Read the 'exp' dataset\n",
    "#     original_exp = original_file['exp']\n",
    "    \n",
    "#     # Check the shape of the 'exp' dataset\n",
    "#     original_shape = original_exp.shape\n",
    "#     print(f\"Original shape: {original_shape}\")\n",
    "\n",
    "#     # Check if the original dataset has at least num_cells cells\n",
    "#     if original_shape[0] < num_cells:\n",
    "#         print(f\"The original dataset has fewer than {num_cells} cells.\")\n",
    "#     else:\n",
    "#         # Create the new HDF5 file\n",
    "#         with h5.File(subset_file_path, 'w') as subset_file:\n",
    "#             # Create a new dataset in the new file with the same name ('exp')\n",
    "#             # but only the first num_cells cells\n",
    "#             subset_file.create_dataset('exp', data=original_exp[:num_cells])\n",
    "#             subset_file.create_dataset('gid', data=original_file['gid'][:num_cells])\n",
    "#             subset_file.create_dataset('med', data=original_file['med'][:num_cells])\n",
    "\n",
    "#         print(f\"Subset file created with {num_cells} cells at {subset_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['exp', 'gid', 'med']>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = h5.File(subset_path)\n",
    "subset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset['exp'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 2, 1, 2, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset['exp'][9][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset['gid'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = h5.File(original_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4266,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original['gid'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m zeros \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(original[\u001b[39m'\u001b[39m\u001b[39mexp\u001b[39m\u001b[39m'\u001b[39m])):\n\u001b[0;32m----> 3\u001b[0m     exp_i \u001b[39m=\u001b[39m original[\u001b[39m'\u001b[39;49m\u001b[39mexp\u001b[39;49m\u001b[39m'\u001b[39;49m][i]\n\u001b[1;32m      4\u001b[0m     zeros \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mwhere(exp_i \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/data/rsg/chemistry/johnyang/miniconda3/envs/pcvr/lib/python3.9/site-packages/h5py/_hl/dataset.py:756\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Read a slice from the HDF5 dataset.\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \n\u001b[1;32m    746\u001b[0m \u001b[39mTakes slices and recarray-style field names (more than one is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39m* Boolean \"mask\" array indexing\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    754\u001b[0m args \u001b[39m=\u001b[39m args \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(args, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m (args,)\n\u001b[0;32m--> 756\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fast_read_ok \u001b[39mand\u001b[39;00m (new_dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    757\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    758\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fast_reader\u001b[39m.\u001b[39mread(args)\n",
      "File \u001b[0;32m/data/rsg/chemistry/johnyang/miniconda3/envs/pcvr/lib/python3.9/site-packages/h5py/_hl/base.py:536\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    534\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m--> 536\u001b[0m value \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(obj)\n\u001b[1;32m    537\u001b[0m \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m/data/rsg/chemistry/johnyang/miniconda3/envs/pcvr/lib/python3.9/site-packages/h5py/_hl/dataset.py:739\u001b[0m, in \u001b[0;36mDataset._fast_read_ok\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[39m@cached_property\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fast_read_ok\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    736\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Is this dataset suitable for simple reading\"\"\"\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    738\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extent_type \u001b[39m==\u001b[39m h5s\u001b[39m.\u001b[39mSIMPLE\n\u001b[0;32m--> 739\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid\u001b[39m.\u001b[39;49mget_type(), (h5t\u001b[39m.\u001b[39mTypeIntegerID, h5t\u001b[39m.\u001b[39mTypeFloatID))\n\u001b[1;32m    740\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "zeros = 0\n",
    "for i in range(len(original['exp'])):\n",
    "    exp_i = original['exp'][i]\n",
    "    zeros += np.sum(np.where(exp_i == 1, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18899664"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60873"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_collate()\n",
    "\n",
    "dm = DM(\n",
    "    subset_path,\n",
    "    vocab=tokenizer,\n",
    "    subset_genes=ccle_vocab_genes,\n",
    "    nbins=BINS,\n",
    "    train_percentage=0.85,\n",
    "    val_percentage=0.10,\n",
    "    test_percentage=0.05,\n",
    "    batch_size=16,\n",
    "    num_workers=16,\n",
    "    timeout=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9}\n",
      "(tensor([[2, 3, 4]]), tensor([[5, 7, 7]]), tensor([[False,  True, False]]))\n"
     ]
    }
   ],
   "source": [
    "test_collate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"dryrun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/rsg/chemistry/johnyang/miniconda3/envs/pcvr/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "/data/rsg/chemistry/johnyang/miniconda3/envs/pcvr/lib/python3.9/site-packages/lightning_fabric/connector.py:554: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | encoder   | Encoder          | 44.9 M\n",
      "1 | decoder   | Decoder          | 1.1 M \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "46.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "46.0 M    Total params\n",
      "184.025   Total estimated model params size (MB)\n",
      "/data/rsg/chemistry/johnyang/miniconda3/envs/pcvr/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:08<00:00,  8.33s/it, v_num=]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:08<00:00,  8.33s/it, v_num=]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CellGP(\n",
    "    lr=1e-4,\n",
    "    mask_prob=0.5,\n",
    "    mask_ignore_token_ids=[0],\n",
    "    mask_token_id=1,\n",
    "    emb_dim=256,\n",
    "    logits_dim_enc=None,\n",
    "    logits_dim_dec=BINS,\n",
    "    depth=8,\n",
    "    num_latents=256,\n",
    "    latent_dim=256,\n",
    "    cross_heads=1,\n",
    "    latent_heads=8,\n",
    "    cross_dim_head=256,\n",
    "    latent_dim_head=256,\n",
    "    weight_tie_layers=False,\n",
    "    seq_dropout_prob=0.1,\n",
    "    nbins=BINS,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# trainer = pl.Trainer(\n",
    "#     accelerator=\"cpu\",\n",
    "#     precision=32,\n",
    "#     max_epochs=1,\n",
    "# )\n",
    "\n",
    "wandb_logger = WandbLogger(log_model=\"all\", project=\"CellGP_Encoder\")\n",
    "cback = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_top_k=1)\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    strategy=\"auto\",\n",
    "    devices=1,\n",
    "    precision=16,\n",
    "    max_epochs=11,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[cback],\n",
    "    fast_dev_run=True,\n",
    ")\n",
    "trainer.fit(model, dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cot2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
