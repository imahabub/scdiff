{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from absl import logging\n",
    "from absl.flags import FLAGS\n",
    "from cellot import losses\n",
    "from cellot.utils.loaders import load\n",
    "from cellot.models.cellot import compute_loss_f, compute_loss_g, compute_w2_distance\n",
    "from cellot.train.summary import Logger\n",
    "from cellot.data.utils import cast_loader_to_iterator\n",
    "from cellot.models.ae import compute_scgen_shift\n",
    "from tqdm import trange\n",
    "\n",
    "from cellot.models.ae import AutoEncoder\n",
    "\n",
    "import omegaconf\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, Linear\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "logger = logging.getLogger(\"data_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# %%\n",
    "DEBUG = False\n",
    "TARGET = 'trametinib' #'all' if not DEBUG else 'trametinib'\n",
    "LATENT_DIM = 50\n",
    "COND_CLASSES = 189 if TARGET == 'all' else 2\n",
    "\n",
    "# from pathlib import Path\n",
    "# outdir_path = '/Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/full_ae'\n",
    "# outdir = Path(outdir_path)\n",
    "\n",
    "# # %%\n",
    "# outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# cachedir = outdir / \"cache\"\n",
    "# cachedir.mkdir(exist_ok=True)\n",
    "\n",
    "# %%\n",
    "\n",
    "import torch\n",
    "import GPUtil\n",
    "import os\n",
    "\n",
    "def get_free_gpu():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "    # Set environment variables for which GPUs to use.\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    chosen_gpu = ''.join(\n",
    "        [str(x) for x in GPUtil.getAvailable(order='memory')])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = chosen_gpu\n",
    "    print(f\"Using GPUs: {chosen_gpu}\")\n",
    "    return chosen_gpu\n",
    "\n",
    "# status = cachedir / \"status\"\n",
    "# status.write_text(\"running\")\n",
    "\n",
    "device = f'cuda:{get_free_gpu()}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "else:\n",
    "    n_iters = 250000\n",
    "    batch_size = 256\n",
    "\n",
    "yaml_str = f\"\"\"\n",
    "model:\n",
    "   name: scgen\n",
    "   beta: 0.0\n",
    "   dropout: 0.0\n",
    "   hidden_units: [512, 512]\n",
    "   latent_dim: 50\n",
    "\n",
    "optim:\n",
    "   lr: 0.001\n",
    "   optimizer: Adam\n",
    "   weight_decay: 1.0e-05\n",
    "\n",
    "scheduler:\n",
    "   gamma: 0.5\n",
    "   step_size: 100000\n",
    "\n",
    "training:\n",
    "  cache_freq: 10000\n",
    "  eval_freq: 2500\n",
    "  logs_freq: 250\n",
    "  n_iters: {n_iters}\n",
    "\n",
    "data:\n",
    "  type: cell\n",
    "  source: control\n",
    "  condition: drug\n",
    "  path: /Mounts/rbg-storage1/users/johnyang/cellot/datasets/scrna-sciplex3/hvg.h5ad\n",
    "  target: {TARGET}\n",
    "\n",
    "datasplit:\n",
    "    groupby: drug   \n",
    "    name: train_test\n",
    "    test_size: 0.2\n",
    "    random_state: 0\n",
    "\n",
    "dataloader:\n",
    "    batch_size: {batch_size}\n",
    "    shuffle: true\n",
    "\"\"\"\n",
    "\n",
    "config = omegaconf.OmegaConf.create(yaml_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "import cellot.models\n",
    "from cellot.data.cell import load_cell_data\n",
    "\n",
    "def load_data(config, **kwargs):\n",
    "    data_type = config.get(\"data.type\", \"cell\")\n",
    "    if data_type in [\"cell\", \"cell-merged\", \"tupro-cohort\"]:\n",
    "        loadfxn = load_cell_data\n",
    "\n",
    "    elif data_type == \"toy\":\n",
    "        loadfxn = load_toy_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return loadfxn(config, **kwargs)\n",
    "\n",
    "\n",
    "def load_model(config, device, restore=None, **kwargs):\n",
    "    # def load_autoencoder_model(config, restore=None, **kwargs):\n",
    "    \n",
    "    def load_optimizer(config, params):\n",
    "        kwargs = dict(config.get(\"optim\", {}))\n",
    "        assert kwargs.pop(\"optimizer\", \"Adam\") == \"Adam\"\n",
    "        optim = torch.optim.Adam(params, **kwargs)\n",
    "        return optim\n",
    "\n",
    "\n",
    "    def load_networks(config, **kwargs):\n",
    "        kwargs = kwargs.copy()\n",
    "        kwargs.update(dict(config.get(\"model\", {})))\n",
    "        name = kwargs.pop(\"name\")\n",
    "\n",
    "        if name == \"scgen\":\n",
    "            model = AutoEncoder\n",
    "\n",
    "        # elif name == \"cae\":\n",
    "        #     model = ConditionalAutoEncoder\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        return model(**kwargs)\n",
    "    \n",
    "    model = load_networks(config, **kwargs)\n",
    "    optim = load_optimizer(config, model.parameters())\n",
    "\n",
    "    if restore is not None and Path(restore).exists():\n",
    "        print('Loading model from checkpoint')\n",
    "        ckpt = torch.load(restore, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optim.load_state_dict(ckpt[\"optim_state\"])\n",
    "        if config.model.name == \"scgen\" and \"code_means\" in ckpt:\n",
    "            model.code_means = ckpt[\"code_means\"]\n",
    "            \n",
    "    # logger.info(f'Model on device {next(model.parameters()).device}')\n",
    "\n",
    "    return model, optim\n",
    "\n",
    "def load(config, device, restore=None, include_model_kwargs=False, **kwargs):\n",
    "\n",
    "    loader, model_kwargs = load_data(config, include_model_kwargs=True, **kwargs)\n",
    "\n",
    "    model, opt = load_model(config, device, restore=restore, **model_kwargs)\n",
    "\n",
    "    return model, opt, loader\n",
    "# %% [markdown]\n",
    "# ### Training\n",
    "\n",
    "# %%\n",
    "restore_path = '/Mounts/rbg-storage1/users/johnyang/cellot/saved_weights/ae/ae.pt'\n",
    "ae = load_model(config, 'cuda', restore=restore_path, input_dim=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 21:14:21,914 Loaded cell data with TARGET trametinib and OBS SHAPE (20842, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from cellot.data.cell import *\n",
    "\n",
    "def load_cell_data(\n",
    "    config,\n",
    "    data=None,\n",
    "    split_on=None,\n",
    "    return_as=\"loader\",\n",
    "    include_model_kwargs=False,\n",
    "    pair_batch_on=None,\n",
    "    **kwargs\n",
    "):\n",
    "\n",
    "    if isinstance(return_as, str):\n",
    "        return_as = [return_as]\n",
    "\n",
    "    assert set(return_as).issubset({\"anndata\", \"dataset\", \"loader\"})\n",
    "    config.data.condition = config.data.get(\"condition\", \"drug\")\n",
    "    condition = config.data.condition\n",
    "    \n",
    "    data = read_single_anndata(config, **kwargs)\n",
    "\n",
    "    # if \"ae_emb\" in config.data:\n",
    "        # load path to autoencoder\n",
    "        # assert config.get(\"model.name\", \"cellot\") == \"cellot\"\n",
    "    # path_ae = Path(outdir_path)\n",
    "    # model_kwargs = {\"input_dim\": data.n_vars}\n",
    "    # config_ae = load_config('/Mounts/rbg-storage1/users/johnyang/cellot/configs/models/scgen.yaml')\n",
    "    # ae_model, _ = load_autoencoder_model(\n",
    "    #     config_ae, restore=path_ae / \"cache/model.pt\", **model_kwargs\n",
    "    # )\n",
    "\n",
    "    inputs = torch.Tensor(\n",
    "        data.X if not sparse.issparse(data.X) else data.X.todense()\n",
    "    )\n",
    "\n",
    "    # genes = data.var_names.to_list()\n",
    "    # data = anndata.AnnData(\n",
    "    #     ae[0].eval().encode(inputs).detach().numpy(),\n",
    "    #     obs=data.obs.copy(),\n",
    "    #     uns=data.uns.copy(),\n",
    "    # )\n",
    "    # data.uns[\"genes\"] = genes\n",
    "\n",
    "    # cast to dense and check for nans\n",
    "    if sparse.issparse(data.X):\n",
    "        data.X = data.X.todense()\n",
    "    assert not np.isnan(data.X).any()\n",
    "\n",
    "    dataset_args = dict()\n",
    "    model_kwargs = {}\n",
    "\n",
    "    model_kwargs[\"input_dim\"] = data.n_vars\n",
    "\n",
    "    # if config.get(\"model.name\") == \"cae\":\n",
    "    # condition_labels = sorted(data.obs[condition].cat.categories)\n",
    "    # model_kwargs[\"conditions\"] = condition_labels\n",
    "    # dataset_args[\"obs\"] = condition\n",
    "    # dataset_args[\"categories\"] = condition_labels\n",
    "\n",
    "    if \"training\" in config:\n",
    "        pair_batch_on = config.training.get(\"pair_batch_on\", pair_batch_on)\n",
    "\n",
    "    # if split_on is None:\n",
    "        # if config.model.name == \"cellot\":\n",
    "            # datasets & dataloaders accessed as loader.train.source\n",
    "    split_on = [\"split\", \"transport\"]\n",
    "    if pair_batch_on is not None:\n",
    "        split_on.append(pair_batch_on)\n",
    "\n",
    "        # elif (config.model.name == \"scgen\" or config.model.name == \"cae\"\n",
    "        #       or config.model.name == \"popalign\"):\n",
    "        #     split_on = [\"split\"]\n",
    "\n",
    "        # else:\n",
    "        #     raise ValueError\n",
    "\n",
    "    if isinstance(split_on, str):\n",
    "        split_on = [split_on]\n",
    "\n",
    "    for key in split_on:\n",
    "        assert key in data.obs.columns\n",
    "\n",
    "    if len(split_on) > 0:\n",
    "        splits = {\n",
    "            (key if isinstance(key, str) else \".\".join(key)): data[index]\n",
    "            for key, index in data.obs[split_on].groupby(split_on).groups.items()\n",
    "        }\n",
    "\n",
    "        dataset = nest_dict(\n",
    "            {\n",
    "                key: AnnDataDataset(val.copy(), **dataset_args)\n",
    "                for key, val in splits.items()\n",
    "            },\n",
    "            as_dot_dict=True,\n",
    "        )\n",
    "    else:\n",
    "        dataset = AnnDataDataset(data.copy(), **dataset_args)\n",
    "\n",
    "    if \"loader\" in return_as:\n",
    "        kwargs = dict(config.dataloader)\n",
    "        kwargs.setdefault(\"drop_last\", True)\n",
    "        loader = cast_dataset_to_loader(dataset, **kwargs)\n",
    "\n",
    "    returns = list()\n",
    "    for key in return_as:\n",
    "        if key == \"anndata\":\n",
    "            returns.append(data)\n",
    "\n",
    "        elif key == \"dataset\":\n",
    "            returns.append(dataset)\n",
    "\n",
    "        elif key == \"loader\":\n",
    "            returns.append(loader)\n",
    "\n",
    "    if include_model_kwargs:\n",
    "        returns.append(model_kwargs)\n",
    "\n",
    "    if len(returns) == 1:\n",
    "        return returns[0]\n",
    "\n",
    "    # returns.append(data)\n",
    "\n",
    "    return tuple(returns)\n",
    "\n",
    "datasets = load_cell_data(config, return_as=\"dataset\")\n",
    "loader = cast_dataset_to_loader(datasets, batch_size=config.dataloader.batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellot.data.utils import cast_loader_to_iterator\n",
    "iterator = cast_loader_to_iterator(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iterator.train.source).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lr_scheduler(optim, config):\n",
    "    if \"scheduler\" not in config:\n",
    "        return None\n",
    "\n",
    "    return torch.optim.lr_scheduler.StepLR(optim, **config.scheduler)\n",
    "\n",
    "\n",
    "def check_loss(*args):\n",
    "    for arg in args:\n",
    "        if torch.isnan(arg):\n",
    "            raise ValueError\n",
    "\n",
    "\n",
    "def load_item_from_save(path, key, default):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return default\n",
    "\n",
    "    ckpt = torch.load(path)\n",
    "    if key not in ckpt:\n",
    "        logging.warn(f\"'{key}' not found in ckpt: {str(path)}\")\n",
    "        return default\n",
    "\n",
    "    return ckpt[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_cellot(outdir, config):\n",
    "outdir_string = '/Mounts/rbg-storage1/users/johnyang/cellot/results/sciplex3/cellot_our_ae'\n",
    "cellot_outdir = Path(outdir_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_config_str = f\"\"\"\n",
    "model:\n",
    "  name: cellot\n",
    "  hidden_units: [64, 64, 64, 64]\n",
    "  latent_dim: 50\n",
    "  softplus_W_kernels: false\n",
    "\n",
    "  g:\n",
    "    fnorm_penalty: 1\n",
    "\n",
    "  kernel_init_fxn:\n",
    "    b: 0.1\n",
    "    name: uniform\n",
    "\n",
    "optim:\n",
    "  optimizer: Adam\n",
    "  lr: 0.0001\n",
    "  beta1: 0.5\n",
    "  beta2: 0.9\n",
    "  weight_decay: 0\n",
    "\n",
    "training:\n",
    "  n_iters: 100000\n",
    "  n_inner_iters: 10\n",
    "  cache_freq: 1000\n",
    "  eval_freq: 250\n",
    "  logs_freq: 50\n",
    "\"\"\"\n",
    "ot_config = omegaconf.OmegaConf.create(ot_config_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def state_dict(f, g, opts, **kwargs):\n",
    "    state = {\n",
    "        \"g_state\": g.state_dict(),\n",
    "        \"f_state\": f.state_dict(),\n",
    "        \"opt_g_state\": opts.g.state_dict(),\n",
    "        \"opt_f_state\": opts.f.state_dict(),\n",
    "    }\n",
    "    state.update(kwargs)\n",
    "\n",
    "    return state\n",
    "\n",
    "logger = Logger(cellot_outdir / \"cache/scalars\")\n",
    "cachedir = cellot_outdir / \"cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from collections import namedtuple\n",
    "from cellot.networks.icnns import ICNN\n",
    "\n",
    "from absl import flags\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "FGPair = namedtuple(\"FGPair\", \"f g\")\n",
    "\n",
    "def load_networks(config, **kwargs):\n",
    "    def unpack_kernel_init_fxn(name=\"uniform\", **kwargs):\n",
    "        if name == \"normal\":\n",
    "\n",
    "            def init(*args):\n",
    "                return torch.nn.init.normal_(*args, **kwargs)\n",
    "\n",
    "        elif name == \"uniform\":\n",
    "\n",
    "            def init(*args):\n",
    "                return torch.nn.init.uniform_(*args, **kwargs)\n",
    "\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        return init\n",
    "\n",
    "    kwargs.setdefault(\"hidden_units\", [64] * 4)\n",
    "    kwargs.update(dict(config.get(\"model\", {})))\n",
    "\n",
    "    # eg parameters specific to g are stored in config.model.g\n",
    "    kwargs.pop(\"name\")\n",
    "    if \"latent_dim\" in kwargs:\n",
    "        kwargs.pop(\"latent_dim\")\n",
    "    fupd = kwargs.pop(\"f\", {})\n",
    "    gupd = kwargs.pop(\"g\", {})\n",
    "\n",
    "    fkwargs = kwargs.copy()\n",
    "    fkwargs.update(fupd)\n",
    "    fkwargs[\"kernel_init_fxn\"] = unpack_kernel_init_fxn(\n",
    "        **fkwargs.pop(\"kernel_init_fxn\")\n",
    "    )\n",
    "\n",
    "    gkwargs = kwargs.copy()\n",
    "    gkwargs.update(gupd)\n",
    "    gkwargs[\"kernel_init_fxn\"] = unpack_kernel_init_fxn(\n",
    "        **gkwargs.pop(\"kernel_init_fxn\")\n",
    "    )\n",
    "\n",
    "    f = ICNN(**fkwargs)\n",
    "    g = ICNN(**gkwargs)\n",
    "\n",
    "    if \"verbose\" in FLAGS and FLAGS.verbose:\n",
    "        print(g)\n",
    "        print(kwargs)\n",
    "\n",
    "    return f, g\n",
    "\n",
    "\n",
    "def load_opts(config, f, g):\n",
    "    kwargs = dict(config.get(\"optim\", {}))\n",
    "    assert kwargs.pop(\"optimizer\", \"Adam\") == \"Adam\"\n",
    "\n",
    "    fupd = kwargs.pop(\"f\", {})\n",
    "    gupd = kwargs.pop(\"g\", {})\n",
    "\n",
    "    fkwargs = kwargs.copy()\n",
    "    fkwargs.update(fupd)\n",
    "    fkwargs[\"betas\"] = (fkwargs.pop(\"beta1\", 0.9), fkwargs.pop(\"beta2\", 0.999))\n",
    "\n",
    "    gkwargs = kwargs.copy()\n",
    "    gkwargs.update(gupd)\n",
    "    gkwargs[\"betas\"] = (gkwargs.pop(\"beta1\", 0.9), gkwargs.pop(\"beta2\", 0.999))\n",
    "\n",
    "    opts = FGPair(\n",
    "        f=torch.optim.Adam(f.parameters(), **fkwargs),\n",
    "        g=torch.optim.Adam(g.parameters(), **gkwargs),\n",
    "    )\n",
    "\n",
    "    return opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cellot_model(config, restore=None, **kwargs):\n",
    "    f, g = load_networks(config, **kwargs)\n",
    "    f = f.to(device)\n",
    "    g = g.to(device)\n",
    "    \n",
    "    opts = load_opts(config, f, g)\n",
    "\n",
    "    if restore is not None and Path(restore).exists():\n",
    "        ckpt = torch.load(restore, map_location='cpu')\n",
    "        f.load_state_dict(ckpt[\"f_state\"])\n",
    "        opts.f.load_state_dict(ckpt[\"opt_f_state\"])\n",
    "\n",
    "        g.load_state_dict(ckpt[\"g_state\"])\n",
    "        opts.g.load_state_dict(ckpt[\"opt_g_state\"])\n",
    "\n",
    "    return (f, g), opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(f, g), opts = load_cellot_model(config=ot_config, restore=cachedir / 'last.pt', input_dim=LATENT_DIM)\n",
    "f, g = f.to(device), g.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3513"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.test.source.dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellot.losses.mmd import mmd_distance\n",
    "import numpy as np\n",
    "\n",
    "def compute_mmd_loss(lhs, rhs, gammas):\n",
    "    return np.mean([mmd_distance(lhs, rhs, g) for g in gammas])\n",
    "\n",
    "gammas = np.logspace(1, -3, num=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder_net): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=50, bias=True)\n",
       "  )\n",
       "  (decoder_net): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (mse): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = ae[0].to(device)\n",
    "autoencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_train_target = iterator.train.target\n",
    "iterator_train_source = iterator.train.source\n",
    "iterator_test_target = iterator.test.target\n",
    "iterator_test_source = iterator.test.source\n",
    "\n",
    "def DEV_evaluate(target, source):\n",
    "    # with torch.inference_mode():\n",
    "    # source.requires_grad_(True) \n",
    "    source_latent = autoencoder.encode(source)\n",
    "    source_latent.requires_grad_(True)\n",
    "    target_latent = autoencoder.encode(target)\n",
    "    transport_latent = g.transport(source_latent).to(device)\n",
    "    with torch.inference_mode():\n",
    "        transport_genes = autoencoder.decode(transport_latent)\n",
    "        transport_latent = transport_latent.detach()\n",
    "    # with torch.no_grad():\n",
    "        gl = compute_loss_g(f, g, source_latent, transport_latent).mean()\n",
    "        fl = compute_loss_f(f, g, source_latent, target_latent, transport_latent).mean()\n",
    "        dist = compute_w2_distance(f, g, source_latent, target_latent, transport_latent)\n",
    "        mmd = losses.compute_scalar_mmd(\n",
    "            target_latent.detach().cpu().numpy(), transport_latent.detach().cpu().numpy()\n",
    "        )\n",
    "        mmd_2 = compute_mmd_loss(target_latent.detach().cpu().numpy(), transport_latent.detach().cpu().numpy(), gammas)\n",
    "        \n",
    "        \n",
    "        return mmd, mmd_2, transport_genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trametinib'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 20:52:56,292 Loaded cell data with TARGET trametinib and OBS SHAPE (20842, 16)\n"
     ]
    }
   ],
   "source": [
    "data = read_single_anndata(config, path=None)\n",
    "key = f'marker_genes-{config.data.condition}-rank'\n",
    "sel_mg = (\n",
    "        data.varm[key][config.data.target]\n",
    "        .sort_values()\n",
    "        .index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellot.data.cell import read_single_anndata\n",
    "def load_markers(config, n_genes=50):\n",
    "    data = read_single_anndata(config, path=None)\n",
    "    key = f'marker_genes-{config.data.condition}-rank'\n",
    "\n",
    "    # rebuttal preprocessing stored marker genes using\n",
    "    # a generic marker_genes-condition-rank key\n",
    "    # instead of e.g. marker_genes-drug-rank\n",
    "    # let's just patch that here:\n",
    "    if key not in data.varm:\n",
    "        key = 'marker_genes-condition-rank'\n",
    "        print('WARNING: using generic condition marker genes')\n",
    "\n",
    "    sel_mg = (\n",
    "        data.varm[key][config.data.target]\n",
    "        .sort_values()\n",
    "        .index\n",
    "    )[:50]\n",
    "    marker_gene_indices = [i for i, gene in enumerate(data.var_names) if gene in sel_mg]\n",
    "\n",
    "    return sel_mg, marker_gene_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 20:53:49,898 Loaded cell data with TARGET trametinib and OBS SHAPE (20842, 16)\n"
     ]
    }
   ],
   "source": [
    "sel_mg, marker_gene_indices = load_markers(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENSG00000198074.9', 'ENSG00000019186.9', 'ENSG00000108846.15',\n",
       "       'ENSG00000115414.18', 'ENSG00000231185.6', 'ENSG00000112541.13',\n",
       "       'ENSG00000117983.17', 'ENSG00000145819.15', 'ENSG00000184588.17',\n",
       "       'ENSG00000165376.10', 'ENSG00000154529.14', 'ENSG00000182752.9',\n",
       "       'ENSG00000251003.7', 'ENSG00000101144.12', 'ENSG00000117724.12',\n",
       "       'ENSG00000157168.18', 'ENSG00000275395.5', 'ENSG00000185483.11',\n",
       "       'ENSG00000108405.3', 'ENSG00000089199.9', 'ENSG00000254166.2',\n",
       "       'ENSG00000215182.8', 'ENSG00000004948.13', 'ENSG00000227706.3',\n",
       "       'ENSG00000065809.13', 'ENSG00000004799.7', 'ENSG00000144847.12',\n",
       "       'ENSG00000107957.16', 'ENSG00000108602.17', 'ENSG00000059804.15',\n",
       "       'ENSG00000047648.21', 'ENSG00000076706.16', 'ENSG00000003436.15',\n",
       "       'ENSG00000229140.8', 'ENSG00000066279.17', 'ENSG00000153956.15',\n",
       "       'ENSG00000086548.8', 'ENSG00000171408.13', 'ENSG00000005108.15',\n",
       "       'ENSG00000138696.10', 'ENSG00000236213.1', 'ENSG00000038427.15',\n",
       "       'ENSG00000064042.17', 'ENSG00000130656.4', 'ENSG00000180287.16',\n",
       "       'ENSG00000204740.10', 'ENSG00000023171.16', 'ENSG00000153976.2',\n",
       "       'ENSG00000167281.18', 'ENSG00000113448.18'],\n",
       "      dtype='object', name='id')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11,\n",
       " 33,\n",
       " 34,\n",
       " 62,\n",
       " 79,\n",
       " 88,\n",
       " 94,\n",
       " 111,\n",
       " 124,\n",
       " 150,\n",
       " 157,\n",
       " 167,\n",
       " 175,\n",
       " 205,\n",
       " 229,\n",
       " 265,\n",
       " 284,\n",
       " 292,\n",
       " 293,\n",
       " 303,\n",
       " 308,\n",
       " 329,\n",
       " 337,\n",
       " 382,\n",
       " 445,\n",
       " 457,\n",
       " 464,\n",
       " 474,\n",
       " 497,\n",
       " 499,\n",
       " 556,\n",
       " 563,\n",
       " 565,\n",
       " 576,\n",
       " 577,\n",
       " 598,\n",
       " 657,\n",
       " 664,\n",
       " 682,\n",
       " 707,\n",
       " 713,\n",
       " 750,\n",
       " 795,\n",
       " 811,\n",
       " 823,\n",
       " 846,\n",
       " 883,\n",
       " 893,\n",
       " 898,\n",
       " 938]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marker_gene_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X = datasets.test.target.adata.X\n",
    "sel_target = target_X[:, marker_gene_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:01<00:00,  1.62it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mmds = []\n",
    "mmd_2s = []\n",
    "gene_mmds = []\n",
    "batched_gene_mmds = []\n",
    "for _ in tqdm(range(100)):\n",
    "    target = next(iterator_test_target).to(device)\n",
    "    source = next(iterator_test_source).to(device)\n",
    "    # print(target.shape, source.shape)\n",
    "    mmd, mmd_2, transport_genes = DEV_evaluate(target, source)\n",
    "    mmds.append(mmd)\n",
    "    mmd_2s.append(mmd_2)\n",
    "    transport_genes = transport_genes.detach().cpu().numpy()[:, marker_gene_indices]\n",
    "    source_genes = source.detach().cpu().numpy()[:, marker_gene_indices]\n",
    "    target_genes = target_X[:, marker_gene_indices]\n",
    "    \n",
    "    gene_mmd = compute_mmd_loss(target_genes, transport_genes, gammas)\n",
    "    batch_gene_mmd = compute_mmd_loss(target[:, marker_gene_indices].detach().cpu().numpy(), transport_genes, gammas)\n",
    "    gene_mmds.append(gene_mmd)\n",
    "    batched_gene_mmds.append(batch_gene_mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01001216194451563"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010999672540181835"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mmd_2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020130562480702063"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(gene_mmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021846194356679914"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(batched_gene_mmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009932666073094709"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007746106900313521"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]2023-07-06 11:44:46,870 Note: detected 80 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2023-07-06 11:44:46,873 Note: NumExpr detected 80 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-07-06 11:44:46,874 NumExpr defaulting to 8 threads.\n",
      "100%|██████████| 100000/100000 [3:29:58<00:00,  7.94it/s]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (f, g), opts, loader = load(ot_config, restore=cachedir / \"last.pt\")\n",
    "# iterator = cast_loader_to_iterator(loader, cycle_all=True)\n",
    "\n",
    "n_iters = ot_config.training.n_iters\n",
    "# step = load_item_from_save(cachedir / \"last.pt\", \"step\", 0)\n",
    "\n",
    "# minmmd = load_item_from_save(cachedir / \"model.pt\", \"minmmd\", np.inf)\n",
    "# mmd = minmmd\n",
    "step = 0\n",
    "minmmd = np.inf\n",
    "mmd = minmmd\n",
    "\n",
    "def evaluate():\n",
    "    target = next(iterator_test_target).to(device)\n",
    "    source = next(iterator_test_source).to(device)\n",
    "    source.requires_grad_(True)\n",
    "    transport = g.transport(source).to(device)\n",
    "\n",
    "    transport = transport.detach()\n",
    "    with torch.no_grad():\n",
    "        gl = compute_loss_g(f, g, source, transport).mean()\n",
    "        fl = compute_loss_f(f, g, source, target, transport).mean()\n",
    "        dist = compute_w2_distance(f, g, source, target, transport)\n",
    "        mmd = losses.compute_scalar_mmd(\n",
    "            target.detach().cpu().numpy(), transport.detach().cpu().numpy()\n",
    "        )\n",
    "\n",
    "    # log to logger object\n",
    "    logger.log(\n",
    "        \"eval\",\n",
    "        gloss=gl.item(),\n",
    "        floss=fl.item(),\n",
    "        jloss=dist.item(),\n",
    "        mmd=mmd,\n",
    "        step=step,\n",
    "    )\n",
    "    check_loss(gl, gl, dist)\n",
    "\n",
    "    return mmd\n",
    "\n",
    "if 'pair_batch_on' in ot_config.training:\n",
    "    keys = list(iterator.train.target.keys())\n",
    "    test_keys = list(iterator.test.target.keys())\n",
    "else:\n",
    "    keys = None\n",
    "\n",
    "ticker = trange(step, n_iters, initial=step, total=n_iters)\n",
    "for step in ticker:\n",
    "    if 'pair_batch_on' in ot_config.training:\n",
    "        assert keys is not None\n",
    "        key = random.choice(keys)\n",
    "        iterator_train_target = iterator.train.target[key]\n",
    "        iterator_train_source = iterator.train.source[key]\n",
    "        try:\n",
    "            iterator_test_target = iterator.test.target[key]\n",
    "            iterator_test_source = iterator.test.source[key]\n",
    "        # in the iid mode of the ood setting,\n",
    "        # train and test keys are not necessarily the same ...\n",
    "        except KeyError:\n",
    "            test_key = random.choice(test_keys)\n",
    "            iterator_test_target = iterator.test.target[test_key]\n",
    "            iterator_test_source = iterator.test.source[test_key]\n",
    "\n",
    "    else:\n",
    "        iterator_train_target = iterator.train.target\n",
    "        iterator_train_source = iterator.train.source\n",
    "        iterator_test_target = iterator.test.target\n",
    "        iterator_test_source = iterator.test.source\n",
    "        \n",
    "    target = next(iterator_train_target).to(device)\n",
    "    \n",
    "    for _ in range(ot_config.training.n_inner_iters):\n",
    "        source = next(iterator_train_source).requires_grad_(True).to(device)\n",
    "\n",
    "        opts.g.zero_grad()\n",
    "        gl = compute_loss_g(f, g, source).mean()\n",
    "        if not g.softplus_W_kernels and g.fnorm_penalty > 0:\n",
    "            gl = gl + g.penalize_w()\n",
    "\n",
    "        gl.backward()\n",
    "        opts.g.step()\n",
    "\n",
    "    source = next(iterator_train_source).requires_grad_(True).to(device)\n",
    "\n",
    "    opts.f.zero_grad()\n",
    "    fl = compute_loss_f(f, g, source, target).mean()\n",
    "    fl.backward()\n",
    "    opts.f.step()\n",
    "    check_loss(gl, fl)\n",
    "    f.clamp_w()\n",
    "\n",
    "    if step % ot_config.training.logs_freq == 0:\n",
    "        # log to logger object\n",
    "        logger.log(\"train\", gloss=gl.item(), floss=fl.item(), step=step)\n",
    "\n",
    "    if step % ot_config.training.eval_freq == 0:\n",
    "        mmd = evaluate()\n",
    "        if mmd < minmmd:\n",
    "            minmmd = mmd\n",
    "            torch.save(\n",
    "                state_dict(f, g, opts, step=step, minmmd=minmmd),\n",
    "                cachedir / \"model.pt\",\n",
    "            )\n",
    "\n",
    "    if step % ot_config.training.cache_freq == 0:\n",
    "        torch.save(state_dict(f, g, opts, step=step), cachedir / \"last.pt\")\n",
    "\n",
    "        logger.flush()\n",
    "\n",
    "torch.save(state_dict(f, g, opts, step=step), cachedir / \"last.pt\")\n",
    "\n",
    "logger.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = '/Mounts/rbg-storage1/users/johnyang/cellot/saved_weights/ae/ae.pt'\n",
    "# torch.save({\n",
    "#     'model_state': ae[0].state_dict(),\n",
    "#     'optim_state': ae[1].state_dict(),\n",
    "# }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
